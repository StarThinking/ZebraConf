[msx] before_class
2020-04-02 05:08:50,949 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=9
Formatting using clusterid: testClusterID
2020-04-02 05:08:51,751 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:08:51,766 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:08:51,768 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:08:51,769 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:08:51,781 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:08:51,790 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:08:51,791 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:08:51,791 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:08:51,838 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:51,843 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:08:51,844 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:08:51,844 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:08:51,850 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:08:51,851 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:08:51
2020-04-02 05:08:51,854 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:08:51,856 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:51,858 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:08:51,859 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:08:51,892 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:08:51,902 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:08:51,902 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:08:51,903 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:08:51,903 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:08:51,903 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:08:51,903 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:08:51,904 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:08:51,904 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 0
2020-04-02 05:08:51,904 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:08:51,904 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:08:51,905 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:08:51,940 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:08:51,960 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:08:51,960 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:51,961 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:08:51,961 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:08:51,967 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:08:51,968 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:08:51,968 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:08:51,968 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:08:51,975 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:08:51,979 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:08:51,986 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:08:51,986 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:51,987 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:08:51,987 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:08:51,997 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:08:51,997 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:08:51,998 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:08:52,003 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:08:52,003 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:08:52,006 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:08:52,007 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:52,007 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:08:52,008 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:08:52,047 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:52,063 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:08:52,067 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:08:52,080 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:08:52,080 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:08:52,239 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:08:52,247 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:08:52,272 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:08:52,277 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:08:52,466 [main] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:08:52,530 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:08:52,998 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:08:52,999 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:08:53,006 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:08:53,043 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:08:53,081 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@54e1c68b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:53,103 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:08:53,110 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:53,129 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3539ms
2020-04-02 05:08:53,259 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:53,267 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:08:53,268 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:53,280 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:53,283 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:08:53,283 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:53,283 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:53,325 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:08:53,326 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:08:53,337 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37396
2020-04-02 05:08:53,339 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:53,430 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7d322cad{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:53,431 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4f49f6af{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:53,478 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@797b0699{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:08:53,487 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4f704591{HTTP/1.1,[http/1.1]}{localhost:37396}
2020-04-02 05:08:53,488 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3898ms
2020-04-02 05:08:53,523 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:08:53,524 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:08:53,524 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:08:53,524 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:08:53,524 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:08:53,524 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:08:53,525 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:08:53,525 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:08:53,525 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:53,526 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:08:53,526 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:08:53,527 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:08:53,527 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:08:53
2020-04-02 05:08:53,527 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:08:53,527 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:53,528 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:08:53,528 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:08:53,540 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:08:53,541 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:08:53,541 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:08:53,542 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:08:53,542 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:08:53,542 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:08:53,542 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:08:53,542 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:08:53,542 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 0
2020-04-02 05:08:53,543 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:08:53,543 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:08:53,543 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:08:53,543 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:08:53,543 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:53,544 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:08:53,544 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:08:53,558 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:08:53,559 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:08:53,559 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:08:53,559 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:08:53,560 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:08:53,560 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:08:53,560 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:08:53,560 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:53,561 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:08:53,561 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:08:53,562 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:08:53,562 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:08:53,562 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:08:53,563 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:08:53,563 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:08:53,563 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:08:53,563 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:53,564 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:08:53,564 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:08:53,578 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:08:53,583 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:08:53,587 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:08:53,587 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:08:53,588 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:08:53,588 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:08:53,661 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:08:53,668 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:08:53,669 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:08:53,674 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:08:53,675 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:08:53,695 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:08:53,696 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 121 msecs
2020-04-02 05:08:53,900 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:08:53,911 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:53,938 [Socket Reader #1 for port 46003] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46003
2020-04-02 05:08:54,276 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:46003 to access this namenode/service.
2020-04-02 05:08:54,301 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:08:54,386 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:08:54,392 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@7e7b159b] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:08:54,434 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:08:54,442 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:08:54,442 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:08:54,442 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:08:54,446 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:08:54,447 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:08:54,447 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:08:54,447 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:08:54,447 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:08:54,447 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-04-02 05:08:54,540 [IPC Server listener on 46003] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46003: starting
2020-04-02 05:08:54,579 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:46003
2020-04-02 05:08:54,582 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:54,586 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:08:54,586 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:08:54,608 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 21 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:08:54,619 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 46003 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:54,619 [CacheReplicationMonitor(1367490423)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:08:54,654 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:08:54,748 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:08:54,789 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:08:54,801 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:54,805 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:54,810 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:54,814 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:54,821 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:54,822 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:54,828 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:54,844 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:43768
2020-04-02 05:08:54,846 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:54,847 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:54,865 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:54,867 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:54,869 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:54,869 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:54,871 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:54,872 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:54,872 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:54,872 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:54,875 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40800
2020-04-02 05:08:54,876 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:54,877 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@665df3c6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:54,878 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4044fb95{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:54,886 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@40cb698e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:54,889 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3382f8ae{HTTP/1.1,[http/1.1]}{localhost:40800}
2020-04-02 05:08:54,889 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5299ms
2020-04-02 05:08:55,324 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36712
2020-04-02 05:08:55,330 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@165b8a71] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:55,332 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:55,332 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:55,353 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:55,354 [Socket Reader #1 for port 36016] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36016
2020-04-02 05:08:55,369 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:36016
2020-04-02 05:08:55,387 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:55,392 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:55,921 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46003 starting to offer service
2020-04-02 05:08:55,931 [IPC Server listener on 36016] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36016: starting
2020-04-02 05:08:55,931 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:55,933 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 36016 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:55,934 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:08:55,936 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:08:55,936 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:08:55,952 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:55,953 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:55,953 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:55,954 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:55,972 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:55,973 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:55,974 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:55,975 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37040
2020-04-02 05:08:55,975 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:55,975 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:55,977 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:55,999 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:56,037 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:56,037 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:56,040 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:56,041 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:56,041 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:56,042 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:56,043 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 36030
2020-04-02 05:08:56,043 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:56,045 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@60fa3495{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:56,046 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@79e18e38{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:56,068 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@35fe2125{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:56,069 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@94f6bfb{HTTP/1.1,[http/1.1]}{localhost:36030}
2020-04-02 05:08:56,070 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6480ms
2020-04-02 05:08:56,252 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36945
2020-04-02 05:08:56,256 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2484f433] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:56,256 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:56,256 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:56,257 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:56,258 [Socket Reader #1 for port 44658] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44658
2020-04-02 05:08:56,286 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:44658
2020-04-02 05:08:56,291 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:56,297 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:56,302 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46003 starting to offer service
2020-04-02 05:08:56,303 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:56,303 [IPC Server listener on 44658] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44658: starting
2020-04-02 05:08:56,335 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 44658 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:56,337 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:08:56,339 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:08:56,354 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:08:56,400 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:56,400 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:56,401 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:56,401 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:56,406 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:56,406 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:56,407 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:56,408 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:38956
2020-04-02 05:08:56,408 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:56,408 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:56,410 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:56,412 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:56,414 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:56,414 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:56,416 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:56,417 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:56,417 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:56,432 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:56,439 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41405
2020-04-02 05:08:56,439 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:56,454 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1d9bec4d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:56,455 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@10c8f62{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:56,461 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@72ccd81a{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:56,462 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6d8792db{HTTP/1.1,[http/1.1]}{localhost:41405}
2020-04-02 05:08:56,462 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6872ms
2020-04-02 05:08:56,484 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36791
2020-04-02 05:08:56,485 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@493dfb8e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:56,485 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:56,490 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:56,490 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:56,492 [Socket Reader #1 for port 36980] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36980
2020-04-02 05:08:56,528 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:36980
2020-04-02 05:08:56,541 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:56,554 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:56,555 [Thread-108] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46003 starting to offer service
2020-04-02 05:08:56,556 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:56,560 [IPC Server listener on 36980] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36980: starting
2020-04-02 05:08:56,569 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 36980 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:56,654 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:08:56,655 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:08:56,656 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:08:56,666 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:56,666 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:56,666 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:56,666 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:56,667 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:56,667 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:56,668 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:56,669 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37012
2020-04-02 05:08:56,669 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:56,669 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:56,672 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:56,674 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:56,675 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:56,676 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:56,677 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:56,678 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:56,678 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:56,679 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:56,680 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34096
2020-04-02 05:08:56,680 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:56,697 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@549621f3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:56,699 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@32232e55{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:56,733 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@192f2f27{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:56,734 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@8a589a2{HTTP/1.1,[http/1.1]}{localhost:34096}
2020-04-02 05:08:56,734 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7145ms
2020-04-02 05:08:56,860 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33158
2020-04-02 05:08:56,861 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6b5176f2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:56,861 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:56,861 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:56,861 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:56,870 [Socket Reader #1 for port 40579] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40579
2020-04-02 05:08:56,878 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40579
2020-04-02 05:08:56,883 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:56,884 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:56,885 [Thread-131] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46003 starting to offer service
2020-04-02 05:08:56,887 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:56,888 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40579 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:56,887 [IPC Server listener on 40579] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40579: starting
2020-04-02 05:08:56,946 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:08:56,948 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:08:56,952 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:08:56,953 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:56,953 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:56,953 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:56,953 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:56,958 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:56,958 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:56,959 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:56,959 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37102
2020-04-02 05:08:56,960 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:56,960 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:56,961 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:56,963 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:56,964 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:56,965 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:56,966 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:56,967 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:56,967 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:56,968 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:56,969 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33325
2020-04-02 05:08:56,969 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:56,971 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3bde62ff{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:56,972 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2baa8d82{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:56,995 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@66971f6b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:56,996 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@50687efb{HTTP/1.1,[http/1.1]}{localhost:33325}
2020-04-02 05:08:57,002 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7412ms
2020-04-02 05:08:57,034 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40852
2020-04-02 05:08:57,038 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:57,038 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@142eef62] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:57,038 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:57,041 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:57,049 [Socket Reader #1 for port 33146] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33146
2020-04-02 05:08:57,067 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:33146
2020-04-02 05:08:57,079 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:57,088 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:57,133 [Thread-131] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46003
2020-04-02 05:08:57,135 [Thread-131] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:57,138 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46003
2020-04-02 05:08:57,138 [Thread-154] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46003 starting to offer service
2020-04-02 05:08:57,138 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46003
2020-04-02 05:08:57,154 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 33146 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:57,149 [Thread-108] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46003
2020-04-02 05:08:57,148 [IPC Server listener on 33146] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33146: starting
2020-04-02 05:08:57,148 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:57,145 [Thread-131] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:08:57,139 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:57,156 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:08:57,156 [Thread-131] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 873357056. Formatting...
2020-04-02 05:08:57,157 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:08:57,157 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 873357056. Formatting...
2020-04-02 05:08:57,157 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:08:57,158 [Thread-131] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4bb0dddd-0253-47c2-9104-bbac55c648c9 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-04-02 05:08:57,158 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b0b5649b-5a54-4991-8466-d6109f206e71 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:08:57,161 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:08:57,162 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 873357056. Formatting...
2020-04-02 05:08:57,162 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f996263e-6fdd-494a-a59c-a647b7eb4013 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:08:57,163 [Thread-131] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:08:57,164 [Thread-131] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 873357056. Formatting...
2020-04-02 05:08:57,164 [Thread-131] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c7a90c92-7250-4a78-af04-fec73d32d73d for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-04-02 05:08:57,174 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:08:57,176 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:57,177 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:57,177 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:57,177 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:57,178 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:57,178 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:57,178 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:57,179 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:36142
2020-04-02 05:08:57,179 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:57,179 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:57,181 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:57,183 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:57,184 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:57,184 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:57,189 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:57,190 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:57,190 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:57,191 [Thread-83] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:08:57,191 [Thread-108] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:57,192 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 873357056. Formatting...
2020-04-02 05:08:57,193 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bf5d6cb7-14ea-424c-9049-88419e444644 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:08:57,193 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:57,194 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:57,199 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41150
2020-04-02 05:08:57,199 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,199 [Thread-83] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:08:57,199 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:57,199 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 873357056. Formatting...
2020-04-02 05:08:57,199 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,200 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-eb910106-c911-43eb-bb41-fcf6ef4fc559 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:08:57,200 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-546423474-172.17.0.14-1585804132033 is not formatted. Formatting ...
2020-04-02 05:08:57,202 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@64712be{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:57,203 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@30ed9c6c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:57,204 [Thread-131] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,204 [Thread-131] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,205 [Thread-131] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-546423474-172.17.0.14-1585804132033 is not formatted. Formatting ...
2020-04-02 05:08:57,205 [Thread-131] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-546423474-172.17.0.14-1585804132033 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-546423474-172.17.0.14-1585804132033/current
2020-04-02 05:08:57,206 [Thread-108] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:08:57,207 [Thread-108] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 873357056. Formatting...
2020-04-02 05:08:57,207 [Thread-108] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-47cc88ad-9f2a-471e-a976-22e1ae47f498 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:08:57,207 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1eba372c{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:57,208 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@21ec5d87{HTTP/1.1,[http/1.1]}{localhost:41150}
2020-04-02 05:08:57,208 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7618ms
2020-04-02 05:08:57,211 [Thread-108] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:08:57,212 [Thread-108] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 873357056. Formatting...
2020-04-02 05:08:57,212 [Thread-154] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46003
2020-04-02 05:08:57,212 [Thread-108] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c34961ca-a210-4cb0-a394-c5877e623d7e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:08:57,213 [Thread-154] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:57,215 [Thread-154] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:08:57,215 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,215 [Thread-83] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,215 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-546423474-172.17.0.14-1585804132033 is not formatted. Formatting ...
2020-04-02 05:08:57,215 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-546423474-172.17.0.14-1585804132033 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-546423474-172.17.0.14-1585804132033/current
2020-04-02 05:08:57,215 [Thread-154] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 873357056. Formatting...
2020-04-02 05:08:57,216 [Thread-154] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1a37025d-77bf-41dd-8612-1ed465e6299f for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-04-02 05:08:57,223 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-546423474-172.17.0.14-1585804132033 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-546423474-172.17.0.14-1585804132033/current
2020-04-02 05:08:57,232 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34497
2020-04-02 05:08:57,232 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@552518c3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:57,232 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:57,233 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:57,233 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:57,234 [Socket Reader #1 for port 32823] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 32823
2020-04-02 05:08:57,250 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,251 [Thread-108] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,251 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-546423474-172.17.0.14-1585804132033 is not formatted. Formatting ...
2020-04-02 05:08:57,251 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-546423474-172.17.0.14-1585804132033 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-546423474-172.17.0.14-1585804132033/current
2020-04-02 05:08:57,251 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,251 [Thread-83] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,252 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-546423474-172.17.0.14-1585804132033 is not formatted. Formatting ...
2020-04-02 05:08:57,252 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-546423474-172.17.0.14-1585804132033 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-546423474-172.17.0.14-1585804132033/current
2020-04-02 05:08:57,257 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:32823
2020-04-02 05:08:57,259 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=873357056;bpid=BP-546423474-172.17.0.14-1585804132033;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=873357056;c=1585804132033;bpid=BP-546423474-172.17.0.14-1585804132033;dnuuid=null
2020-04-02 05:08:57,261 [Thread-154] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:08:57,261 [Thread-154] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 873357056. Formatting...
2020-04-02 05:08:57,261 [Thread-154] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c43df3d0-ea14-4543-96de-b93a0d908fba for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-04-02 05:08:57,262 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 6de4f9c9-79b0-4647-9414-f876428e3175
2020-04-02 05:08:57,269 [Thread-131] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,269 [Thread-131] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,270 [Thread-131] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-546423474-172.17.0.14-1585804132033 is not formatted. Formatting ...
2020-04-02 05:08:57,270 [Thread-131] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-546423474-172.17.0.14-1585804132033 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-546423474-172.17.0.14-1585804132033/current
2020-04-02 05:08:57,275 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:57,276 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:57,277 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,277 [Thread-131] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=873357056;bpid=BP-546423474-172.17.0.14-1585804132033;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=873357056;c=1585804132033;bpid=BP-546423474-172.17.0.14-1585804132033;dnuuid=null
2020-04-02 05:08:57,277 [Thread-177] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46003 starting to offer service
2020-04-02 05:08:57,279 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,279 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:57,279 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-546423474-172.17.0.14-1585804132033 is not formatted. Formatting ...
2020-04-02 05:08:57,279 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-546423474-172.17.0.14-1585804132033 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-546423474-172.17.0.14-1585804132033/current
2020-04-02 05:08:57,279 [IPC Server listener on 32823] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 32823: starting
2020-04-02 05:08:57,281 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 32823 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:57,282 [Thread-131] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 7506b242-281c-466a-9c9b-c68449a86341
2020-04-02 05:08:57,283 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=873357056;bpid=BP-546423474-172.17.0.14-1585804132033;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=873357056;c=1585804132033;bpid=BP-546423474-172.17.0.14-1585804132033;dnuuid=null
2020-04-02 05:08:57,284 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:08:57,285 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 8555c340-c479-402b-b028-7e7d1e5d93d1
2020-04-02 05:08:57,301 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:08:57,303 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:08:57,304 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,304 [Thread-154] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,305 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-546423474-172.17.0.14-1585804132033 is not formatted. Formatting ...
2020-04-02 05:08:57,305 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-546423474-172.17.0.14-1585804132033 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-546423474-172.17.0.14-1585804132033/current
2020-04-02 05:08:57,306 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,306 [Thread-108] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,306 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-546423474-172.17.0.14-1585804132033 is not formatted. Formatting ...
2020-04-02 05:08:57,306 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-546423474-172.17.0.14-1585804132033 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-546423474-172.17.0.14-1585804132033/current
2020-04-02 05:08:57,309 [Thread-108] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=873357056;bpid=BP-546423474-172.17.0.14-1585804132033;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=873357056;c=1585804132033;bpid=BP-546423474-172.17.0.14-1585804132033;dnuuid=null
2020-04-02 05:08:57,311 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:57,311 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:57,311 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:57,312 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:57,312 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:57,312 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:57,312 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:57,313 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42843
2020-04-02 05:08:57,313 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:57,314 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:57,315 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:57,316 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:57,317 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:57,317 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:57,319 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:57,320 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:57,320 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:57,334 [Thread-108] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 8e065a51-9e8f-4e5d-b97e-3d42a0cebae8
2020-04-02 05:08:57,338 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:57,339 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41844
2020-04-02 05:08:57,339 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:57,379 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6de54b40{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:57,381 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,381 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@388ffbc2{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:57,381 [Thread-154] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,382 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-546423474-172.17.0.14-1585804132033 is not formatted. Formatting ...
2020-04-02 05:08:57,382 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-546423474-172.17.0.14-1585804132033 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-546423474-172.17.0.14-1585804132033/current
2020-04-02 05:08:57,384 [Thread-154] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=873357056;bpid=BP-546423474-172.17.0.14-1585804132033;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=873357056;c=1585804132033;bpid=BP-546423474-172.17.0.14-1585804132033;dnuuid=null
2020-04-02 05:08:57,386 [Thread-154] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 655fc58e-502f-4c62-a998-55c25928e1de
2020-04-02 05:08:57,406 [Thread-177] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46003
2020-04-02 05:08:57,407 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@560cbf1a{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:57,409 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5fe8b721{HTTP/1.1,[http/1.1]}{localhost:41844}
2020-04-02 05:08:57,409 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7820ms
2020-04-02 05:08:57,412 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:08:57,431 [Thread-177] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:57,434 [Thread-177] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:08:57,434 [Thread-177] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 873357056. Formatting...
2020-04-02 05:08:57,435 [Thread-177] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6b0808c3-6154-4d68-af84-9c6406ac52f0 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-04-02 05:08:57,462 [Thread-177] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:08:57,462 [Thread-177] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 873357056. Formatting...
2020-04-02 05:08:57,463 [Thread-177] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-998237d1-de80-4cf4-b032-ef5991f68f92 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-04-02 05:08:57,465 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44561
2020-04-02 05:08:57,466 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:57,466 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:57,466 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@578524c3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:57,484 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:57,486 [Socket Reader #1 for port 45598] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45598
2020-04-02 05:08:57,489 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:45598
2020-04-02 05:08:57,505 [Thread-177] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,505 [Thread-177] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,506 [Thread-177] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-546423474-172.17.0.14-1585804132033 is not formatted. Formatting ...
2020-04-02 05:08:57,506 [Thread-177] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-546423474-172.17.0.14-1585804132033 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-546423474-172.17.0.14-1585804132033/current
2020-04-02 05:08:57,508 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:57,508 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:57,509 [Thread-200] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46003 starting to offer service
2020-04-02 05:08:57,516 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:57,516 [IPC Server listener on 45598] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45598: starting
2020-04-02 05:08:57,516 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 45598 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:57,517 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:08:57,527 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:08:57,527 [Thread-200] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46003
2020-04-02 05:08:57,528 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:08:57,534 [Thread-200] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:57,535 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:57,535 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:57,536 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:57,536 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:57,536 [Thread-200] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:08:57,536 [Thread-200] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 873357056. Formatting...
2020-04-02 05:08:57,536 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:57,536 [Thread-200] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-63829bc4-26b0-4710-ab7c-ad8fbd49701a for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-04-02 05:08:57,536 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:57,537 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:57,542 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:43884
2020-04-02 05:08:57,542 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:57,543 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:57,544 [Thread-200] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:08:57,544 [Thread-200] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 873357056. Formatting...
2020-04-02 05:08:57,544 [Thread-200] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9e221eab-2732-49d2-b93b-e289117101ee for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-04-02 05:08:57,552 [Thread-177] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,553 [Thread-177] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,553 [Thread-177] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-546423474-172.17.0.14-1585804132033 is not formatted. Formatting ...
2020-04-02 05:08:57,553 [Thread-177] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-546423474-172.17.0.14-1585804132033 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-546423474-172.17.0.14-1585804132033/current
2020-04-02 05:08:57,554 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:57,556 [Thread-177] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=873357056;bpid=BP-546423474-172.17.0.14-1585804132033;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=873357056;c=1585804132033;bpid=BP-546423474-172.17.0.14-1585804132033;dnuuid=null
2020-04-02 05:08:57,556 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:57,557 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:57,557 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:57,557 [Thread-177] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID b830a9b1-fa6b-4bea-b8f7-dff8c35c043b
2020-04-02 05:08:57,558 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:57,560 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:57,561 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:57,561 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:57,571 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 36691
2020-04-02 05:08:57,571 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:57,573 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@72c927f1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:57,594 [Thread-200] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,595 [Thread-200] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,595 [Thread-200] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-546423474-172.17.0.14-1585804132033 is not formatted. Formatting ...
2020-04-02 05:08:57,595 [Thread-200] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-546423474-172.17.0.14-1585804132033 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-546423474-172.17.0.14-1585804132033/current
2020-04-02 05:08:57,665 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3dd69f5a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:57,679 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7927bd9f{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:57,680 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@532721fd{HTTP/1.1,[http/1.1]}{localhost:36691}
2020-04-02 05:08:57,680 [main] INFO  server.Server (Server.java:doStart(419)) - Started @8090ms
2020-04-02 05:08:57,744 [Thread-200] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,745 [Thread-200] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:57,746 [Thread-200] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-546423474-172.17.0.14-1585804132033 is not formatted. Formatting ...
2020-04-02 05:08:57,746 [Thread-200] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-546423474-172.17.0.14-1585804132033 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-546423474-172.17.0.14-1585804132033/current
2020-04-02 05:08:57,756 [Thread-200] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=873357056;bpid=BP-546423474-172.17.0.14-1585804132033;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=873357056;c=1585804132033;bpid=BP-546423474-172.17.0.14-1585804132033;dnuuid=null
2020-04-02 05:08:57,767 [Thread-200] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID cf3eecb1-bd14-4122-95a1-3e277869dc39
2020-04-02 05:08:57,882 [Thread-108] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-47cc88ad-9f2a-471e-a976-22e1ae47f498
2020-04-02 05:08:57,883 [Thread-108] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:08:57,890 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-bf5d6cb7-14ea-424c-9049-88419e444644
2020-04-02 05:08:57,890 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:08:57,893 [Thread-131] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-4bb0dddd-0253-47c2-9104-bbac55c648c9
2020-04-02 05:08:57,894 [Thread-131] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:08:57,896 [Thread-131] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c7a90c92-7250-4a78-af04-fec73d32d73d
2020-04-02 05:08:57,896 [Thread-131] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:08:57,897 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-eb910106-c911-43eb-bb41-fcf6ef4fc559
2020-04-02 05:08:57,897 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:08:57,903 [Thread-108] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c34961ca-a210-4cb0-a394-c5877e623d7e
2020-04-02 05:08:57,903 [Thread-108] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:08:57,910 [Thread-200] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-63829bc4-26b0-4710-ab7c-ad8fbd49701a
2020-04-02 05:08:57,911 [Thread-200] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-04-02 05:08:57,912 [Thread-200] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-9e221eab-2732-49d2-b93b-e289117101ee
2020-04-02 05:08:57,913 [Thread-200] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-04-02 05:08:57,923 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-1a37025d-77bf-41dd-8612-1ed465e6299f
2020-04-02 05:08:57,923 [Thread-154] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-04-02 05:08:57,925 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c43df3d0-ea14-4543-96de-b93a0d908fba
2020-04-02 05:08:57,925 [Thread-154] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-04-02 05:08:57,929 [Thread-177] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-6b0808c3-6154-4d68-af84-9c6406ac52f0
2020-04-02 05:08:57,929 [Thread-177] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-04-02 05:08:57,883 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-b0b5649b-5a54-4991-8466-d6109f206e71
2020-04-02 05:08:57,943 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:08:57,944 [Thread-177] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-998237d1-de80-4cf4-b032-ef5991f68f92
2020-04-02 05:08:57,945 [Thread-177] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-04-02 05:08:57,946 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38168
2020-04-02 05:08:57,954 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:57,955 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:57,955 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:57,955 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-f996263e-6fdd-494a-a59c-a647b7eb4013
2020-04-02 05:08:57,956 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:08:57,956 [Thread-177] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:57,956 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:57,955 [Thread-154] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:57,962 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7fb9f71f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:57,959 [Thread-131] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:57,959 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:57,958 [Thread-108] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:57,958 [Thread-200] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:57,974 [Socket Reader #1 for port 34113] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34113
2020-04-02 05:08:57,985 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:34113
2020-04-02 05:08:57,981 [Thread-200] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:08:57,982 [Thread-108] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:08:58,010 [Thread-177] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:08:58,011 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:08:58,013 [Thread-131] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:08:58,014 [Thread-154] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:08:58,019 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:08:58,029 [Thread-131] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:08:58,030 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:58,030 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:58,030 [Thread-131] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:08:58,031 [Thread-131] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:08:58,045 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:58,045 [IPC Server listener on 34113] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34113: starting
2020-04-02 05:08:58,030 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:08:58,047 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:08:58,031 [Thread-108] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:08:58,050 [Thread-108] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:08:58,031 [Thread-200] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:08:58,050 [Thread-200] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:08:58,052 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 34113 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:58,053 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:08:58,055 [Thread-237] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46003 starting to offer service
2020-04-02 05:08:58,060 [Thread-177] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:08:58,060 [Thread-177] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:08:58,060 [Thread-177] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:08:58,063 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:08:58,063 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:08:58,063 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:08:58,063 [Thread-108] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:08:58,063 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:08:58,063 [Thread-200] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:08:58,065 [Thread-154] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:08:58,065 [Thread-154] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:08:58,065 [Thread-154] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:08:58,067 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:08:58,068 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:08:58,080 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:58,080 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:58,081 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:58,081 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:58,082 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:58,082 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:58,082 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:58,083 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42028
2020-04-02 05:08:58,083 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:58,083 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:58,085 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:58,090 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:58,092 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:58,093 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:58,094 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:58,095 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:58,095 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:58,095 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:58,095 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33123
2020-04-02 05:08:58,096 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:58,115 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62d363ab{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:58,116 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3aee3976{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:58,121 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7d61eccf{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:58,122 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@cc6460c{HTTP/1.1,[http/1.1]}{localhost:33123}
2020-04-02 05:08:58,123 [main] INFO  server.Server (Server.java:doStart(419)) - Started @8534ms
2020-04-02 05:08:58,148 [Thread-131] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,148 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,149 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,149 [Thread-177] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,162 [Thread-257] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:08:58,162 [Thread-255] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:08:58,163 [Thread-237] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46003
2020-04-02 05:08:58,164 [Thread-108] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,171 [Thread-200] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,172 [Thread-254] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:08:58,173 [Thread-154] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,178 [Thread-258] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:08:58,178 [Thread-256] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:08:58,182 [Thread-237] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:58,186 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:08:58,187 [Thread-237] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:08:58,187 [Thread-237] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 873357056. Formatting...
2020-04-02 05:08:58,187 [Thread-237] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c201dc3a-7099-4a0b-a0e4-6a46c18e63a7 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-04-02 05:08:58,189 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:08:58,206 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:08:58,208 [Thread-237] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:08:58,209 [Thread-237] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 873357056. Formatting...
2020-04-02 05:08:58,209 [Thread-237] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d7cf7842-e826-4d35-b95a-d9313f843cc1 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-04-02 05:08:58,230 [Thread-261] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:08:58,246 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,255 [Thread-237] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,256 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-546423474-172.17.0.14-1585804132033 is not formatted. Formatting ...
2020-04-02 05:08:58,256 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-546423474-172.17.0.14-1585804132033 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-546423474-172.17.0.14-1585804132033/current
2020-04-02 05:08:58,270 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:08:58,272 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:08:58,283 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:08:58,289 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:08:58,289 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:08:58,306 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,307 [Thread-237] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,308 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-546423474-172.17.0.14-1585804132033 is not formatted. Formatting ...
2020-04-02 05:08:58,308 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-546423474-172.17.0.14-1585804132033 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-546423474-172.17.0.14-1585804132033/current
2020-04-02 05:08:58,312 [Thread-237] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=873357056;bpid=BP-546423474-172.17.0.14-1585804132033;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=873357056;c=1585804132033;bpid=BP-546423474-172.17.0.14-1585804132033;dnuuid=null
2020-04-02 05:08:58,315 [Thread-237] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID d20ef059-92c7-4f68-a334-2502d86c073f
2020-04-02 05:08:58,387 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c201dc3a-7099-4a0b-a0e4-6a46c18e63a7
2020-04-02 05:08:58,388 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-04-02 05:08:58,392 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-d7cf7842-e826-4d35-b95a-d9313f843cc1
2020-04-02 05:08:58,392 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-04-02 05:08:58,393 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:58,394 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:08:58,441 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:08:58,441 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:08:58,486 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:08:58,486 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44984
2020-04-02 05:08:58,486 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,487 [Thread-258] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-546423474-172.17.0.14-1585804132033 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 309ms
2020-04-02 05:08:58,496 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:08:58,497 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:08:58,497 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:58,497 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:58,498 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:58,498 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@681aad3b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:58,509 [Socket Reader #1 for port 41887] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41887
2020-04-02 05:08:58,512 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:41887
2020-04-02 05:08:58,573 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:58,573 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:58,578 [Thread-292] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46003 starting to offer service
2020-04-02 05:08:58,595 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-546423474-172.17.0.14-1585804132033 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 305ms
2020-04-02 05:08:58,603 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:58,604 [IPC Server listener on 41887] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41887: starting
2020-04-02 05:08:58,664 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-546423474-172.17.0.14-1585804132033 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 394ms
2020-04-02 05:08:58,668 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-546423474-172.17.0.14-1585804132033 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 172ms
2020-04-02 05:08:58,669 [Thread-257] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-546423474-172.17.0.14-1585804132033 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 507ms
2020-04-02 05:08:58,669 [Thread-177] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-546423474-172.17.0.14-1585804132033: 515ms
2020-04-02 05:08:58,669 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-546423474-172.17.0.14-1585804132033 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 463ms
2020-04-02 05:08:58,669 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-546423474-172.17.0.14-1585804132033 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 479ms
2020-04-02 05:08:58,671 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 41887 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:58,685 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:08:58,685 [Thread-306] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-546423474-172.17.0.14-1585804132033/current/replicas doesn't exist 
2020-04-02 05:08:58,664 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-546423474-172.17.0.14-1585804132033 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 392ms
2020-04-02 05:08:58,703 [Thread-200] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-546423474-172.17.0.14-1585804132033: 532ms
2020-04-02 05:08:58,701 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-546423474-172.17.0.14-1585804132033 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 412ms
2020-04-02 05:08:58,697 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:08:58,697 [Thread-261] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-546423474-172.17.0.14-1585804132033 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 466ms
2020-04-02 05:08:58,693 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-546423474-172.17.0.14-1585804132033 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 507ms
2020-04-02 05:08:58,742 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:08:58,690 [Thread-254] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-546423474-172.17.0.14-1585804132033 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 518ms
2020-04-02 05:08:58,688 [Thread-256] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-546423474-172.17.0.14-1585804132033 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 509ms
2020-04-02 05:08:58,742 [Thread-131] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-546423474-172.17.0.14-1585804132033: 594ms
2020-04-02 05:08:58,742 [Thread-108] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-546423474-172.17.0.14-1585804132033: 578ms
2020-04-02 05:08:58,741 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-546423474-172.17.0.14-1585804132033 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 244ms
2020-04-02 05:08:58,743 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:08:58,740 [Thread-255] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-546423474-172.17.0.14-1585804132033 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 577ms
2020-04-02 05:08:58,743 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-546423474-172.17.0.14-1585804132033: 596ms
2020-04-02 05:08:58,737 [Thread-307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:08:58,744 [Thread-292] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46003
2020-04-02 05:08:58,762 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-546423474-172.17.0.14-1585804132033: 613ms
2020-04-02 05:08:58,743 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:08:58,743 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-546423474-172.17.0.14-1585804132033: 256ms
2020-04-02 05:08:58,774 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:08:58,774 [Thread-309] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-546423474-172.17.0.14-1585804132033/current/replicas doesn't exist 
2020-04-02 05:08:58,775 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:08:58,775 [Thread-315] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-546423474-172.17.0.14-1585804132033/current/replicas doesn't exist 
2020-04-02 05:08:58,774 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:08:58,771 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:08:58,775 [Thread-314] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-546423474-172.17.0.14-1585804132033/current/replicas doesn't exist 
2020-04-02 05:08:58,743 [Thread-311] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-546423474-172.17.0.14-1585804132033/current/replicas doesn't exist 
2020-04-02 05:08:58,771 [Thread-307] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-546423474-172.17.0.14-1585804132033/current/replicas doesn't exist 
2020-04-02 05:08:58,767 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:08:58,766 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-546423474-172.17.0.14-1585804132033 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 484ms
2020-04-02 05:08:58,764 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:08:58,764 [Thread-292] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:58,742 [Thread-308] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-546423474-172.17.0.14-1585804132033/current/replicas doesn't exist 
2020-04-02 05:08:58,781 [Thread-313] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-546423474-172.17.0.14-1585804132033/current/replicas doesn't exist 
2020-04-02 05:08:58,782 [Thread-307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 38ms
2020-04-02 05:08:58,782 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 8ms
2020-04-02 05:08:58,762 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:08:58,783 [Thread-312] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-546423474-172.17.0.14-1585804132033/current/replicas doesn't exist 
2020-04-02 05:08:58,742 [Thread-305] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-546423474-172.17.0.14-1585804132033/current/replicas doesn't exist 
2020-04-02 05:08:58,762 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 77ms
2020-04-02 05:08:58,784 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 1ms
2020-04-02 05:08:58,780 [Thread-310] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-546423474-172.17.0.14-1585804132033/current/replicas doesn't exist 
2020-04-02 05:08:58,780 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-546423474-172.17.0.14-1585804132033: 606ms
2020-04-02 05:08:58,776 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:08:58,802 [Thread-318] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-546423474-172.17.0.14-1585804132033/current/replicas doesn't exist 
2020-04-02 05:08:58,803 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 61ms
2020-04-02 05:08:58,803 [Thread-177] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-546423474-172.17.0.14-1585804132033: 119ms
2020-04-02 05:08:58,803 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:08:58,803 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 24ms
2020-04-02 05:08:58,775 [Thread-316] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-546423474-172.17.0.14-1585804132033/current/replicas doesn't exist 
2020-04-02 05:08:58,805 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:08:58,775 [Thread-317] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-546423474-172.17.0.14-1585804132033/current/replicas doesn't exist 
2020-04-02 05:08:58,826 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 51ms
2020-04-02 05:08:58,826 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-546423474-172.17.0.14-1585804132033: 52ms
2020-04-02 05:08:58,827 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:08:58,829 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:08:58,831 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-6b0808c3-6154-4d68-af84-9c6406ac52f0): finished scanning block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,833 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:18 AM with interval of 21600000ms
2020-04-02 05:08:58,826 [Thread-108] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-546423474-172.17.0.14-1585804132033: 83ms
2020-04-02 05:08:58,805 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:08:58,854 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-998237d1-de80-4cf4-b032-ef5991f68f92): finished scanning block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,825 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 44ms
2020-04-02 05:08:58,825 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 83ms
2020-04-02 05:08:58,825 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 82ms
2020-04-02 05:08:58,803 [Thread-320] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-546423474-172.17.0.14-1585804132033/current/replicas doesn't exist 
2020-04-02 05:08:58,857 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:08:58,857 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 54ms
2020-04-02 05:08:58,857 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-47cc88ad-9f2a-471e-a976-22e1ae47f498): finished scanning block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,803 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 1ms
2020-04-02 05:08:58,802 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:08:58,801 [Thread-292] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:08:58,863 [Thread-292] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 873357056. Formatting...
2020-04-02 05:08:58,864 [Thread-292] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d038668f-30ff-4c12-aa23-3dd382355fe2 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-04-02 05:08:58,864 [Thread-319] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-546423474-172.17.0.14-1585804132033/current/replicas doesn't exist 
2020-04-02 05:08:58,865 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 1ms
2020-04-02 05:08:58,875 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-546423474-172.17.0.14-1585804132033: 73ms
2020-04-02 05:08:58,875 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-47cc88ad-9f2a-471e-a976-22e1ae47f498): no suitable block pools found to scan.  Waiting 1814399978 ms.
2020-04-02 05:08:58,875 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:08:58,876 [Thread-154] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:30 AM with interval of 21600000ms
2020-04-02 05:08:58,876 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-c43df3d0-ea14-4543-96de-b93a0d908fba): finished scanning block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,877 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-c43df3d0-ea14-4543-96de-b93a0d908fba): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:08:58,798 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 24ms
2020-04-02 05:08:58,886 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-546423474-172.17.0.14-1585804132033 (Datanode Uuid 655fc58e-502f-4c62-a998-55c25928e1de) service to localhost/127.0.0.1:46003 beginning handshake with NN
2020-04-02 05:08:58,886 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:08:58,876 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-6b0808c3-6154-4d68-af84-9c6406ac52f0): no suitable block pools found to scan.  Waiting 1814399928 ms.
2020-04-02 05:08:58,919 [IPC Server handler 1 on 46003] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37102, datanodeUuid=655fc58e-502f-4c62-a998-55c25928e1de, infoPort=40852, infoSecurePort=0, ipcPort=33146, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033) storage 655fc58e-502f-4c62-a998-55c25928e1de
2020-04-02 05:08:58,876 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-998237d1-de80-4cf4-b032-ef5991f68f92): no suitable block pools found to scan.  Waiting 1814399929 ms.
2020-04-02 05:08:58,922 [IPC Server handler 1 on 46003] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37102
2020-04-02 05:08:58,854 [Thread-108] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:53 AM with interval of 21600000ms
2020-04-02 05:08:58,867 [Thread-292] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:08:58,866 [Thread-177] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:39 AM with interval of 21600000ms
2020-04-02 05:08:58,923 [Thread-292] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 873357056. Formatting...
2020-04-02 05:08:58,865 [Thread-200] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-546423474-172.17.0.14-1585804132033: 162ms
2020-04-02 05:08:58,925 [Thread-292] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-254a211a-bd79-4ab5-b879-2c065d4d9e68 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-04-02 05:08:58,855 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-546423474-172.17.0.14-1585804132033 (Datanode Uuid 8555c340-c479-402b-b028-7e7d1e5d93d1) service to localhost/127.0.0.1:46003 beginning handshake with NN
2020-04-02 05:08:58,929 [Thread-200] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:53 AM with interval of 21600000ms
2020-04-02 05:08:58,933 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-546423474-172.17.0.14-1585804132033 (Datanode Uuid cf3eecb1-bd14-4122-95a1-3e277869dc39) service to localhost/127.0.0.1:46003 beginning handshake with NN
2020-04-02 05:08:58,855 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:08:58,934 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-c34961ca-a210-4cb0-a394-c5877e623d7e): finished scanning block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,946 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-c34961ca-a210-4cb0-a394-c5877e623d7e): no suitable block pools found to scan.  Waiting 1814399907 ms.
2020-04-02 05:08:58,853 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-b0b5649b-5a54-4991-8466-d6109f206e71): finished scanning block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,947 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-b0b5649b-5a54-4991-8466-d6109f206e71): no suitable block pools found to scan.  Waiting 1814399879 ms.
2020-04-02 05:08:58,853 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-f996263e-6fdd-494a-a59c-a647b7eb4013): finished scanning block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,850 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 75ms
2020-04-02 05:08:58,948 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-546423474-172.17.0.14-1585804132033: 174ms
2020-04-02 05:08:58,949 [Thread-237] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:56 AM with interval of 21600000ms
2020-04-02 05:08:58,844 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 69ms
2020-04-02 05:08:58,950 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:08:58,951 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-d7cf7842-e826-4d35-b95a-d9313f843cc1): finished scanning block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,951 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-d7cf7842-e826-4d35-b95a-d9313f843cc1): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:08:58,950 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:08:58,952 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-c201dc3a-7099-4a0b-a0e4-6a46c18e63a7): finished scanning block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,953 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-c201dc3a-7099-4a0b-a0e4-6a46c18e63a7): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:08:58,948 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-f996263e-6fdd-494a-a59c-a647b7eb4013): no suitable block pools found to scan.  Waiting 1814399878 ms.
2020-04-02 05:08:58,929 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:08:58,928 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:08:58,953 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-63829bc4-26b0-4710-ab7c-ad8fbd49701a): finished scanning block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,953 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-546423474-172.17.0.14-1585804132033: 209ms
2020-04-02 05:08:58,953 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-9e221eab-2732-49d2-b93b-e289117101ee): finished scanning block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,954 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:08:58,927 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-546423474-172.17.0.14-1585804132033 (Datanode Uuid b830a9b1-fa6b-4bea-b8f7-dff8c35c043b) service to localhost/127.0.0.1:46003 beginning handshake with NN
2020-04-02 05:08:58,925 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-546423474-172.17.0.14-1585804132033 (Datanode Uuid 8e065a51-9e8f-4e5d-b97e-3d42a0cebae8) service to localhost/127.0.0.1:46003 beginning handshake with NN
2020-04-02 05:08:58,967 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:15 AM with interval of 21600000ms
2020-04-02 05:08:58,968 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-9e221eab-2732-49d2-b93b-e289117101ee): no suitable block pools found to scan.  Waiting 1814399957 ms.
2020-04-02 05:08:58,968 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-63829bc4-26b0-4710-ab7c-ad8fbd49701a): no suitable block pools found to scan.  Waiting 1814399957 ms.
2020-04-02 05:08:58,970 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-546423474-172.17.0.14-1585804132033 (Datanode Uuid 6de4f9c9-79b0-4647-9414-f876428e3175) service to localhost/127.0.0.1:46003 beginning handshake with NN
2020-04-02 05:08:58,923 [IPC Server handler 1 on 46003] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 655fc58e-502f-4c62-a998-55c25928e1de (127.0.0.1:37102).
2020-04-02 05:08:58,907 [Thread-131] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-546423474-172.17.0.14-1585804132033: 165ms
2020-04-02 05:08:58,907 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-1a37025d-77bf-41dd-8612-1ed465e6299f): finished scanning block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,975 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-1a37025d-77bf-41dd-8612-1ed465e6299f): no suitable block pools found to scan.  Waiting 1814399900 ms.
2020-04-02 05:08:58,965 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:08:58,956 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-546423474-172.17.0.14-1585804132033 (Datanode Uuid d20ef059-92c7-4f68-a334-2502d86c073f) service to localhost/127.0.0.1:46003 beginning handshake with NN
2020-04-02 05:08:58,975 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-eb910106-c911-43eb-bb41-fcf6ef4fc559): finished scanning block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,976 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-eb910106-c911-43eb-bb41-fcf6ef4fc559): no suitable block pools found to scan.  Waiting 1814399978 ms.
2020-04-02 05:08:58,975 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:08:58,977 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-c7a90c92-7250-4a78-af04-fec73d32d73d): finished scanning block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,975 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:08:58,986 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-4bb0dddd-0253-47c2-9104-bbac55c648c9): finished scanning block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,987 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-4bb0dddd-0253-47c2-9104-bbac55c648c9): no suitable block pools found to scan.  Waiting 1814399987 ms.
2020-04-02 05:08:58,975 [Thread-131] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:22 AM with interval of 21600000ms
2020-04-02 05:08:58,979 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-c7a90c92-7250-4a78-af04-fec73d32d73d): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:08:58,988 [Thread-292] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,989 [Thread-292] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:58,989 [Thread-292] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-546423474-172.17.0.14-1585804132033 is not formatted. Formatting ...
2020-04-02 05:08:58,989 [Thread-292] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-546423474-172.17.0.14-1585804132033 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-546423474-172.17.0.14-1585804132033/current
2020-04-02 05:08:58,999 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-546423474-172.17.0.14-1585804132033 (Datanode Uuid 7506b242-281c-466a-9c9b-c68449a86341) service to localhost/127.0.0.1:46003 beginning handshake with NN
2020-04-02 05:08:59,002 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-bf5d6cb7-14ea-424c-9049-88419e444644): finished scanning block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:59,004 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-bf5d6cb7-14ea-424c-9049-88419e444644): no suitable block pools found to scan.  Waiting 1814399950 ms.
2020-04-02 05:08:59,008 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-546423474-172.17.0.14-1585804132033 (Datanode Uuid 655fc58e-502f-4c62-a998-55c25928e1de) service to localhost/127.0.0.1:46003 successfully registered with NN
2020-04-02 05:08:59,009 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46003 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:59,010 [IPC Server handler 7 on 46003] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38956, datanodeUuid=8e065a51-9e8f-4e5d-b97e-3d42a0cebae8, infoPort=36791, infoSecurePort=0, ipcPort=36980, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033) storage 8e065a51-9e8f-4e5d-b97e-3d42a0cebae8
2020-04-02 05:08:59,010 [IPC Server handler 7 on 46003] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38956
2020-04-02 05:08:59,010 [IPC Server handler 7 on 46003] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8e065a51-9e8f-4e5d-b97e-3d42a0cebae8 (127.0.0.1:38956).
2020-04-02 05:08:59,010 [IPC Server handler 6 on 46003] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43768, datanodeUuid=8555c340-c479-402b-b028-7e7d1e5d93d1, infoPort=36712, infoSecurePort=0, ipcPort=36016, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033) storage 8555c340-c479-402b-b028-7e7d1e5d93d1
2020-04-02 05:08:59,011 [IPC Server handler 6 on 46003] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43768
2020-04-02 05:08:59,011 [IPC Server handler 6 on 46003] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8555c340-c479-402b-b028-7e7d1e5d93d1 (127.0.0.1:43768).
2020-04-02 05:08:59,018 [IPC Server handler 8 on 46003] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37040, datanodeUuid=6de4f9c9-79b0-4647-9414-f876428e3175, infoPort=36945, infoSecurePort=0, ipcPort=44658, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033) storage 6de4f9c9-79b0-4647-9414-f876428e3175
2020-04-02 05:08:59,018 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-546423474-172.17.0.14-1585804132033 (Datanode Uuid 8e065a51-9e8f-4e5d-b97e-3d42a0cebae8) service to localhost/127.0.0.1:46003 successfully registered with NN
2020-04-02 05:08:59,018 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46003 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:59,018 [IPC Server handler 8 on 46003] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37040
2020-04-02 05:08:59,018 [IPC Server handler 8 on 46003] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 6de4f9c9-79b0-4647-9414-f876428e3175 (127.0.0.1:37040).
2020-04-02 05:08:59,026 [IPC Server handler 9 on 46003] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42843, datanodeUuid=cf3eecb1-bd14-4122-95a1-3e277869dc39, infoPort=44561, infoSecurePort=0, ipcPort=45598, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033) storage cf3eecb1-bd14-4122-95a1-3e277869dc39
2020-04-02 05:08:59,027 [IPC Server handler 9 on 46003] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42843
2020-04-02 05:08:59,027 [IPC Server handler 9 on 46003] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN cf3eecb1-bd14-4122-95a1-3e277869dc39 (127.0.0.1:42843).
2020-04-02 05:08:59,030 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-546423474-172.17.0.14-1585804132033 (Datanode Uuid 6de4f9c9-79b0-4647-9414-f876428e3175) service to localhost/127.0.0.1:46003 successfully registered with NN
2020-04-02 05:08:59,030 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46003 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:59,018 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-546423474-172.17.0.14-1585804132033 (Datanode Uuid 8555c340-c479-402b-b028-7e7d1e5d93d1) service to localhost/127.0.0.1:46003 successfully registered with NN
2020-04-02 05:08:59,031 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46003 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:59,033 [IPC Server handler 5 on 46003] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43884, datanodeUuid=d20ef059-92c7-4f68-a334-2502d86c073f, infoPort=38168, infoSecurePort=0, ipcPort=34113, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033) storage d20ef059-92c7-4f68-a334-2502d86c073f
2020-04-02 05:08:59,033 [IPC Server handler 5 on 46003] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43884
2020-04-02 05:08:59,033 [IPC Server handler 5 on 46003] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d20ef059-92c7-4f68-a334-2502d86c073f (127.0.0.1:43884).
2020-04-02 05:08:59,033 [IPC Server handler 3 on 46003] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37012, datanodeUuid=7506b242-281c-466a-9c9b-c68449a86341, infoPort=33158, infoSecurePort=0, ipcPort=40579, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033) storage 7506b242-281c-466a-9c9b-c68449a86341
2020-04-02 05:08:59,034 [IPC Server handler 3 on 46003] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37012
2020-04-02 05:08:59,034 [IPC Server handler 3 on 46003] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7506b242-281c-466a-9c9b-c68449a86341 (127.0.0.1:37012).
2020-04-02 05:08:59,038 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-546423474-172.17.0.14-1585804132033 (Datanode Uuid d20ef059-92c7-4f68-a334-2502d86c073f) service to localhost/127.0.0.1:46003 successfully registered with NN
2020-04-02 05:08:59,038 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-546423474-172.17.0.14-1585804132033 (Datanode Uuid cf3eecb1-bd14-4122-95a1-3e277869dc39) service to localhost/127.0.0.1:46003 successfully registered with NN
2020-04-02 05:08:59,038 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46003 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:59,038 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46003 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:59,044 [IPC Server handler 4 on 46003] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36142, datanodeUuid=b830a9b1-fa6b-4bea-b8f7-dff8c35c043b, infoPort=34497, infoSecurePort=0, ipcPort=32823, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033) storage b830a9b1-fa6b-4bea-b8f7-dff8c35c043b
2020-04-02 05:08:59,044 [IPC Server handler 4 on 46003] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36142
2020-04-02 05:08:59,044 [IPC Server handler 4 on 46003] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b830a9b1-fa6b-4bea-b8f7-dff8c35c043b (127.0.0.1:36142).
2020-04-02 05:08:59,046 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-546423474-172.17.0.14-1585804132033 (Datanode Uuid b830a9b1-fa6b-4bea-b8f7-dff8c35c043b) service to localhost/127.0.0.1:46003 successfully registered with NN
2020-04-02 05:08:59,046 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-546423474-172.17.0.14-1585804132033 (Datanode Uuid 7506b242-281c-466a-9c9b-c68449a86341) service to localhost/127.0.0.1:46003 successfully registered with NN
2020-04-02 05:08:59,046 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46003 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:59,046 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46003 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:59,077 [Thread-292] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:59,078 [Thread-292] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:59,079 [Thread-292] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-546423474-172.17.0.14-1585804132033 is not formatted. Formatting ...
2020-04-02 05:08:59,079 [Thread-292] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-546423474-172.17.0.14-1585804132033 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-546423474-172.17.0.14-1585804132033/current
2020-04-02 05:08:59,081 [Thread-292] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=873357056;bpid=BP-546423474-172.17.0.14-1585804132033;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=873357056;c=1585804132033;bpid=BP-546423474-172.17.0.14-1585804132033;dnuuid=null
2020-04-02 05:08:59,083 [Thread-292] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 7389bfe0-0e69-4d1e-818b-e4ae73da3315
2020-04-02 05:08:59,086 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-d038668f-30ff-4c12-aa23-3dd382355fe2
2020-04-02 05:08:59,086 [Thread-292] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-04-02 05:08:59,090 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-254a211a-bd79-4ab5-b879-2c065d4d9e68
2020-04-02 05:08:59,091 [Thread-292] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-04-02 05:08:59,092 [Thread-292] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:59,093 [Thread-292] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:08:59,119 [Thread-292] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:08:59,119 [Thread-292] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:08:59,119 [Thread-292] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:08:59,126 [Thread-292] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:59,130 [Thread-348] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:08:59,134 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:08:59,199 [IPC Server handler 0 on 46003] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-47cc88ad-9f2a-471e-a976-22e1ae47f498 for DN 127.0.0.1:38956
2020-04-02 05:08:59,200 [IPC Server handler 0 on 46003] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c34961ca-a210-4cb0-a394-c5877e623d7e for DN 127.0.0.1:38956
2020-04-02 05:08:59,238 [IPC Server handler 2 on 46003] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4bb0dddd-0253-47c2-9104-bbac55c648c9 for DN 127.0.0.1:37012
2020-04-02 05:08:59,245 [IPC Server handler 2 on 46003] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c7a90c92-7250-4a78-af04-fec73d32d73d for DN 127.0.0.1:37012
2020-04-02 05:08:59,286 [IPC Server handler 1 on 46003] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c201dc3a-7099-4a0b-a0e4-6a46c18e63a7 for DN 127.0.0.1:43884
2020-04-02 05:08:59,286 [IPC Server handler 1 on 46003] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d7cf7842-e826-4d35-b95a-d9313f843cc1 for DN 127.0.0.1:43884
2020-04-02 05:08:59,291 [Thread-348] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-546423474-172.17.0.14-1585804132033 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 161ms
2020-04-02 05:08:59,314 [IPC Server handler 1 on 46003] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1a37025d-77bf-41dd-8612-1ed465e6299f for DN 127.0.0.1:37102
2020-04-02 05:08:59,315 [IPC Server handler 1 on 46003] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c43df3d0-ea14-4543-96de-b93a0d908fba for DN 127.0.0.1:37102
2020-04-02 05:08:59,318 [IPC Server handler 6 on 46003] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b0b5649b-5a54-4991-8466-d6109f206e71 for DN 127.0.0.1:43768
2020-04-02 05:08:59,318 [IPC Server handler 6 on 46003] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f996263e-6fdd-494a-a59c-a647b7eb4013 for DN 127.0.0.1:43768
2020-04-02 05:08:59,322 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-546423474-172.17.0.14-1585804132033 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 188ms
2020-04-02 05:08:59,324 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-546423474-172.17.0.14-1585804132033: 198ms
2020-04-02 05:08:59,367 [Thread-351] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:08:59,367 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:08:59,368 [Thread-351] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-546423474-172.17.0.14-1585804132033/current/replicas doesn't exist 
2020-04-02 05:08:59,368 [Thread-351] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 0ms
2020-04-02 05:08:59,369 [IPC Server handler 9 on 46003] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:37012, datanodeUuid=7506b242-281c-466a-9c9b-c68449a86341, infoPort=33158, infoSecurePort=0, ipcPort=40579, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), reports.length=2
2020-04-02 05:08:59,372 [IPC Server handler 8 on 46003] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bf5d6cb7-14ea-424c-9049-88419e444644 for DN 127.0.0.1:37040
2020-04-02 05:08:59,372 [IPC Server handler 8 on 46003] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-eb910106-c911-43eb-bb41-fcf6ef4fc559 for DN 127.0.0.1:37040
2020-04-02 05:08:59,374 [IPC Server handler 2 on 46003] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:43884, datanodeUuid=d20ef059-92c7-4f68-a334-2502d86c073f, infoPort=38168, infoSecurePort=0, ipcPort=34113, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), reports.length=2
2020-04-02 05:08:59,374 [IPC Server handler 5 on 46003] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:37102, datanodeUuid=655fc58e-502f-4c62-a998-55c25928e1de, infoPort=40852, infoSecurePort=0, ipcPort=33146, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), reports.length=2
2020-04-02 05:08:59,379 [IPC Server handler 0 on 46003] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:43768, datanodeUuid=8555c340-c479-402b-b028-7e7d1e5d93d1, infoPort=36712, infoSecurePort=0, ipcPort=36016, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), reports.length=2
2020-04-02 05:08:59,381 [IPC Server handler 3 on 46003] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6b0808c3-6154-4d68-af84-9c6406ac52f0 for DN 127.0.0.1:36142
2020-04-02 05:08:59,382 [IPC Server handler 3 on 46003] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-998237d1-de80-4cf4-b032-ef5991f68f92 for DN 127.0.0.1:36142
2020-04-02 05:08:59,382 [IPC Server handler 1 on 46003] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:38956, datanodeUuid=8e065a51-9e8f-4e5d-b97e-3d42a0cebae8, infoPort=36791, infoSecurePort=0, ipcPort=36980, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), reports.length=2
2020-04-02 05:08:59,391 [Thread-352] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-546423474-172.17.0.14-1585804132033/current/replicas doesn't exist 
2020-04-02 05:08:59,392 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 24ms
2020-04-02 05:08:59,392 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-546423474-172.17.0.14-1585804132033: 54ms
2020-04-02 05:08:59,393 [Thread-292] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:51 AM with interval of 21600000ms
2020-04-02 05:08:59,393 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:08:59,394 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-254a211a-bd79-4ab5-b879-2c065d4d9e68): finished scanning block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:59,394 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-254a211a-bd79-4ab5-b879-2c065d4d9e68): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:08:59,395 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-546423474-172.17.0.14-1585804132033 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:08:59,395 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-d038668f-30ff-4c12-aa23-3dd382355fe2): finished scanning block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:59,395 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-d038668f-30ff-4c12-aa23-3dd382355fe2): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:08:59,398 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-546423474-172.17.0.14-1585804132033 (Datanode Uuid 7389bfe0-0e69-4d1e-818b-e4ae73da3315) service to localhost/127.0.0.1:46003 beginning handshake with NN
2020-04-02 05:08:59,404 [IPC Server handler 4 on 46003] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-63829bc4-26b0-4710-ab7c-ad8fbd49701a for DN 127.0.0.1:42843
2020-04-02 05:08:59,417 [IPC Server handler 4 on 46003] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9e221eab-2732-49d2-b93b-e289117101ee for DN 127.0.0.1:42843
2020-04-02 05:08:59,418 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe78bdf804dc6eb3c: Processing first storage report for DS-c7a90c92-7250-4a78-af04-fec73d32d73d from datanode 7506b242-281c-466a-9c9b-c68449a86341
2020-04-02 05:08:59,419 [IPC Server handler 6 on 46003] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:37040, datanodeUuid=6de4f9c9-79b0-4647-9414-f876428e3175, infoPort=36945, infoSecurePort=0, ipcPort=44658, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), reports.length=2
2020-04-02 05:08:59,420 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe78bdf804dc6eb3c: from storage DS-c7a90c92-7250-4a78-af04-fec73d32d73d node DatanodeRegistration(127.0.0.1:37012, datanodeUuid=7506b242-281c-466a-9c9b-c68449a86341, infoPort=33158, infoSecurePort=0, ipcPort=40579, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:08:59,421 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xaef6145699d23236: Processing first storage report for DS-d7cf7842-e826-4d35-b95a-d9313f843cc1 from datanode d20ef059-92c7-4f68-a334-2502d86c073f
2020-04-02 05:08:59,421 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xaef6145699d23236: from storage DS-d7cf7842-e826-4d35-b95a-d9313f843cc1 node DatanodeRegistration(127.0.0.1:43884, datanodeUuid=d20ef059-92c7-4f68-a334-2502d86c073f, infoPort=38168, infoSecurePort=0, ipcPort=34113, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:59,427 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x1cbe7601a88831e7: Processing first storage report for DS-1a37025d-77bf-41dd-8612-1ed465e6299f from datanode 655fc58e-502f-4c62-a998-55c25928e1de
2020-04-02 05:08:59,427 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x1cbe7601a88831e7: from storage DS-1a37025d-77bf-41dd-8612-1ed465e6299f node DatanodeRegistration(127.0.0.1:37102, datanodeUuid=655fc58e-502f-4c62-a998-55c25928e1de, infoPort=40852, infoSecurePort=0, ipcPort=33146, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), blocks: 0, hasStaleStorage: true, processing time: 5 msecs, invalidatedBlocks: 0
2020-04-02 05:08:59,427 [IPC Server handler 7 on 46003] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42028, datanodeUuid=7389bfe0-0e69-4d1e-818b-e4ae73da3315, infoPort=44984, infoSecurePort=0, ipcPort=41887, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033) storage 7389bfe0-0e69-4d1e-818b-e4ae73da3315
2020-04-02 05:08:59,429 [IPC Server handler 7 on 46003] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42028
2020-04-02 05:08:59,429 [IPC Server handler 7 on 46003] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7389bfe0-0e69-4d1e-818b-e4ae73da3315 (127.0.0.1:42028).
2020-04-02 05:08:59,440 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-546423474-172.17.0.14-1585804132033 (Datanode Uuid 7389bfe0-0e69-4d1e-818b-e4ae73da3315) service to localhost/127.0.0.1:46003 successfully registered with NN
2020-04-02 05:08:59,440 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46003 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:59,454 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x34104764846e9276: Processing first storage report for DS-b0b5649b-5a54-4991-8466-d6109f206e71 from datanode 8555c340-c479-402b-b028-7e7d1e5d93d1
2020-04-02 05:08:59,480 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x34104764846e9276: from storage DS-b0b5649b-5a54-4991-8466-d6109f206e71 node DatanodeRegistration(127.0.0.1:43768, datanodeUuid=8555c340-c479-402b-b028-7e7d1e5d93d1, infoPort=36712, infoSecurePort=0, ipcPort=36016, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), blocks: 0, hasStaleStorage: true, processing time: 42 msecs, invalidatedBlocks: 0
2020-04-02 05:08:59,498 [IPC Server handler 8 on 46003] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d038668f-30ff-4c12-aa23-3dd382355fe2 for DN 127.0.0.1:42028
2020-04-02 05:08:59,499 [IPC Server handler 8 on 46003] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-254a211a-bd79-4ab5-b879-2c065d4d9e68 for DN 127.0.0.1:42028
2020-04-02 05:08:59,506 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2ba8c0617cef671: Processing first storage report for DS-47cc88ad-9f2a-471e-a976-22e1ae47f498 from datanode 8e065a51-9e8f-4e5d-b97e-3d42a0cebae8
2020-04-02 05:08:59,506 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2ba8c0617cef671: from storage DS-47cc88ad-9f2a-471e-a976-22e1ae47f498 node DatanodeRegistration(127.0.0.1:38956, datanodeUuid=8e065a51-9e8f-4e5d-b97e-3d42a0cebae8, infoPort=36791, infoSecurePort=0, ipcPort=36980, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:59,511 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x313a93cd8b297f0f: Processing first storage report for DS-bf5d6cb7-14ea-424c-9049-88419e444644 from datanode 6de4f9c9-79b0-4647-9414-f876428e3175
2020-04-02 05:08:59,511 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x313a93cd8b297f0f: from storage DS-bf5d6cb7-14ea-424c-9049-88419e444644 node DatanodeRegistration(127.0.0.1:37040, datanodeUuid=6de4f9c9-79b0-4647-9414-f876428e3175, infoPort=36945, infoSecurePort=0, ipcPort=44658, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), blocks: 0, hasStaleStorage: true, processing time: 4 msecs, invalidatedBlocks: 0
2020-04-02 05:08:59,511 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xaef6145699d23236: Processing first storage report for DS-c201dc3a-7099-4a0b-a0e4-6a46c18e63a7 from datanode d20ef059-92c7-4f68-a334-2502d86c073f
2020-04-02 05:08:59,511 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xaef6145699d23236: from storage DS-c201dc3a-7099-4a0b-a0e4-6a46c18e63a7 node DatanodeRegistration(127.0.0.1:43884, datanodeUuid=d20ef059-92c7-4f68-a334-2502d86c073f, infoPort=38168, infoSecurePort=0, ipcPort=34113, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:59,512 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe78bdf804dc6eb3c: Processing first storage report for DS-4bb0dddd-0253-47c2-9104-bbac55c648c9 from datanode 7506b242-281c-466a-9c9b-c68449a86341
2020-04-02 05:08:59,512 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe78bdf804dc6eb3c: from storage DS-4bb0dddd-0253-47c2-9104-bbac55c648c9 node DatanodeRegistration(127.0.0.1:37012, datanodeUuid=7506b242-281c-466a-9c9b-c68449a86341, infoPort=33158, infoSecurePort=0, ipcPort=40579, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:59,512 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x1cbe7601a88831e7: Processing first storage report for DS-c43df3d0-ea14-4543-96de-b93a0d908fba from datanode 655fc58e-502f-4c62-a998-55c25928e1de
2020-04-02 05:08:59,512 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x1cbe7601a88831e7: from storage DS-c43df3d0-ea14-4543-96de-b93a0d908fba node DatanodeRegistration(127.0.0.1:37102, datanodeUuid=655fc58e-502f-4c62-a998-55c25928e1de, infoPort=40852, infoSecurePort=0, ipcPort=33146, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:59,512 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x34104764846e9276: Processing first storage report for DS-f996263e-6fdd-494a-a59c-a647b7eb4013 from datanode 8555c340-c479-402b-b028-7e7d1e5d93d1
2020-04-02 05:08:59,512 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x34104764846e9276: from storage DS-f996263e-6fdd-494a-a59c-a647b7eb4013 node DatanodeRegistration(127.0.0.1:43768, datanodeUuid=8555c340-c479-402b-b028-7e7d1e5d93d1, infoPort=36712, infoSecurePort=0, ipcPort=36016, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:59,512 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2ba8c0617cef671: Processing first storage report for DS-c34961ca-a210-4cb0-a394-c5877e623d7e from datanode 8e065a51-9e8f-4e5d-b97e-3d42a0cebae8
2020-04-02 05:08:59,516 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2ba8c0617cef671: from storage DS-c34961ca-a210-4cb0-a394-c5877e623d7e node DatanodeRegistration(127.0.0.1:38956, datanodeUuid=8e065a51-9e8f-4e5d-b97e-3d42a0cebae8, infoPort=36791, infoSecurePort=0, ipcPort=36980, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), blocks: 0, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2020-04-02 05:08:59,518 [IPC Server handler 2 on 46003] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xaef6145699d23236
2020-04-02 05:08:59,523 [IPC Server handler 5 on 46003] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x1cbe7601a88831e7
2020-04-02 05:08:59,523 [IPC Server handler 9 on 46003] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xe78bdf804dc6eb3c
2020-04-02 05:08:59,540 [IPC Server handler 0 on 46003] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x34104764846e9276
2020-04-02 05:08:59,543 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xaef6145699d23236,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 10 msec to generate and 227 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:59,544 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:59,544 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x313a93cd8b297f0f: Processing first storage report for DS-eb910106-c911-43eb-bb41-fcf6ef4fc559 from datanode 6de4f9c9-79b0-4647-9414-f876428e3175
2020-04-02 05:08:59,540 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x1cbe7601a88831e7,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 215 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:59,558 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:59,558 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xe78bdf804dc6eb3c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 25 msec to generate and 249 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:59,562 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:59,570 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x34104764846e9276,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 240 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:59,570 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:59,571 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x313a93cd8b297f0f: from storage DS-eb910106-c911-43eb-bb41-fcf6ef4fc559 node DatanodeRegistration(127.0.0.1:37040, datanodeUuid=6de4f9c9-79b0-4647-9414-f876428e3175, infoPort=36945, infoSecurePort=0, ipcPort=44658, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), blocks: 0, hasStaleStorage: false, processing time: 14 msecs, invalidatedBlocks: 0
2020-04-02 05:08:59,572 [IPC Server handler 1 on 46003] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x2ba8c0617cef671
2020-04-02 05:08:59,572 [IPC Server handler 6 on 46003] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x313a93cd8b297f0f
2020-04-02 05:08:59,574 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x2ba8c0617cef671,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 244 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:59,574 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:59,574 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x313a93cd8b297f0f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 173 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:59,574 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:08:59,853 [IPC Server handler 3 on 46003] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:08:59,868 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:08:59,888 [IPC Server handler 4 on 46003] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-04-02 05:08:59,923 [IPC Server handler 7 on 46003] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure#testReadWithDNFailure[0]
[msx] unitTestCounterInClass = 0
[msx] before_class
2020-04-02 05:08:59,947 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=9
Formatting using clusterid: testClusterID
2020-04-02 05:08:59,951 [Thread-359] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:08:59,952 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:08:59,952 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:08:59,952 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:08:59,953 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:08:59,953 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:08:59,953 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:08:59,953 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:08:59,954 [Thread-359] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:59,954 [Thread-359] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:08:59,954 [Thread-359] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:08:59,954 [Thread-359] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:08:59,955 [Thread-359] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:08:59
2020-04-02 05:08:59,955 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:08:59,955 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:59,955 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:08:59,955 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:08:59,968 [Thread-359] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:08:59,969 [Thread-359] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:08:59,969 [Thread-359] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:08:59,969 [Thread-359] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:08:59,969 [Thread-359] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:08:59,969 [Thread-359] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:08:59,969 [Thread-359] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:08:59,969 [Thread-359] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:08:59,970 [Thread-359] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 0
2020-04-02 05:08:59,970 [Thread-359] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:08:59,970 [Thread-359] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:08:59,970 [Thread-359] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:08:59,970 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:08:59,970 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:59,971 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:08:59,971 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:09:00,132 [Thread-359] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:09:00,133 [Thread-359] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:09:00,138 [Thread-359] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:09:00,139 [Thread-359] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:09:00,139 [Thread-359] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:09:00,139 [Thread-359] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:09:00,139 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:09:00,139 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:00,140 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:09:00,140 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:09:00,142 [Thread-359] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:09:00,142 [Thread-359] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:09:00,142 [Thread-359] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:09:00,142 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:09:00,142 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:09:00,142 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:09:00,142 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:00,143 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:09:00,143 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:09:00,181 [Thread-359] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:00,197 [Thread-359] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:09:00,201 [Thread-359] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:09:00,205 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:09:00,205 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:09:00,212 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 421 bytes saved in 0 seconds .
2020-04-02 05:09:00,213 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 421 bytes saved in 0 seconds .
2020-04-02 05:09:00,219 [Thread-359] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:09:00,220 [Thread-359] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:09:00,221 [Thread-359] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:09:00,221 [Thread-359] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:09:00,221 [Thread-359] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:09:00,234 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6bba96f1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:00,234 [Thread-359] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:09:00,234 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:00,236 [Thread-359] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:00,236 [Thread-359] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:09:00,237 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:00,238 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:00,239 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:09:00,239 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:00,240 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:00,242 [Thread-359] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:09:00,242 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:09:00,242 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44289
2020-04-02 05:09:00,243 [Thread-359] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:00,254 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@433b65e0{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:00,256 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6c28d7c9{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:00,261 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7911dcfa{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:09:00,263 [Thread-359] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4d5a3d57{HTTP/1.1,[http/1.1]}{localhost:44289}
2020-04-02 05:09:00,263 [Thread-359] INFO  server.Server (Server.java:doStart(419)) - Started @10673ms
2020-04-02 05:09:00,267 [Thread-359] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:09:00,268 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:09:00,268 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:09:00,268 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:09:00,268 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:09:00,268 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:09:00,268 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:09:00,269 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:09:00,269 [Thread-359] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:00,269 [Thread-359] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:09:00,274 [Thread-359] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:09:00,274 [Thread-359] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:09:00,275 [Thread-359] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:09:00
2020-04-02 05:09:00,275 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:09:00,275 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:00,275 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:09:00,275 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:09:00,288 [Thread-359] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:09:00,288 [Thread-359] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:09:00,289 [Thread-359] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:09:00,289 [Thread-359] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:09:00,289 [Thread-359] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:09:00,289 [Thread-359] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:09:00,289 [Thread-359] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:09:00,289 [Thread-359] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:09:00,289 [Thread-359] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 0
2020-04-02 05:09:00,290 [Thread-359] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:09:00,290 [Thread-359] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:09:00,290 [Thread-359] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:09:00,290 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:09:00,290 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:00,291 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:09:00,291 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:09:00,305 [Thread-359] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:09:00,305 [Thread-359] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:09:00,306 [Thread-359] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:09:00,306 [Thread-359] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:09:00,306 [Thread-359] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:09:00,306 [Thread-359] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:09:00,307 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:09:00,308 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:00,308 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:09:00,309 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:09:00,310 [Thread-359] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:09:00,311 [Thread-359] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:09:00,311 [Thread-359] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:09:00,311 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:09:00,311 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:09:00,311 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:09:00,312 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:00,313 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:09:00,313 [Thread-359] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:09:00,317 [Thread-359] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:00,319 [Thread-359] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:00,321 [Thread-359] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:09:00,321 [Thread-359] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:09:00,322 [Thread-359] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:09:00,322 [Thread-359] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:09:00,324 [Thread-359] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:09:00,325 [Thread-359] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:09:00,326 [Thread-359] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:09:00,326 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:09:00,327 [Thread-359] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:09:00,349 [Thread-359] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:09:00,350 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 35 msecs
2020-04-02 05:09:00,350 [Thread-359] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:09:00,350 [Thread-359] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:00,352 [Socket Reader #1 for port 46429] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46429
2020-04-02 05:09:00,367 [Thread-359] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:46429 to access this namenode/service.
2020-04-02 05:09:00,369 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:09:00,414 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:00,438 [Thread-359] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:09:00,439 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@2c50e11d] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:09:00,472 [Thread-359] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:09:00,473 [Thread-359] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:09:00,473 [Thread-359] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:09:00,479 [Thread-359] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:09:00,509 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:09:00,509 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:09:00,509 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:09:00,509 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:09:00,509 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:09:00,509 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 28 msec
2020-04-02 05:09:00,531 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:00,531 [IPC Server listener on 46429] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46429: starting
2020-04-02 05:09:00,541 [Thread-359] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:46429
2020-04-02 05:09:00,544 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:09:00,545 [Thread-359] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:09:00,546 [Thread-359] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:09:00,552 [Thread-359] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 46429 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:00,577 [CacheReplicationMonitor(1957886113)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:09:00,590 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:00,591 [Thread-359] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:00,592 [Thread-359] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:00,621 [Thread-359] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:00,622 [Thread-359] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:00,622 [Thread-359] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:00,622 [Thread-359] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:00,630 [Thread-359] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:00,631 [Thread-359] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:00,631 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:00,635 [Thread-359] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:36280
2020-04-02 05:09:00,635 [Thread-359] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:00,635 [Thread-359] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:00,659 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:00,661 [Thread-359] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:00,666 [Thread-359] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:00,667 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:00,670 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:00,670 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:00,682 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:00,682 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:00,686 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43017
2020-04-02 05:09:00,687 [Thread-359] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:00,688 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7cdcf74f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:00,689 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@72f13a77{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:00,695 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2d70b62e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:00,696 [Thread-359] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2aa50597{HTTP/1.1,[http/1.1]}{localhost:43017}
2020-04-02 05:09:00,696 [Thread-359] INFO  server.Server (Server.java:doStart(419)) - Started @11106ms
2020-04-02 05:09:00,729 [Thread-359] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38233
2020-04-02 05:09:00,731 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:00,731 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3b3d0ecc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:00,731 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:00,732 [Thread-359] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:00,732 [Socket Reader #1 for port 45970] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45970
2020-04-02 05:09:00,743 [Thread-359] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:45970
2020-04-02 05:09:00,761 [Thread-359] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:00,761 [Thread-359] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:00,770 [Thread-413] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46429 starting to offer service
2020-04-02 05:09:00,806 [IPC Server listener on 45970] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45970: starting
2020-04-02 05:09:00,815 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:00,847 [Thread-359] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 45970 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:00,855 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:00,856 [Thread-359] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:09:00,862 [Thread-359] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:00,875 [Thread-359] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:00,875 [Thread-413] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46429
2020-04-02 05:09:00,875 [Thread-359] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:00,879 [Thread-359] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:00,880 [Thread-359] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:00,880 [Thread-359] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:00,881 [Thread-359] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:00,881 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:00,882 [Thread-359] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:41614
2020-04-02 05:09:00,882 [Thread-359] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:00,882 [Thread-359] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:00,883 [Thread-413] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:00,887 [Thread-413] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:00,887 [Thread-413] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1632793555. Formatting...
2020-04-02 05:09:00,887 [Thread-413] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-cea4480b-5159-448f-9e29-d4a50c371ed3 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:09:00,897 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:00,899 [Thread-359] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:00,899 [Thread-359] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:00,900 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:00,901 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:00,901 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:00,902 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:00,902 [Thread-413] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:00,902 [Thread-413] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1632793555. Formatting...
2020-04-02 05:09:00,903 [Thread-413] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e07a8967-b41f-4089-8035-d20cb21c35fb for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:09:00,902 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:00,908 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38701
2020-04-02 05:09:00,908 [Thread-359] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:00,910 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5f753edf{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:00,911 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d373c13{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:00,925 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4888ea91{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:00,926 [Thread-359] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1c32cecd{HTTP/1.1,[http/1.1]}{localhost:38701}
2020-04-02 05:09:00,926 [Thread-359] INFO  server.Server (Server.java:doStart(419)) - Started @11336ms
2020-04-02 05:09:00,938 [Thread-413] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:00,938 [Thread-413] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:00,939 [Thread-413] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1486927160-172.17.0.14-1585804140181 is not formatted. Formatting ...
2020-04-02 05:09:00,939 [Thread-413] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1486927160-172.17.0.14-1585804140181 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1486927160-172.17.0.14-1585804140181/current
2020-04-02 05:09:00,950 [Thread-359] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40941
2020-04-02 05:09:00,954 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:00,954 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:00,954 [Thread-359] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:00,955 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2f405191] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:00,955 [Socket Reader #1 for port 37290] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37290
2020-04-02 05:09:00,959 [Thread-359] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:37290
2020-04-02 05:09:00,971 [Thread-359] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:00,972 [Thread-359] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:00,973 [Thread-437] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46429 starting to offer service
2020-04-02 05:09:00,973 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:00,973 [IPC Server listener on 37290] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37290: starting
2020-04-02 05:09:00,985 [Thread-413] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:00,999 [Thread-413] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:00,999 [Thread-413] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1486927160-172.17.0.14-1585804140181 is not formatted. Formatting ...
2020-04-02 05:09:01,000 [Thread-413] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1486927160-172.17.0.14-1585804140181 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1486927160-172.17.0.14-1585804140181/current
2020-04-02 05:09:01,006 [Thread-359] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 37290 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:01,007 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:09:01,008 [Thread-359] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:09:01,009 [Thread-359] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:09:01,018 [Thread-359] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:01,019 [Thread-359] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:01,019 [Thread-359] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:01,019 [Thread-359] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:01,020 [Thread-359] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:01,020 [Thread-359] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:01,020 [Thread-437] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46429
2020-04-02 05:09:01,020 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:01,024 [Thread-359] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34039
2020-04-02 05:09:01,024 [Thread-359] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:01,025 [Thread-359] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:01,026 [Thread-413] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1632793555;bpid=BP-1486927160-172.17.0.14-1585804140181;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1632793555;c=1585804140181;bpid=BP-1486927160-172.17.0.14-1585804140181;dnuuid=null
2020-04-02 05:09:01,027 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:01,029 [Thread-359] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:01,030 [Thread-437] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:01,031 [Thread-437] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:01,031 [Thread-437] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1632793555. Formatting...
2020-04-02 05:09:01,031 [Thread-437] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-147fd5b8-349a-4f9c-a815-be1af224249e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:09:01,032 [Thread-359] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:01,032 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:01,034 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:01,034 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:01,035 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:01,035 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:01,036 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40488
2020-04-02 05:09:01,036 [Thread-359] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:01,038 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@dc813b6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:01,038 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@990a4ac{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:01,042 [Thread-413] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 31570cf7-70bb-4a63-9199-32333f90bc23
2020-04-02 05:09:01,046 [Thread-437] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:01,046 [Thread-437] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1632793555. Formatting...
2020-04-02 05:09:01,047 [Thread-437] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-698d701a-7991-41cd-9a17-adce3e1f3ad9 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:09:01,050 [Thread-413] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-cea4480b-5159-448f-9e29-d4a50c371ed3
2020-04-02 05:09:01,050 [Thread-413] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:09:01,052 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@180988b0{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:01,052 [Thread-359] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6d8cfe11{HTTP/1.1,[http/1.1]}{localhost:40488}
2020-04-02 05:09:01,053 [Thread-359] INFO  server.Server (Server.java:doStart(419)) - Started @11463ms
2020-04-02 05:09:01,072 [Thread-413] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-e07a8967-b41f-4089-8035-d20cb21c35fb
2020-04-02 05:09:01,073 [Thread-413] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:09:01,082 [Thread-413] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:01,083 [Thread-413] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:01,084 [Thread-413] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:01,085 [Thread-413] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:01,085 [Thread-413] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:01,085 [Thread-437] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,086 [Thread-437] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,086 [Thread-437] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1486927160-172.17.0.14-1585804140181 is not formatted. Formatting ...
2020-04-02 05:09:01,086 [Thread-437] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1486927160-172.17.0.14-1585804140181 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1486927160-172.17.0.14-1585804140181/current
2020-04-02 05:09:01,089 [Thread-413] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,090 [Thread-456] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:09:01,090 [Thread-457] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:09:01,131 [Thread-359] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42020
2020-04-02 05:09:01,132 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2c872e68] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:01,132 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:01,132 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:01,133 [Thread-359] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:01,134 [Socket Reader #1 for port 40490] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40490
2020-04-02 05:09:01,141 [Thread-359] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40490
2020-04-02 05:09:01,178 [Thread-359] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:01,179 [Thread-359] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:01,202 [Thread-437] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,202 [Thread-437] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,203 [Thread-437] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1486927160-172.17.0.14-1585804140181 is not formatted. Formatting ...
2020-04-02 05:09:01,203 [Thread-437] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1486927160-172.17.0.14-1585804140181 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1486927160-172.17.0.14-1585804140181/current
2020-04-02 05:09:01,214 [Thread-466] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46429 starting to offer service
2020-04-02 05:09:01,218 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:01,218 [IPC Server listener on 40490] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40490: starting
2020-04-02 05:09:01,221 [Thread-456] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1486927160-172.17.0.14-1585804140181 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 131ms
2020-04-02 05:09:01,222 [Thread-359] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40490 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:01,223 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:09:01,236 [Thread-457] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1486927160-172.17.0.14-1585804140181 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 147ms
2020-04-02 05:09:01,237 [Thread-413] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1486927160-172.17.0.14-1585804140181: 149ms
2020-04-02 05:09:01,238 [Thread-437] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1632793555;bpid=BP-1486927160-172.17.0.14-1585804140181;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1632793555;c=1585804140181;bpid=BP-1486927160-172.17.0.14-1585804140181;dnuuid=null
2020-04-02 05:09:01,238 [Thread-359] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:09:01,239 [Thread-477] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:09:01,239 [Thread-477] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1486927160-172.17.0.14-1585804140181/current/replicas doesn't exist 
2020-04-02 05:09:01,240 [Thread-477] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:09:01,240 [Thread-478] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:09:01,240 [Thread-478] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1486927160-172.17.0.14-1585804140181/current/replicas doesn't exist 
2020-04-02 05:09:01,240 [Thread-478] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:09:01,270 [Thread-359] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:09:01,272 [Thread-359] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:01,278 [Thread-359] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:01,278 [Thread-359] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:01,278 [Thread-359] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:01,279 [Thread-359] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:01,279 [Thread-359] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:01,279 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:01,280 [Thread-359] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:38052
2020-04-02 05:09:01,280 [Thread-359] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:01,280 [Thread-359] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:01,281 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:01,282 [Thread-466] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46429
2020-04-02 05:09:01,283 [Thread-359] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:01,284 [Thread-359] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:01,284 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:01,285 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:01,286 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:01,286 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:01,286 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:01,287 [Thread-413] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181: 49ms
2020-04-02 05:09:01,288 [Thread-437] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID c2d9af8a-9989-4e6e-8027-9383819b4df6
2020-04-02 05:09:01,289 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:01,289 [Thread-466] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:01,289 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-e07a8967-b41f-4089-8035-d20cb21c35fb): finished scanning block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,289 [Thread-413] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:09 AM with interval of 21600000ms
2020-04-02 05:09:01,289 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:01,290 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-cea4480b-5159-448f-9e29-d4a50c371ed3): finished scanning block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,290 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-e07a8967-b41f-4089-8035-d20cb21c35fb): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:09:01,290 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-cea4480b-5159-448f-9e29-d4a50c371ed3): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:09:01,293 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid 31570cf7-70bb-4a63-9199-32333f90bc23) service to localhost/127.0.0.1:46429 beginning handshake with NN
2020-04-02 05:09:01,295 [Thread-437] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-147fd5b8-349a-4f9c-a815-be1af224249e
2020-04-02 05:09:01,295 [Thread-437] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:09:01,294 [Thread-466] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:01,302 [Thread-466] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1632793555. Formatting...
2020-04-02 05:09:01,303 [Thread-466] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2a7db348-c283-4bea-90a8-f23c1428c357 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:09:01,302 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41293
2020-04-02 05:09:01,303 [Thread-359] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:01,306 [Thread-437] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-698d701a-7991-41cd-9a17-adce3e1f3ad9
2020-04-02 05:09:01,306 [Thread-437] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:09:01,307 [Thread-437] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:01,308 [Thread-437] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:09:01,309 [IPC Server handler 3 on 46429] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36280, datanodeUuid=31570cf7-70bb-4a63-9199-32333f90bc23, infoPort=38233, infoSecurePort=0, ipcPort=45970, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181) storage 31570cf7-70bb-4a63-9199-32333f90bc23
2020-04-02 05:09:01,309 [IPC Server handler 3 on 46429] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36280
2020-04-02 05:09:01,309 [IPC Server handler 3 on 46429] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 31570cf7-70bb-4a63-9199-32333f90bc23 (127.0.0.1:36280).
2020-04-02 05:09:01,311 [Thread-437] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:09:01,311 [Thread-437] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:01,311 [Thread-437] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:01,311 [Thread-466] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:01,311 [Thread-466] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1632793555. Formatting...
2020-04-02 05:09:01,312 [Thread-466] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-22bd7456-d5b8-4b50-8c87-e06f621f0017 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:09:01,326 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@77e2de27{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:01,326 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1e0761c6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:01,335 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid 31570cf7-70bb-4a63-9199-32333f90bc23) service to localhost/127.0.0.1:46429 successfully registered with NN
2020-04-02 05:09:01,335 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46429 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:01,339 [Thread-437] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,344 [Thread-490] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:09:01,347 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7935c823{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:01,348 [Thread-359] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@67a8df83{HTTP/1.1,[http/1.1]}{localhost:41293}
2020-04-02 05:09:01,349 [Thread-359] INFO  server.Server (Server.java:doStart(419)) - Started @11759ms
2020-04-02 05:09:01,349 [Thread-491] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:09:01,379 [IPC Server handler 4 on 46429] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-cea4480b-5159-448f-9e29-d4a50c371ed3 for DN 127.0.0.1:36280
2020-04-02 05:09:01,379 [IPC Server handler 4 on 46429] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e07a8967-b41f-4089-8035-d20cb21c35fb for DN 127.0.0.1:36280
2020-04-02 05:09:01,401 [Thread-466] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,402 [Thread-466] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,402 [Thread-466] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1486927160-172.17.0.14-1585804140181 is not formatted. Formatting ...
2020-04-02 05:09:01,402 [Thread-466] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1486927160-172.17.0.14-1585804140181 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1486927160-172.17.0.14-1585804140181/current
2020-04-02 05:09:01,402 [IPC Server handler 5 on 46429] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:36280, datanodeUuid=31570cf7-70bb-4a63-9199-32333f90bc23, infoPort=38233, infoSecurePort=0, ipcPort=45970, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), reports.length=2
2020-04-02 05:09:01,403 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x3e4832dcad501cca: Processing first storage report for DS-cea4480b-5159-448f-9e29-d4a50c371ed3 from datanode 31570cf7-70bb-4a63-9199-32333f90bc23
2020-04-02 05:09:01,405 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x3e4832dcad501cca: from storage DS-cea4480b-5159-448f-9e29-d4a50c371ed3 node DatanodeRegistration(127.0.0.1:36280, datanodeUuid=31570cf7-70bb-4a63-9199-32333f90bc23, infoPort=38233, infoSecurePort=0, ipcPort=45970, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:01,405 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x3e4832dcad501cca: Processing first storage report for DS-e07a8967-b41f-4089-8035-d20cb21c35fb from datanode 31570cf7-70bb-4a63-9199-32333f90bc23
2020-04-02 05:09:01,405 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x3e4832dcad501cca: from storage DS-e07a8967-b41f-4089-8035-d20cb21c35fb node DatanodeRegistration(127.0.0.1:36280, datanodeUuid=31570cf7-70bb-4a63-9199-32333f90bc23, infoPort=38233, infoSecurePort=0, ipcPort=45970, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:01,405 [IPC Server handler 5 on 46429] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x3e4832dcad501cca
2020-04-02 05:09:01,408 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x3e4832dcad501cca,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 24 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:01,408 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,429 [Thread-466] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,429 [Thread-466] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,429 [Thread-466] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1486927160-172.17.0.14-1585804140181 is not formatted. Formatting ...
2020-04-02 05:09:01,429 [Thread-466] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1486927160-172.17.0.14-1585804140181 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1486927160-172.17.0.14-1585804140181/current
2020-04-02 05:09:01,450 [Thread-466] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1632793555;bpid=BP-1486927160-172.17.0.14-1585804140181;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1632793555;c=1585804140181;bpid=BP-1486927160-172.17.0.14-1585804140181;dnuuid=null
2020-04-02 05:09:01,454 [Thread-359] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41357
2020-04-02 05:09:01,455 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:01,455 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:01,455 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4ab36bfb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:01,456 [Thread-359] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:01,462 [Thread-466] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 2e9e3c88-d3b6-4f24-93ed-3ab840d73a49
2020-04-02 05:09:01,464 [Socket Reader #1 for port 42294] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42294
2020-04-02 05:09:01,464 [Thread-466] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-2a7db348-c283-4bea-90a8-f23c1428c357
2020-04-02 05:09:01,470 [Thread-466] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:09:01,511 [Thread-490] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1486927160-172.17.0.14-1585804140181 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 167ms
2020-04-02 05:09:01,515 [Thread-359] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:42294
2020-04-02 05:09:01,516 [Thread-491] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1486927160-172.17.0.14-1585804140181 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 167ms
2020-04-02 05:09:01,516 [Thread-437] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1486927160-172.17.0.14-1585804140181: 177ms
2020-04-02 05:09:01,521 [Thread-359] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:01,521 [Thread-359] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:01,522 [Thread-502] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46429 starting to offer service
2020-04-02 05:09:01,523 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:01,524 [IPC Server listener on 42294] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42294: starting
2020-04-02 05:09:01,530 [Thread-359] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 42294 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:01,531 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:09:01,532 [Thread-359] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:09:01,533 [Thread-359] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:09:01,534 [Thread-359] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:01,534 [Thread-359] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:01,535 [Thread-359] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:01,535 [Thread-359] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:01,535 [Thread-359] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:01,535 [Thread-359] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:01,536 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:01,546 [Thread-359] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:35062
2020-04-02 05:09:01,546 [Thread-359] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:01,546 [Thread-359] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:01,547 [Thread-499] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:09:01,547 [Thread-499] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1486927160-172.17.0.14-1585804140181/current/replicas doesn't exist 
2020-04-02 05:09:01,548 [Thread-499] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-04-02 05:09:01,555 [Thread-466] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-22bd7456-d5b8-4b50-8c87-e06f621f0017
2020-04-02 05:09:01,557 [Thread-466] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:09:01,557 [Thread-516] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:09:01,557 [Thread-466] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:01,557 [Thread-516] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1486927160-172.17.0.14-1585804140181/current/replicas doesn't exist 
2020-04-02 05:09:01,557 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:01,558 [Thread-516] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-04-02 05:09:01,558 [Thread-466] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:09:01,559 [Thread-466] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:09:01,560 [Thread-466] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:09:01,560 [Thread-359] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:01,560 [Thread-359] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:01,561 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:01,576 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:01,576 [Thread-466] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:09:01,579 [Thread-466] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,588 [Thread-518] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:09:01,593 [Thread-437] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181: 77ms
2020-04-02 05:09:01,593 [Thread-519] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:09:01,594 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:09:01,594 [Thread-437] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:36 AM with interval of 21600000ms
2020-04-02 05:09:01,595 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:01,595 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-147fd5b8-349a-4f9c-a815-be1af224249e): finished scanning block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,595 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-698d701a-7991-41cd-9a17-adce3e1f3ad9): finished scanning block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,597 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid c2d9af8a-9989-4e6e-8027-9383819b4df6) service to localhost/127.0.0.1:46429 beginning handshake with NN
2020-04-02 05:09:01,597 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-698d701a-7991-41cd-9a17-adce3e1f3ad9): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:09:01,597 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:01,598 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:01,624 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:01,625 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41147
2020-04-02 05:09:01,625 [Thread-359] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:01,598 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-147fd5b8-349a-4f9c-a815-be1af224249e): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:09:01,630 [Thread-502] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46429
2020-04-02 05:09:01,630 [IPC Server handler 1 on 46429] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41614, datanodeUuid=c2d9af8a-9989-4e6e-8027-9383819b4df6, infoPort=40941, infoSecurePort=0, ipcPort=37290, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181) storage c2d9af8a-9989-4e6e-8027-9383819b4df6
2020-04-02 05:09:01,631 [IPC Server handler 1 on 46429] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41614
2020-04-02 05:09:01,631 [IPC Server handler 1 on 46429] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c2d9af8a-9989-4e6e-8027-9383819b4df6 (127.0.0.1:41614).
2020-04-02 05:09:01,632 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid c2d9af8a-9989-4e6e-8027-9383819b4df6) service to localhost/127.0.0.1:46429 successfully registered with NN
2020-04-02 05:09:01,632 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46429 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:01,633 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@500d5da2{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:01,651 [IPC Server handler 2 on 46429] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-147fd5b8-349a-4f9c-a815-be1af224249e for DN 127.0.0.1:41614
2020-04-02 05:09:01,642 [Thread-502] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:01,681 [IPC Server handler 2 on 46429] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-698d701a-7991-41cd-9a17-adce3e1f3ad9 for DN 127.0.0.1:41614
2020-04-02 05:09:01,687 [IPC Server handler 3 on 46429] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:41614, datanodeUuid=c2d9af8a-9989-4e6e-8027-9383819b4df6, infoPort=40941, infoSecurePort=0, ipcPort=37290, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), reports.length=2
2020-04-02 05:09:01,687 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xcec5361cafc14820: Processing first storage report for DS-147fd5b8-349a-4f9c-a815-be1af224249e from datanode c2d9af8a-9989-4e6e-8027-9383819b4df6
2020-04-02 05:09:01,687 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xcec5361cafc14820: from storage DS-147fd5b8-349a-4f9c-a815-be1af224249e node DatanodeRegistration(127.0.0.1:41614, datanodeUuid=c2d9af8a-9989-4e6e-8027-9383819b4df6, infoPort=40941, infoSecurePort=0, ipcPort=37290, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:09:01,688 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xcec5361cafc14820: Processing first storage report for DS-698d701a-7991-41cd-9a17-adce3e1f3ad9 from datanode c2d9af8a-9989-4e6e-8027-9383819b4df6
2020-04-02 05:09:01,688 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xcec5361cafc14820: from storage DS-698d701a-7991-41cd-9a17-adce3e1f3ad9 node DatanodeRegistration(127.0.0.1:41614, datanodeUuid=c2d9af8a-9989-4e6e-8027-9383819b4df6, infoPort=40941, infoSecurePort=0, ipcPort=37290, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:01,688 [IPC Server handler 3 on 46429] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xcec5361cafc14820
2020-04-02 05:09:01,690 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xcec5361cafc14820,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:01,690 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,699 [Thread-519] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1486927160-172.17.0.14-1585804140181 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 105ms
2020-04-02 05:09:01,712 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d466016{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:01,713 [Thread-502] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:01,714 [Thread-502] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1632793555. Formatting...
2020-04-02 05:09:01,714 [Thread-502] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-45c150a4-6239-43b7-b910-94f498851d60 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-04-02 05:09:01,718 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4016fc6a{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:01,719 [Thread-359] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7bb6d3ae{HTTP/1.1,[http/1.1]}{localhost:41147}
2020-04-02 05:09:01,719 [Thread-359] INFO  server.Server (Server.java:doStart(419)) - Started @12130ms
2020-04-02 05:09:01,723 [Thread-518] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1486927160-172.17.0.14-1585804140181 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 135ms
2020-04-02 05:09:01,753 [Thread-466] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1486927160-172.17.0.14-1585804140181: 174ms
2020-04-02 05:09:01,742 [Thread-502] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:01,754 [Thread-502] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1632793555. Formatting...
2020-04-02 05:09:01,754 [Thread-502] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-878baa2c-a649-4436-817d-80e490ac7842 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-04-02 05:09:01,755 [Thread-528] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:09:01,755 [Thread-529] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:09:01,755 [Thread-528] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1486927160-172.17.0.14-1585804140181/current/replicas doesn't exist 
2020-04-02 05:09:01,755 [Thread-529] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1486927160-172.17.0.14-1585804140181/current/replicas doesn't exist 
2020-04-02 05:09:01,756 [Thread-529] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 0ms
2020-04-02 05:09:01,756 [Thread-528] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 1ms
2020-04-02 05:09:01,764 [Thread-466] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181: 10ms
2020-04-02 05:09:01,764 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:09:01,764 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:09:01,765 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-2a7db348-c283-4bea-90a8-f23c1428c357): finished scanning block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,765 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-22bd7456-d5b8-4b50-8c87-e06f621f0017): finished scanning block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,765 [Thread-466] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:21 AM with interval of 21600000ms
2020-04-02 05:09:01,768 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-2a7db348-c283-4bea-90a8-f23c1428c357): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:09:01,773 [Thread-359] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35491
2020-04-02 05:09:01,776 [Thread-502] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,776 [Thread-502] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,776 [Thread-502] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1486927160-172.17.0.14-1585804140181 is not formatted. Formatting ...
2020-04-02 05:09:01,777 [Thread-502] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1486927160-172.17.0.14-1585804140181 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1486927160-172.17.0.14-1585804140181/current
2020-04-02 05:09:01,783 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:01,783 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:01,786 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6d38cedc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:01,785 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-22bd7456-d5b8-4b50-8c87-e06f621f0017): no suitable block pools found to scan.  Waiting 1814399979 ms.
2020-04-02 05:09:01,788 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid 2e9e3c88-d3b6-4f24-93ed-3ab840d73a49) service to localhost/127.0.0.1:46429 beginning handshake with NN
2020-04-02 05:09:01,789 [Thread-359] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:01,790 [IPC Server handler 4 on 46429] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34039, datanodeUuid=2e9e3c88-d3b6-4f24-93ed-3ab840d73a49, infoPort=42020, infoSecurePort=0, ipcPort=40490, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181) storage 2e9e3c88-d3b6-4f24-93ed-3ab840d73a49
2020-04-02 05:09:01,790 [IPC Server handler 4 on 46429] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34039
2020-04-02 05:09:01,790 [IPC Server handler 4 on 46429] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2e9e3c88-d3b6-4f24-93ed-3ab840d73a49 (127.0.0.1:34039).
2020-04-02 05:09:01,790 [Socket Reader #1 for port 32933] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 32933
2020-04-02 05:09:01,803 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid 2e9e3c88-d3b6-4f24-93ed-3ab840d73a49) service to localhost/127.0.0.1:46429 successfully registered with NN
2020-04-02 05:09:01,803 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46429 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:01,803 [Thread-359] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:32933
2020-04-02 05:09:01,822 [Thread-502] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,824 [Thread-502] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,825 [Thread-502] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1486927160-172.17.0.14-1585804140181 is not formatted. Formatting ...
2020-04-02 05:09:01,825 [Thread-502] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1486927160-172.17.0.14-1585804140181 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1486927160-172.17.0.14-1585804140181/current
2020-04-02 05:09:01,824 [Thread-359] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:01,826 [Thread-359] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:01,834 [Thread-539] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46429 starting to offer service
2020-04-02 05:09:01,834 [IPC Server handler 5 on 46429] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2a7db348-c283-4bea-90a8-f23c1428c357 for DN 127.0.0.1:34039
2020-04-02 05:09:01,840 [IPC Server handler 5 on 46429] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-22bd7456-d5b8-4b50-8c87-e06f621f0017 for DN 127.0.0.1:34039
2020-04-02 05:09:01,843 [Thread-539] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46429
2020-04-02 05:09:01,843 [Thread-502] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1632793555;bpid=BP-1486927160-172.17.0.14-1585804140181;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1632793555;c=1585804140181;bpid=BP-1486927160-172.17.0.14-1585804140181;dnuuid=null
2020-04-02 05:09:01,845 [Thread-502] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID ba3e5711-21ac-4347-945f-dcf4d33687ed
2020-04-02 05:09:01,849 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:01,849 [IPC Server listener on 32933] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 32933: starting
2020-04-02 05:09:01,858 [Thread-539] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:01,859 [Thread-539] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:01,860 [Thread-539] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 1632793555. Formatting...
2020-04-02 05:09:01,860 [IPC Server handler 9 on 46429] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:34039, datanodeUuid=2e9e3c88-d3b6-4f24-93ed-3ab840d73a49, infoPort=42020, infoSecurePort=0, ipcPort=40490, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), reports.length=2
2020-04-02 05:09:01,860 [Thread-539] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-32e9c9e0-4513-42ee-9675-abcf2e3d687b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-04-02 05:09:01,860 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf6d197e57dbcc73b: Processing first storage report for DS-22bd7456-d5b8-4b50-8c87-e06f621f0017 from datanode 2e9e3c88-d3b6-4f24-93ed-3ab840d73a49
2020-04-02 05:09:01,860 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf6d197e57dbcc73b: from storage DS-22bd7456-d5b8-4b50-8c87-e06f621f0017 node DatanodeRegistration(127.0.0.1:34039, datanodeUuid=2e9e3c88-d3b6-4f24-93ed-3ab840d73a49, infoPort=42020, infoSecurePort=0, ipcPort=40490, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:01,860 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf6d197e57dbcc73b: Processing first storage report for DS-2a7db348-c283-4bea-90a8-f23c1428c357 from datanode 2e9e3c88-d3b6-4f24-93ed-3ab840d73a49
2020-04-02 05:09:01,860 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf6d197e57dbcc73b: from storage DS-2a7db348-c283-4bea-90a8-f23c1428c357 node DatanodeRegistration(127.0.0.1:34039, datanodeUuid=2e9e3c88-d3b6-4f24-93ed-3ab840d73a49, infoPort=42020, infoSecurePort=0, ipcPort=40490, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:01,860 [IPC Server handler 9 on 46429] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xf6d197e57dbcc73b
2020-04-02 05:09:01,864 [Thread-359] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 32933 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:01,867 [Thread-539] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:01,871 [Thread-539] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 1632793555. Formatting...
2020-04-02 05:09:01,872 [Thread-539] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-baf60bac-f625-47b7-864c-ca2826e89d8e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-04-02 05:09:01,867 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:09:01,867 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xf6d197e57dbcc73b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:01,872 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,873 [Thread-502] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-45c150a4-6239-43b7-b910-94f498851d60
2020-04-02 05:09:01,920 [Thread-502] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:09:01,922 [Thread-502] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-878baa2c-a649-4436-817d-80e490ac7842
2020-04-02 05:09:01,922 [Thread-502] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:09:01,923 [Thread-502] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:01,930 [Thread-359] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:09:01,931 [Thread-502] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:09:01,939 [Thread-539] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,940 [Thread-539] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,940 [Thread-539] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-1486927160-172.17.0.14-1585804140181 is not formatted. Formatting ...
2020-04-02 05:09:01,940 [Thread-539] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1486927160-172.17.0.14-1585804140181 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1486927160-172.17.0.14-1585804140181/current
2020-04-02 05:09:01,941 [Thread-359] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:09:01,944 [Thread-502] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:09:01,944 [Thread-502] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:09:01,944 [Thread-502] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:09:01,958 [Thread-359] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:01,958 [Thread-359] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:01,958 [Thread-359] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:01,959 [Thread-359] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:01,959 [Thread-359] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:01,959 [Thread-359] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:01,960 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:01,960 [Thread-359] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:36855
2020-04-02 05:09:01,961 [Thread-359] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:01,961 [Thread-359] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:01,958 [Thread-502] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:01,962 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:01,963 [Thread-555] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:09:01,964 [Thread-359] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:01,965 [Thread-556] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:09:01,965 [Thread-359] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:01,966 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:01,967 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:01,968 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:01,968 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:01,968 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:01,969 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35349
2020-04-02 05:09:01,969 [Thread-359] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:01,970 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@71ba55cb{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:01,971 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a3b770{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:01,976 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@17bdc055{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:01,977 [Thread-359] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1aa9630d{HTTP/1.1,[http/1.1]}{localhost:35349}
2020-04-02 05:09:01,977 [Thread-359] INFO  server.Server (Server.java:doStart(419)) - Started @12387ms
2020-04-02 05:09:02,032 [Thread-539] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:02,041 [Thread-539] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:02,041 [Thread-539] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-1486927160-172.17.0.14-1585804140181 is not formatted. Formatting ...
2020-04-02 05:09:02,041 [Thread-539] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1486927160-172.17.0.14-1585804140181 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1486927160-172.17.0.14-1585804140181/current
2020-04-02 05:09:02,046 [Thread-539] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1632793555;bpid=BP-1486927160-172.17.0.14-1585804140181;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1632793555;c=1585804140181;bpid=BP-1486927160-172.17.0.14-1585804140181;dnuuid=null
2020-04-02 05:09:02,060 [Thread-539] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 5395e94e-1a47-416a-a398-f204c01205d3
2020-04-02 05:09:02,069 [Thread-556] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1486927160-172.17.0.14-1585804140181 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 104ms
2020-04-02 05:09:02,070 [Thread-539] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-32e9c9e0-4513-42ee-9675-abcf2e3d687b
2020-04-02 05:09:02,070 [Thread-539] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-04-02 05:09:02,072 [Thread-539] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-baf60bac-f625-47b7-864c-ca2826e89d8e
2020-04-02 05:09:02,072 [Thread-539] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-04-02 05:09:02,072 [Thread-539] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:02,073 [Thread-539] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:09:02,074 [Thread-539] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:09:02,106 [Thread-539] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:09:02,112 [Thread-539] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:09:02,118 [Thread-555] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1486927160-172.17.0.14-1585804140181 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 155ms
2020-04-02 05:09:02,132 [Thread-502] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1486927160-172.17.0.14-1585804140181: 170ms
2020-04-02 05:09:02,133 [Thread-564] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:09:02,133 [Thread-564] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1486927160-172.17.0.14-1585804140181/current/replicas doesn't exist 
2020-04-02 05:09:02,129 [Thread-359] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44633
2020-04-02 05:09:02,133 [Thread-565] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:09:02,142 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:02,143 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:02,143 [IPC Server handler 7 on 46003] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:36142, datanodeUuid=b830a9b1-fa6b-4bea-b8f7-dff8c35c043b, infoPort=34497, infoSecurePort=0, ipcPort=32823, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), reports.length=2
2020-04-02 05:09:02,143 [Thread-359] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:02,144 [Socket Reader #1 for port 43837] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43837
2020-04-02 05:09:02,133 [IPC Server handler 4 on 46003] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:42843, datanodeUuid=cf3eecb1-bd14-4122-95a1-3e277869dc39, infoPort=44561, infoSecurePort=0, ipcPort=45598, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), reports.length=2
2020-04-02 05:09:02,147 [Thread-359] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43837
2020-04-02 05:09:02,142 [Thread-565] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1486927160-172.17.0.14-1585804140181/current/replicas doesn't exist 
2020-04-02 05:09:02,142 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4d633a5e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:02,148 [Thread-565] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 6ms
2020-04-02 05:09:02,156 [Thread-564] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 23ms
2020-04-02 05:09:02,159 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb3d8405bf3f4e1cb: Processing first storage report for DS-998237d1-de80-4cf4-b032-ef5991f68f92 from datanode b830a9b1-fa6b-4bea-b8f7-dff8c35c043b
2020-04-02 05:09:02,159 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb3d8405bf3f4e1cb: from storage DS-998237d1-de80-4cf4-b032-ef5991f68f92 node DatanodeRegistration(127.0.0.1:36142, datanodeUuid=b830a9b1-fa6b-4bea-b8f7-dff8c35c043b, infoPort=34497, infoSecurePort=0, ipcPort=32823, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:02,159 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x283a76b0ace5367f: Processing first storage report for DS-9e221eab-2732-49d2-b93b-e289117101ee from datanode cf3eecb1-bd14-4122-95a1-3e277869dc39
2020-04-02 05:09:02,159 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x283a76b0ace5367f: from storage DS-9e221eab-2732-49d2-b93b-e289117101ee node DatanodeRegistration(127.0.0.1:42843, datanodeUuid=cf3eecb1-bd14-4122-95a1-3e277869dc39, infoPort=44561, infoSecurePort=0, ipcPort=45598, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:09:02,160 [Thread-502] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181: 27ms
2020-04-02 05:09:02,160 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb3d8405bf3f4e1cb: Processing first storage report for DS-6b0808c3-6154-4d68-af84-9c6406ac52f0 from datanode b830a9b1-fa6b-4bea-b8f7-dff8c35c043b
2020-04-02 05:09:02,160 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb3d8405bf3f4e1cb: from storage DS-6b0808c3-6154-4d68-af84-9c6406ac52f0 node DatanodeRegistration(127.0.0.1:36142, datanodeUuid=b830a9b1-fa6b-4bea-b8f7-dff8c35c043b, infoPort=34497, infoSecurePort=0, ipcPort=32823, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:02,160 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x283a76b0ace5367f: Processing first storage report for DS-63829bc4-26b0-4710-ab7c-ad8fbd49701a from datanode cf3eecb1-bd14-4122-95a1-3e277869dc39
2020-04-02 05:09:02,160 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x283a76b0ace5367f: from storage DS-63829bc4-26b0-4710-ab7c-ad8fbd49701a node DatanodeRegistration(127.0.0.1:42843, datanodeUuid=cf3eecb1-bd14-4122-95a1-3e277869dc39, infoPort=44561, infoSecurePort=0, ipcPort=45598, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:02,160 [IPC Server handler 4 on 46003] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x283a76b0ace5367f
2020-04-02 05:09:02,160 [Thread-502] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:09 AM with interval of 21600000ms
2020-04-02 05:09:02,161 [IPC Server handler 7 on 46003] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xb3d8405bf3f4e1cb
2020-04-02 05:09:02,161 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x283a76b0ace5367f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 32 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:02,161 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:09:02,159 [Thread-359] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:02,163 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid ba3e5711-21ac-4347-945f-dcf4d33687ed) service to localhost/127.0.0.1:46429 beginning handshake with NN
2020-04-02 05:09:02,161 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xb3d8405bf3f4e1cb,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 28 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:02,164 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:09:02,164 [Thread-359] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:02,165 [Thread-575] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46429 starting to offer service
2020-04-02 05:09:02,165 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:02,166 [IPC Server listener on 43837] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43837: starting
2020-04-02 05:09:02,160 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:09:02,160 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:09:02,167 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-878baa2c-a649-4436-817d-80e490ac7842): finished scanning block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:02,167 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-45c150a4-6239-43b7-b910-94f498851d60): finished scanning block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:02,168 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-878baa2c-a649-4436-817d-80e490ac7842): no suitable block pools found to scan.  Waiting 1814399992 ms.
2020-04-02 05:09:02,168 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-45c150a4-6239-43b7-b910-94f498851d60): no suitable block pools found to scan.  Waiting 1814399992 ms.
2020-04-02 05:09:02,160 [Thread-539] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:02,175 [Thread-578] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:09:02,175 [Thread-586] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:09:02,182 [IPC Server handler 6 on 46429] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38052, datanodeUuid=ba3e5711-21ac-4347-945f-dcf4d33687ed, infoPort=41357, infoSecurePort=0, ipcPort=42294, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181) storage ba3e5711-21ac-4347-945f-dcf4d33687ed
2020-04-02 05:09:02,182 [IPC Server handler 6 on 46429] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38052
2020-04-02 05:09:02,182 [IPC Server handler 6 on 46429] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ba3e5711-21ac-4347-945f-dcf4d33687ed (127.0.0.1:38052).
2020-04-02 05:09:02,182 [Thread-359] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43837 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:02,184 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid ba3e5711-21ac-4347-945f-dcf4d33687ed) service to localhost/127.0.0.1:46429 successfully registered with NN
2020-04-02 05:09:02,184 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46429 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:02,184 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:09:02,193 [Thread-359] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:09:02,194 [Thread-359] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:09:02,194 [Thread-575] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46429
2020-04-02 05:09:02,222 [Thread-575] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:02,244 [Thread-359] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:02,244 [Thread-359] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:02,246 [Thread-359] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:02,258 [Thread-359] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:02,253 [IPC Server handler 0 on 46429] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-45c150a4-6239-43b7-b910-94f498851d60 for DN 127.0.0.1:38052
2020-04-02 05:09:02,259 [IPC Server handler 0 on 46429] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-878baa2c-a649-4436-817d-80e490ac7842 for DN 127.0.0.1:38052
2020-04-02 05:09:02,262 [Thread-575] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:02,262 [Thread-359] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:02,276 [Thread-359] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:02,277 [Thread-575] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 1632793555. Formatting...
2020-04-02 05:09:02,277 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:02,277 [Thread-575] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f93514d7-ea4d-46b4-aa07-346ab362fcb6 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-04-02 05:09:02,278 [Thread-359] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:35664
2020-04-02 05:09:02,279 [Thread-359] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:02,279 [Thread-359] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:02,280 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:02,281 [Thread-575] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:02,298 [Thread-575] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 1632793555. Formatting...
2020-04-02 05:09:02,299 [Thread-575] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a82d5f8f-be71-44b4-b962-7dcebe33da1c for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-04-02 05:09:02,300 [Thread-359] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:02,317 [Thread-359] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:02,317 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:02,347 [Thread-578] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1486927160-172.17.0.14-1585804140181 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 173ms
2020-04-02 05:09:02,350 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:02,350 [IPC Server handler 1 on 46429] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:38052, datanodeUuid=ba3e5711-21ac-4347-945f-dcf4d33687ed, infoPort=41357, infoSecurePort=0, ipcPort=42294, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), reports.length=2
2020-04-02 05:09:02,354 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:02,355 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:02,355 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:02,356 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34005
2020-04-02 05:09:02,356 [Thread-359] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:02,357 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x1236688a4f805594: Processing first storage report for DS-45c150a4-6239-43b7-b910-94f498851d60 from datanode ba3e5711-21ac-4347-945f-dcf4d33687ed
2020-04-02 05:09:02,357 [Thread-586] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1486927160-172.17.0.14-1585804140181 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 183ms
2020-04-02 05:09:02,358 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x1236688a4f805594: from storage DS-45c150a4-6239-43b7-b910-94f498851d60 node DatanodeRegistration(127.0.0.1:38052, datanodeUuid=ba3e5711-21ac-4347-945f-dcf4d33687ed, infoPort=41357, infoSecurePort=0, ipcPort=42294, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:09:02,358 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x1236688a4f805594: Processing first storage report for DS-878baa2c-a649-4436-817d-80e490ac7842 from datanode ba3e5711-21ac-4347-945f-dcf4d33687ed
2020-04-02 05:09:02,358 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x1236688a4f805594: from storage DS-878baa2c-a649-4436-817d-80e490ac7842 node DatanodeRegistration(127.0.0.1:38052, datanodeUuid=ba3e5711-21ac-4347-945f-dcf4d33687ed, infoPort=41357, infoSecurePort=0, ipcPort=42294, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:02,358 [IPC Server handler 1 on 46429] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x1236688a4f805594
2020-04-02 05:09:02,359 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@391cb7b2{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:02,361 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x1236688a4f805594,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 56 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:02,361 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:02,370 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f70340a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:02,372 [Thread-539] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1486927160-172.17.0.14-1585804140181: 204ms
2020-04-02 05:09:02,372 [Thread-596] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:09:02,373 [Thread-596] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1486927160-172.17.0.14-1585804140181/current/replicas doesn't exist 
2020-04-02 05:09:02,373 [Thread-597] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:09:02,373 [Thread-597] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1486927160-172.17.0.14-1585804140181/current/replicas doesn't exist 
2020-04-02 05:09:02,373 [Thread-596] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 0ms
2020-04-02 05:09:02,373 [Thread-597] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 1ms
2020-04-02 05:09:02,386 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@312c8e39{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:02,389 [Thread-359] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@247315a9{HTTP/1.1,[http/1.1]}{localhost:34005}
2020-04-02 05:09:02,390 [Thread-359] INFO  server.Server (Server.java:doStart(419)) - Started @12800ms
2020-04-02 05:09:02,390 [Thread-539] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181: 18ms
2020-04-02 05:09:02,390 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:09:02,391 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-32e9c9e0-4513-42ee-9675-abcf2e3d687b): finished scanning block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:02,391 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-32e9c9e0-4513-42ee-9675-abcf2e3d687b): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:09:02,392 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:09:02,420 [Thread-575] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:02,438 [Thread-575] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:02,417 [Thread-539] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:30 AM with interval of 21600000ms
2020-04-02 05:09:02,438 [Thread-575] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-1486927160-172.17.0.14-1585804140181 is not formatted. Formatting ...
2020-04-02 05:09:02,443 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid 5395e94e-1a47-416a-a398-f204c01205d3) service to localhost/127.0.0.1:46429 beginning handshake with NN
2020-04-02 05:09:02,443 [Thread-575] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1486927160-172.17.0.14-1585804140181 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1486927160-172.17.0.14-1585804140181/current
2020-04-02 05:09:02,444 [IPC Server handler 2 on 46429] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35062, datanodeUuid=5395e94e-1a47-416a-a398-f204c01205d3, infoPort=35491, infoSecurePort=0, ipcPort=32933, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181) storage 5395e94e-1a47-416a-a398-f204c01205d3
2020-04-02 05:09:02,445 [IPC Server handler 2 on 46429] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35062
2020-04-02 05:09:02,445 [IPC Server handler 2 on 46429] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5395e94e-1a47-416a-a398-f204c01205d3 (127.0.0.1:35062).
2020-04-02 05:09:02,446 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid 5395e94e-1a47-416a-a398-f204c01205d3) service to localhost/127.0.0.1:46429 successfully registered with NN
2020-04-02 05:09:02,446 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46429 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:02,452 [IPC Server handler 3 on 46429] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-32e9c9e0-4513-42ee-9675-abcf2e3d687b for DN 127.0.0.1:35062
2020-04-02 05:09:02,453 [IPC Server handler 3 on 46429] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-baf60bac-f625-47b7-864c-ca2826e89d8e for DN 127.0.0.1:35062
2020-04-02 05:09:02,459 [IPC Server handler 9 on 46003] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:42028, datanodeUuid=7389bfe0-0e69-4d1e-818b-e4ae73da3315, infoPort=44984, infoSecurePort=0, ipcPort=41887, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), reports.length=2
2020-04-02 05:09:02,472 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x68013d3b740fab40: Processing first storage report for DS-d038668f-30ff-4c12-aa23-3dd382355fe2 from datanode 7389bfe0-0e69-4d1e-818b-e4ae73da3315
2020-04-02 05:09:02,472 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x68013d3b740fab40: from storage DS-d038668f-30ff-4c12-aa23-3dd382355fe2 node DatanodeRegistration(127.0.0.1:42028, datanodeUuid=7389bfe0-0e69-4d1e-818b-e4ae73da3315, infoPort=44984, infoSecurePort=0, ipcPort=41887, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:02,473 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x68013d3b740fab40: Processing first storage report for DS-254a211a-bd79-4ab5-b879-2c065d4d9e68 from datanode 7389bfe0-0e69-4d1e-818b-e4ae73da3315
2020-04-02 05:09:02,473 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x68013d3b740fab40: from storage DS-254a211a-bd79-4ab5-b879-2c065d4d9e68 node DatanodeRegistration(127.0.0.1:42028, datanodeUuid=7389bfe0-0e69-4d1e-818b-e4ae73da3315, infoPort=44984, infoSecurePort=0, ipcPort=41887, storageInfo=lv=-57;cid=testClusterID;nsid=873357056;c=1585804132033), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:02,473 [IPC Server handler 9 on 46003] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x68013d3b740fab40
2020-04-02 05:09:02,542 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-baf60bac-f625-47b7-864c-ca2826e89d8e): finished scanning block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:02,544 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-baf60bac-f625-47b7-864c-ca2826e89d8e): no suitable block pools found to scan.  Waiting 1814399846 ms.
2020-04-02 05:09:02,546 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x68013d3b740fab40,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 100 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:02,546 [BP-546423474-172.17.0.14-1585804132033 heartbeating to localhost/127.0.0.1:46003] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-546423474-172.17.0.14-1585804132033
2020-04-02 05:09:02,574 [IPC Server handler 4 on 46429] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:35062, datanodeUuid=5395e94e-1a47-416a-a398-f204c01205d3, infoPort=35491, infoSecurePort=0, ipcPort=32933, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), reports.length=2
2020-04-02 05:09:02,574 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe39bf38aa033519: Processing first storage report for DS-32e9c9e0-4513-42ee-9675-abcf2e3d687b from datanode 5395e94e-1a47-416a-a398-f204c01205d3
2020-04-02 05:09:02,574 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe39bf38aa033519: from storage DS-32e9c9e0-4513-42ee-9675-abcf2e3d687b node DatanodeRegistration(127.0.0.1:35062, datanodeUuid=5395e94e-1a47-416a-a398-f204c01205d3, infoPort=35491, infoSecurePort=0, ipcPort=32933, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:02,574 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe39bf38aa033519: Processing first storage report for DS-baf60bac-f625-47b7-864c-ca2826e89d8e from datanode 5395e94e-1a47-416a-a398-f204c01205d3
2020-04-02 05:09:02,575 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe39bf38aa033519: from storage DS-baf60bac-f625-47b7-864c-ca2826e89d8e node DatanodeRegistration(127.0.0.1:35062, datanodeUuid=5395e94e-1a47-416a-a398-f204c01205d3, infoPort=35491, infoSecurePort=0, ipcPort=32933, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:02,575 [IPC Server handler 4 on 46429] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xe39bf38aa033519
2020-04-02 05:09:02,576 [Thread-575] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:02,576 [Thread-575] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:02,576 [Thread-575] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-1486927160-172.17.0.14-1585804140181 is not formatted. Formatting ...
2020-04-02 05:09:02,577 [Thread-575] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1486927160-172.17.0.14-1585804140181 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1486927160-172.17.0.14-1585804140181/current
2020-04-02 05:09:02,578 [Thread-359] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33237
2020-04-02 05:09:02,584 [Thread-575] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1632793555;bpid=BP-1486927160-172.17.0.14-1585804140181;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1632793555;c=1585804140181;bpid=BP-1486927160-172.17.0.14-1585804140181;dnuuid=null
2020-04-02 05:09:02,586 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:02,586 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:02,586 [Thread-359] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:02,587 [Socket Reader #1 for port 37921] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37921
2020-04-02 05:09:02,583 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xe39bf38aa033519,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 23 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:02,588 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:02,589 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@34b30bfc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:02,592 [Thread-575] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 9d8cdd83-40bb-408e-bb18-63b20e5b9cd1
2020-04-02 05:09:02,593 [Thread-359] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:37921
2020-04-02 05:09:02,759 [Thread-575] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-f93514d7-ea4d-46b4-aa07-346ab362fcb6
2020-04-02 05:09:02,772 [Thread-575] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-04-02 05:09:02,773 [Thread-359] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:02,773 [Thread-359] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:02,782 [Thread-608] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46429 starting to offer service
2020-04-02 05:09:02,792 [Thread-575] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-a82d5f8f-be71-44b4-b962-7dcebe33da1c
2020-04-02 05:09:02,793 [Thread-575] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-04-02 05:09:02,793 [Thread-575] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:02,795 [Thread-575] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:09:02,797 [Thread-575] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:09:02,797 [Thread-575] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:09:02,826 [IPC Server listener on 37921] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37921: starting
2020-04-02 05:09:02,827 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:02,827 [Thread-575] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:09:02,846 [Thread-359] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 37921 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:02,847 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:09:02,847 [Thread-359] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:09:02,854 [Thread-575] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:02,854 [Thread-620] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:09:02,855 [Thread-621] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:09:02,855 [Thread-359] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:09:02,860 [Thread-359] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:02,860 [Thread-608] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46429
2020-04-02 05:09:02,860 [Thread-359] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:02,863 [Thread-359] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:02,863 [Thread-359] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:02,868 [Thread-359] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:02,869 [Thread-359] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:02,869 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:02,870 [Thread-359] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42402
2020-04-02 05:09:02,870 [Thread-359] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:02,870 [Thread-608] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:02,870 [Thread-359] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:02,871 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:02,873 [Thread-359] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:02,873 [Thread-608] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:02,873 [Thread-608] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 1632793555. Formatting...
2020-04-02 05:09:02,873 [Thread-608] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-74fcdc80-60df-46d7-8de8-9e7b0eb59a53 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-04-02 05:09:02,874 [Thread-359] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:02,874 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:02,875 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:02,876 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:02,876 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:02,876 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:02,876 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 32783
2020-04-02 05:09:02,877 [Thread-359] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:02,924 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@599cb335{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:02,930 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@277ab8e1{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:02,938 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6d670e0f{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:02,942 [Thread-359] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@17162395{HTTP/1.1,[http/1.1]}{localhost:32783}
2020-04-02 05:09:02,942 [Thread-359] INFO  server.Server (Server.java:doStart(419)) - Started @13352ms
2020-04-02 05:09:02,970 [Thread-608] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:02,971 [Thread-608] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 1632793555. Formatting...
2020-04-02 05:09:02,971 [Thread-608] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-fdc3b500-23f2-4371-acbb-7e3b537265fd for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-04-02 05:09:02,981 [Thread-620] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1486927160-172.17.0.14-1585804140181 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 127ms
2020-04-02 05:09:02,984 [Thread-608] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:02,984 [Thread-608] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:02,984 [Thread-608] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-1486927160-172.17.0.14-1585804140181 is not formatted. Formatting ...
2020-04-02 05:09:02,984 [Thread-608] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1486927160-172.17.0.14-1585804140181 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1486927160-172.17.0.14-1585804140181/current
2020-04-02 05:09:02,996 [Thread-608] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:02,996 [Thread-608] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:02,996 [Thread-608] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-1486927160-172.17.0.14-1585804140181 is not formatted. Formatting ...
2020-04-02 05:09:02,996 [Thread-621] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1486927160-172.17.0.14-1585804140181 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 141ms
2020-04-02 05:09:02,996 [Thread-608] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1486927160-172.17.0.14-1585804140181 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1486927160-172.17.0.14-1585804140181/current
2020-04-02 05:09:02,998 [Thread-575] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1486927160-172.17.0.14-1585804140181: 144ms
2020-04-02 05:09:02,999 [Thread-631] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:09:02,999 [Thread-630] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:09:02,999 [Thread-631] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1486927160-172.17.0.14-1585804140181/current/replicas doesn't exist 
2020-04-02 05:09:02,999 [Thread-630] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1486927160-172.17.0.14-1585804140181/current/replicas doesn't exist 
2020-04-02 05:09:03,000 [Thread-630] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 1ms
2020-04-02 05:09:03,000 [Thread-631] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 1ms
2020-04-02 05:09:03,000 [Thread-575] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181: 2ms
2020-04-02 05:09:03,000 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:09:03,000 [Thread-575] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:33 AM with interval of 21600000ms
2020-04-02 05:09:03,001 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-a82d5f8f-be71-44b4-b962-7dcebe33da1c): finished scanning block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,001 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:09:03,001 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-f93514d7-ea4d-46b4-aa07-346ab362fcb6): finished scanning block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,001 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-a82d5f8f-be71-44b4-b962-7dcebe33da1c): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:09:03,002 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-f93514d7-ea4d-46b4-aa07-346ab362fcb6): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:09:03,004 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid 9d8cdd83-40bb-408e-bb18-63b20e5b9cd1) service to localhost/127.0.0.1:46429 beginning handshake with NN
2020-04-02 05:09:03,007 [IPC Server handler 6 on 46429] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36855, datanodeUuid=9d8cdd83-40bb-408e-bb18-63b20e5b9cd1, infoPort=44633, infoSecurePort=0, ipcPort=43837, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181) storage 9d8cdd83-40bb-408e-bb18-63b20e5b9cd1
2020-04-02 05:09:03,007 [IPC Server handler 6 on 46429] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36855
2020-04-02 05:09:03,010 [Thread-608] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1632793555;bpid=BP-1486927160-172.17.0.14-1585804140181;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1632793555;c=1585804140181;bpid=BP-1486927160-172.17.0.14-1585804140181;dnuuid=null
2020-04-02 05:09:03,012 [IPC Server handler 6 on 46429] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9d8cdd83-40bb-408e-bb18-63b20e5b9cd1 (127.0.0.1:36855).
2020-04-02 05:09:03,013 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid 9d8cdd83-40bb-408e-bb18-63b20e5b9cd1) service to localhost/127.0.0.1:46429 successfully registered with NN
2020-04-02 05:09:03,014 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46429 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:03,027 [Thread-608] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 8bb44eb3-2505-4c54-8ed6-c9be07a5921d
2020-04-02 05:09:03,033 [Thread-359] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43493
2020-04-02 05:09:03,038 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:03,038 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:03,038 [Thread-359] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:03,040 [Socket Reader #1 for port 39650] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39650
2020-04-02 05:09:03,043 [Thread-359] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:39650
2020-04-02 05:09:03,050 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@69c6328a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:03,067 [IPC Server handler 8 on 46429] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f93514d7-ea4d-46b4-aa07-346ab362fcb6 for DN 127.0.0.1:36855
2020-04-02 05:09:03,068 [IPC Server handler 8 on 46429] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a82d5f8f-be71-44b4-b962-7dcebe33da1c for DN 127.0.0.1:36855
2020-04-02 05:09:03,070 [IPC Server handler 0 on 46429] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:36855, datanodeUuid=9d8cdd83-40bb-408e-bb18-63b20e5b9cd1, infoPort=44633, infoSecurePort=0, ipcPort=43837, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), reports.length=2
2020-04-02 05:09:03,070 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf0e657ec27bb5ef7: Processing first storage report for DS-f93514d7-ea4d-46b4-aa07-346ab362fcb6 from datanode 9d8cdd83-40bb-408e-bb18-63b20e5b9cd1
2020-04-02 05:09:03,070 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf0e657ec27bb5ef7: from storage DS-f93514d7-ea4d-46b4-aa07-346ab362fcb6 node DatanodeRegistration(127.0.0.1:36855, datanodeUuid=9d8cdd83-40bb-408e-bb18-63b20e5b9cd1, infoPort=44633, infoSecurePort=0, ipcPort=43837, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:03,070 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf0e657ec27bb5ef7: Processing first storage report for DS-a82d5f8f-be71-44b4-b962-7dcebe33da1c from datanode 9d8cdd83-40bb-408e-bb18-63b20e5b9cd1
2020-04-02 05:09:03,071 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf0e657ec27bb5ef7: from storage DS-a82d5f8f-be71-44b4-b962-7dcebe33da1c node DatanodeRegistration(127.0.0.1:36855, datanodeUuid=9d8cdd83-40bb-408e-bb18-63b20e5b9cd1, infoPort=44633, infoSecurePort=0, ipcPort=43837, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:03,071 [IPC Server handler 0 on 46429] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xf0e657ec27bb5ef7
2020-04-02 05:09:03,072 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xf0e657ec27bb5ef7,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:03,072 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,074 [Thread-608] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-74fcdc80-60df-46d7-8de8-9e7b0eb59a53
2020-04-02 05:09:03,074 [Thread-608] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-04-02 05:09:03,084 [Thread-359] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:03,089 [Thread-359] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:03,096 [Thread-608] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-fdc3b500-23f2-4371-acbb-7e3b537265fd
2020-04-02 05:09:03,096 [Thread-608] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-04-02 05:09:03,097 [Thread-608] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:03,098 [Thread-643] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46429 starting to offer service
2020-04-02 05:09:03,098 [Thread-608] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:09:03,098 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:03,102 [IPC Server listener on 39650] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39650: starting
2020-04-02 05:09:03,104 [Thread-359] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 39650 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:03,105 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:09:03,113 [Thread-359] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:09:03,116 [Thread-359] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:09:03,117 [Thread-359] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:03,117 [Thread-359] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:03,118 [Thread-359] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:03,118 [Thread-359] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:03,122 [Thread-608] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:09:03,122 [Thread-608] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:09:03,122 [Thread-359] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:03,122 [Thread-359] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:03,122 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:03,123 [Thread-359] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34169
2020-04-02 05:09:03,123 [Thread-359] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:03,123 [Thread-359] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:03,122 [Thread-608] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:09:03,124 [Thread-608] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,124 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:03,125 [Thread-359] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:03,130 [Thread-359] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:03,130 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:03,131 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:03,132 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:03,132 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:03,132 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:03,133 [Thread-359] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42426
2020-04-02 05:09:03,133 [Thread-359] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:03,135 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3155555c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:03,135 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@456660b7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:03,145 [Thread-657] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:09:03,145 [Thread-661] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:09:03,145 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5964e730{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:03,147 [Thread-359] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7dd6c510{HTTP/1.1,[http/1.1]}{localhost:42426}
2020-04-02 05:09:03,147 [Thread-359] INFO  server.Server (Server.java:doStart(419)) - Started @13557ms
2020-04-02 05:09:03,154 [Thread-643] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46429
2020-04-02 05:09:03,182 [Thread-643] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:03,184 [Thread-643] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:03,184 [Thread-643] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 1632793555. Formatting...
2020-04-02 05:09:03,184 [Thread-643] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c43b81c9-47a3-4418-b1b6-9ba5a33290b9 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-04-02 05:09:03,193 [Thread-643] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:03,193 [Thread-643] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 1632793555. Formatting...
2020-04-02 05:09:03,193 [Thread-643] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a7a1c1a2-02b1-4cf3-aa5d-f62c42ded043 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-04-02 05:09:03,221 [Thread-643] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,224 [Thread-657] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1486927160-172.17.0.14-1585804140181 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 79ms
2020-04-02 05:09:03,231 [Thread-643] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,232 [Thread-643] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-1486927160-172.17.0.14-1585804140181 is not formatted. Formatting ...
2020-04-02 05:09:03,243 [Thread-661] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1486927160-172.17.0.14-1585804140181 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 98ms
2020-04-02 05:09:03,235 [Thread-359] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36780
2020-04-02 05:09:03,243 [Thread-608] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1486927160-172.17.0.14-1585804140181: 119ms
2020-04-02 05:09:03,243 [Thread-643] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1486927160-172.17.0.14-1585804140181 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1486927160-172.17.0.14-1585804140181/current
2020-04-02 05:09:03,243 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:03,244 [Thread-359] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:03,244 [Thread-359] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:03,245 [Socket Reader #1 for port 34846] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34846
2020-04-02 05:09:03,247 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@220a18c0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:03,253 [Thread-665] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:09:03,253 [Thread-665] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1486927160-172.17.0.14-1585804140181/current/replicas doesn't exist 
2020-04-02 05:09:03,254 [Thread-665] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 1ms
2020-04-02 05:09:03,268 [Thread-359] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:34846
2020-04-02 05:09:03,280 [Thread-359] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:03,280 [Thread-359] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:03,281 [Thread-672] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46429 starting to offer service
2020-04-02 05:09:03,283 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:03,286 [IPC Server listener on 34846] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34846: starting
2020-04-02 05:09:03,289 [Thread-359] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 34846 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:03,372 [Thread-669] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:09:03,382 [Thread-669] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1486927160-172.17.0.14-1585804140181/current/replicas doesn't exist 
2020-04-02 05:09:03,386 [Thread-672] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46429
2020-04-02 05:09:03,406 [Thread-643] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,431 [Thread-643] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,431 [Thread-643] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-1486927160-172.17.0.14-1585804140181 is not formatted. Formatting ...
2020-04-02 05:09:03,431 [Thread-643] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1486927160-172.17.0.14-1585804140181 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1486927160-172.17.0.14-1585804140181/current
2020-04-02 05:09:03,429 [Thread-672] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:03,429 [Thread-669] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 56ms
2020-04-02 05:09:03,414 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:03,436 [Thread-608] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181: 193ms
2020-04-02 05:09:03,439 [Thread-672] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:03,439 [Thread-672] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 1632793555. Formatting...
2020-04-02 05:09:03,439 [Thread-672] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-35676acc-b5c1-46f3-a928-9c6c0b3077e0 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-04-02 05:09:03,439 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:09:03,440 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-fdc3b500-23f2-4371-acbb-7e3b537265fd): finished scanning block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,440 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-fdc3b500-23f2-4371-acbb-7e3b537265fd): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:09:03,440 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:09:03,440 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-74fcdc80-60df-46d7-8de8-9e7b0eb59a53): finished scanning block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,441 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-74fcdc80-60df-46d7-8de8-9e7b0eb59a53): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:09:03,441 [Thread-608] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:49 AM with interval of 21600000ms
2020-04-02 05:09:03,442 [Thread-643] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1632793555;bpid=BP-1486927160-172.17.0.14-1585804140181;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1632793555;c=1585804140181;bpid=BP-1486927160-172.17.0.14-1585804140181;dnuuid=null
2020-04-02 05:09:03,446 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid 8bb44eb3-2505-4c54-8ed6-c9be07a5921d) service to localhost/127.0.0.1:46429 beginning handshake with NN
2020-04-02 05:09:03,448 [IPC Server handler 4 on 46429] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35664, datanodeUuid=8bb44eb3-2505-4c54-8ed6-c9be07a5921d, infoPort=33237, infoSecurePort=0, ipcPort=37921, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181) storage 8bb44eb3-2505-4c54-8ed6-c9be07a5921d
2020-04-02 05:09:03,448 [IPC Server handler 4 on 46429] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35664
2020-04-02 05:09:03,448 [IPC Server handler 4 on 46429] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8bb44eb3-2505-4c54-8ed6-c9be07a5921d (127.0.0.1:35664).
2020-04-02 05:09:03,449 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid 8bb44eb3-2505-4c54-8ed6-c9be07a5921d) service to localhost/127.0.0.1:46429 successfully registered with NN
2020-04-02 05:09:03,449 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46429 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:03,453 [Thread-643] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID e583112a-f889-4df4-a8bf-fcffbaf12c5c
2020-04-02 05:09:03,453 [Thread-672] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:03,453 [Thread-672] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 1632793555. Formatting...
2020-04-02 05:09:03,455 [Thread-672] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3cf1ee01-c758-4975-9d28-7a74bed30f56 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-04-02 05:09:03,468 [Thread-643] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c43b81c9-47a3-4418-b1b6-9ba5a33290b9
2020-04-02 05:09:03,468 [Thread-643] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-04-02 05:09:03,471 [Thread-643] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-a7a1c1a2-02b1-4cf3-aa5d-f62c42ded043
2020-04-02 05:09:03,471 [Thread-643] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-04-02 05:09:03,472 [Thread-643] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:03,473 [Thread-643] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:09:03,472 [Thread-672] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,474 [Thread-672] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,474 [Thread-672] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-1486927160-172.17.0.14-1585804140181 is not formatted. Formatting ...
2020-04-02 05:09:03,474 [Thread-672] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1486927160-172.17.0.14-1585804140181 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1486927160-172.17.0.14-1585804140181/current
2020-04-02 05:09:03,475 [Thread-643] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:09:03,475 [Thread-643] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:09:03,475 [Thread-643] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:09:03,486 [IPC Server handler 3 on 46429] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,515 [Thread-672] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,516 [IPC Server handler 5 on 46429] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-74fcdc80-60df-46d7-8de8-9e7b0eb59a53 for DN 127.0.0.1:35664
2020-04-02 05:09:03,523 [IPC Server handler 5 on 46429] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fdc3b500-23f2-4371-acbb-7e3b537265fd for DN 127.0.0.1:35664
2020-04-02 05:09:03,516 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:03,523 [Thread-672] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,521 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:09:03,530 [Thread-643] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,539 [IPC Server handler 7 on 46429] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:35664, datanodeUuid=8bb44eb3-2505-4c54-8ed6-c9be07a5921d, infoPort=33237, infoSecurePort=0, ipcPort=37921, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), reports.length=2
2020-04-02 05:09:03,539 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:09:03,539 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x4acf1122e8f9df98: Processing first storage report for DS-74fcdc80-60df-46d7-8de8-9e7b0eb59a53 from datanode 8bb44eb3-2505-4c54-8ed6-c9be07a5921d
2020-04-02 05:09:03,539 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x4acf1122e8f9df98: from storage DS-74fcdc80-60df-46d7-8de8-9e7b0eb59a53 node DatanodeRegistration(127.0.0.1:35664, datanodeUuid=8bb44eb3-2505-4c54-8ed6-c9be07a5921d, infoPort=33237, infoSecurePort=0, ipcPort=37921, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:03,539 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x4acf1122e8f9df98: Processing first storage report for DS-fdc3b500-23f2-4371-acbb-7e3b537265fd from datanode 8bb44eb3-2505-4c54-8ed6-c9be07a5921d
2020-04-02 05:09:03,539 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x4acf1122e8f9df98: from storage DS-fdc3b500-23f2-4371-acbb-7e3b537265fd node DatanodeRegistration(127.0.0.1:35664, datanodeUuid=8bb44eb3-2505-4c54-8ed6-c9be07a5921d, infoPort=33237, infoSecurePort=0, ipcPort=37921, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:09:03,540 [Thread-690] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:09:03,539 [Thread-672] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-1486927160-172.17.0.14-1585804140181 is not formatted. Formatting ...
2020-04-02 05:09:03,540 [IPC Server handler 7 on 46429] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x4acf1122e8f9df98
2020-04-02 05:09:03,540 [Thread-672] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1486927160-172.17.0.14-1585804140181 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1486927160-172.17.0.14-1585804140181/current
2020-04-02 05:09:03,540 [Thread-689] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:09:03,541 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x4acf1122e8f9df98,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:03,541 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,543 [Thread-672] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1632793555;bpid=BP-1486927160-172.17.0.14-1585804140181;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1632793555;c=1585804140181;bpid=BP-1486927160-172.17.0.14-1585804140181;dnuuid=null
2020-04-02 05:09:03,545 [Thread-672] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID a5c40564-5b1f-48d1-8cc4-d9cd1f45f596
2020-04-02 05:09:03,547 [Thread-672] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-35676acc-b5c1-46f3-a928-9c6c0b3077e0
2020-04-02 05:09:03,547 [Thread-672] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-04-02 05:09:03,548 [Thread-672] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-3cf1ee01-c758-4975-9d28-7a74bed30f56
2020-04-02 05:09:03,548 [Thread-672] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-04-02 05:09:03,549 [Thread-672] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:03,549 [Thread-672] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:09:03,551 [Thread-672] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:09:03,551 [Thread-672] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:09:03,604 [Thread-672] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:09:03,605 [Thread-672] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,623 [Thread-695] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:09:03,623 [Thread-694] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:09:03,643 [IPC Server handler 9 on 46429] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,644 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:09:03,645 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:09:03,675 [Thread-689] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1486927160-172.17.0.14-1585804140181 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 136ms
2020-04-02 05:09:03,743 [Thread-690] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1486927160-172.17.0.14-1585804140181 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 204ms
2020-04-02 05:09:03,744 [Thread-643] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1486927160-172.17.0.14-1585804140181: 205ms
2020-04-02 05:09:03,744 [Thread-700] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:09:03,745 [Thread-700] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1486927160-172.17.0.14-1585804140181/current/replicas doesn't exist 
2020-04-02 05:09:03,745 [Thread-699] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:09:03,745 [Thread-699] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1486927160-172.17.0.14-1585804140181/current/replicas doesn't exist 
2020-04-02 05:09:03,745 [Thread-699] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 0ms
2020-04-02 05:09:03,746 [Thread-700] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 1ms
2020-04-02 05:09:03,746 [Thread-643] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181: 2ms
2020-04-02 05:09:03,746 [Thread-643] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:46 AM with interval of 21600000ms
2020-04-02 05:09:03,746 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:09:03,747 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-a7a1c1a2-02b1-4cf3-aa5d-f62c42ded043): finished scanning block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,747 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-a7a1c1a2-02b1-4cf3-aa5d-f62c42ded043): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:09:03,747 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:09:03,748 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-c43b81c9-47a3-4418-b1b6-9ba5a33290b9): finished scanning block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,749 [IPC Server handler 6 on 46429] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,751 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:09:03,751 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:09:03,757 [Thread-694] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1486927160-172.17.0.14-1585804140181 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 133ms
2020-04-02 05:09:03,782 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-c43b81c9-47a3-4418-b1b6-9ba5a33290b9): no suitable block pools found to scan.  Waiting 1814399964 ms.
2020-04-02 05:09:03,782 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid e583112a-f889-4df4-a8bf-fcffbaf12c5c) service to localhost/127.0.0.1:46429 beginning handshake with NN
2020-04-02 05:09:03,783 [IPC Server handler 8 on 46429] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42402, datanodeUuid=e583112a-f889-4df4-a8bf-fcffbaf12c5c, infoPort=43493, infoSecurePort=0, ipcPort=39650, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181) storage e583112a-f889-4df4-a8bf-fcffbaf12c5c
2020-04-02 05:09:03,783 [IPC Server handler 8 on 46429] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42402
2020-04-02 05:09:03,784 [IPC Server handler 8 on 46429] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e583112a-f889-4df4-a8bf-fcffbaf12c5c (127.0.0.1:42402).
2020-04-02 05:09:03,786 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid e583112a-f889-4df4-a8bf-fcffbaf12c5c) service to localhost/127.0.0.1:46429 successfully registered with NN
2020-04-02 05:09:03,786 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46429 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:03,778 [Thread-695] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1486927160-172.17.0.14-1585804140181 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 155ms
2020-04-02 05:09:03,786 [Thread-672] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1486927160-172.17.0.14-1585804140181: 181ms
2020-04-02 05:09:03,832 [Thread-705] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:09:03,832 [Thread-704] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:09:03,833 [Thread-704] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1486927160-172.17.0.14-1585804140181/current/replicas doesn't exist 
2020-04-02 05:09:03,833 [Thread-704] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 0ms
2020-04-02 05:09:03,834 [Thread-705] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1486927160-172.17.0.14-1585804140181/current/replicas doesn't exist 
2020-04-02 05:09:03,834 [Thread-705] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 0ms
2020-04-02 05:09:03,834 [Thread-672] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1486927160-172.17.0.14-1585804140181: 42ms
2020-04-02 05:09:03,838 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:09:03,838 [Thread-672] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:53 AM with interval of 21600000ms
2020-04-02 05:09:03,838 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1486927160-172.17.0.14-1585804140181 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:09:03,838 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-3cf1ee01-c758-4975-9d28-7a74bed30f56): finished scanning block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,839 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-3cf1ee01-c758-4975-9d28-7a74bed30f56): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:09:03,841 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid a5c40564-5b1f-48d1-8cc4-d9cd1f45f596) service to localhost/127.0.0.1:46429 beginning handshake with NN
2020-04-02 05:09:03,837 [IPC Server handler 0 on 46429] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c43b81c9-47a3-4418-b1b6-9ba5a33290b9 for DN 127.0.0.1:42402
2020-04-02 05:09:03,842 [IPC Server handler 0 on 46429] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a7a1c1a2-02b1-4cf3-aa5d-f62c42ded043 for DN 127.0.0.1:42402
2020-04-02 05:09:03,838 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-35676acc-b5c1-46f3-a928-9c6c0b3077e0): finished scanning block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,843 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-35676acc-b5c1-46f3-a928-9c6c0b3077e0): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:09:03,844 [IPC Server handler 1 on 46429] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34169, datanodeUuid=a5c40564-5b1f-48d1-8cc4-d9cd1f45f596, infoPort=36780, infoSecurePort=0, ipcPort=34846, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181) storage a5c40564-5b1f-48d1-8cc4-d9cd1f45f596
2020-04-02 05:09:03,844 [IPC Server handler 1 on 46429] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34169
2020-04-02 05:09:03,844 [IPC Server handler 1 on 46429] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a5c40564-5b1f-48d1-8cc4-d9cd1f45f596 (127.0.0.1:34169).
2020-04-02 05:09:03,847 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid a5c40564-5b1f-48d1-8cc4-d9cd1f45f596) service to localhost/127.0.0.1:46429 successfully registered with NN
2020-04-02 05:09:03,847 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46429 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:03,857 [IPC Server handler 4 on 46429] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-35676acc-b5c1-46f3-a928-9c6c0b3077e0 for DN 127.0.0.1:34169
2020-04-02 05:09:03,857 [IPC Server handler 4 on 46429] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3cf1ee01-c758-4975-9d28-7a74bed30f56 for DN 127.0.0.1:34169
2020-04-02 05:09:03,858 [IPC Server handler 4 on 46429] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:42402, datanodeUuid=e583112a-f889-4df4-a8bf-fcffbaf12c5c, infoPort=43493, infoSecurePort=0, ipcPort=39650, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), reports.length=2
2020-04-02 05:09:03,859 [IPC Server handler 2 on 46429] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,859 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x66c35dc56cf41ab: Processing first storage report for DS-a7a1c1a2-02b1-4cf3-aa5d-f62c42ded043 from datanode e583112a-f889-4df4-a8bf-fcffbaf12c5c
2020-04-02 05:09:03,859 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x66c35dc56cf41ab: from storage DS-a7a1c1a2-02b1-4cf3-aa5d-f62c42ded043 node DatanodeRegistration(127.0.0.1:42402, datanodeUuid=e583112a-f889-4df4-a8bf-fcffbaf12c5c, infoPort=43493, infoSecurePort=0, ipcPort=39650, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:03,860 [IPC Server handler 5 on 46429] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:34169, datanodeUuid=a5c40564-5b1f-48d1-8cc4-d9cd1f45f596, infoPort=36780, infoSecurePort=0, ipcPort=34846, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), reports.length=2
2020-04-02 05:09:03,860 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2718)) - No heartbeat from DataNode: 127.0.0.1:34169
2020-04-02 05:09:03,861 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:09:03,861 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x153c765e0aadb985: Processing first storage report for DS-35676acc-b5c1-46f3-a928-9c6c0b3077e0 from datanode a5c40564-5b1f-48d1-8cc4-d9cd1f45f596
2020-04-02 05:09:03,861 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x153c765e0aadb985: from storage DS-35676acc-b5c1-46f3-a928-9c6c0b3077e0 node DatanodeRegistration(127.0.0.1:34169, datanodeUuid=a5c40564-5b1f-48d1-8cc4-d9cd1f45f596, infoPort=36780, infoSecurePort=0, ipcPort=34846, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:03,861 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x66c35dc56cf41ab: Processing first storage report for DS-c43b81c9-47a3-4418-b1b6-9ba5a33290b9 from datanode e583112a-f889-4df4-a8bf-fcffbaf12c5c
2020-04-02 05:09:03,861 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x66c35dc56cf41ab: from storage DS-c43b81c9-47a3-4418-b1b6-9ba5a33290b9 node DatanodeRegistration(127.0.0.1:42402, datanodeUuid=e583112a-f889-4df4-a8bf-fcffbaf12c5c, infoPort=43493, infoSecurePort=0, ipcPort=39650, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:03,861 [IPC Server handler 4 on 46429] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x66c35dc56cf41ab
2020-04-02 05:09:03,861 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x153c765e0aadb985: Processing first storage report for DS-3cf1ee01-c758-4975-9d28-7a74bed30f56 from datanode a5c40564-5b1f-48d1-8cc4-d9cd1f45f596
2020-04-02 05:09:03,861 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x153c765e0aadb985: from storage DS-3cf1ee01-c758-4975-9d28-7a74bed30f56 node DatanodeRegistration(127.0.0.1:34169, datanodeUuid=a5c40564-5b1f-48d1-8cc4-d9cd1f45f596, infoPort=36780, infoSecurePort=0, ipcPort=34846, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:09:03,862 [IPC Server handler 5 on 46429] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x153c765e0aadb985
2020-04-02 05:09:03,862 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x66c35dc56cf41ab,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 12 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:03,862 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,862 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x153c765e0aadb985,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:03,862 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:03,962 [IPC Server handler 7 on 46429] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,964 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:09:03,975 [IPC Server handler 9 on 46429] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,981 [IPC Server handler 6 on 46429] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:03,982 [Thread-359] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithDNFailure(160)) - testReadWithDNFailure: file = /dnFailure_1_smallFile, fileSize = 25165701, dnFailureNum = 1
2020-04-02 05:09:04,076 [IPC Server handler 8 on 46429] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dnFailure_1_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:09:04,090 [IPC Server handler 0 on 46429] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /dnFailure_1_smallFile for DFSClient_NONMAPREDUCE_-570153914_1968 at 127.0.0.1
2020-04-02 05:09:04,090 [IPC Server handler 0 on 46429] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/dnFailure_1_smallFile, holder=DFSClient_NONMAPREDUCE_-570153914_1968, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:09:04,104 [IPC Server handler 0 on 46429] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: dnFailure_1_smallFile is added
2020-04-02 05:09:04,105 [IPC Server handler 0 on 46429] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /dnFailure_1_smallFile inode 16386 DFSClient_NONMAPREDUCE_-570153914_1968
2020-04-02 05:09:04,115 [IPC Server handler 0 on 46429] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/dnFailure_1_smallFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:04,136 [Thread-359] WARN  erasurecode.ErasureCodeNative (ErasureCodeNative.java:<clinit>(55)) - ISA-L support is not available in your platform... using builtin-java codec where applicable
2020-04-02 05:09:04,403 [IPC Server handler 3 on 46429] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /dnFailure_1_smallFile  inodeId 16386 for DFSClient_NONMAPREDUCE_-570153914_1968
2020-04-02 05:09:04,408 [IPC Server handler 3 on 46429] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:09:04,417 [IPC Server handler 3 on 46429] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /dnFailure_1_smallFile with blk_-9223372036854775792_1001 block is added to the in-memory file system
2020-04-02 05:09:04,417 [IPC Server handler 3 on 46429] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:34169, 127.0.0.1:35062, 127.0.0.1:38052, 127.0.0.1:42402, 127.0.0.1:35664, 127.0.0.1:41614, 127.0.0.1:36855, 127.0.0.1:34039, 127.0.0.1:36280 for /dnFailure_1_smallFile
2020-04-02 05:09:04,417 [IPC Server handler 3 on 46429] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /dnFailure_1_smallFile with new block blk_-9223372036854775792_1001, current total block count is 1
2020-04-02 05:09:04,631 [DataXceiver for client DFSClient_NONMAPREDUCE_-570153914_1968 at /127.0.0.1:47864 [Receiving block BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775792_1001 src: /127.0.0.1:47864 dest: /127.0.0.1:34169
2020-04-02 05:09:04,633 [DataXceiver for client DFSClient_NONMAPREDUCE_-570153914_1968 at /127.0.0.1:48878 [Receiving block BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775788_1001 src: /127.0.0.1:48878 dest: /127.0.0.1:35664
2020-04-02 05:09:04,642 [DataXceiver for client DFSClient_NONMAPREDUCE_-570153914_1968 at /127.0.0.1:56952 [Receiving block BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775790_1001 src: /127.0.0.1:56952 dest: /127.0.0.1:38052
2020-04-02 05:09:04,642 [DataXceiver for client DFSClient_NONMAPREDUCE_-570153914_1968 at /127.0.0.1:38214 [Receiving block BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775791_1001 src: /127.0.0.1:38214 dest: /127.0.0.1:35062
2020-04-02 05:09:04,642 [DataXceiver for client DFSClient_NONMAPREDUCE_-570153914_1968 at /127.0.0.1:54366 [Receiving block BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775787_1001 src: /127.0.0.1:54366 dest: /127.0.0.1:41614
2020-04-02 05:09:04,642 [DataXceiver for client DFSClient_NONMAPREDUCE_-570153914_1968 at /127.0.0.1:52038 [Receiving block BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775789_1001 src: /127.0.0.1:52038 dest: /127.0.0.1:42402
2020-04-02 05:09:04,986 [DataXceiver for client DFSClient_NONMAPREDUCE_-570153914_1968 at /127.0.0.1:35366 [Receiving block BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775786_1001 src: /127.0.0.1:35366 dest: /127.0.0.1:36855
2020-04-02 05:09:05,114 [DataXceiver for client DFSClient_NONMAPREDUCE_-570153914_1968 at /127.0.0.1:33654 [Receiving block BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775785_1001 src: /127.0.0.1:33654 dest: /127.0.0.1:34039
2020-04-02 05:09:05,153 [DataXceiver for client DFSClient_NONMAPREDUCE_-570153914_1968 at /127.0.0.1:52736 [Receiving block BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775784_1001 src: /127.0.0.1:52736 dest: /127.0.0.1:36280
2020-04-02 05:09:05,293 [IPC Server handler 3 on 46429] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38052, datanodeUuid=ba3e5711-21ac-4347-945f-dcf4d33687ed, infoPort=41357, infoSecurePort=0, ipcPort=42294, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181) 1 blocks.
2020-04-02 05:09:05,296 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775790_1001 on 127.0.0.1:38052 size 4194304 replicaState = RBW
2020-04-02 05:09:05,296 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:05,300 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775790_1001 is received from 127.0.0.1:38052
2020-04-02 05:09:05,300 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38052 receiving: 1, received: 0, deleted: 0
2020-04-02 05:09:05,482 [IPC Server handler 4 on 46429] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:35062, datanodeUuid=5395e94e-1a47-416a-a398-f204c01205d3, infoPort=35491, infoSecurePort=0, ipcPort=32933, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181) 1 blocks.
2020-04-02 05:09:05,483 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775791_1001 on 127.0.0.1:35062 size 4194304 replicaState = RBW
2020-04-02 05:09:05,483 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:05,483 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775791_1001 is received from 127.0.0.1:35062
2020-04-02 05:09:05,483 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:35062 receiving: 1, received: 0, deleted: 0
2020-04-02 05:09:05,643 [PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47864, dest: /127.0.0.1:34169, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-570153914_1968, offset: 0, srvID: a5c40564-5b1f-48d1-8cc4-d9cd1f45f596, blockid: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775792_1001, duration(ns): 921343203
2020-04-02 05:09:05,643 [PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:05,646 [IPC Server handler 5 on 46429] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34169, datanodeUuid=a5c40564-5b1f-48d1-8cc4-d9cd1f45f596, infoPort=36780, infoSecurePort=0, ipcPort=34846, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181) 1 blocks.
2020-04-02 05:09:05,647 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775792_1001 on 127.0.0.1:34169 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:05,647 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:05,647 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34169 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:09:05,649 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775792_1001 is received from 127.0.0.1:34169
2020-04-02 05:09:05,658 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34169 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:05,671 [PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38214, dest: /127.0.0.1:35062, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-570153914_1968, offset: 0, srvID: 5395e94e-1a47-416a-a398-f204c01205d3, blockid: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775791_1001, duration(ns): 936676614
2020-04-02 05:09:05,674 [PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:05,682 [IPC Server handler 7 on 46429] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:35062, datanodeUuid=5395e94e-1a47-416a-a398-f204c01205d3, infoPort=35491, infoSecurePort=0, ipcPort=32933, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181) 1 blocks.
2020-04-02 05:09:05,683 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775791_1001 on 127.0.0.1:35062 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:05,683 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:05,683 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:35062 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:09:05,683 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775791_1001 is received from 127.0.0.1:35062
2020-04-02 05:09:05,683 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:35062 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:05,686 [PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56952, dest: /127.0.0.1:38052, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-570153914_1968, offset: 0, srvID: ba3e5711-21ac-4347-945f-dcf4d33687ed, blockid: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775790_1001, duration(ns): 961627359
2020-04-02 05:09:05,686 [PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:05,701 [PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52038, dest: /127.0.0.1:42402, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-570153914_1968, offset: 0, srvID: e583112a-f889-4df4-a8bf-fcffbaf12c5c, blockid: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775789_1001, duration(ns): 981488889
2020-04-02 05:09:05,701 [IPC Server handler 9 on 46429] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38052, datanodeUuid=ba3e5711-21ac-4347-945f-dcf4d33687ed, infoPort=41357, infoSecurePort=0, ipcPort=42294, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181) 1 blocks.
2020-04-02 05:09:05,702 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775790_1001 on 127.0.0.1:38052 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:05,702 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:05,702 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38052 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:09:05,702 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775790_1001 is received from 127.0.0.1:38052
2020-04-02 05:09:05,702 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38052 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:05,701 [PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:05,705 [IPC Server handler 6 on 46429] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:42402, datanodeUuid=e583112a-f889-4df4-a8bf-fcffbaf12c5c, infoPort=43493, infoSecurePort=0, ipcPort=39650, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181) 1 blocks.
2020-04-02 05:09:05,705 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775789_1001 on 127.0.0.1:42402 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:05,706 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:05,706 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:42402 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:09:05,706 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775789_1001 is received from 127.0.0.1:42402
2020-04-02 05:09:05,706 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:42402 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:05,714 [PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48878, dest: /127.0.0.1:35664, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-570153914_1968, offset: 0, srvID: 8bb44eb3-2505-4c54-8ed6-c9be07a5921d, blockid: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775788_1001, duration(ns): 986570520
2020-04-02 05:09:05,715 [PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:05,732 [PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54366, dest: /127.0.0.1:41614, bytes: 4194181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-570153914_1968, offset: 0, srvID: c2d9af8a-9989-4e6e-8027-9383819b4df6, blockid: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775787_1001, duration(ns): 1012603941
2020-04-02 05:09:05,732 [PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:05,738 [IPC Server handler 8 on 46429] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:35664, datanodeUuid=8bb44eb3-2505-4c54-8ed6-c9be07a5921d, infoPort=33237, infoSecurePort=0, ipcPort=37921, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181) 1 blocks.
2020-04-02 05:09:05,739 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:35664 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:05,739 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:05,742 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:35664 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:09:05,742 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775788_1001 is received from 127.0.0.1:35664
2020-04-02 05:09:05,742 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:35664 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:05,746 [IPC Server handler 0 on 46429] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41614, datanodeUuid=c2d9af8a-9989-4e6e-8027-9383819b4df6, infoPort=40941, infoSecurePort=0, ipcPort=37290, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181) 1 blocks.
2020-04-02 05:09:05,747 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775787_1001 on 127.0.0.1:41614 size 4194181 replicaState = FINALIZED
2020-04-02 05:09:05,747 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:05,747 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:41614 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:09:05,747 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775787_1001 is received from 127.0.0.1:41614
2020-04-02 05:09:05,747 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41614 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:05,765 [PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35366, dest: /127.0.0.1:36855, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-570153914_1968, offset: 0, srvID: 9d8cdd83-40bb-408e-bb18-63b20e5b9cd1, blockid: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775786_1001, duration(ns): 774487697
2020-04-02 05:09:05,765 [PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:05,778 [IPC Server handler 1 on 46429] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:36855, datanodeUuid=9d8cdd83-40bb-408e-bb18-63b20e5b9cd1, infoPort=44633, infoSecurePort=0, ipcPort=43837, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181) 1 blocks.
2020-04-02 05:09:05,781 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775786_1001 on 127.0.0.1:36855 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:05,781 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:05,781 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:36855 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:09:05,781 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775786_1001 is received from 127.0.0.1:36855
2020-04-02 05:09:05,781 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:36855 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:05,786 [PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33654, dest: /127.0.0.1:34039, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-570153914_1968, offset: 0, srvID: 2e9e3c88-d3b6-4f24-93ed-3ab840d73a49, blockid: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775785_1001, duration(ns): 655967773
2020-04-02 05:09:05,786 [PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:05,788 [IPC Server handler 3 on 46429] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34039, datanodeUuid=2e9e3c88-d3b6-4f24-93ed-3ab840d73a49, infoPort=42020, infoSecurePort=0, ipcPort=40490, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181) 1 blocks.
2020-04-02 05:09:05,788 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775785_1001 on 127.0.0.1:34039 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:05,788 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:05,789 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34039 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:09:05,789 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775785_1001 is received from 127.0.0.1:34039
2020-04-02 05:09:05,789 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34039 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:05,794 [PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52736, dest: /127.0.0.1:36280, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-570153914_1968, offset: 0, srvID: 31570cf7-70bb-4a63-9199-32333f90bc23, blockid: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775784_1001, duration(ns): 627780992
2020-04-02 05:09:05,794 [PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:05,798 [IPC Server handler 2 on 46429] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:36280, datanodeUuid=31570cf7-70bb-4a63-9199-32333f90bc23, infoPort=38233, infoSecurePort=0, ipcPort=45970, storageInfo=lv=-57;cid=testClusterID;nsid=1632793555;c=1585804140181) 1 blocks.
2020-04-02 05:09:05,798 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775784_1001 on 127.0.0.1:36280 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:05,799 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:05,799 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:36280 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:09:05,799 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775784_1001 is received from 127.0.0.1:36280
2020-04-02 05:09:05,799 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:36280 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:05,812 [IPC Server handler 4 on 46429] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /dnFailure_1_smallFile for DFSClient_NONMAPREDUCE_-570153914_1968
2020-04-02 05:09:05,823 [IPC Server handler 4 on 46429] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /dnFailure_1_smallFile with 1 blocks is persisted to the file system
2020-04-02 05:09:05,825 [IPC Server handler 4 on 46429] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /dnFailure_1_smallFile is closed by DFSClient_NONMAPREDUCE_-570153914_1968
2020-04-02 05:09:05,834 [IPC Server handler 5 on 46429] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:05,845 [IPC Server handler 7 on 46429] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:09:05,847 [IPC Server handler 7 on 46429] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_1_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:09:05,866 [Thread-359] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:waitBlockGroupsReported(290)) - All blockGroups of file /dnFailure_1_smallFile verified to have all internalBlocks.
2020-04-02 05:09:05,868 [IPC Server handler 9 on 46429] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:09:05,869 [IPC Server handler 9 on 46429] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_1_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:09:05,873 [Thread-359] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 34846 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:05,874 [Thread-359] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:05,874 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@54859f92] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:05,877 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-35676acc-b5c1-46f3-a928-9c6c0b3077e0) exiting.
2020-04-02 05:09:05,878 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-3cf1ee01-c758-4975-9d28-7a74bed30f56) exiting.
2020-04-02 05:09:05,993 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5964e730{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:06,000 [Thread-359] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7dd6c510{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:06,001 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@456660b7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:06,002 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3155555c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:06,010 [Thread-359] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34846
2020-04-02 05:09:06,012 [IPC Server listener on 34846] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34846
2020-04-02 05:09:06,013 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:06,027 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:06,029 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid a5c40564-5b1f-48d1-8cc4-d9cd1f45f596) service to localhost/127.0.0.1:46429
2020-04-02 05:09:06,029 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid a5c40564-5b1f-48d1-8cc4-d9cd1f45f596)
2020-04-02 05:09:06,030 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:06,098 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1486927160-172.17.0.14-1585804140181] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:06,105 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1486927160-172.17.0.14-1585804140181] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:06,126 [Thread-359] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:06,127 [Thread-359] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:06,129 [Thread-359] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:06,129 [Thread-359] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:06,140 [Thread-359] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:06,140 [Thread-359] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /dnFailure_1_smallFile
2020-04-02 05:09:06,151 [Thread-359] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /dnFailure_1_smallFile
2020-04-02 05:09:06,154 [IPC Server handler 8 on 46429] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dnFailure_1_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:09:06,155 [Thread-359] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /dnFailure_1_smallFile
2020-04-02 05:09:06,156 [IPC Server handler 0 on 46429] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:06,163 [IPC Server handler 1 on 46429] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:09:06,164 [IPC Server handler 1 on 46429] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_1_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:09:06,421 [Thread-359] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:06,424 [Thread-359] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:34169 for blockBP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:06,428 [IPC Server handler 3 on 46429] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:09:06,428 [IPC Server handler 3 on 46429] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_1_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:09:06,436 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:06,445 [Thread-359] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:34169,DS-35676acc-b5c1-46f3-a928-9c6c0b3077e0,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:09:06,526 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:09,437 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:09,527 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:12,455 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:12,530 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:15,456 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:15,530 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:18,456 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:18,531 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:21,457 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:21,531 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:24,457 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:24,580 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:27,458 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:27,580 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:27,627 [Thread-359] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /dnFailure_1_smallFile
2020-04-02 05:09:27,642 [IPC Server handler 1 on 46429] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:09:27,645 [IPC Server handler 1 on 46429] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_1_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:09:27,655 [Thread-359] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:27,656 [Thread-359] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:34169 for blockBP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:27,659 [IPC Server handler 8 on 46429] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:09:27,669 [IPC Server handler 8 on 46429] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_1_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:09:27,684 [Thread-359] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:34169,DS-35676acc-b5c1-46f3-a928-9c6c0b3077e0,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:09:30,458 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:30,581 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:32,444 [Thread-359] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /dnFailure_1_smallFile
2020-04-02 05:09:32,451 [IPC Server handler 2 on 46429] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:09:32,452 [IPC Server handler 2 on 46429] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_1_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:09:32,465 [Thread-359] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:32,466 [Thread-359] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:34169 for blockBP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:32,468 [IPC Server handler 5 on 46429] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:09:32,469 [IPC Server handler 5 on 46429] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_1_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:09:32,478 [Thread-359] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:34169,DS-35676acc-b5c1-46f3-a928-9c6c0b3077e0,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:09:33,462 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:33,581 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:36,462 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:36,582 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:37,529 [Thread-359] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /dnFailure_1_smallFile
2020-04-02 05:09:37,530 [IPC Server handler 1 on 46429] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:09:37,531 [IPC Server handler 1 on 46429] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_1_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:09:37,543 [Thread-359] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:37,544 [Thread-359] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:34169 for blockBP-1486927160-172.17.0.14-1585804140181:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:37,545 [IPC Server handler 8 on 46429] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:09:37,546 [IPC Server handler 8 on 46429] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_1_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:09:37,547 [Thread-359] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:34169,DS-35676acc-b5c1-46f3-a928-9c6c0b3077e0,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:09:39,463 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:39,582 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:42,511 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:42,586 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:45,038 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:09:45,039 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 8
2020-04-02 05:09:45,039 [Thread-359] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 34846 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:45,039 [Thread-359] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(340)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-04-02 05:09:45,040 [Thread-359] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34846
2020-04-02 05:09:45,041 [Thread-359] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-a5c40564-5b1f-48d1-8cc4-d9cd1f45f596
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-a5c40564-5b1f-48d1-8cc4-d9cd1f45f596
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2146)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2048)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2038)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2017)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1991)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1984)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.tearDownCluster(ReadStripedFileWithDecodingHelper.java:97)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.tearDown(TestReadStripedFileWithDNFailure.java:64)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:105)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:45,042 [Thread-359] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(190)) - AsyncDiskService has already shut down.
2020-04-02 05:09:45,042 [Thread-359] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(174)) - AsyncLazyPersistService has already shut down.
2020-04-02 05:09:45,043 [Thread-359] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:45,043 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 7
2020-04-02 05:09:45,043 [Thread-359] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 39650 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:45,043 [Thread-359] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:45,043 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@16d105c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:45,046 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-c43b81c9-47a3-4418-b1b6-9ba5a33290b9) exiting.
2020-04-02 05:09:45,047 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-a7a1c1a2-02b1-4cf3-aa5d-f62c42ded043) exiting.
2020-04-02 05:09:45,123 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6d670e0f{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:45,134 [Thread-359] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@17162395{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:45,134 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@277ab8e1{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:45,138 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@599cb335{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:45,142 [Thread-359] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39650
2020-04-02 05:09:45,156 [IPC Server listener on 39650] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39650
2020-04-02 05:09:45,157 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:45,158 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:45,176 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid e583112a-f889-4df4-a8bf-fcffbaf12c5c) service to localhost/127.0.0.1:46429
2020-04-02 05:09:45,176 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid e583112a-f889-4df4-a8bf-fcffbaf12c5c)
2020-04-02 05:09:45,176 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:45,205 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1486927160-172.17.0.14-1585804140181] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:45,230 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1486927160-172.17.0.14-1585804140181] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:45,248 [Thread-359] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:45,248 [Thread-359] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:45,250 [Thread-359] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:45,250 [Thread-359] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:45,254 [Thread-359] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:45,254 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 6
2020-04-02 05:09:45,254 [Thread-359] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 37921 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:45,254 [Thread-359] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:45,255 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@421e178f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:45,278 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-74fcdc80-60df-46d7-8de8-9e7b0eb59a53) exiting.
2020-04-02 05:09:45,278 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-fdc3b500-23f2-4371-acbb-7e3b537265fd) exiting.
2020-04-02 05:09:45,512 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:45,546 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@312c8e39{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:45,547 [Thread-359] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@247315a9{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:45,548 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f70340a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:45,548 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@391cb7b2{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:45,557 [Thread-359] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37921
2020-04-02 05:09:45,602 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid 8bb44eb3-2505-4c54-8ed6-c9be07a5921d) service to localhost/127.0.0.1:46429
2020-04-02 05:09:45,625 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid 8bb44eb3-2505-4c54-8ed6-c9be07a5921d)
2020-04-02 05:09:45,625 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:45,629 [IPC Server listener on 37921] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37921
2020-04-02 05:09:45,602 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:45,672 [Thread-359] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:45,702 [Thread-359] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:45,652 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:45,707 [Thread-359] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:45,707 [Thread-359] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:45,726 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1486927160-172.17.0.14-1585804140181] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:45,744 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1486927160-172.17.0.14-1585804140181] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:45,769 [Thread-359] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:45,769 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 5
2020-04-02 05:09:45,769 [Thread-359] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43837 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:45,770 [Thread-359] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:45,771 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@68d31abd] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:45,778 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-a82d5f8f-be71-44b4-b962-7dcebe33da1c) exiting.
2020-04-02 05:09:45,778 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-f93514d7-ea4d-46b4-aa07-346ab362fcb6) exiting.
2020-04-02 05:09:45,842 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@17bdc055{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:45,846 [Thread-359] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1aa9630d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:45,850 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5a3b770{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:45,850 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@71ba55cb{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:45,893 [Thread-359] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43837
2020-04-02 05:09:45,904 [IPC Server listener on 43837] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43837
2020-04-02 05:09:45,904 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:45,907 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:45,917 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid 9d8cdd83-40bb-408e-bb18-63b20e5b9cd1) service to localhost/127.0.0.1:46429
2020-04-02 05:09:45,917 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid 9d8cdd83-40bb-408e-bb18-63b20e5b9cd1)
2020-04-02 05:09:45,917 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:45,925 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1486927160-172.17.0.14-1585804140181] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:45,936 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1486927160-172.17.0.14-1585804140181] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:45,984 [Thread-359] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:45,985 [Thread-359] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:45,988 [Thread-359] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:45,988 [Thread-359] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:45,995 [Thread-359] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:45,995 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 4
2020-04-02 05:09:45,995 [Thread-359] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 32933 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:45,995 [Thread-359] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:45,996 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4f68b1ae] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:46,008 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-32e9c9e0-4513-42ee-9675-abcf2e3d687b) exiting.
2020-04-02 05:09:46,008 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-baf60bac-f625-47b7-864c-ca2826e89d8e) exiting.
2020-04-02 05:09:46,082 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4016fc6a{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:46,083 [Thread-359] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7bb6d3ae{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:46,084 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6d466016{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:46,084 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@500d5da2{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:46,090 [Thread-359] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 32933
2020-04-02 05:09:46,111 [IPC Server listener on 32933] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 32933
2020-04-02 05:09:46,111 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:46,112 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:46,112 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid 5395e94e-1a47-416a-a398-f204c01205d3) service to localhost/127.0.0.1:46429
2020-04-02 05:09:46,112 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid 5395e94e-1a47-416a-a398-f204c01205d3)
2020-04-02 05:09:46,112 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:46,121 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1486927160-172.17.0.14-1585804140181] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:46,144 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1486927160-172.17.0.14-1585804140181] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:46,155 [Thread-359] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:46,155 [Thread-359] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:46,160 [Thread-359] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:46,160 [Thread-359] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:46,185 [Thread-359] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:46,185 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 3
2020-04-02 05:09:46,186 [Thread-359] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 42294 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:46,186 [Thread-359] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:46,190 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5e241c86] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:46,200 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-878baa2c-a649-4436-817d-80e490ac7842) exiting.
2020-04-02 05:09:46,200 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-45c150a4-6239-43b7-b910-94f498851d60) exiting.
2020-04-02 05:09:46,236 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7935c823{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:46,237 [Thread-359] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@67a8df83{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:46,237 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1e0761c6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:46,238 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@77e2de27{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:46,245 [Thread-359] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42294
2020-04-02 05:09:46,278 [IPC Server listener on 42294] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42294
2020-04-02 05:09:46,278 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:46,278 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid ba3e5711-21ac-4347-945f-dcf4d33687ed) service to localhost/127.0.0.1:46429
2020-04-02 05:09:46,314 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid ba3e5711-21ac-4347-945f-dcf4d33687ed)
2020-04-02 05:09:46,314 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:46,329 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:46,349 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1486927160-172.17.0.14-1585804140181] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:46,379 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1486927160-172.17.0.14-1585804140181] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:46,394 [Thread-359] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:46,394 [Thread-359] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:46,398 [Thread-359] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:46,399 [Thread-359] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:46,412 [Thread-359] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:46,412 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:09:46,412 [Thread-359] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40490 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:46,412 [Thread-359] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:46,413 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@92065df] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:46,418 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-2a7db348-c283-4bea-90a8-f23c1428c357) exiting.
2020-04-02 05:09:46,421 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-22bd7456-d5b8-4b50-8c87-e06f621f0017) exiting.
2020-04-02 05:09:46,515 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@180988b0{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:46,516 [Thread-359] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6d8cfe11{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:46,516 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@990a4ac{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:46,516 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@dc813b6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:46,521 [Thread-359] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40490
2020-04-02 05:09:46,542 [IPC Server listener on 40490] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40490
2020-04-02 05:09:46,547 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:46,547 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:46,548 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid 2e9e3c88-d3b6-4f24-93ed-3ab840d73a49) service to localhost/127.0.0.1:46429
2020-04-02 05:09:46,548 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid 2e9e3c88-d3b6-4f24-93ed-3ab840d73a49)
2020-04-02 05:09:46,548 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:46,563 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1486927160-172.17.0.14-1585804140181] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:46,593 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1486927160-172.17.0.14-1585804140181] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:46,603 [Thread-359] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:46,603 [Thread-359] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:46,608 [Thread-359] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:46,608 [Thread-359] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:46,639 [Thread-359] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:46,639 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:09:46,639 [Thread-359] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 37290 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:46,639 [Thread-359] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:46,641 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@737414b7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:46,663 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-698d701a-7991-41cd-9a17-adce3e1f3ad9) exiting.
2020-04-02 05:09:46,663 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-147fd5b8-349a-4f9c-a815-be1af224249e) exiting.
2020-04-02 05:09:46,700 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4888ea91{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:46,702 [Thread-359] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1c32cecd{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:46,703 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d373c13{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:46,703 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5f753edf{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:46,712 [Thread-359] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37290
2020-04-02 05:09:46,728 [IPC Server listener on 37290] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37290
2020-04-02 05:09:46,728 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:46,728 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid c2d9af8a-9989-4e6e-8027-9383819b4df6) service to localhost/127.0.0.1:46429
2020-04-02 05:09:46,728 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid c2d9af8a-9989-4e6e-8027-9383819b4df6)
2020-04-02 05:09:46,728 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:46,734 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:46,752 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1486927160-172.17.0.14-1585804140181] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:46,776 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1486927160-172.17.0.14-1585804140181] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:46,789 [Thread-359] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:46,790 [Thread-359] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:46,799 [Thread-359] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:46,799 [Thread-359] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:46,819 [Thread-359] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:46,820 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:09:46,820 [Thread-359] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 45970 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:46,820 [Thread-359] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:46,822 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@67e2a93c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:46,848 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-cea4480b-5159-448f-9e29-d4a50c371ed3) exiting.
2020-04-02 05:09:46,848 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-e07a8967-b41f-4089-8035-d20cb21c35fb) exiting.
2020-04-02 05:09:46,992 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2d70b62e{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:46,994 [Thread-359] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2aa50597{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:46,995 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@72f13a77{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:46,995 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7cdcf74f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:47,051 [Thread-359] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45970
2020-04-02 05:09:47,073 [IPC Server listener on 45970] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45970
2020-04-02 05:09:47,073 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:47,102 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:47,102 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid 31570cf7-70bb-4a63-9199-32333f90bc23) service to localhost/127.0.0.1:46429
2020-04-02 05:09:47,102 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1486927160-172.17.0.14-1585804140181 (Datanode Uuid 31570cf7-70bb-4a63-9199-32333f90bc23)
2020-04-02 05:09:47,102 [BP-1486927160-172.17.0.14-1585804140181 heartbeating to localhost/127.0.0.1:46429] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1486927160-172.17.0.14-1585804140181
2020-04-02 05:09:47,128 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1486927160-172.17.0.14-1585804140181] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:47,169 [Thread-359] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:47,169 [Thread-359] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:47,175 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1486927160-172.17.0.14-1585804140181] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:47,176 [Thread-359] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:47,176 [Thread-359] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:47,190 [Thread-359] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:47,190 [Thread-359] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:09:47,190 [Thread-359] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 46429 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:47,190 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:09:47,209 [Thread-359] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 8
2020-04-02 05:09:47,210 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@184ea43d] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:09:47,210 [Thread-359] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 9 Total time for transactions(ms): 9 Number of transactions batched in Syncs: 2 Number of syncs: 8 SyncTimes(ms): 2 1 
2020-04-02 05:09:47,222 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@2a8b4081] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:09:47,224 [Thread-359] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:09:47,225 [Thread-359] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:09:47,226 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:09:47,226 [CacheReplicationMonitor(1957886113)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:09:47,232 [Thread-359] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46429
2020-04-02 05:09:47,240 [IPC Server listener on 46429] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46429
2020-04-02 05:09:47,240 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:47,250 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:09:47,251 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:09:47,264 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@2c50e11d] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:09:47,493 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:09:47,494 [Thread-359] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:09:47,497 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7911dcfa{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:09:47,521 [Thread-359] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4d5a3d57{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:47,522 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6c28d7c9{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:47,522 [Thread-359] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@433b65e0{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure#testReadWithDNFailure[0]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure#testReadWithDNFailure[0]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure#testReadWithDNFailure[1]
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] before_class
2020-04-02 05:09:47,559 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=9
Formatting using clusterid: testClusterID
2020-04-02 05:09:47,562 [Thread-776] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:09:47,563 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:09:47,563 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:09:47,563 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:09:47,564 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:09:47,564 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:09:47,564 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:09:47,564 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:09:47,564 [Thread-776] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:47,565 [Thread-776] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:09:47,565 [Thread-776] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:09:47,565 [Thread-776] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:09:47,565 [Thread-776] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:09:47
2020-04-02 05:09:47,566 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:09:47,566 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:47,566 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 2.0 GB = 40.2 MB
2020-04-02 05:09:47,566 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:09:47,571 [Thread-776] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:09:47,572 [Thread-776] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:09:47,572 [Thread-776] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:09:47,572 [Thread-776] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:09:47,572 [Thread-776] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:09:47,572 [Thread-776] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:09:47,573 [Thread-776] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:09:47,573 [Thread-776] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:09:47,573 [Thread-776] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 0
2020-04-02 05:09:47,573 [Thread-776] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:09:47,573 [Thread-776] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:09:47,573 [Thread-776] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:09:47,574 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:09:47,574 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:47,574 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 2.0 GB = 20.1 MB
2020-04-02 05:09:47,574 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:09:47,577 [Thread-776] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:09:47,577 [Thread-776] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:09:47,577 [Thread-776] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:09:47,577 [Thread-776] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:09:47,577 [Thread-776] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:09:47,577 [Thread-776] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:09:47,578 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:09:47,578 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:47,578 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 2.0 GB = 5.0 MB
2020-04-02 05:09:47,578 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:09:47,579 [Thread-776] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:09:47,579 [Thread-776] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:09:47,579 [Thread-776] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:09:47,579 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:09:47,580 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:09:47,580 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:09:47,580 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:47,580 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 2.0 GB = 617.5 KB
2020-04-02 05:09:47,580 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:09:47,582 [Thread-776] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:47,585 [Thread-776] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:09:47,587 [Thread-776] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:09:47,588 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:09:47,594 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:09:47,595 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 426 bytes saved in 0 seconds .
2020-04-02 05:09:47,612 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 426 bytes saved in 0 seconds .
2020-04-02 05:09:47,617 [Thread-776] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:09:47,619 [Thread-776] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:09:47,619 [Thread-776] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:09:47,619 [Thread-776] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:09:47,620 [Thread-776] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:09:47,682 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2df9d417] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:47,683 [Thread-776] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:09:47,683 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:47,724 [Thread-776] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:47,725 [Thread-776] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:09:47,725 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:47,727 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:47,727 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:09:47,727 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:47,727 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:47,729 [Thread-776] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:09:47,729 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:09:47,750 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37013
2020-04-02 05:09:47,750 [Thread-776] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:47,756 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4a5c6370{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:47,757 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@784486ae{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:47,764 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3ab0be91{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:09:47,765 [Thread-776] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@73e80a06{HTTP/1.1,[http/1.1]}{localhost:37013}
2020-04-02 05:09:47,765 [Thread-776] INFO  server.Server (Server.java:doStart(419)) - Started @58175ms
2020-04-02 05:09:47,856 [Thread-776] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:09:47,862 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:09:47,863 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:09:47,863 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:09:47,863 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:09:47,863 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:09:47,864 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:09:47,864 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:09:47,926 [Thread-776] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:47,926 [Thread-776] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:09:47,926 [Thread-776] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:09:47,927 [Thread-776] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:09:47,927 [Thread-776] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:09:47
2020-04-02 05:09:47,927 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:09:47,927 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:47,927 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 2.0 GB = 40.2 MB
2020-04-02 05:09:47,928 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:09:47,931 [Thread-776] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:09:47,935 [Thread-776] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:09:47,935 [Thread-776] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:09:47,935 [Thread-776] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:09:47,936 [Thread-776] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:09:47,936 [Thread-776] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:09:47,936 [Thread-776] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:09:47,936 [Thread-776] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:09:47,936 [Thread-776] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 0
2020-04-02 05:09:47,936 [Thread-776] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:09:47,936 [Thread-776] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:09:47,937 [Thread-776] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:09:47,937 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:09:47,937 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:47,938 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 2.0 GB = 20.1 MB
2020-04-02 05:09:47,938 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:09:47,939 [Thread-776] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:09:47,939 [Thread-776] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:09:47,940 [Thread-776] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:09:47,940 [Thread-776] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:09:47,940 [Thread-776] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:09:47,940 [Thread-776] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:09:47,940 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:09:47,940 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:47,941 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 2.0 GB = 5.0 MB
2020-04-02 05:09:47,941 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:09:47,942 [Thread-776] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:09:47,942 [Thread-776] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:09:47,943 [Thread-776] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:09:47,943 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:09:47,943 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:09:47,943 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:09:47,943 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:47,944 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 2.0 GB = 617.5 KB
2020-04-02 05:09:47,944 [Thread-776] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:09:47,948 [Thread-776] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:47,950 [Thread-776] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:47,951 [Thread-776] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:09:47,952 [Thread-776] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:09:47,952 [Thread-776] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:09:47,952 [Thread-776] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:09:47,954 [Thread-776] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:09:47,954 [Thread-776] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:09:47,955 [Thread-776] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:09:47,955 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:09:47,959 [Thread-776] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:09:48,010 [Thread-776] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:09:48,010 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 65 msecs
2020-04-02 05:09:48,011 [Thread-776] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:09:48,011 [Thread-776] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:48,012 [Socket Reader #1 for port 39615] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39615
2020-04-02 05:09:48,041 [Thread-776] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:39615 to access this namenode/service.
2020-04-02 05:09:48,042 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:09:48,141 [Thread-776] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:09:48,142 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@2580d37a] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:09:48,143 [Thread-776] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:09:48,143 [Thread-776] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:09:48,143 [Thread-776] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:09:48,143 [Thread-776] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:09:48,154 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:09:48,154 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:09:48,154 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:09:48,154 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:09:48,154 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:09:48,155 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2020-04-02 05:09:48,158 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:48,158 [IPC Server listener on 39615] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39615: starting
2020-04-02 05:09:48,191 [Thread-776] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:39615
2020-04-02 05:09:48,195 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:09:48,195 [Thread-776] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:09:48,214 [Thread-776] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 19 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:09:48,221 [Thread-776] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 39615 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:48,228 [CacheReplicationMonitor(829831996)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:09:48,283 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:48,283 [Thread-776] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:48,284 [Thread-776] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:48,301 [Thread-776] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:48,301 [Thread-776] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:48,313 [Thread-776] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:48,313 [Thread-776] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:48,313 [Thread-776] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:48,314 [Thread-776] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:48,314 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:48,314 [Thread-776] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37887
2020-04-02 05:09:48,315 [Thread-776] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:48,315 [Thread-776] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:48,316 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:48,372 [Thread-776] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:48,378 [Thread-776] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:48,378 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:48,379 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:48,380 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:48,380 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:48,380 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:48,381 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35361
2020-04-02 05:09:48,381 [Thread-776] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:48,387 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6a312512{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:48,388 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1174ac3b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:48,392 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1cff4ee2{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:48,392 [Thread-776] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@11533cf6{HTTP/1.1,[http/1.1]}{localhost:35361}
2020-04-02 05:09:48,393 [Thread-776] INFO  server.Server (Server.java:doStart(419)) - Started @58803ms
2020-04-02 05:09:48,439 [Thread-776] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43494
2020-04-02 05:09:48,441 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:48,442 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:48,442 [Thread-776] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:48,441 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@25c80476] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:48,443 [Socket Reader #1 for port 44718] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44718
2020-04-02 05:09:48,445 [Thread-776] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:44718
2020-04-02 05:09:48,514 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:48,514 [Thread-776] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:48,514 [Thread-776] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:48,521 [Thread-830] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39615 starting to offer service
2020-04-02 05:09:48,554 [IPC Server listener on 44718] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44718: starting
2020-04-02 05:09:48,558 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:48,559 [Thread-776] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 44718 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:48,587 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:48,588 [Thread-776] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:09:48,588 [Thread-776] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:48,619 [Thread-776] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:48,619 [Thread-776] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:48,619 [Thread-776] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:48,619 [Thread-776] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:48,620 [Thread-776] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:48,620 [Thread-776] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:48,620 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:48,632 [Thread-830] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39615
2020-04-02 05:09:48,654 [Thread-776] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34418
2020-04-02 05:09:48,654 [Thread-776] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:48,654 [Thread-776] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:48,670 [Thread-830] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:48,675 [Thread-830] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:48,675 [Thread-830] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 292980063. Formatting...
2020-04-02 05:09:48,675 [Thread-830] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3ef33c0c-a00b-4586-9005-ad242a337eef for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:09:48,682 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:48,682 [Thread-830] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:48,683 [Thread-830] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 292980063. Formatting...
2020-04-02 05:09:48,683 [Thread-830] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-cf219190-77f6-462d-b393-0cf75e6fb3bc for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:09:48,683 [Thread-776] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:48,685 [Thread-776] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:48,685 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:48,686 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:48,686 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:48,686 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:48,687 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:48,687 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38015
2020-04-02 05:09:48,687 [Thread-776] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:48,693 [Thread-830] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:48,693 [Thread-830] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:48,693 [Thread-830] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1079677155-172.17.0.14-1585804187582 is not formatted. Formatting ...
2020-04-02 05:09:48,693 [Thread-830] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1079677155-172.17.0.14-1585804187582 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1079677155-172.17.0.14-1585804187582/current
2020-04-02 05:09:48,702 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2dcff38c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:48,704 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2d8c972a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:48,708 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6b372b67{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:48,709 [Thread-776] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7b18483d{HTTP/1.1,[http/1.1]}{localhost:38015}
2020-04-02 05:09:48,709 [Thread-776] INFO  server.Server (Server.java:doStart(419)) - Started @59119ms
2020-04-02 05:09:48,716 [Thread-830] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:48,717 [Thread-830] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:48,717 [Thread-830] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1079677155-172.17.0.14-1585804187582 is not formatted. Formatting ...
2020-04-02 05:09:48,717 [Thread-830] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1079677155-172.17.0.14-1585804187582 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1079677155-172.17.0.14-1585804187582/current
2020-04-02 05:09:48,774 [Thread-776] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34490
2020-04-02 05:09:48,775 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:48,775 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@40ff7ba] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:48,775 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:48,776 [Thread-776] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:48,777 [Socket Reader #1 for port 44913] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44913
2020-04-02 05:09:48,780 [Thread-776] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:44913
2020-04-02 05:09:48,785 [Thread-830] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=292980063;bpid=BP-1079677155-172.17.0.14-1585804187582;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=292980063;c=1585804187582;bpid=BP-1079677155-172.17.0.14-1585804187582;dnuuid=null
2020-04-02 05:09:48,787 [Thread-830] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID a071e6d5-59e7-4050-8f61-49fbbf5f73d0
2020-04-02 05:09:48,805 [Thread-776] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:48,806 [Thread-776] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:48,806 [Thread-854] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39615 starting to offer service
2020-04-02 05:09:48,807 [Thread-830] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-3ef33c0c-a00b-4586-9005-ad242a337eef
2020-04-02 05:09:48,807 [Thread-830] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:09:48,809 [Thread-830] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-cf219190-77f6-462d-b393-0cf75e6fb3bc
2020-04-02 05:09:48,809 [Thread-830] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:09:48,809 [Thread-830] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:48,820 [Thread-854] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39615
2020-04-02 05:09:48,832 [Thread-854] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:48,834 [Thread-854] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:48,834 [Thread-854] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 292980063. Formatting...
2020-04-02 05:09:48,835 [Thread-854] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-85e921d2-e9e0-4797-8770-ea05386d04cb for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:09:48,859 [Thread-830] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:48,861 [Thread-830] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:48,861 [Thread-830] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:48,861 [Thread-830] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:48,861 [Thread-830] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:48,869 [Thread-857] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:09:48,870 [IPC Server listener on 44913] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44913: starting
2020-04-02 05:09:48,882 [Thread-776] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 44913 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:48,902 [Thread-858] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:09:48,917 [Thread-854] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:48,927 [Thread-854] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 292980063. Formatting...
2020-04-02 05:09:48,928 [Thread-854] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a8705adb-4a10-44c0-94d3-1c5b20c71202 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:09:48,913 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:48,978 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:09:48,989 [Thread-857] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1079677155-172.17.0.14-1585804187582 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 120ms
2020-04-02 05:09:49,000 [Thread-854] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,000 [Thread-854] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,000 [Thread-854] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1079677155-172.17.0.14-1585804187582 is not formatted. Formatting ...
2020-04-02 05:09:49,000 [Thread-854] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1079677155-172.17.0.14-1585804187582 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1079677155-172.17.0.14-1585804187582/current
2020-04-02 05:09:48,990 [Thread-776] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:09:49,013 [Thread-854] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,014 [Thread-854] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,014 [Thread-854] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1079677155-172.17.0.14-1585804187582 is not formatted. Formatting ...
2020-04-02 05:09:49,014 [Thread-854] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1079677155-172.17.0.14-1585804187582 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1079677155-172.17.0.14-1585804187582/current
2020-04-02 05:09:49,016 [Thread-854] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=292980063;bpid=BP-1079677155-172.17.0.14-1585804187582;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=292980063;c=1585804187582;bpid=BP-1079677155-172.17.0.14-1585804187582;dnuuid=null
2020-04-02 05:09:49,018 [Thread-776] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:09:49,019 [Thread-854] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID a81c8a11-cec5-4613-b635-0eb191a7492f
2020-04-02 05:09:49,024 [Thread-858] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1079677155-172.17.0.14-1585804187582 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 97ms
2020-04-02 05:09:49,025 [Thread-830] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1079677155-172.17.0.14-1585804187582: 164ms
2020-04-02 05:09:49,026 [Thread-872] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:09:49,026 [Thread-872] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1079677155-172.17.0.14-1585804187582/current/replicas doesn't exist 
2020-04-02 05:09:49,026 [Thread-872] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:09:49,028 [Thread-854] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-85e921d2-e9e0-4797-8770-ea05386d04cb
2020-04-02 05:09:49,028 [Thread-854] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:09:49,029 [Thread-854] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-a8705adb-4a10-44c0-94d3-1c5b20c71202
2020-04-02 05:09:49,029 [Thread-854] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:09:49,030 [Thread-854] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:49,083 [Thread-873] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:09:49,083 [Thread-873] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1079677155-172.17.0.14-1585804187582/current/replicas doesn't exist 
2020-04-02 05:09:49,084 [Thread-873] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:09:49,089 [Thread-830] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582: 65ms
2020-04-02 05:09:49,090 [Thread-830] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:50 AM with interval of 21600000ms
2020-04-02 05:09:49,093 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:49,094 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:49,094 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-3ef33c0c-a00b-4586-9005-ad242a337eef): finished scanning block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,105 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid a071e6d5-59e7-4050-8f61-49fbbf5f73d0) service to localhost/127.0.0.1:39615 beginning handshake with NN
2020-04-02 05:09:49,112 [Thread-776] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:49,112 [Thread-854] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:09:49,112 [Thread-776] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:49,112 [Thread-776] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:49,112 [Thread-776] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:49,113 [Thread-776] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:49,113 [Thread-776] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:49,113 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:49,114 [Thread-776] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40904
2020-04-02 05:09:49,131 [Thread-776] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:49,131 [Thread-776] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:49,134 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-cf219190-77f6-462d-b393-0cf75e6fb3bc): finished scanning block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,135 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-3ef33c0c-a00b-4586-9005-ad242a337eef): no suitable block pools found to scan.  Waiting 1814399955 ms.
2020-04-02 05:09:49,142 [IPC Server handler 2 on 39615] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37887, datanodeUuid=a071e6d5-59e7-4050-8f61-49fbbf5f73d0, infoPort=43494, infoSecurePort=0, ipcPort=44718, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582) storage a071e6d5-59e7-4050-8f61-49fbbf5f73d0
2020-04-02 05:09:49,143 [IPC Server handler 2 on 39615] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37887
2020-04-02 05:09:49,143 [IPC Server handler 2 on 39615] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a071e6d5-59e7-4050-8f61-49fbbf5f73d0 (127.0.0.1:37887).
2020-04-02 05:09:49,148 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid a071e6d5-59e7-4050-8f61-49fbbf5f73d0) service to localhost/127.0.0.1:39615 successfully registered with NN
2020-04-02 05:09:49,148 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:39615 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:49,158 [IPC Server handler 3 on 39615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3ef33c0c-a00b-4586-9005-ad242a337eef for DN 127.0.0.1:37887
2020-04-02 05:09:49,158 [IPC Server handler 3 on 39615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-cf219190-77f6-462d-b393-0cf75e6fb3bc for DN 127.0.0.1:37887
2020-04-02 05:09:49,171 [IPC Server handler 4 on 39615] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:37887, datanodeUuid=a071e6d5-59e7-4050-8f61-49fbbf5f73d0, infoPort=43494, infoSecurePort=0, ipcPort=44718, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), reports.length=2
2020-04-02 05:09:49,172 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-cf219190-77f6-462d-b393-0cf75e6fb3bc): no suitable block pools found to scan.  Waiting 1814399918 ms.
2020-04-02 05:09:49,175 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd20447ad344288e7: Processing first storage report for DS-3ef33c0c-a00b-4586-9005-ad242a337eef from datanode a071e6d5-59e7-4050-8f61-49fbbf5f73d0
2020-04-02 05:09:49,175 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd20447ad344288e7: from storage DS-3ef33c0c-a00b-4586-9005-ad242a337eef node DatanodeRegistration(127.0.0.1:37887, datanodeUuid=a071e6d5-59e7-4050-8f61-49fbbf5f73d0, infoPort=43494, infoSecurePort=0, ipcPort=44718, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:49,177 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd20447ad344288e7: Processing first storage report for DS-cf219190-77f6-462d-b393-0cf75e6fb3bc from datanode a071e6d5-59e7-4050-8f61-49fbbf5f73d0
2020-04-02 05:09:49,177 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd20447ad344288e7: from storage DS-cf219190-77f6-462d-b393-0cf75e6fb3bc node DatanodeRegistration(127.0.0.1:37887, datanodeUuid=a071e6d5-59e7-4050-8f61-49fbbf5f73d0, infoPort=43494, infoSecurePort=0, ipcPort=44718, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:49,177 [IPC Server handler 4 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xd20447ad344288e7
2020-04-02 05:09:49,182 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xd20447ad344288e7,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 20 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:49,182 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:49,182 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,183 [Thread-776] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:49,184 [Thread-776] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:49,184 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:49,185 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:49,186 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:49,186 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:49,186 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:49,187 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42476
2020-04-02 05:09:49,187 [Thread-776] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:49,194 [Thread-854] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:09:49,194 [Thread-854] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:49,195 [Thread-854] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:49,196 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@b204856{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:49,197 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4b66adf{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:49,205 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3a77ea3b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:49,206 [Thread-776] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@20ca9db9{HTTP/1.1,[http/1.1]}{localhost:42476}
2020-04-02 05:09:49,206 [Thread-776] INFO  server.Server (Server.java:doStart(419)) - Started @59616ms
2020-04-02 05:09:49,246 [Thread-854] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,246 [Thread-884] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:09:49,260 [Thread-885] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:09:49,266 [Thread-776] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37378
2020-04-02 05:09:49,267 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:49,267 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:49,267 [Thread-776] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:49,268 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1e7383da] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:49,270 [Socket Reader #1 for port 39477] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39477
2020-04-02 05:09:49,278 [Thread-776] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:39477
2020-04-02 05:09:49,288 [Thread-776] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:49,288 [Thread-776] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:49,289 [Thread-894] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39615 starting to offer service
2020-04-02 05:09:49,289 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:49,289 [IPC Server listener on 39477] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39477: starting
2020-04-02 05:09:49,290 [Thread-776] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 39477 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:49,307 [Thread-884] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1079677155-172.17.0.14-1585804187582 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 61ms
2020-04-02 05:09:49,299 [Thread-885] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1079677155-172.17.0.14-1585804187582 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 39ms
2020-04-02 05:09:49,294 [Thread-894] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39615
2020-04-02 05:09:49,307 [Thread-854] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1079677155-172.17.0.14-1585804187582: 62ms
2020-04-02 05:09:49,310 [Thread-894] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:49,312 [Thread-905] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:09:49,312 [Thread-905] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1079677155-172.17.0.14-1585804187582/current/replicas doesn't exist 
2020-04-02 05:09:49,313 [Thread-905] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-04-02 05:09:49,314 [Thread-906] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:09:49,314 [Thread-906] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1079677155-172.17.0.14-1585804187582/current/replicas doesn't exist 
2020-04-02 05:09:49,315 [Thread-906] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-04-02 05:09:49,315 [Thread-854] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582: 5ms
2020-04-02 05:09:49,315 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:49,315 [Thread-854] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:16 AM with interval of 21600000ms
2020-04-02 05:09:49,316 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-a8705adb-4a10-44c0-94d3-1c5b20c71202): finished scanning block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,316 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:09:49,316 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-85e921d2-e9e0-4797-8770-ea05386d04cb): finished scanning block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,316 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-a8705adb-4a10-44c0-94d3-1c5b20c71202): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:09:49,316 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-85e921d2-e9e0-4797-8770-ea05386d04cb): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:09:49,317 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid a81c8a11-cec5-4613-b635-0eb191a7492f) service to localhost/127.0.0.1:39615 beginning handshake with NN
2020-04-02 05:09:49,318 [IPC Server handler 1 on 39615] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34418, datanodeUuid=a81c8a11-cec5-4613-b635-0eb191a7492f, infoPort=34490, infoSecurePort=0, ipcPort=44913, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582) storage a81c8a11-cec5-4613-b635-0eb191a7492f
2020-04-02 05:09:49,318 [IPC Server handler 1 on 39615] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34418
2020-04-02 05:09:49,318 [IPC Server handler 1 on 39615] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a81c8a11-cec5-4613-b635-0eb191a7492f (127.0.0.1:34418).
2020-04-02 05:09:49,319 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid a81c8a11-cec5-4613-b635-0eb191a7492f) service to localhost/127.0.0.1:39615 successfully registered with NN
2020-04-02 05:09:49,319 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:39615 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:49,325 [Thread-894] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:49,325 [Thread-894] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 292980063. Formatting...
2020-04-02 05:09:49,325 [Thread-894] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-38c97080-41ad-4d14-91fe-0d48b1417f76 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:09:49,326 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:09:49,329 [IPC Server handler 2 on 39615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-85e921d2-e9e0-4797-8770-ea05386d04cb for DN 127.0.0.1:34418
2020-04-02 05:09:49,329 [Thread-776] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:09:49,332 [Thread-894] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:49,332 [Thread-776] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:09:49,332 [Thread-894] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 292980063. Formatting...
2020-04-02 05:09:49,332 [Thread-894] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-01ed9015-b18d-4d61-a43d-7ddc46ea5bfa for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:09:49,338 [Thread-776] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:49,338 [Thread-776] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:49,339 [Thread-776] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:49,339 [Thread-776] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:49,339 [Thread-776] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:49,339 [Thread-776] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:49,340 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:49,344 [IPC Server handler 2 on 39615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a8705adb-4a10-44c0-94d3-1c5b20c71202 for DN 127.0.0.1:34418
2020-04-02 05:09:49,347 [IPC Server handler 3 on 39615] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:34418, datanodeUuid=a81c8a11-cec5-4613-b635-0eb191a7492f, infoPort=34490, infoSecurePort=0, ipcPort=44913, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), reports.length=2
2020-04-02 05:09:49,347 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd93682052e13d6ea: Processing first storage report for DS-85e921d2-e9e0-4797-8770-ea05386d04cb from datanode a81c8a11-cec5-4613-b635-0eb191a7492f
2020-04-02 05:09:49,347 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd93682052e13d6ea: from storage DS-85e921d2-e9e0-4797-8770-ea05386d04cb node DatanodeRegistration(127.0.0.1:34418, datanodeUuid=a81c8a11-cec5-4613-b635-0eb191a7492f, infoPort=34490, infoSecurePort=0, ipcPort=44913, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:49,347 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd93682052e13d6ea: Processing first storage report for DS-a8705adb-4a10-44c0-94d3-1c5b20c71202 from datanode a81c8a11-cec5-4613-b635-0eb191a7492f
2020-04-02 05:09:49,347 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd93682052e13d6ea: from storage DS-a8705adb-4a10-44c0-94d3-1c5b20c71202 node DatanodeRegistration(127.0.0.1:34418, datanodeUuid=a81c8a11-cec5-4613-b635-0eb191a7492f, infoPort=34490, infoSecurePort=0, ipcPort=44913, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:49,347 [IPC Server handler 3 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xd93682052e13d6ea
2020-04-02 05:09:49,348 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xd93682052e13d6ea,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:49,348 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,348 [Thread-894] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,355 [Thread-776] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:39673
2020-04-02 05:09:49,355 [Thread-894] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,355 [Thread-776] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:49,356 [Thread-776] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:49,355 [Thread-894] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1079677155-172.17.0.14-1585804187582 is not formatted. Formatting ...
2020-04-02 05:09:49,356 [Thread-894] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1079677155-172.17.0.14-1585804187582 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1079677155-172.17.0.14-1585804187582/current
2020-04-02 05:09:49,366 [Thread-894] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,367 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:49,367 [Thread-894] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,367 [Thread-894] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1079677155-172.17.0.14-1585804187582 is not formatted. Formatting ...
2020-04-02 05:09:49,367 [Thread-894] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1079677155-172.17.0.14-1585804187582 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1079677155-172.17.0.14-1585804187582/current
2020-04-02 05:09:49,368 [Thread-776] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:49,370 [Thread-894] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=292980063;bpid=BP-1079677155-172.17.0.14-1585804187582;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=292980063;c=1585804187582;bpid=BP-1079677155-172.17.0.14-1585804187582;dnuuid=null
2020-04-02 05:09:49,372 [Thread-894] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID d5c8becf-f706-4887-bfd5-e8783bfec939
2020-04-02 05:09:49,377 [Thread-776] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:49,380 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:49,377 [Thread-894] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-38c97080-41ad-4d14-91fe-0d48b1417f76
2020-04-02 05:09:49,380 [Thread-894] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:09:49,381 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:49,381 [Thread-894] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-01ed9015-b18d-4d61-a43d-7ddc46ea5bfa
2020-04-02 05:09:49,383 [Thread-894] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:09:49,383 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:49,384 [Thread-894] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:49,385 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:49,388 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:49,388 [Thread-894] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:09:49,389 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33716
2020-04-02 05:09:49,389 [Thread-776] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:49,398 [Thread-894] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:09:49,398 [Thread-894] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:09:49,400 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2ea3fb33{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:49,400 [Thread-894] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:09:49,401 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@55e07e92{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:49,426 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@491c9f23{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:49,426 [Thread-776] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@642dc537{HTTP/1.1,[http/1.1]}{localhost:33716}
2020-04-02 05:09:49,426 [Thread-776] INFO  server.Server (Server.java:doStart(419)) - Started @59837ms
2020-04-02 05:09:49,427 [Thread-894] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,428 [Thread-919] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:09:49,428 [Thread-918] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:09:49,450 [Thread-776] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38498
2020-04-02 05:09:49,451 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:49,452 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:49,452 [Thread-776] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:49,451 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2176df19] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:49,452 [Socket Reader #1 for port 41532] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41532
2020-04-02 05:09:49,460 [Thread-776] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:41532
2020-04-02 05:09:49,469 [Thread-776] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:49,469 [Thread-776] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:49,474 [Thread-918] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1079677155-172.17.0.14-1585804187582 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 46ms
2020-04-02 05:09:49,475 [Thread-928] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39615 starting to offer service
2020-04-02 05:09:49,478 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:49,487 [IPC Server listener on 41532] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41532: starting
2020-04-02 05:09:49,491 [Thread-776] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 41532 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:49,492 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:09:49,492 [Thread-776] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:09:49,493 [Thread-776] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:09:49,494 [Thread-776] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:49,494 [Thread-776] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:49,494 [Thread-776] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:49,495 [Thread-776] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:49,495 [Thread-776] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:49,495 [Thread-776] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:49,495 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:49,496 [Thread-776] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40621
2020-04-02 05:09:49,496 [Thread-776] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:49,496 [Thread-776] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:49,497 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:49,518 [Thread-919] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1079677155-172.17.0.14-1585804187582 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 90ms
2020-04-02 05:09:49,518 [Thread-894] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1079677155-172.17.0.14-1585804187582: 90ms
2020-04-02 05:09:49,519 [Thread-942] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:09:49,519 [Thread-942] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1079677155-172.17.0.14-1585804187582/current/replicas doesn't exist 
2020-04-02 05:09:49,519 [Thread-942] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 0ms
2020-04-02 05:09:49,520 [Thread-776] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:49,522 [Thread-943] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:09:49,522 [Thread-943] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1079677155-172.17.0.14-1585804187582/current/replicas doesn't exist 
2020-04-02 05:09:49,522 [Thread-776] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:49,522 [Thread-943] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 0ms
2020-04-02 05:09:49,522 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:49,523 [Thread-928] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39615
2020-04-02 05:09:49,547 [Thread-894] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582: 29ms
2020-04-02 05:09:49,548 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:09:49,548 [Thread-894] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:12 AM with interval of 21600000ms
2020-04-02 05:09:49,548 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-01ed9015-b18d-4d61-a43d-7ddc46ea5bfa): finished scanning block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,548 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:09:49,549 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-01ed9015-b18d-4d61-a43d-7ddc46ea5bfa): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:09:49,558 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-38c97080-41ad-4d14-91fe-0d48b1417f76): finished scanning block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,559 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-38c97080-41ad-4d14-91fe-0d48b1417f76): no suitable block pools found to scan.  Waiting 1814399989 ms.
2020-04-02 05:09:49,559 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:49,559 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:49,559 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:49,559 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:49,560 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40940
2020-04-02 05:09:49,560 [Thread-776] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:49,566 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@11bdf96c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:49,567 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@352ad656{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:49,567 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid d5c8becf-f706-4887-bfd5-e8783bfec939) service to localhost/127.0.0.1:39615 beginning handshake with NN
2020-04-02 05:09:49,571 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@29eb7247{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:49,572 [Thread-776] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@48a0f431{HTTP/1.1,[http/1.1]}{localhost:40940}
2020-04-02 05:09:49,572 [Thread-776] INFO  server.Server (Server.java:doStart(419)) - Started @59982ms
2020-04-02 05:09:49,598 [Thread-928] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:49,601 [Thread-928] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:49,601 [Thread-928] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 292980063. Formatting...
2020-04-02 05:09:49,601 [Thread-928] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d4ee1a18-c641-45d3-827c-313617f075b6 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-04-02 05:09:49,606 [Thread-928] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:49,606 [Thread-928] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 292980063. Formatting...
2020-04-02 05:09:49,606 [Thread-928] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-68d1a46b-06e4-4e43-9bcd-1490062e530d for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-04-02 05:09:49,608 [IPC Server handler 5 on 39615] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40904, datanodeUuid=d5c8becf-f706-4887-bfd5-e8783bfec939, infoPort=37378, infoSecurePort=0, ipcPort=39477, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582) storage d5c8becf-f706-4887-bfd5-e8783bfec939
2020-04-02 05:09:49,609 [IPC Server handler 5 on 39615] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40904
2020-04-02 05:09:49,609 [IPC Server handler 5 on 39615] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d5c8becf-f706-4887-bfd5-e8783bfec939 (127.0.0.1:40904).
2020-04-02 05:09:49,610 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid d5c8becf-f706-4887-bfd5-e8783bfec939) service to localhost/127.0.0.1:39615 successfully registered with NN
2020-04-02 05:09:49,610 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:39615 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:49,612 [IPC Server handler 5 on 39615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-38c97080-41ad-4d14-91fe-0d48b1417f76 for DN 127.0.0.1:40904
2020-04-02 05:09:49,612 [IPC Server handler 5 on 39615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-01ed9015-b18d-4d61-a43d-7ddc46ea5bfa for DN 127.0.0.1:40904
2020-04-02 05:09:49,614 [IPC Server handler 7 on 39615] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:40904, datanodeUuid=d5c8becf-f706-4887-bfd5-e8783bfec939, infoPort=37378, infoSecurePort=0, ipcPort=39477, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), reports.length=2
2020-04-02 05:09:49,626 [Thread-928] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,628 [Thread-928] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,628 [Thread-928] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1079677155-172.17.0.14-1585804187582 is not formatted. Formatting ...
2020-04-02 05:09:49,629 [Thread-928] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1079677155-172.17.0.14-1585804187582 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1079677155-172.17.0.14-1585804187582/current
2020-04-02 05:09:49,636 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb94e7846cc0908ff: Processing first storage report for DS-38c97080-41ad-4d14-91fe-0d48b1417f76 from datanode d5c8becf-f706-4887-bfd5-e8783bfec939
2020-04-02 05:09:49,637 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb94e7846cc0908ff: from storage DS-38c97080-41ad-4d14-91fe-0d48b1417f76 node DatanodeRegistration(127.0.0.1:40904, datanodeUuid=d5c8becf-f706-4887-bfd5-e8783bfec939, infoPort=37378, infoSecurePort=0, ipcPort=39477, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), blocks: 0, hasStaleStorage: true, processing time: 19 msecs, invalidatedBlocks: 0
2020-04-02 05:09:49,637 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb94e7846cc0908ff: Processing first storage report for DS-01ed9015-b18d-4d61-a43d-7ddc46ea5bfa from datanode d5c8becf-f706-4887-bfd5-e8783bfec939
2020-04-02 05:09:49,637 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb94e7846cc0908ff: from storage DS-01ed9015-b18d-4d61-a43d-7ddc46ea5bfa node DatanodeRegistration(127.0.0.1:40904, datanodeUuid=d5c8becf-f706-4887-bfd5-e8783bfec939, infoPort=37378, infoSecurePort=0, ipcPort=39477, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:49,637 [IPC Server handler 7 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xb94e7846cc0908ff
2020-04-02 05:09:49,637 [Thread-776] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36101
2020-04-02 05:09:49,638 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6be91131] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:49,638 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:49,639 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:49,639 [Thread-776] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:49,640 [Socket Reader #1 for port 45041] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45041
2020-04-02 05:09:49,642 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xb94e7846cc0908ff,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 28 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:49,642 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,644 [Thread-776] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:45041
2020-04-02 05:09:49,646 [Thread-928] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,646 [Thread-928] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,646 [Thread-928] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1079677155-172.17.0.14-1585804187582 is not formatted. Formatting ...
2020-04-02 05:09:49,646 [Thread-928] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1079677155-172.17.0.14-1585804187582 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1079677155-172.17.0.14-1585804187582/current
2020-04-02 05:09:49,648 [Thread-928] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=292980063;bpid=BP-1079677155-172.17.0.14-1585804187582;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=292980063;c=1585804187582;bpid=BP-1079677155-172.17.0.14-1585804187582;dnuuid=null
2020-04-02 05:09:49,649 [Thread-928] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 6eb2ee0b-09b4-4f85-bd48-c25214cb4512
2020-04-02 05:09:49,650 [Thread-776] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:49,650 [Thread-776] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:49,650 [Thread-956] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39615 starting to offer service
2020-04-02 05:09:49,652 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:49,652 [IPC Server listener on 45041] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45041: starting
2020-04-02 05:09:49,672 [Thread-956] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39615
2020-04-02 05:09:49,662 [Thread-776] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 45041 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:49,680 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:09:49,681 [Thread-776] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:09:49,656 [Thread-928] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-d4ee1a18-c641-45d3-827c-313617f075b6
2020-04-02 05:09:49,681 [Thread-776] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:09:49,677 [Thread-956] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:49,681 [Thread-928] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:09:49,684 [Thread-956] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:49,684 [Thread-956] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 292980063. Formatting...
2020-04-02 05:09:49,684 [Thread-956] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-daae56b6-12ff-4ca7-80db-758c19f0c12d for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-04-02 05:09:49,686 [Thread-776] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:49,686 [Thread-776] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:49,686 [Thread-776] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:49,686 [Thread-776] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:49,687 [Thread-956] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:49,687 [Thread-956] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 292980063. Formatting...
2020-04-02 05:09:49,687 [Thread-956] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3a54a967-e047-4a49-92fd-5e35f7c3d315 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-04-02 05:09:49,688 [Thread-776] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:49,688 [Thread-776] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:49,688 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:49,689 [Thread-776] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42333
2020-04-02 05:09:49,689 [Thread-776] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:49,689 [Thread-776] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:49,690 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:49,691 [Thread-776] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:49,692 [Thread-776] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:49,692 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:49,693 [Thread-928] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-68d1a46b-06e4-4e43-9bcd-1490062e530d
2020-04-02 05:09:49,693 [Thread-928] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:09:49,694 [Thread-928] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:49,702 [Thread-928] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:09:49,703 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:49,706 [Thread-956] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,706 [Thread-956] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,706 [Thread-956] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-1079677155-172.17.0.14-1585804187582 is not formatted. Formatting ...
2020-04-02 05:09:49,706 [Thread-956] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1079677155-172.17.0.14-1585804187582 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1079677155-172.17.0.14-1585804187582/current
2020-04-02 05:09:49,711 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:49,711 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:49,712 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:49,712 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35340
2020-04-02 05:09:49,712 [Thread-776] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:49,715 [Thread-928] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:09:49,715 [Thread-928] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:09:49,716 [Thread-956] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,716 [Thread-956] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,716 [Thread-956] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-1079677155-172.17.0.14-1585804187582 is not formatted. Formatting ...
2020-04-02 05:09:49,716 [Thread-956] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1079677155-172.17.0.14-1585804187582 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1079677155-172.17.0.14-1585804187582/current
2020-04-02 05:09:49,719 [Thread-928] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:09:49,740 [Thread-956] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=292980063;bpid=BP-1079677155-172.17.0.14-1585804187582;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=292980063;c=1585804187582;bpid=BP-1079677155-172.17.0.14-1585804187582;dnuuid=null
2020-04-02 05:09:49,741 [Thread-956] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 60182ee3-8267-455e-8b07-2b7f696a2f02
2020-04-02 05:09:49,746 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@690661dd{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:49,747 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@64018add{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:49,750 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4a970d99{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:49,751 [Thread-776] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3ecc4994{HTTP/1.1,[http/1.1]}{localhost:35340}
2020-04-02 05:09:49,751 [Thread-776] INFO  server.Server (Server.java:doStart(419)) - Started @60161ms
2020-04-02 05:09:49,795 [Thread-956] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-daae56b6-12ff-4ca7-80db-758c19f0c12d
2020-04-02 05:09:49,796 [Thread-956] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-04-02 05:09:49,797 [Thread-956] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-3a54a967-e047-4a49-92fd-5e35f7c3d315
2020-04-02 05:09:49,797 [Thread-956] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-04-02 05:09:49,798 [Thread-956] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:49,798 [Thread-956] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:09:49,802 [Thread-928] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,810 [Thread-977] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:09:49,810 [Thread-978] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:09:49,810 [Thread-956] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:09:49,811 [Thread-956] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:09:49,811 [Thread-956] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:09:49,812 [Thread-776] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36025
2020-04-02 05:09:49,819 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:49,820 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:49,820 [Thread-776] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:49,821 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3d827ee5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:49,821 [Socket Reader #1 for port 46667] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46667
2020-04-02 05:09:49,826 [Thread-776] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:46667
2020-04-02 05:09:49,843 [Thread-776] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:49,844 [Thread-776] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:49,846 [Thread-985] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39615 starting to offer service
2020-04-02 05:09:49,846 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:49,847 [IPC Server listener on 46667] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46667: starting
2020-04-02 05:09:49,848 [Thread-776] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 46667 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:49,848 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:09:49,849 [Thread-776] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:09:49,849 [Thread-956] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,853 [Thread-776] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:09:49,854 [Thread-997] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:09:49,858 [Thread-999] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:09:49,859 [Thread-985] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39615
2020-04-02 05:09:49,862 [Thread-985] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:49,862 [Thread-776] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:49,864 [Thread-776] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:49,865 [Thread-776] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:49,865 [Thread-776] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:49,865 [Thread-776] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:49,865 [Thread-776] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:49,866 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:49,866 [Thread-985] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:49,866 [Thread-985] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 292980063. Formatting...
2020-04-02 05:09:49,866 [Thread-776] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:39389
2020-04-02 05:09:49,866 [Thread-985] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-eb5b1698-027f-4f61-a9f2-ba2f9f26b3d1 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-04-02 05:09:49,866 [Thread-776] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:49,866 [Thread-776] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:49,868 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:49,869 [Thread-985] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:49,869 [Thread-985] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 292980063. Formatting...
2020-04-02 05:09:49,869 [Thread-985] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3ed479df-6c94-4bf6-ac15-8e527fb1eb2b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-04-02 05:09:49,869 [Thread-776] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:49,870 [Thread-776] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:49,870 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:49,871 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:49,871 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:49,871 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:49,871 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:49,872 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43237
2020-04-02 05:09:49,872 [Thread-776] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:49,875 [Thread-978] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1079677155-172.17.0.14-1585804187582 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 65ms
2020-04-02 05:09:49,887 [Thread-985] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,887 [Thread-985] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,887 [Thread-985] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-1079677155-172.17.0.14-1585804187582 is not formatted. Formatting ...
2020-04-02 05:09:49,888 [Thread-985] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1079677155-172.17.0.14-1585804187582 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1079677155-172.17.0.14-1585804187582/current
2020-04-02 05:09:49,900 [Thread-985] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,900 [Thread-985] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,900 [Thread-985] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-1079677155-172.17.0.14-1585804187582 is not formatted. Formatting ...
2020-04-02 05:09:49,900 [Thread-985] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1079677155-172.17.0.14-1585804187582 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1079677155-172.17.0.14-1585804187582/current
2020-04-02 05:09:49,906 [Thread-985] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=292980063;bpid=BP-1079677155-172.17.0.14-1585804187582;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=292980063;c=1585804187582;bpid=BP-1079677155-172.17.0.14-1585804187582;dnuuid=null
2020-04-02 05:09:49,907 [Thread-985] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID df50cddc-ef1d-488e-9914-df13927bdc9f
2020-04-02 05:09:49,910 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@73a81df7{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:49,912 [Thread-997] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1079677155-172.17.0.14-1585804187582 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 58ms
2020-04-02 05:09:49,912 [Thread-985] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-eb5b1698-027f-4f61-a9f2-ba2f9f26b3d1
2020-04-02 05:09:49,912 [Thread-985] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-04-02 05:09:49,912 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@69ba3f36{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:49,921 [Thread-977] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1079677155-172.17.0.14-1585804187582 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 111ms
2020-04-02 05:09:49,921 [Thread-928] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1079677155-172.17.0.14-1585804187582: 120ms
2020-04-02 05:09:49,922 [Thread-1009] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:09:49,922 [Thread-1010] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:09:49,922 [Thread-1009] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1079677155-172.17.0.14-1585804187582/current/replicas doesn't exist 
2020-04-02 05:09:49,922 [Thread-1010] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1079677155-172.17.0.14-1585804187582/current/replicas doesn't exist 
2020-04-02 05:09:49,923 [Thread-985] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-3ed479df-6c94-4bf6-ac15-8e527fb1eb2b
2020-04-02 05:09:49,923 [Thread-1009] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 1ms
2020-04-02 05:09:49,923 [Thread-1010] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 1ms
2020-04-02 05:09:49,923 [Thread-985] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-04-02 05:09:49,926 [Thread-985] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:49,926 [Thread-928] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582: 4ms
2020-04-02 05:09:49,926 [Thread-928] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:30 AM with interval of 21600000ms
2020-04-02 05:09:49,927 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:09:49,927 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-68d1a46b-06e4-4e43-9bcd-1490062e530d): finished scanning block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,928 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-68d1a46b-06e4-4e43-9bcd-1490062e530d): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:09:49,927 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:09:49,928 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-d4ee1a18-c641-45d3-827c-313617f075b6): finished scanning block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,928 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-d4ee1a18-c641-45d3-827c-313617f075b6): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:09:49,931 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid 6eb2ee0b-09b4-4f85-bd48-c25214cb4512) service to localhost/127.0.0.1:39615 beginning handshake with NN
2020-04-02 05:09:49,933 [IPC Server handler 0 on 39615] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39673, datanodeUuid=6eb2ee0b-09b4-4f85-bd48-c25214cb4512, infoPort=38498, infoSecurePort=0, ipcPort=41532, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582) storage 6eb2ee0b-09b4-4f85-bd48-c25214cb4512
2020-04-02 05:09:49,933 [IPC Server handler 0 on 39615] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39673
2020-04-02 05:09:49,933 [IPC Server handler 0 on 39615] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 6eb2ee0b-09b4-4f85-bd48-c25214cb4512 (127.0.0.1:39673).
2020-04-02 05:09:49,933 [Thread-985] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:09:49,934 [Thread-985] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:09:49,934 [Thread-985] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:09:49,937 [Thread-985] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:09:49,938 [Thread-985] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,938 [Thread-1015] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:09:49,938 [Thread-1016] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:09:49,938 [Thread-999] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1079677155-172.17.0.14-1585804187582 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 81ms
2020-04-02 05:09:49,941 [Thread-956] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1079677155-172.17.0.14-1585804187582: 89ms
2020-04-02 05:09:49,941 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6c591d22{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:49,944 [Thread-776] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6da2fd3b{HTTP/1.1,[http/1.1]}{localhost:43237}
2020-04-02 05:09:49,944 [Thread-1018] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:09:49,944 [Thread-776] INFO  server.Server (Server.java:doStart(419)) - Started @60355ms
2020-04-02 05:09:49,945 [Thread-1018] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1079677155-172.17.0.14-1585804187582/current/replicas doesn't exist 
2020-04-02 05:09:49,945 [Thread-1018] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 0ms
2020-04-02 05:09:49,946 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid 6eb2ee0b-09b4-4f85-bd48-c25214cb4512) service to localhost/127.0.0.1:39615 successfully registered with NN
2020-04-02 05:09:49,946 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:39615 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:49,946 [Thread-1017] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:09:49,950 [Thread-1017] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1079677155-172.17.0.14-1585804187582/current/replicas doesn't exist 
2020-04-02 05:09:49,950 [Thread-1017] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 0ms
2020-04-02 05:09:49,950 [Thread-956] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582: 8ms
2020-04-02 05:09:49,954 [Thread-956] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:35 AM with interval of 21600000ms
2020-04-02 05:09:49,955 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:09:49,955 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-3a54a967-e047-4a49-92fd-5e35f7c3d315): finished scanning block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,956 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-3a54a967-e047-4a49-92fd-5e35f7c3d315): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:09:49,957 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:09:49,958 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-daae56b6-12ff-4ca7-80db-758c19f0c12d): finished scanning block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,965 [IPC Server handler 1 on 39615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d4ee1a18-c641-45d3-827c-313617f075b6 for DN 127.0.0.1:39673
2020-04-02 05:09:49,965 [IPC Server handler 1 on 39615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-68d1a46b-06e4-4e43-9bcd-1490062e530d for DN 127.0.0.1:39673
2020-04-02 05:09:49,974 [Thread-776] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41849
2020-04-02 05:09:49,975 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid 60182ee3-8267-455e-8b07-2b7f696a2f02) service to localhost/127.0.0.1:39615 beginning handshake with NN
2020-04-02 05:09:49,976 [IPC Server handler 2 on 39615] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:39673, datanodeUuid=6eb2ee0b-09b4-4f85-bd48-c25214cb4512, infoPort=38498, infoSecurePort=0, ipcPort=41532, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), reports.length=2
2020-04-02 05:09:49,976 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-daae56b6-12ff-4ca7-80db-758c19f0c12d): no suitable block pools found to scan.  Waiting 1814399978 ms.
2020-04-02 05:09:49,976 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x9ef8c91a14f5cef8: Processing first storage report for DS-d4ee1a18-c641-45d3-827c-313617f075b6 from datanode 6eb2ee0b-09b4-4f85-bd48-c25214cb4512
2020-04-02 05:09:49,976 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x9ef8c91a14f5cef8: from storage DS-d4ee1a18-c641-45d3-827c-313617f075b6 node DatanodeRegistration(127.0.0.1:39673, datanodeUuid=6eb2ee0b-09b4-4f85-bd48-c25214cb4512, infoPort=38498, infoSecurePort=0, ipcPort=41532, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:49,976 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x9ef8c91a14f5cef8: Processing first storage report for DS-68d1a46b-06e4-4e43-9bcd-1490062e530d from datanode 6eb2ee0b-09b4-4f85-bd48-c25214cb4512
2020-04-02 05:09:49,976 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x9ef8c91a14f5cef8: from storage DS-68d1a46b-06e4-4e43-9bcd-1490062e530d node DatanodeRegistration(127.0.0.1:39673, datanodeUuid=6eb2ee0b-09b4-4f85-bd48-c25214cb4512, infoPort=38498, infoSecurePort=0, ipcPort=41532, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:09:49,977 [IPC Server handler 2 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x9ef8c91a14f5cef8
2020-04-02 05:09:49,977 [IPC Server handler 3 on 39615] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40621, datanodeUuid=60182ee3-8267-455e-8b07-2b7f696a2f02, infoPort=36101, infoSecurePort=0, ipcPort=45041, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582) storage 60182ee3-8267-455e-8b07-2b7f696a2f02
2020-04-02 05:09:49,977 [IPC Server handler 3 on 39615] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40621
2020-04-02 05:09:49,977 [IPC Server handler 3 on 39615] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 60182ee3-8267-455e-8b07-2b7f696a2f02 (127.0.0.1:40621).
2020-04-02 05:09:49,977 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x9ef8c91a14f5cef8,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 11 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:49,977 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:49,978 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid 60182ee3-8267-455e-8b07-2b7f696a2f02) service to localhost/127.0.0.1:39615 successfully registered with NN
2020-04-02 05:09:49,978 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:39615 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:49,984 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:49,984 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:49,984 [Thread-776] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:49,985 [Socket Reader #1 for port 43421] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43421
2020-04-02 05:09:49,988 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@642edcfd] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:49,994 [Thread-1015] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1079677155-172.17.0.14-1585804187582 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 56ms
2020-04-02 05:09:50,003 [Thread-776] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43421
2020-04-02 05:09:50,010 [Thread-1016] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1079677155-172.17.0.14-1585804187582 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 72ms
2020-04-02 05:09:50,013 [IPC Server handler 4 on 39615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-daae56b6-12ff-4ca7-80db-758c19f0c12d for DN 127.0.0.1:40621
2020-04-02 05:09:50,013 [Thread-985] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1079677155-172.17.0.14-1585804187582: 75ms
2020-04-02 05:09:50,013 [IPC Server handler 4 on 39615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3a54a967-e047-4a49-92fd-5e35f7c3d315 for DN 127.0.0.1:40621
2020-04-02 05:09:50,014 [Thread-1028] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:09:50,014 [Thread-1029] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:09:50,014 [Thread-1028] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1079677155-172.17.0.14-1585804187582/current/replicas doesn't exist 
2020-04-02 05:09:50,014 [Thread-1029] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1079677155-172.17.0.14-1585804187582/current/replicas doesn't exist 
2020-04-02 05:09:50,014 [Thread-1028] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 0ms
2020-04-02 05:09:50,014 [Thread-1029] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 1ms
2020-04-02 05:09:50,015 [Thread-985] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582: 1ms
2020-04-02 05:09:50,015 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:09:50,015 [Thread-985] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:05 AM with interval of 21600000ms
2020-04-02 05:09:50,015 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-3ed479df-6c94-4bf6-ac15-8e527fb1eb2b): finished scanning block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,015 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:09:50,016 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-eb5b1698-027f-4f61-a9f2-ba2f9f26b3d1): finished scanning block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,018 [IPC Server handler 6 on 39615] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:40621, datanodeUuid=60182ee3-8267-455e-8b07-2b7f696a2f02, infoPort=36101, infoSecurePort=0, ipcPort=45041, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), reports.length=2
2020-04-02 05:09:50,018 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid df50cddc-ef1d-488e-9914-df13927bdc9f) service to localhost/127.0.0.1:39615 beginning handshake with NN
2020-04-02 05:09:50,018 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-3ed479df-6c94-4bf6-ac15-8e527fb1eb2b): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:09:50,018 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-eb5b1698-027f-4f61-a9f2-ba2f9f26b3d1): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:09:50,019 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x7f266f3243b609f9: Processing first storage report for DS-3a54a967-e047-4a49-92fd-5e35f7c3d315 from datanode 60182ee3-8267-455e-8b07-2b7f696a2f02
2020-04-02 05:09:50,019 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x7f266f3243b609f9: from storage DS-3a54a967-e047-4a49-92fd-5e35f7c3d315 node DatanodeRegistration(127.0.0.1:40621, datanodeUuid=60182ee3-8267-455e-8b07-2b7f696a2f02, infoPort=36101, infoSecurePort=0, ipcPort=45041, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:50,019 [IPC Server handler 5 on 39615] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42333, datanodeUuid=df50cddc-ef1d-488e-9914-df13927bdc9f, infoPort=36025, infoSecurePort=0, ipcPort=46667, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582) storage df50cddc-ef1d-488e-9914-df13927bdc9f
2020-04-02 05:09:50,020 [IPC Server handler 5 on 39615] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42333
2020-04-02 05:09:50,020 [IPC Server handler 5 on 39615] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN df50cddc-ef1d-488e-9914-df13927bdc9f (127.0.0.1:42333).
2020-04-02 05:09:50,020 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x7f266f3243b609f9: Processing first storage report for DS-daae56b6-12ff-4ca7-80db-758c19f0c12d from datanode 60182ee3-8267-455e-8b07-2b7f696a2f02
2020-04-02 05:09:50,020 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x7f266f3243b609f9: from storage DS-daae56b6-12ff-4ca7-80db-758c19f0c12d node DatanodeRegistration(127.0.0.1:40621, datanodeUuid=60182ee3-8267-455e-8b07-2b7f696a2f02, infoPort=36101, infoSecurePort=0, ipcPort=45041, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:50,020 [IPC Server handler 6 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x7f266f3243b609f9
2020-04-02 05:09:50,020 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid df50cddc-ef1d-488e-9914-df13927bdc9f) service to localhost/127.0.0.1:39615 successfully registered with NN
2020-04-02 05:09:50,021 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:39615 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:50,023 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x7f266f3243b609f9,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 9 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:50,023 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,027 [IPC Server handler 7 on 39615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-eb5b1698-027f-4f61-a9f2-ba2f9f26b3d1 for DN 127.0.0.1:42333
2020-04-02 05:09:50,027 [IPC Server handler 7 on 39615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3ed479df-6c94-4bf6-ac15-8e527fb1eb2b for DN 127.0.0.1:42333
2020-04-02 05:09:50,029 [IPC Server handler 8 on 39615] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:42333, datanodeUuid=df50cddc-ef1d-488e-9914-df13927bdc9f, infoPort=36025, infoSecurePort=0, ipcPort=46667, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), reports.length=2
2020-04-02 05:09:50,029 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x48fcee03efd0b3ad: Processing first storage report for DS-eb5b1698-027f-4f61-a9f2-ba2f9f26b3d1 from datanode df50cddc-ef1d-488e-9914-df13927bdc9f
2020-04-02 05:09:50,030 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x48fcee03efd0b3ad: from storage DS-eb5b1698-027f-4f61-a9f2-ba2f9f26b3d1 node DatanodeRegistration(127.0.0.1:42333, datanodeUuid=df50cddc-ef1d-488e-9914-df13927bdc9f, infoPort=36025, infoSecurePort=0, ipcPort=46667, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:50,030 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x48fcee03efd0b3ad: Processing first storage report for DS-3ed479df-6c94-4bf6-ac15-8e527fb1eb2b from datanode df50cddc-ef1d-488e-9914-df13927bdc9f
2020-04-02 05:09:50,030 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x48fcee03efd0b3ad: from storage DS-3ed479df-6c94-4bf6-ac15-8e527fb1eb2b node DatanodeRegistration(127.0.0.1:42333, datanodeUuid=df50cddc-ef1d-488e-9914-df13927bdc9f, infoPort=36025, infoSecurePort=0, ipcPort=46667, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:50,030 [IPC Server handler 8 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x48fcee03efd0b3ad
2020-04-02 05:09:50,030 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x48fcee03efd0b3ad,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:50,031 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,031 [Thread-776] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:50,031 [Thread-776] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:50,032 [Thread-1035] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39615 starting to offer service
2020-04-02 05:09:50,036 [Thread-1035] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39615
2020-04-02 05:09:50,037 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:50,037 [IPC Server listener on 43421] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43421: starting
2020-04-02 05:09:50,046 [Thread-776] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43421 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:50,047 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:09:50,047 [Thread-776] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:09:50,048 [Thread-776] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:09:50,050 [Thread-776] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:50,051 [Thread-776] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:50,051 [Thread-776] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:50,051 [Thread-776] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:50,051 [Thread-776] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:50,051 [Thread-776] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:50,051 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:50,052 [Thread-776] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:33864
2020-04-02 05:09:50,052 [Thread-776] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:50,052 [Thread-776] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:50,053 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:50,056 [Thread-776] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:50,058 [Thread-776] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:50,058 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:50,059 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:50,059 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:50,060 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:50,060 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:50,060 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39597
2020-04-02 05:09:50,060 [Thread-776] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:50,061 [Thread-1035] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:50,064 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2e339a64{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:50,065 [Thread-1035] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:50,065 [Thread-1035] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 292980063. Formatting...
2020-04-02 05:09:50,066 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7fe99b2a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:50,066 [Thread-1035] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a7ded864-c73b-491b-90b5-a4bd6d98f526 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-04-02 05:09:50,069 [Thread-1035] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:50,070 [Thread-1035] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 292980063. Formatting...
2020-04-02 05:09:50,070 [Thread-1035] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b4b7100b-9880-4028-99fb-0d1992697b8b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-04-02 05:09:50,071 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3542a536{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:50,071 [Thread-776] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@52a89470{HTTP/1.1,[http/1.1]}{localhost:39597}
2020-04-02 05:09:50,071 [Thread-776] INFO  server.Server (Server.java:doStart(419)) - Started @60482ms
2020-04-02 05:09:50,091 [Thread-776] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40765
2020-04-02 05:09:50,092 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:50,092 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:50,092 [Thread-776] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:50,092 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@747043a2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:50,093 [Socket Reader #1 for port 44674] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44674
2020-04-02 05:09:50,100 [Thread-1035] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,100 [Thread-1035] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,100 [Thread-1035] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-1079677155-172.17.0.14-1585804187582 is not formatted. Formatting ...
2020-04-02 05:09:50,100 [Thread-1035] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1079677155-172.17.0.14-1585804187582 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1079677155-172.17.0.14-1585804187582/current
2020-04-02 05:09:50,101 [Thread-776] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:44674
2020-04-02 05:09:50,112 [Thread-776] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:50,112 [Thread-1035] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,113 [Thread-776] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:50,113 [Thread-1035] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,113 [Thread-1035] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-1079677155-172.17.0.14-1585804187582 is not formatted. Formatting ...
2020-04-02 05:09:50,113 [Thread-1035] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1079677155-172.17.0.14-1585804187582 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1079677155-172.17.0.14-1585804187582/current
2020-04-02 05:09:50,113 [Thread-1058] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39615 starting to offer service
2020-04-02 05:09:50,116 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:50,116 [IPC Server listener on 44674] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44674: starting
2020-04-02 05:09:50,117 [Thread-776] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 44674 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:50,120 [Thread-1058] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39615
2020-04-02 05:09:50,122 [Thread-1058] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:50,124 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:09:50,124 [Thread-1058] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:50,124 [Thread-1058] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 292980063. Formatting...
2020-04-02 05:09:50,124 [Thread-1058] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-52f81f9c-cbfd-4ad8-a4eb-af1fffa2bdd1 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-04-02 05:09:50,124 [Thread-1035] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=292980063;bpid=BP-1079677155-172.17.0.14-1585804187582;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=292980063;c=1585804187582;bpid=BP-1079677155-172.17.0.14-1585804187582;dnuuid=null
2020-04-02 05:09:50,125 [Thread-776] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:09:50,126 [Thread-776] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:09:50,126 [Thread-1035] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 829765f2-8f35-4380-94c8-a372df2cef81
2020-04-02 05:09:50,126 [Thread-776] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:50,129 [Thread-776] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:50,129 [Thread-776] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:50,129 [Thread-776] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:50,129 [Thread-776] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:50,129 [Thread-776] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:50,130 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:50,130 [Thread-1058] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:50,130 [Thread-1058] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 292980063. Formatting...
2020-04-02 05:09:50,130 [Thread-776] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42132
2020-04-02 05:09:50,130 [Thread-776] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:50,130 [Thread-776] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:50,130 [Thread-1058] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3ad27b82-2f9a-4a0d-b313-b3a8592dd53f for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-04-02 05:09:50,131 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:50,132 [Thread-1035] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-a7ded864-c73b-491b-90b5-a4bd6d98f526
2020-04-02 05:09:50,138 [Thread-1035] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-04-02 05:09:50,138 [Thread-776] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:50,139 [Thread-1035] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-b4b7100b-9880-4028-99fb-0d1992697b8b
2020-04-02 05:09:50,156 [Thread-1035] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-04-02 05:09:50,158 [Thread-1035] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:50,159 [Thread-1035] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:09:50,160 [Thread-776] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:50,161 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:50,162 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:50,162 [Thread-1035] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:09:50,162 [Thread-1035] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:09:50,163 [Thread-1035] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:09:50,163 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:50,163 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:50,164 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:50,164 [Thread-776] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37091
2020-04-02 05:09:50,164 [Thread-776] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:50,188 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2905b4dc{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:50,191 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5d644352{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:50,195 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@391754b1{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:50,196 [Thread-1058] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,197 [Thread-1058] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,197 [Thread-776] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@119e7ace{HTTP/1.1,[http/1.1]}{localhost:37091}
2020-04-02 05:09:50,203 [Thread-1058] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-1079677155-172.17.0.14-1585804187582 is not formatted. Formatting ...
2020-04-02 05:09:50,204 [Thread-1058] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1079677155-172.17.0.14-1585804187582 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1079677155-172.17.0.14-1585804187582/current
2020-04-02 05:09:50,204 [Thread-776] INFO  server.Server (Server.java:doStart(419)) - Started @60614ms
2020-04-02 05:09:50,229 [Thread-1035] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,238 [Thread-1077] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:09:50,244 [Thread-1078] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:09:50,251 [Thread-776] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42449
2020-04-02 05:09:50,253 [Thread-1058] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,253 [Thread-1058] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,254 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6f1a8bb5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:50,254 [Thread-1058] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-1079677155-172.17.0.14-1585804187582 is not formatted. Formatting ...
2020-04-02 05:09:50,254 [Thread-1058] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1079677155-172.17.0.14-1585804187582 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1079677155-172.17.0.14-1585804187582/current
2020-04-02 05:09:50,254 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:50,254 [Thread-776] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:50,255 [Thread-776] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:50,256 [Socket Reader #1 for port 35426] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35426
2020-04-02 05:09:50,256 [Thread-1058] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=292980063;bpid=BP-1079677155-172.17.0.14-1585804187582;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=292980063;c=1585804187582;bpid=BP-1079677155-172.17.0.14-1585804187582;dnuuid=null
2020-04-02 05:09:50,266 [Thread-776] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:35426
2020-04-02 05:09:50,279 [Thread-1058] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 93fa5443-690e-4c57-acd2-566890e3323f
2020-04-02 05:09:50,281 [Thread-776] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:50,281 [Thread-776] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:50,281 [Thread-1086] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39615 starting to offer service
2020-04-02 05:09:50,283 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:50,283 [IPC Server listener on 35426] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35426: starting
2020-04-02 05:09:50,284 [Thread-776] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 35426 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:50,297 [Thread-1058] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-52f81f9c-cbfd-4ad8-a4eb-af1fffa2bdd1
2020-04-02 05:09:50,309 [Thread-1058] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-04-02 05:09:50,310 [Thread-1058] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-3ad27b82-2f9a-4a0d-b313-b3a8592dd53f
2020-04-02 05:09:50,311 [Thread-1058] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-04-02 05:09:50,311 [Thread-1058] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:50,312 [Thread-1058] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:09:50,312 [Thread-1058] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:09:50,312 [Thread-1058] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:09:50,312 [Thread-1058] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:09:50,312 [Thread-1086] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39615
2020-04-02 05:09:50,323 [Thread-1086] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:50,328 [Thread-1058] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,334 [Thread-1086] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:50,334 [Thread-1086] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 292980063. Formatting...
2020-04-02 05:09:50,334 [Thread-1086] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e0316177-73d2-4099-ae12-c27935c097b0 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-04-02 05:09:50,335 [Thread-1101] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:09:50,335 [Thread-1102] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:09:50,342 [IPC Server handler 2 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:50,344 [Thread-1078] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1079677155-172.17.0.14-1585804187582 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 100ms
2020-04-02 05:09:50,359 [Thread-1077] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1079677155-172.17.0.14-1585804187582 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 115ms
2020-04-02 05:09:50,367 [Thread-1035] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1079677155-172.17.0.14-1585804187582: 138ms
2020-04-02 05:09:50,367 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:09:50,367 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:09:50,368 [Thread-1103] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:09:50,368 [Thread-1103] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1079677155-172.17.0.14-1585804187582/current/replicas doesn't exist 
2020-04-02 05:09:50,368 [Thread-1104] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:09:50,368 [Thread-1104] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1079677155-172.17.0.14-1585804187582/current/replicas doesn't exist 
2020-04-02 05:09:50,368 [Thread-1104] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 0ms
2020-04-02 05:09:50,368 [Thread-1103] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 1ms
2020-04-02 05:09:50,368 [Thread-1035] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582: 2ms
2020-04-02 05:09:50,369 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:09:50,369 [Thread-1086] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:09:50,369 [Thread-1035] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:33 AM with interval of 21600000ms
2020-04-02 05:09:50,369 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-b4b7100b-9880-4028-99fb-0d1992697b8b): finished scanning block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,369 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:09:50,369 [Thread-1086] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 292980063. Formatting...
2020-04-02 05:09:50,372 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-b4b7100b-9880-4028-99fb-0d1992697b8b): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:09:50,372 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid 829765f2-8f35-4380-94c8-a372df2cef81) service to localhost/127.0.0.1:39615 beginning handshake with NN
2020-04-02 05:09:50,373 [Thread-1086] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-57a24baf-d5b5-4861-a7f6-fa849de485f4 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-04-02 05:09:50,369 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-a7ded864-c73b-491b-90b5-a4bd6d98f526): finished scanning block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,373 [IPC Server handler 3 on 39615] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39389, datanodeUuid=829765f2-8f35-4380-94c8-a372df2cef81, infoPort=41849, infoSecurePort=0, ipcPort=43421, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582) storage 829765f2-8f35-4380-94c8-a372df2cef81
2020-04-02 05:09:50,374 [IPC Server handler 3 on 39615] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39389
2020-04-02 05:09:50,374 [IPC Server handler 3 on 39615] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 829765f2-8f35-4380-94c8-a372df2cef81 (127.0.0.1:39389).
2020-04-02 05:09:50,373 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-a7ded864-c73b-491b-90b5-a4bd6d98f526): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:09:50,375 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid 829765f2-8f35-4380-94c8-a372df2cef81) service to localhost/127.0.0.1:39615 successfully registered with NN
2020-04-02 05:09:50,375 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:39615 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:50,381 [IPC Server handler 4 on 39615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a7ded864-c73b-491b-90b5-a4bd6d98f526 for DN 127.0.0.1:39389
2020-04-02 05:09:50,381 [IPC Server handler 4 on 39615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b4b7100b-9880-4028-99fb-0d1992697b8b for DN 127.0.0.1:39389
2020-04-02 05:09:50,383 [IPC Server handler 5 on 39615] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:39389, datanodeUuid=829765f2-8f35-4380-94c8-a372df2cef81, infoPort=41849, infoSecurePort=0, ipcPort=43421, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), reports.length=2
2020-04-02 05:09:50,386 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xda1c2d7bb7b9050c: Processing first storage report for DS-a7ded864-c73b-491b-90b5-a4bd6d98f526 from datanode 829765f2-8f35-4380-94c8-a372df2cef81
2020-04-02 05:09:50,386 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xda1c2d7bb7b9050c: from storage DS-a7ded864-c73b-491b-90b5-a4bd6d98f526 node DatanodeRegistration(127.0.0.1:39389, datanodeUuid=829765f2-8f35-4380-94c8-a372df2cef81, infoPort=41849, infoSecurePort=0, ipcPort=43421, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:50,387 [Thread-1086] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,388 [Thread-1086] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,388 [Thread-1086] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-1079677155-172.17.0.14-1585804187582 is not formatted. Formatting ...
2020-04-02 05:09:50,388 [Thread-1086] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1079677155-172.17.0.14-1585804187582 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1079677155-172.17.0.14-1585804187582/current
2020-04-02 05:09:50,389 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xda1c2d7bb7b9050c: Processing first storage report for DS-b4b7100b-9880-4028-99fb-0d1992697b8b from datanode 829765f2-8f35-4380-94c8-a372df2cef81
2020-04-02 05:09:50,390 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xda1c2d7bb7b9050c: from storage DS-b4b7100b-9880-4028-99fb-0d1992697b8b node DatanodeRegistration(127.0.0.1:39389, datanodeUuid=829765f2-8f35-4380-94c8-a372df2cef81, infoPort=41849, infoSecurePort=0, ipcPort=43421, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:50,390 [IPC Server handler 5 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xda1c2d7bb7b9050c
2020-04-02 05:09:50,390 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xda1c2d7bb7b9050c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 9 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:50,391 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,398 [Thread-1086] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,399 [Thread-1086] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,399 [Thread-1086] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-1079677155-172.17.0.14-1585804187582 is not formatted. Formatting ...
2020-04-02 05:09:50,399 [Thread-1086] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1079677155-172.17.0.14-1585804187582 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1079677155-172.17.0.14-1585804187582/current
2020-04-02 05:09:50,401 [Thread-1086] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=292980063;bpid=BP-1079677155-172.17.0.14-1585804187582;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=292980063;c=1585804187582;bpid=BP-1079677155-172.17.0.14-1585804187582;dnuuid=null
2020-04-02 05:09:50,402 [Thread-1086] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 517a2a8f-cb78-48a4-9295-9075657e0d88
2020-04-02 05:09:50,404 [Thread-1086] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-e0316177-73d2-4099-ae12-c27935c097b0
2020-04-02 05:09:50,406 [Thread-1086] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-04-02 05:09:50,407 [Thread-1086] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-57a24baf-d5b5-4861-a7f6-fa849de485f4
2020-04-02 05:09:50,408 [Thread-1086] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-04-02 05:09:50,410 [Thread-1086] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:50,410 [Thread-1086] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:09:50,411 [Thread-1086] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:09:50,411 [Thread-1086] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:09:50,411 [Thread-1086] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:09:50,411 [Thread-1086] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,413 [Thread-1112] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:09:50,413 [Thread-1113] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:09:50,413 [Thread-1101] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1079677155-172.17.0.14-1585804187582 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 79ms
2020-04-02 05:09:50,417 [Thread-1102] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1079677155-172.17.0.14-1585804187582 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 82ms
2020-04-02 05:09:50,417 [Thread-1058] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1079677155-172.17.0.14-1585804187582: 89ms
2020-04-02 05:09:50,417 [Thread-1114] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:09:50,417 [Thread-1115] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:09:50,417 [Thread-1114] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1079677155-172.17.0.14-1585804187582/current/replicas doesn't exist 
2020-04-02 05:09:50,417 [Thread-1115] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1079677155-172.17.0.14-1585804187582/current/replicas doesn't exist 
2020-04-02 05:09:50,418 [Thread-1114] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 1ms
2020-04-02 05:09:50,422 [Thread-1115] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 5ms
2020-04-02 05:09:50,422 [Thread-1058] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582: 5ms
2020-04-02 05:09:50,423 [Thread-1058] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:23 AM with interval of 21600000ms
2020-04-02 05:09:50,423 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:09:50,423 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:09:50,423 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-52f81f9c-cbfd-4ad8-a4eb-af1fffa2bdd1): finished scanning block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,423 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-3ad27b82-2f9a-4a0d-b313-b3a8592dd53f): finished scanning block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,424 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-3ad27b82-2f9a-4a0d-b313-b3a8592dd53f): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:09:50,426 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid 93fa5443-690e-4c57-acd2-566890e3323f) service to localhost/127.0.0.1:39615 beginning handshake with NN
2020-04-02 05:09:50,424 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-52f81f9c-cbfd-4ad8-a4eb-af1fffa2bdd1): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:09:50,428 [IPC Server handler 6 on 39615] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33864, datanodeUuid=93fa5443-690e-4c57-acd2-566890e3323f, infoPort=40765, infoSecurePort=0, ipcPort=44674, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582) storage 93fa5443-690e-4c57-acd2-566890e3323f
2020-04-02 05:09:50,429 [IPC Server handler 6 on 39615] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33864
2020-04-02 05:09:50,429 [IPC Server handler 6 on 39615] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 93fa5443-690e-4c57-acd2-566890e3323f (127.0.0.1:33864).
2020-04-02 05:09:50,429 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid 93fa5443-690e-4c57-acd2-566890e3323f) service to localhost/127.0.0.1:39615 successfully registered with NN
2020-04-02 05:09:50,429 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:39615 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:50,434 [IPC Server handler 7 on 39615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-52f81f9c-cbfd-4ad8-a4eb-af1fffa2bdd1 for DN 127.0.0.1:33864
2020-04-02 05:09:50,434 [IPC Server handler 7 on 39615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3ad27b82-2f9a-4a0d-b313-b3a8592dd53f for DN 127.0.0.1:33864
2020-04-02 05:09:50,437 [IPC Server handler 8 on 39615] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:33864, datanodeUuid=93fa5443-690e-4c57-acd2-566890e3323f, infoPort=40765, infoSecurePort=0, ipcPort=44674, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), reports.length=2
2020-04-02 05:09:50,437 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xaadfa65b8c104f38: Processing first storage report for DS-52f81f9c-cbfd-4ad8-a4eb-af1fffa2bdd1 from datanode 93fa5443-690e-4c57-acd2-566890e3323f
2020-04-02 05:09:50,437 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xaadfa65b8c104f38: from storage DS-52f81f9c-cbfd-4ad8-a4eb-af1fffa2bdd1 node DatanodeRegistration(127.0.0.1:33864, datanodeUuid=93fa5443-690e-4c57-acd2-566890e3323f, infoPort=40765, infoSecurePort=0, ipcPort=44674, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:50,437 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xaadfa65b8c104f38: Processing first storage report for DS-3ad27b82-2f9a-4a0d-b313-b3a8592dd53f from datanode 93fa5443-690e-4c57-acd2-566890e3323f
2020-04-02 05:09:50,438 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xaadfa65b8c104f38: from storage DS-3ad27b82-2f9a-4a0d-b313-b3a8592dd53f node DatanodeRegistration(127.0.0.1:33864, datanodeUuid=93fa5443-690e-4c57-acd2-566890e3323f, infoPort=40765, infoSecurePort=0, ipcPort=44674, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:50,438 [IPC Server handler 8 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xaadfa65b8c104f38
2020-04-02 05:09:50,438 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xaadfa65b8c104f38,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:50,438 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,459 [Thread-1112] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1079677155-172.17.0.14-1585804187582 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 46ms
2020-04-02 05:09:50,459 [Thread-1113] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1079677155-172.17.0.14-1585804187582 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 46ms
2020-04-02 05:09:50,459 [Thread-1086] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1079677155-172.17.0.14-1585804187582: 48ms
2020-04-02 05:09:50,460 [Thread-1121] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:09:50,460 [Thread-1121] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1079677155-172.17.0.14-1585804187582/current/replicas doesn't exist 
2020-04-02 05:09:50,460 [Thread-1122] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:09:50,460 [Thread-1122] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1079677155-172.17.0.14-1585804187582/current/replicas doesn't exist 
2020-04-02 05:09:50,460 [Thread-1121] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 0ms
2020-04-02 05:09:50,461 [Thread-1122] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 1ms
2020-04-02 05:09:50,461 [Thread-1086] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1079677155-172.17.0.14-1585804187582: 1ms
2020-04-02 05:09:50,462 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:09:50,462 [Thread-1086] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:52 AM with interval of 21600000ms
2020-04-02 05:09:50,462 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-57a24baf-d5b5-4861-a7f6-fa849de485f4): finished scanning block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,462 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-57a24baf-d5b5-4861-a7f6-fa849de485f4): no suitable block pools found to scan.  Waiting 1814400000 ms.
2020-04-02 05:09:50,464 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid 517a2a8f-cb78-48a4-9295-9075657e0d88) service to localhost/127.0.0.1:39615 beginning handshake with NN
2020-04-02 05:09:50,465 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1079677155-172.17.0.14-1585804187582 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:09:50,466 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-e0316177-73d2-4099-ae12-c27935c097b0): finished scanning block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,466 [IPC Server handler 9 on 39615] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42132, datanodeUuid=517a2a8f-cb78-48a4-9295-9075657e0d88, infoPort=42449, infoSecurePort=0, ipcPort=35426, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582) storage 517a2a8f-cb78-48a4-9295-9075657e0d88
2020-04-02 05:09:50,466 [IPC Server handler 9 on 39615] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42132
2020-04-02 05:09:50,466 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-e0316177-73d2-4099-ae12-c27935c097b0): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:09:50,466 [IPC Server handler 9 on 39615] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 517a2a8f-cb78-48a4-9295-9075657e0d88 (127.0.0.1:42132).
2020-04-02 05:09:50,471 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid 517a2a8f-cb78-48a4-9295-9075657e0d88) service to localhost/127.0.0.1:39615 successfully registered with NN
2020-04-02 05:09:50,471 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:39615 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:50,476 [IPC Server handler 0 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:50,477 [IPC Server handler 1 on 39615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e0316177-73d2-4099-ae12-c27935c097b0 for DN 127.0.0.1:42132
2020-04-02 05:09:50,477 [IPC Server handler 1 on 39615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-57a24baf-d5b5-4861-a7f6-fa849de485f4 for DN 127.0.0.1:42132
2020-04-02 05:09:50,477 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2718)) - No heartbeat from DataNode: 127.0.0.1:42132
2020-04-02 05:09:50,478 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:09:50,478 [IPC Server handler 2 on 39615] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:42132, datanodeUuid=517a2a8f-cb78-48a4-9295-9075657e0d88, infoPort=42449, infoSecurePort=0, ipcPort=35426, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), reports.length=2
2020-04-02 05:09:50,478 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xacafe39812ee71a0: Processing first storage report for DS-57a24baf-d5b5-4861-a7f6-fa849de485f4 from datanode 517a2a8f-cb78-48a4-9295-9075657e0d88
2020-04-02 05:09:50,478 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xacafe39812ee71a0: from storage DS-57a24baf-d5b5-4861-a7f6-fa849de485f4 node DatanodeRegistration(127.0.0.1:42132, datanodeUuid=517a2a8f-cb78-48a4-9295-9075657e0d88, infoPort=42449, infoSecurePort=0, ipcPort=35426, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:09:50,478 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xacafe39812ee71a0: Processing first storage report for DS-e0316177-73d2-4099-ae12-c27935c097b0 from datanode 517a2a8f-cb78-48a4-9295-9075657e0d88
2020-04-02 05:09:50,479 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xacafe39812ee71a0: from storage DS-e0316177-73d2-4099-ae12-c27935c097b0 node DatanodeRegistration(127.0.0.1:42132, datanodeUuid=517a2a8f-cb78-48a4-9295-9075657e0d88, infoPort=42449, infoSecurePort=0, ipcPort=35426, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:50,479 [IPC Server handler 2 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xacafe39812ee71a0
2020-04-02 05:09:50,479 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xacafe39812ee71a0,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:50,479 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:50,580 [IPC Server handler 3 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:50,581 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:09:50,585 [IPC Server handler 4 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-04-02 05:09:50,591 [IPC Server handler 5 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:50,593 [Thread-776] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithDNFailure(160)) - testReadWithDNFailure: file = /dnFailure_2_smallFile, fileSize = 25165701, dnFailureNum = 2
2020-04-02 05:09:50,659 [IPC Server handler 6 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dnFailure_2_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:09:50,663 [IPC Server handler 7 on 39615] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /dnFailure_2_smallFile for DFSClient_NONMAPREDUCE_126307238_3968 at 127.0.0.1
2020-04-02 05:09:50,663 [IPC Server handler 7 on 39615] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/dnFailure_2_smallFile, holder=DFSClient_NONMAPREDUCE_126307238_3968, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:09:50,664 [IPC Server handler 7 on 39615] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: dnFailure_2_smallFile is added
2020-04-02 05:09:50,664 [IPC Server handler 7 on 39615] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /dnFailure_2_smallFile inode 16386 DFSClient_NONMAPREDUCE_126307238_3968
2020-04-02 05:09:50,665 [IPC Server handler 7 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/dnFailure_2_smallFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:50,699 [IPC Server handler 8 on 39615] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /dnFailure_2_smallFile  inodeId 16386 for DFSClient_NONMAPREDUCE_126307238_3968
2020-04-02 05:09:50,700 [IPC Server handler 8 on 39615] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:09:50,702 [IPC Server handler 8 on 39615] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /dnFailure_2_smallFile with blk_-9223372036854775792_1001 block is added to the in-memory file system
2020-04-02 05:09:50,702 [IPC Server handler 8 on 39615] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:37887, 127.0.0.1:40621, 127.0.0.1:42333, 127.0.0.1:39389, 127.0.0.1:34418, 127.0.0.1:33864, 127.0.0.1:42132, 127.0.0.1:39673, 127.0.0.1:40904 for /dnFailure_2_smallFile
2020-04-02 05:09:50,703 [IPC Server handler 8 on 39615] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /dnFailure_2_smallFile with new block blk_-9223372036854775792_1001, current total block count is 1
2020-04-02 05:09:50,733 [DataXceiver for client DFSClient_NONMAPREDUCE_126307238_3968 at /127.0.0.1:60782 [Receiving block BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775792_1001 src: /127.0.0.1:60782 dest: /127.0.0.1:37887
2020-04-02 05:09:50,735 [DataXceiver for client DFSClient_NONMAPREDUCE_126307238_3968 at /127.0.0.1:50934 [Receiving block BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775791_1001 src: /127.0.0.1:50934 dest: /127.0.0.1:40621
2020-04-02 05:09:50,787 [DataXceiver for client DFSClient_NONMAPREDUCE_126307238_3968 at /127.0.0.1:57304 [Receiving block BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775789_1001 src: /127.0.0.1:57304 dest: /127.0.0.1:39389
2020-04-02 05:09:50,789 [DataXceiver for client DFSClient_NONMAPREDUCE_126307238_3968 at /127.0.0.1:33616 [Receiving block BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775787_1001 src: /127.0.0.1:33616 dest: /127.0.0.1:33864
2020-04-02 05:09:50,797 [DataXceiver for client DFSClient_NONMAPREDUCE_126307238_3968 at /127.0.0.1:57542 [Receiving block BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775790_1001 src: /127.0.0.1:57542 dest: /127.0.0.1:42333
2020-04-02 05:09:50,838 [DataXceiver for client DFSClient_NONMAPREDUCE_126307238_3968 at /127.0.0.1:59692 [Receiving block BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775786_1001 src: /127.0.0.1:59692 dest: /127.0.0.1:42132
2020-04-02 05:09:50,838 [DataXceiver for client DFSClient_NONMAPREDUCE_126307238_3968 at /127.0.0.1:53784 [Receiving block BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775788_1001 src: /127.0.0.1:53784 dest: /127.0.0.1:34418
2020-04-02 05:09:50,917 [DataXceiver for client DFSClient_NONMAPREDUCE_126307238_3968 at /127.0.0.1:37658 [Receiving block BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775785_1001 src: /127.0.0.1:37658 dest: /127.0.0.1:39673
2020-04-02 05:09:50,988 [DataXceiver for client DFSClient_NONMAPREDUCE_126307238_3968 at /127.0.0.1:54904 [Receiving block BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775784_1001 src: /127.0.0.1:54904 dest: /127.0.0.1:40904
2020-04-02 05:09:51,145 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:51,314 [PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60782, dest: /127.0.0.1:37887, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_126307238_3968, offset: 0, srvID: a071e6d5-59e7-4050-8f61-49fbbf5f73d0, blockid: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775792_1001, duration(ns): 562436371
2020-04-02 05:09:51,315 [PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:51,316 [IPC Server handler 2 on 39615] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37887, datanodeUuid=a071e6d5-59e7-4050-8f61-49fbbf5f73d0, infoPort=43494, infoSecurePort=0, ipcPort=44718, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582) 1 blocks.
2020-04-02 05:09:51,317 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775792_1001 on 127.0.0.1:37887 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:51,317 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:51,323 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37887 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:09:51,323 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775792_1001 is received from 127.0.0.1:37887
2020-04-02 05:09:51,323 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37887 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:51,331 [PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50934, dest: /127.0.0.1:40621, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_126307238_3968, offset: 0, srvID: 60182ee3-8267-455e-8b07-2b7f696a2f02, blockid: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775791_1001, duration(ns): 582981572
2020-04-02 05:09:51,332 [PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:51,336 [IPC Server handler 3 on 39615] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40621, datanodeUuid=60182ee3-8267-455e-8b07-2b7f696a2f02, infoPort=36101, infoSecurePort=0, ipcPort=45041, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582) 1 blocks.
2020-04-02 05:09:51,337 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775791_1001 on 127.0.0.1:40621 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:51,337 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:51,337 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:40621 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:09:51,337 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775791_1001 is received from 127.0.0.1:40621
2020-04-02 05:09:51,337 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40621 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:51,352 [PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57542, dest: /127.0.0.1:42333, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_126307238_3968, offset: 0, srvID: df50cddc-ef1d-488e-9914-df13927bdc9f, blockid: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775790_1001, duration(ns): 514142305
2020-04-02 05:09:51,352 [PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:51,353 [IPC Server handler 4 on 39615] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:42333, datanodeUuid=df50cddc-ef1d-488e-9914-df13927bdc9f, infoPort=36025, infoSecurePort=0, ipcPort=46667, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582) 1 blocks.
2020-04-02 05:09:51,369 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775790_1001 on 127.0.0.1:42333 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:51,369 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:51,369 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:42333 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:09:51,369 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775790_1001 is received from 127.0.0.1:42333
2020-04-02 05:09:51,369 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:42333 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:51,382 [PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57304, dest: /127.0.0.1:39389, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_126307238_3968, offset: 0, srvID: 829765f2-8f35-4380-94c8-a372df2cef81, blockid: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775789_1001, duration(ns): 588586798
2020-04-02 05:09:51,382 [PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:51,390 [PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53784, dest: /127.0.0.1:34418, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_126307238_3968, offset: 0, srvID: a81c8a11-cec5-4613-b635-0eb191a7492f, blockid: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775788_1001, duration(ns): 543415618
2020-04-02 05:09:51,390 [PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:51,394 [IPC Server handler 5 on 39615] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39389, datanodeUuid=829765f2-8f35-4380-94c8-a372df2cef81, infoPort=41849, infoSecurePort=0, ipcPort=43421, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582) 1 blocks.
2020-04-02 05:09:51,394 [IPC Server handler 6 on 39615] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34418, datanodeUuid=a81c8a11-cec5-4613-b635-0eb191a7492f, infoPort=34490, infoSecurePort=0, ipcPort=44913, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582) 1 blocks.
2020-04-02 05:09:51,400 [PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33616, dest: /127.0.0.1:33864, bytes: 4194181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_126307238_3968, offset: 0, srvID: 93fa5443-690e-4c57-acd2-566890e3323f, blockid: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775787_1001, duration(ns): 602514326
2020-04-02 05:09:51,400 [PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:51,401 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775789_1001 on 127.0.0.1:39389 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:51,401 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:51,401 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39389 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:09:51,401 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775789_1001 is received from 127.0.0.1:39389
2020-04-02 05:09:51,401 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39389 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:51,401 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:34418 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:51,402 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:51,402 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34418 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:09:51,402 [IPC Server handler 7 on 39615] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33864, datanodeUuid=93fa5443-690e-4c57-acd2-566890e3323f, infoPort=40765, infoSecurePort=0, ipcPort=44674, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582) 1 blocks.
2020-04-02 05:09:51,402 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775788_1001 is received from 127.0.0.1:34418
2020-04-02 05:09:51,402 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34418 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:51,402 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775787_1001 on 127.0.0.1:33864 size 4194181 replicaState = FINALIZED
2020-04-02 05:09:51,402 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:51,402 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33864 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:09:51,402 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775787_1001 is received from 127.0.0.1:33864
2020-04-02 05:09:51,402 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33864 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:51,412 [PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59692, dest: /127.0.0.1:42132, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_126307238_3968, offset: 0, srvID: 517a2a8f-cb78-48a4-9295-9075657e0d88, blockid: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775786_1001, duration(ns): 557205066
2020-04-02 05:09:51,412 [PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:51,414 [IPC Server handler 8 on 39615] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:42132, datanodeUuid=517a2a8f-cb78-48a4-9295-9075657e0d88, infoPort=42449, infoSecurePort=0, ipcPort=35426, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582) 1 blocks.
2020-04-02 05:09:51,415 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775786_1001 on 127.0.0.1:42132 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:51,415 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:51,416 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:42132 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:09:51,416 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775786_1001 is received from 127.0.0.1:42132
2020-04-02 05:09:51,416 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:42132 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:51,424 [PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37658, dest: /127.0.0.1:39673, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_126307238_3968, offset: 0, srvID: 6eb2ee0b-09b4-4f85-bd48-c25214cb4512, blockid: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775785_1001, duration(ns): 498465126
2020-04-02 05:09:51,424 [PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:51,424 [IPC Server handler 9 on 39615] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39673, datanodeUuid=6eb2ee0b-09b4-4f85-bd48-c25214cb4512, infoPort=38498, infoSecurePort=0, ipcPort=41532, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582) 1 blocks.
2020-04-02 05:09:51,425 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775785_1001 on 127.0.0.1:39673 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:51,425 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:51,425 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39673 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:09:51,425 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775785_1001 is received from 127.0.0.1:39673
2020-04-02 05:09:51,425 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39673 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:51,454 [PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54904, dest: /127.0.0.1:40904, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_126307238_3968, offset: 0, srvID: d5c8becf-f706-4887-bfd5-e8783bfec939, blockid: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775784_1001, duration(ns): 408357096
2020-04-02 05:09:51,454 [PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:51,454 [IPC Server handler 0 on 39615] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40904, datanodeUuid=d5c8becf-f706-4887-bfd5-e8783bfec939, infoPort=37378, infoSecurePort=0, ipcPort=39477, storageInfo=lv=-57;cid=testClusterID;nsid=292980063;c=1585804187582) 1 blocks.
2020-04-02 05:09:51,457 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775784_1001 on 127.0.0.1:40904 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:51,457 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:51,457 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:40904 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:09:51,458 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775784_1001 is received from 127.0.0.1:40904
2020-04-02 05:09:51,458 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40904 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:51,471 [IPC Server handler 1 on 39615] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /dnFailure_2_smallFile for DFSClient_NONMAPREDUCE_126307238_3968
2020-04-02 05:09:51,480 [IPC Server handler 1 on 39615] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /dnFailure_2_smallFile with 1 blocks is persisted to the file system
2020-04-02 05:09:51,481 [IPC Server handler 1 on 39615] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /dnFailure_2_smallFile is closed by DFSClient_NONMAPREDUCE_126307238_3968
2020-04-02 05:09:51,483 [IPC Server handler 2 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:51,487 [IPC Server handler 3 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:09:51,487 [IPC Server handler 3 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:09:51,489 [Thread-776] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:waitBlockGroupsReported(290)) - All blockGroups of file /dnFailure_2_smallFile verified to have all internalBlocks.
2020-04-02 05:09:51,491 [IPC Server handler 4 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:09:51,491 [IPC Server handler 4 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:09:51,493 [Thread-776] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 44718 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:51,494 [Thread-776] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:51,494 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@67afe1cc] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:51,497 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-cf219190-77f6-462d-b393-0cf75e6fb3bc) exiting.
2020-04-02 05:09:51,497 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-3ef33c0c-a00b-4586-9005-ad242a337eef) exiting.
2020-04-02 05:09:51,518 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:51,545 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1cff4ee2{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:51,550 [Thread-776] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@11533cf6{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:51,551 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1174ac3b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:51,551 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6a312512{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:51,572 [Thread-776] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44718
2020-04-02 05:09:51,586 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:51,596 [IPC Server listener on 44718] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44718
2020-04-02 05:09:51,597 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:51,597 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid a071e6d5-59e7-4050-8f61-49fbbf5f73d0) service to localhost/127.0.0.1:39615
2020-04-02 05:09:51,602 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid a071e6d5-59e7-4050-8f61-49fbbf5f73d0)
2020-04-02 05:09:51,602 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:51,625 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1079677155-172.17.0.14-1585804187582] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:51,670 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1079677155-172.17.0.14-1585804187582] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:51,699 [Thread-776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:51,699 [Thread-776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:51,702 [Thread-776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:51,702 [Thread-776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:51,723 [Thread-776] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:51,724 [Thread-776] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 45041 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:51,724 [Thread-776] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:51,724 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@727d4bc7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:51,729 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-daae56b6-12ff-4ca7-80db-758c19f0c12d) exiting.
2020-04-02 05:09:51,729 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-3a54a967-e047-4a49-92fd-5e35f7c3d315) exiting.
2020-04-02 05:09:51,771 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@29eb7247{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:51,772 [Thread-776] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@48a0f431{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:51,772 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@352ad656{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:51,772 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@11bdf96c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:51,773 [Thread-776] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45041
2020-04-02 05:09:51,810 [IPC Server listener on 45041] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45041
2020-04-02 05:09:51,810 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:51,810 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid 60182ee3-8267-455e-8b07-2b7f696a2f02) service to localhost/127.0.0.1:39615
2020-04-02 05:09:51,810 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid 60182ee3-8267-455e-8b07-2b7f696a2f02)
2020-04-02 05:09:51,810 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:51,810 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:09:51,822 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1079677155-172.17.0.14-1585804187582] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:51,831 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1079677155-172.17.0.14-1585804187582] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:51,842 [Thread-776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:51,842 [Thread-776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:51,845 [Thread-776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:51,845 [Thread-776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:51,846 [Thread-776] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:51,846 [Thread-776] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /dnFailure_2_smallFile
2020-04-02 05:09:51,850 [Thread-776] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /dnFailure_2_smallFile
2020-04-02 05:09:51,851 [IPC Server handler 5 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dnFailure_2_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:09:51,852 [Thread-776] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /dnFailure_2_smallFile
2020-04-02 05:09:51,853 [IPC Server handler 6 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:51,854 [IPC Server handler 7 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:09:51,854 [IPC Server handler 7 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:09:51,862 [Thread-776] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:51,863 [Thread-776] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:37887 for blockBP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:51,864 [IPC Server handler 8 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:09:51,864 [IPC Server handler 8 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:09:51,873 [Thread-776] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:37887,DS-3ef33c0c-a00b-4586-9005-ad242a337eef,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:09:51,874 [Thread-776] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:51,874 [Thread-776] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:40621 for blockBP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775791_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:51,877 [IPC Server handler 9 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:09:51,878 [IPC Server handler 9 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:09:51,883 [Thread-776] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:40621,DS-daae56b6-12ff-4ca7-80db-758c19f0c12d,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:09:54,147 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:54,518 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:57,147 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:57,518 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:00,148 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:00,522 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:03,149 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:03,522 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:06,149 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:06,524 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:09,175 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:09,525 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:09,671 [Thread-776] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /dnFailure_2_smallFile
2020-04-02 05:10:09,680 [IPC Server handler 7 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:09,682 [IPC Server handler 7 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:09,691 [Thread-776] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:09,694 [Thread-776] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:37887 for blockBP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:09,696 [IPC Server handler 0 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:09,698 [IPC Server handler 0 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:09,705 [Thread-776] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:37887,DS-3ef33c0c-a00b-4586-9005-ad242a337eef,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:09,705 [Thread-776] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:09,706 [Thread-776] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:40621 for blockBP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775791_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:09,709 [IPC Server handler 6 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:09,709 [IPC Server handler 6 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:09,710 [Thread-776] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:40621,DS-daae56b6-12ff-4ca7-80db-758c19f0c12d,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:12,175 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:12,525 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:13,215 [Thread-776] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /dnFailure_2_smallFile
2020-04-02 05:10:13,232 [IPC Server handler 5 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:13,234 [IPC Server handler 5 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:13,251 [Thread-776] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:13,252 [Thread-776] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:37887 for blockBP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:13,252 [IPC Server handler 9 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:13,253 [IPC Server handler 9 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:13,254 [Thread-776] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:37887,DS-3ef33c0c-a00b-4586-9005-ad242a337eef,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:13,254 [Thread-776] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:13,255 [Thread-776] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:40621 for blockBP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775791_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:13,255 [IPC Server handler 8 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:13,256 [IPC Server handler 8 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:13,258 [Thread-776] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:40621,DS-daae56b6-12ff-4ca7-80db-758c19f0c12d,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:15,176 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:15,526 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:16,935 [Thread-776] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /dnFailure_2_smallFile
2020-04-02 05:10:16,938 [IPC Server handler 1 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:16,939 [IPC Server handler 1 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:16,951 [Thread-776] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:16,951 [Thread-776] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:37887 for blockBP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:16,952 [IPC Server handler 3 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:16,953 [IPC Server handler 3 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:16,954 [Thread-776] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:37887,DS-3ef33c0c-a00b-4586-9005-ad242a337eef,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:16,955 [Thread-776] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:16,955 [Thread-776] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:40621 for blockBP-1079677155-172.17.0.14-1585804187582:blk_-9223372036854775791_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:16,956 [IPC Server handler 5 on 39615] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:16,956 [IPC Server handler 5 on 39615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:16,958 [Thread-776] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:40621,DS-daae56b6-12ff-4ca7-80db-758c19f0c12d,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:18,177 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:18,527 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:21,177 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:21,527 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:21,973 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:10:21,973 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 8
2020-04-02 05:10:21,973 [Thread-776] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 35426 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:21,973 [Thread-776] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:21,976 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2c272b47] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:21,976 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-e0316177-73d2-4099-ae12-c27935c097b0) exiting.
2020-04-02 05:10:21,976 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-57a24baf-d5b5-4861-a7f6-fa849de485f4) exiting.
2020-04-02 05:10:22,000 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@391754b1{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:22,001 [Thread-776] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@119e7ace{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:22,001 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5d644352{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:22,001 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2905b4dc{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:22,003 [Thread-776] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35426
2020-04-02 05:10:22,009 [IPC Server listener on 35426] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35426
2020-04-02 05:10:22,009 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:22,009 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:22,011 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid 517a2a8f-cb78-48a4-9295-9075657e0d88) service to localhost/127.0.0.1:39615
2020-04-02 05:10:22,011 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid 517a2a8f-cb78-48a4-9295-9075657e0d88)
2020-04-02 05:10:22,011 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:10:22,025 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1079677155-172.17.0.14-1585804187582] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:22,032 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1079677155-172.17.0.14-1585804187582] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:22,038 [Thread-776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:22,038 [Thread-776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:22,039 [Thread-776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:22,039 [Thread-776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:22,040 [Thread-776] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:22,040 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 7
2020-04-02 05:10:22,040 [Thread-776] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 44674 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:22,040 [Thread-776] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:22,041 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3e082fb5] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:22,043 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-3ad27b82-2f9a-4a0d-b313-b3a8592dd53f) exiting.
2020-04-02 05:10:22,043 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-52f81f9c-cbfd-4ad8-a4eb-af1fffa2bdd1) exiting.
2020-04-02 05:10:22,061 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3542a536{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:22,061 [Thread-776] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@52a89470{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:22,062 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7fe99b2a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:22,062 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2e339a64{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:22,063 [Thread-776] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44674
2020-04-02 05:10:22,069 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:22,070 [IPC Server listener on 44674] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44674
2020-04-02 05:10:22,070 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:22,072 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid 93fa5443-690e-4c57-acd2-566890e3323f) service to localhost/127.0.0.1:39615
2020-04-02 05:10:22,072 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid 93fa5443-690e-4c57-acd2-566890e3323f)
2020-04-02 05:10:22,072 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:10:22,083 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1079677155-172.17.0.14-1585804187582] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:22,097 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1079677155-172.17.0.14-1585804187582] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:22,099 [Thread-776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:22,099 [Thread-776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:22,101 [Thread-776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:22,101 [Thread-776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:22,102 [Thread-776] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:22,102 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 6
2020-04-02 05:10:22,102 [Thread-776] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43421 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:22,102 [Thread-776] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:22,102 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@9bc65d8] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:22,104 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-a7ded864-c73b-491b-90b5-a4bd6d98f526) exiting.
2020-04-02 05:10:22,104 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-b4b7100b-9880-4028-99fb-0d1992697b8b) exiting.
2020-04-02 05:10:22,127 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6c591d22{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:22,130 [Thread-776] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6da2fd3b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:22,131 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@69ba3f36{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:22,131 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@73a81df7{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:22,132 [Thread-776] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43421
2020-04-02 05:10:22,139 [IPC Server listener on 43421] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43421
2020-04-02 05:10:22,140 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:22,140 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:22,142 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid 829765f2-8f35-4380-94c8-a372df2cef81) service to localhost/127.0.0.1:39615
2020-04-02 05:10:22,142 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid 829765f2-8f35-4380-94c8-a372df2cef81)
2020-04-02 05:10:22,142 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:10:22,153 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1079677155-172.17.0.14-1585804187582] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:22,163 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1079677155-172.17.0.14-1585804187582] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:22,171 [Thread-776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:22,171 [Thread-776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:22,173 [Thread-776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:22,173 [Thread-776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:22,174 [Thread-776] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:22,174 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 5
2020-04-02 05:10:22,174 [Thread-776] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 46667 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:22,174 [Thread-776] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:22,174 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3249313c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:22,177 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-eb5b1698-027f-4f61-a9f2-ba2f9f26b3d1) exiting.
2020-04-02 05:10:22,177 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-3ed479df-6c94-4bf6-ac15-8e527fb1eb2b) exiting.
2020-04-02 05:10:22,193 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4a970d99{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:22,193 [Thread-776] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3ecc4994{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:22,193 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@64018add{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:22,193 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@690661dd{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:22,195 [Thread-776] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46667
2020-04-02 05:10:22,203 [IPC Server listener on 46667] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46667
2020-04-02 05:10:22,206 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:22,206 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:22,207 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid df50cddc-ef1d-488e-9914-df13927bdc9f) service to localhost/127.0.0.1:39615
2020-04-02 05:10:22,207 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid df50cddc-ef1d-488e-9914-df13927bdc9f)
2020-04-02 05:10:22,207 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:10:22,217 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1079677155-172.17.0.14-1585804187582] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:22,229 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1079677155-172.17.0.14-1585804187582] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:22,237 [Thread-776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:22,237 [Thread-776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:22,239 [Thread-776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:22,240 [Thread-776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:22,240 [Thread-776] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:22,240 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 4
2020-04-02 05:10:22,240 [Thread-776] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 45041 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:22,240 [Thread-776] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(340)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-04-02 05:10:22,242 [Thread-776] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45041
2020-04-02 05:10:22,242 [Thread-776] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-60182ee3-8267-455e-8b07-2b7f696a2f02
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-60182ee3-8267-455e-8b07-2b7f696a2f02
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2146)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2048)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2038)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2017)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1991)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1984)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.tearDownCluster(ReadStripedFileWithDecodingHelper.java:97)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.tearDown(TestReadStripedFileWithDNFailure.java:64)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:105)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:22,242 [Thread-776] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(190)) - AsyncDiskService has already shut down.
2020-04-02 05:10:22,243 [Thread-776] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(174)) - AsyncLazyPersistService has already shut down.
2020-04-02 05:10:22,243 [Thread-776] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:22,243 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 3
2020-04-02 05:10:22,243 [Thread-776] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 41532 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:22,243 [Thread-776] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:22,243 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7ebfb01b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:22,246 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-68d1a46b-06e4-4e43-9bcd-1490062e530d) exiting.
2020-04-02 05:10:22,246 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-d4ee1a18-c641-45d3-827c-313617f075b6) exiting.
2020-04-02 05:10:22,262 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@491c9f23{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:22,262 [Thread-776] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@642dc537{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:22,263 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@55e07e92{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:22,263 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2ea3fb33{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:22,264 [Thread-776] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41532
2020-04-02 05:10:22,273 [IPC Server listener on 41532] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41532
2020-04-02 05:10:22,273 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:22,273 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:22,276 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid 6eb2ee0b-09b4-4f85-bd48-c25214cb4512) service to localhost/127.0.0.1:39615
2020-04-02 05:10:22,276 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid 6eb2ee0b-09b4-4f85-bd48-c25214cb4512)
2020-04-02 05:10:22,277 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:10:22,289 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1079677155-172.17.0.14-1585804187582] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:22,305 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1079677155-172.17.0.14-1585804187582] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:22,310 [Thread-776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:22,311 [Thread-776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:22,313 [Thread-776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:22,313 [Thread-776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:22,314 [Thread-776] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:22,314 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:10:22,314 [Thread-776] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 39477 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:22,314 [Thread-776] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:22,314 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@54ff08e7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:22,317 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-38c97080-41ad-4d14-91fe-0d48b1417f76) exiting.
2020-04-02 05:10:22,317 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-01ed9015-b18d-4d61-a43d-7ddc46ea5bfa) exiting.
2020-04-02 05:10:22,333 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3a77ea3b{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:22,334 [Thread-776] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@20ca9db9{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:22,334 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4b66adf{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:22,335 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@b204856{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:22,336 [Thread-776] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39477
2020-04-02 05:10:22,340 [IPC Server listener on 39477] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39477
2020-04-02 05:10:22,344 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:22,344 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:22,344 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid d5c8becf-f706-4887-bfd5-e8783bfec939) service to localhost/127.0.0.1:39615
2020-04-02 05:10:22,344 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid d5c8becf-f706-4887-bfd5-e8783bfec939)
2020-04-02 05:10:22,344 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:10:22,355 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1079677155-172.17.0.14-1585804187582] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:22,366 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1079677155-172.17.0.14-1585804187582] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:22,379 [Thread-776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:22,379 [Thread-776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:22,382 [Thread-776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:22,382 [Thread-776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:22,383 [Thread-776] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:22,383 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:10:22,383 [Thread-776] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 44913 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:22,383 [Thread-776] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:22,384 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@18045c19] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:22,387 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-a8705adb-4a10-44c0-94d3-1c5b20c71202) exiting.
2020-04-02 05:10:22,387 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-85e921d2-e9e0-4797-8770-ea05386d04cb) exiting.
2020-04-02 05:10:22,405 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6b372b67{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:22,406 [Thread-776] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7b18483d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:22,406 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2d8c972a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:22,406 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2dcff38c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:22,413 [Thread-776] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44913
2020-04-02 05:10:22,424 [IPC Server listener on 44913] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44913
2020-04-02 05:10:22,430 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:22,431 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:22,431 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid a81c8a11-cec5-4613-b635-0eb191a7492f) service to localhost/127.0.0.1:39615
2020-04-02 05:10:22,431 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1079677155-172.17.0.14-1585804187582 (Datanode Uuid a81c8a11-cec5-4613-b635-0eb191a7492f)
2020-04-02 05:10:22,431 [BP-1079677155-172.17.0.14-1585804187582 heartbeating to localhost/127.0.0.1:39615] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1079677155-172.17.0.14-1585804187582
2020-04-02 05:10:22,442 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1079677155-172.17.0.14-1585804187582] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:22,453 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1079677155-172.17.0.14-1585804187582] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:22,465 [Thread-776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:22,465 [Thread-776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:22,468 [Thread-776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:22,468 [Thread-776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:22,468 [Thread-776] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:22,468 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:10:22,469 [Thread-776] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 44718 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:22,469 [Thread-776] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(340)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-04-02 05:10:22,470 [Thread-776] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44718
2020-04-02 05:10:22,470 [Thread-776] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-a071e6d5-59e7-4050-8f61-49fbbf5f73d0
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-a071e6d5-59e7-4050-8f61-49fbbf5f73d0
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2146)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2048)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2038)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2017)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1991)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1984)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.tearDownCluster(ReadStripedFileWithDecodingHelper.java:97)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.tearDown(TestReadStripedFileWithDNFailure.java:64)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:105)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:22,470 [Thread-776] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(190)) - AsyncDiskService has already shut down.
2020-04-02 05:10:22,470 [Thread-776] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(174)) - AsyncLazyPersistService has already shut down.
2020-04-02 05:10:22,470 [Thread-776] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:22,471 [Thread-776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:10:22,471 [Thread-776] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 39615 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:22,471 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:10:22,471 [Thread-776] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 8
2020-04-02 05:10:22,472 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4f3b4f73] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:10:22,472 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@14e18b62] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:10:22,472 [Thread-776] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 9 Total time for transactions(ms): 21 Number of transactions batched in Syncs: 2 Number of syncs: 8 SyncTimes(ms): 9 6 
2020-04-02 05:10:22,473 [Thread-776] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:10:22,474 [Thread-776] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:10:22,474 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:10:22,474 [CacheReplicationMonitor(829831996)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:10:22,475 [Thread-776] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39615
2020-04-02 05:10:22,501 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:22,501 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:10:22,505 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:10:22,504 [IPC Server listener on 39615] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39615
2020-04-02 05:10:22,515 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@2580d37a] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:10:22,534 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:10:22,534 [Thread-776] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:10:22,547 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3ab0be91{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:10:22,549 [Thread-776] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@73e80a06{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:22,549 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@784486ae{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:22,549 [Thread-776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4a5c6370{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure#testReadWithDNFailure[1]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure#testReadWithDNFailure[1]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure#testReadWithDNFailure[2]
[msx] perform reset as unitTestCounterInClass 2 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] before_class
2020-04-02 05:10:22,582 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=9
Formatting using clusterid: testClusterID
2020-04-02 05:10:22,585 [Thread-1172] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:10:22,586 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:10:22,586 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:10:22,586 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:10:22,586 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:10:22,586 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:10:22,586 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:10:22,587 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:10:22,587 [Thread-1172] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:22,587 [Thread-1172] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:10:22,588 [Thread-1172] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:10:22,588 [Thread-1172] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:10:22,588 [Thread-1172] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:10:22
2020-04-02 05:10:22,588 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:10:22,588 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:22,589 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 2.0 GB = 40.1 MB
2020-04-02 05:10:22,589 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:10:22,592 [Thread-1172] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:10:22,592 [Thread-1172] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:10:22,592 [Thread-1172] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:10:22,592 [Thread-1172] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:10:22,592 [Thread-1172] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:10:22,592 [Thread-1172] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:10:22,592 [Thread-1172] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:10:22,592 [Thread-1172] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:10:22,593 [Thread-1172] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 0
2020-04-02 05:10:22,593 [Thread-1172] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:10:22,593 [Thread-1172] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:10:22,593 [Thread-1172] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:10:22,593 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:10:22,593 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:22,593 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 2.0 GB = 20.0 MB
2020-04-02 05:10:22,593 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:10:22,595 [Thread-1172] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:10:22,595 [Thread-1172] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:10:22,595 [Thread-1172] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:10:22,595 [Thread-1172] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:10:22,595 [Thread-1172] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:10:22,595 [Thread-1172] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:10:22,595 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:10:22,595 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:22,596 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 2.0 GB = 5.0 MB
2020-04-02 05:10:22,596 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:10:22,596 [Thread-1172] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:10:22,596 [Thread-1172] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:10:22,596 [Thread-1172] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:10:22,596 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:10:22,596 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:10:22,597 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:10:22,597 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:22,597 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 2.0 GB = 615.3 KB
2020-04-02 05:10:22,597 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:10:22,598 [Thread-1172] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:22,601 [Thread-1172] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:10:22,602 [Thread-1172] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:10:22,603 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:10:22,603 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:10:22,614 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 426 bytes saved in 0 seconds .
2020-04-02 05:10:22,614 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 426 bytes saved in 0 seconds .
2020-04-02 05:10:22,616 [Thread-1172] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:10:22,617 [Thread-1172] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:10:22,617 [Thread-1172] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:10:22,617 [Thread-1172] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:10:22,617 [Thread-1172] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:10:22,665 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7ae4f04b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:22,665 [Thread-1172] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:10:22,666 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:22,668 [Thread-1172] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:22,668 [Thread-1172] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:10:22,669 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:22,670 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:22,670 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:10:22,671 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:22,671 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:22,673 [Thread-1172] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:10:22,673 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:10:22,673 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43215
2020-04-02 05:10:22,674 [Thread-1172] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:22,676 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@38630fb9{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:22,676 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3b003940{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:22,682 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@808a07e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:10:22,686 [Thread-1172] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5abcf100{HTTP/1.1,[http/1.1]}{localhost:43215}
2020-04-02 05:10:22,686 [Thread-1172] INFO  server.Server (Server.java:doStart(419)) - Started @93097ms
2020-04-02 05:10:22,688 [Thread-1172] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:10:22,688 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:10:22,688 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:10:22,688 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:10:22,688 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:10:22,688 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:10:22,688 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:10:22,689 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:10:22,689 [Thread-1172] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:22,689 [Thread-1172] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:10:22,689 [Thread-1172] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:10:22,690 [Thread-1172] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:10:22,690 [Thread-1172] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:10:22
2020-04-02 05:10:22,690 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:10:22,690 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:22,690 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 2.0 GB = 40.1 MB
2020-04-02 05:10:22,691 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:10:22,694 [Thread-1172] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:10:22,694 [Thread-1172] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:10:22,694 [Thread-1172] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:10:22,694 [Thread-1172] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:10:22,694 [Thread-1172] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:10:22,694 [Thread-1172] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:10:22,695 [Thread-1172] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:10:22,695 [Thread-1172] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:10:22,695 [Thread-1172] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 0
2020-04-02 05:10:22,695 [Thread-1172] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:10:22,695 [Thread-1172] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:10:22,695 [Thread-1172] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:10:22,695 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:10:22,695 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:22,696 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 2.0 GB = 20.0 MB
2020-04-02 05:10:22,696 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:10:22,697 [Thread-1172] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:10:22,698 [Thread-1172] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:10:22,698 [Thread-1172] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:10:22,698 [Thread-1172] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:10:22,698 [Thread-1172] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:10:22,698 [Thread-1172] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:10:22,698 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:10:22,698 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:22,699 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 2.0 GB = 5.0 MB
2020-04-02 05:10:22,699 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:10:22,699 [Thread-1172] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:10:22,699 [Thread-1172] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:10:22,700 [Thread-1172] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:10:22,700 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:10:22,700 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:10:22,700 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:10:22,700 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:22,700 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 2.0 GB = 615.3 KB
2020-04-02 05:10:22,700 [Thread-1172] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:10:22,702 [Thread-1172] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:22,703 [Thread-1172] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:22,704 [Thread-1172] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:10:22,704 [Thread-1172] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:10:22,704 [Thread-1172] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:10:22,704 [Thread-1172] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:10:22,705 [Thread-1172] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:10:22,705 [Thread-1172] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:10:22,706 [Thread-1172] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:10:22,706 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:10:22,706 [Thread-1172] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:10:22,724 [Thread-1172] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:10:22,724 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 24 msecs
2020-04-02 05:10:22,725 [Thread-1172] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:10:22,725 [Thread-1172] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:22,726 [Socket Reader #1 for port 43680] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43680
2020-04-02 05:10:22,732 [Thread-1172] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:43680 to access this namenode/service.
2020-04-02 05:10:22,733 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:10:22,815 [Thread-1172] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:10:22,816 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@230d72f] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:10:22,816 [Thread-1172] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:10:22,817 [Thread-1172] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:10:22,817 [Thread-1172] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:10:22,817 [Thread-1172] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:10:22,825 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:10:22,825 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:10:22,825 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:10:22,825 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:10:22,825 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:10:22,825 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2020-04-02 05:10:22,827 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:22,827 [IPC Server listener on 43680] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43680: starting
2020-04-02 05:10:22,839 [Thread-1172] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:43680
2020-04-02 05:10:22,839 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:10:22,839 [Thread-1172] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:10:22,840 [Thread-1172] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:10:22,844 [Thread-1172] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 43680 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:22,849 [CacheReplicationMonitor(638488801)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:10:22,885 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:10:22,886 [Thread-1172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:10:22,886 [Thread-1172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:10:22,887 [Thread-1172] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:10:22,890 [Thread-1172] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:10:22,890 [Thread-1172] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:22,890 [Thread-1172] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:10:22,891 [Thread-1172] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:10:22,891 [Thread-1172] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:22,891 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:10:22,891 [Thread-1172] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:36096
2020-04-02 05:10:22,891 [Thread-1172] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:10:22,891 [Thread-1172] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:10:22,892 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:22,893 [Thread-1172] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:22,893 [Thread-1172] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:10:22,893 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:22,894 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:22,894 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:10:22,894 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:22,894 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:22,894 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37224
2020-04-02 05:10:22,894 [Thread-1172] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:22,895 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@19634994{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:22,896 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1e45f3fd{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:22,898 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@64957205{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:10:22,899 [Thread-1172] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6850e306{HTTP/1.1,[http/1.1]}{localhost:37224}
2020-04-02 05:10:22,903 [Thread-1172] INFO  server.Server (Server.java:doStart(419)) - Started @93313ms
2020-04-02 05:10:22,991 [Thread-1172] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45461
2020-04-02 05:10:22,992 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@52159343] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:22,992 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:10:22,992 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:10:22,992 [Thread-1172] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:22,993 [Socket Reader #1 for port 33969] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33969
2020-04-02 05:10:22,998 [Thread-1172] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:33969
2020-04-02 05:10:23,049 [Thread-1172] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:10:23,050 [Thread-1172] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:10:23,050 [Thread-1226] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43680 starting to offer service
2020-04-02 05:10:23,054 [IPC Server listener on 33969] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33969: starting
2020-04-02 05:10:23,054 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:23,059 [Thread-1172] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 33969 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:23,066 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:10:23,067 [Thread-1172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:10:23,067 [Thread-1172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:10:23,068 [Thread-1226] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43680
2020-04-02 05:10:23,068 [Thread-1172] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:10:23,071 [Thread-1172] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:10:23,071 [Thread-1226] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:10:23,072 [Thread-1172] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:23,072 [Thread-1172] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:10:23,072 [Thread-1172] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:10:23,072 [Thread-1172] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:23,072 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:10:23,072 [Thread-1172] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42705
2020-04-02 05:10:23,073 [Thread-1172] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:10:23,073 [Thread-1172] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:10:23,073 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:23,073 [Thread-1226] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:23,074 [Thread-1226] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1458863077. Formatting...
2020-04-02 05:10:23,074 [Thread-1226] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-eb5022ac-fa0b-4efd-8fab-88d12fd94cbd for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:10:23,075 [Thread-1172] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:23,075 [Thread-1172] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:10:23,076 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:23,076 [Thread-1226] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:23,076 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:23,077 [Thread-1226] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1458863077. Formatting...
2020-04-02 05:10:23,077 [Thread-1226] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a9b6147c-75ea-43a4-9953-f4f29f656397 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:10:23,077 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:10:23,077 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:23,077 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:23,078 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40291
2020-04-02 05:10:23,078 [Thread-1172] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:23,079 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2076cbe7{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:23,079 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@49cc3ab1{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:23,083 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1ccd9b06{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:10:23,084 [Thread-1172] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2fda0093{HTTP/1.1,[http/1.1]}{localhost:40291}
2020-04-02 05:10:23,088 [Thread-1172] INFO  server.Server (Server.java:doStart(419)) - Started @93498ms
2020-04-02 05:10:23,093 [Thread-1226] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,093 [Thread-1226] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,094 [Thread-1226] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-371671733-172.17.0.14-1585804222598 is not formatted. Formatting ...
2020-04-02 05:10:23,094 [Thread-1226] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-371671733-172.17.0.14-1585804222598 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-371671733-172.17.0.14-1585804222598/current
2020-04-02 05:10:23,107 [Thread-1172] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36323
2020-04-02 05:10:23,109 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:10:23,109 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:10:23,109 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2af8bfca] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:23,110 [Thread-1172] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:23,112 [Socket Reader #1 for port 36904] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36904
2020-04-02 05:10:23,124 [Thread-1172] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:36904
2020-04-02 05:10:23,124 [Thread-1226] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,124 [Thread-1226] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,124 [Thread-1226] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-371671733-172.17.0.14-1585804222598 is not formatted. Formatting ...
2020-04-02 05:10:23,125 [Thread-1226] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-371671733-172.17.0.14-1585804222598 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-371671733-172.17.0.14-1585804222598/current
2020-04-02 05:10:23,126 [Thread-1226] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1458863077;bpid=BP-371671733-172.17.0.14-1585804222598;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1458863077;c=1585804222598;bpid=BP-371671733-172.17.0.14-1585804222598;dnuuid=null
2020-04-02 05:10:23,127 [Thread-1226] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 8d396def-1786-4275-b49c-2ee91dd52fd8
2020-04-02 05:10:23,169 [Thread-1226] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-eb5022ac-fa0b-4efd-8fab-88d12fd94cbd
2020-04-02 05:10:23,170 [Thread-1226] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:10:23,173 [Thread-1172] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:10:23,174 [Thread-1172] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:10:23,174 [Thread-1251] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43680 starting to offer service
2020-04-02 05:10:23,178 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:23,178 [IPC Server listener on 36904] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36904: starting
2020-04-02 05:10:23,178 [Thread-1226] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-a9b6147c-75ea-43a4-9953-f4f29f656397
2020-04-02 05:10:23,182 [Thread-1172] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 36904 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:23,196 [Thread-1226] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:10:23,197 [Thread-1251] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43680
2020-04-02 05:10:23,197 [Thread-1226] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:10:23,199 [Thread-1251] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:10:23,199 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:10:23,200 [Thread-1226] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:10:23,200 [Thread-1172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:10:23,200 [Thread-1251] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:23,200 [Thread-1172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:10:23,201 [Thread-1251] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1458863077. Formatting...
2020-04-02 05:10:23,201 [Thread-1226] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:10:23,201 [Thread-1251] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6102d9c4-fc3c-4556-a85a-55fb22ecc86e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:10:23,201 [Thread-1226] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:10:23,201 [Thread-1226] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:10:23,201 [Thread-1226] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,201 [Thread-1172] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:10:23,205 [Thread-1172] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:10:23,205 [Thread-1263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:10:23,205 [Thread-1172] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:23,205 [Thread-1264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:10:23,205 [Thread-1172] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:10:23,206 [Thread-1172] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:10:23,206 [Thread-1172] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:23,206 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:10:23,207 [Thread-1172] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34608
2020-04-02 05:10:23,207 [Thread-1172] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:10:23,207 [Thread-1172] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:10:23,208 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:23,208 [Thread-1251] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:23,209 [Thread-1251] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1458863077. Formatting...
2020-04-02 05:10:23,209 [Thread-1251] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7395567f-c8aa-40bc-8eb4-70a04630fe1b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:10:23,210 [Thread-1172] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:23,210 [Thread-1172] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:10:23,210 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:23,211 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:23,212 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:10:23,212 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:23,212 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:23,213 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38472
2020-04-02 05:10:23,213 [Thread-1172] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:23,214 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@48c9621f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:23,214 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1f61d4f7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:23,218 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1fa55103{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:10:23,218 [Thread-1172] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@761f442d{HTTP/1.1,[http/1.1]}{localhost:38472}
2020-04-02 05:10:23,224 [Thread-1172] INFO  server.Server (Server.java:doStart(419)) - Started @93634ms
2020-04-02 05:10:23,226 [Thread-1251] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,227 [Thread-1251] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,227 [Thread-1251] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-371671733-172.17.0.14-1585804222598 is not formatted. Formatting ...
2020-04-02 05:10:23,227 [Thread-1251] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-371671733-172.17.0.14-1585804222598 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-371671733-172.17.0.14-1585804222598/current
2020-04-02 05:10:23,240 [Thread-1172] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34402
2020-04-02 05:10:23,240 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:10:23,240 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@101a00c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:23,240 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:10:23,241 [Thread-1172] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:23,241 [Socket Reader #1 for port 42140] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42140
2020-04-02 05:10:23,247 [Thread-1172] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:42140
2020-04-02 05:10:23,249 [Thread-1251] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,249 [Thread-1251] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,249 [Thread-1251] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-371671733-172.17.0.14-1585804222598 is not formatted. Formatting ...
2020-04-02 05:10:23,249 [Thread-1251] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-371671733-172.17.0.14-1585804222598 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-371671733-172.17.0.14-1585804222598/current
2020-04-02 05:10:23,251 [Thread-1251] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1458863077;bpid=BP-371671733-172.17.0.14-1585804222598;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1458863077;c=1585804222598;bpid=BP-371671733-172.17.0.14-1585804222598;dnuuid=null
2020-04-02 05:10:23,252 [Thread-1251] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID b9473e7d-eaa8-4cc2-95dd-6ef0e032a218
2020-04-02 05:10:23,255 [Thread-1263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-371671733-172.17.0.14-1585804222598 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 50ms
2020-04-02 05:10:23,319 [Thread-1251] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-6102d9c4-fc3c-4556-a85a-55fb22ecc86e
2020-04-02 05:10:23,322 [Thread-1251] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:10:23,323 [Thread-1172] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:10:23,323 [Thread-1264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-371671733-172.17.0.14-1585804222598 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 117ms
2020-04-02 05:10:23,323 [Thread-1226] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-371671733-172.17.0.14-1585804222598: 118ms
2020-04-02 05:10:23,323 [Thread-1172] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:10:23,325 [Thread-1280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:10:23,325 [Thread-1280] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-371671733-172.17.0.14-1585804222598/current/replicas doesn't exist 
2020-04-02 05:10:23,325 [Thread-1281] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43680 starting to offer service
2020-04-02 05:10:23,325 [Thread-1283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:10:23,325 [Thread-1251] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-7395567f-c8aa-40bc-8eb4-70a04630fe1b
2020-04-02 05:10:23,330 [Thread-1251] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:10:23,330 [Thread-1283] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-371671733-172.17.0.14-1585804222598/current/replicas doesn't exist 
2020-04-02 05:10:23,330 [Thread-1280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 5ms
2020-04-02 05:10:23,330 [Thread-1251] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:10:23,330 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:23,330 [Thread-1283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 5ms
2020-04-02 05:10:23,330 [IPC Server listener on 42140] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42140: starting
2020-04-02 05:10:23,330 [Thread-1226] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-371671733-172.17.0.14-1585804222598: 7ms
2020-04-02 05:10:23,335 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:10:23,335 [Thread-1251] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:10:23,335 [Thread-1281] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43680
2020-04-02 05:10:23,335 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:10:23,335 [Thread-1172] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 42140 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:23,335 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-a9b6147c-75ea-43a4-9953-f4f29f656397): finished scanning block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,339 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-eb5022ac-fa0b-4efd-8fab-88d12fd94cbd): finished scanning block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,339 [Thread-1251] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:10:23,339 [Thread-1281] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:10:23,335 [Thread-1226] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:24 AM with interval of 21600000ms
2020-04-02 05:10:23,339 [Thread-1251] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:10:23,340 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-a9b6147c-75ea-43a4-9953-f4f29f656397): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:10:23,340 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-eb5022ac-fa0b-4efd-8fab-88d12fd94cbd): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:10:23,340 [Thread-1251] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:10:23,343 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 8d396def-1786-4275-b49c-2ee91dd52fd8) service to localhost/127.0.0.1:43680 beginning handshake with NN
2020-04-02 05:10:23,340 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:10:23,343 [Thread-1251] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,343 [Thread-1281] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:23,344 [Thread-1297] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:10:23,344 [Thread-1281] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1458863077. Formatting...
2020-04-02 05:10:23,344 [Thread-1172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:10:23,347 [Thread-1281] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bcb950f9-3ce2-42ae-a83e-d747b2031f76 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:10:23,344 [Thread-1298] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:10:23,347 [IPC Server handler 2 on 43680] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36096, datanodeUuid=8d396def-1786-4275-b49c-2ee91dd52fd8, infoPort=45461, infoSecurePort=0, ipcPort=33969, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598) storage 8d396def-1786-4275-b49c-2ee91dd52fd8
2020-04-02 05:10:23,348 [IPC Server handler 2 on 43680] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36096
2020-04-02 05:10:23,348 [IPC Server handler 2 on 43680] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8d396def-1786-4275-b49c-2ee91dd52fd8 (127.0.0.1:36096).
2020-04-02 05:10:23,357 [Thread-1172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:10:23,357 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 8d396def-1786-4275-b49c-2ee91dd52fd8) service to localhost/127.0.0.1:43680 successfully registered with NN
2020-04-02 05:10:23,357 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:43680 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:23,361 [Thread-1281] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:23,365 [IPC Server handler 4 on 43680] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-eb5022ac-fa0b-4efd-8fab-88d12fd94cbd for DN 127.0.0.1:36096
2020-04-02 05:10:23,365 [Thread-1281] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1458863077. Formatting...
2020-04-02 05:10:23,365 [IPC Server handler 4 on 43680] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a9b6147c-75ea-43a4-9953-f4f29f656397 for DN 127.0.0.1:36096
2020-04-02 05:10:23,365 [Thread-1281] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5ce73643-a35c-49a0-9b6f-3a559c673904 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:10:23,368 [Thread-1172] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:10:23,370 [Thread-1172] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:10:23,371 [Thread-1172] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:23,371 [Thread-1172] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:10:23,371 [Thread-1172] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:10:23,371 [Thread-1172] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:23,372 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:10:23,372 [IPC Server handler 5 on 43680] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:36096, datanodeUuid=8d396def-1786-4275-b49c-2ee91dd52fd8, infoPort=45461, infoSecurePort=0, ipcPort=33969, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), reports.length=2
2020-04-02 05:10:23,372 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd2c6bb90dda94f1a: Processing first storage report for DS-eb5022ac-fa0b-4efd-8fab-88d12fd94cbd from datanode 8d396def-1786-4275-b49c-2ee91dd52fd8
2020-04-02 05:10:23,372 [Thread-1172] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:36035
2020-04-02 05:10:23,372 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd2c6bb90dda94f1a: from storage DS-eb5022ac-fa0b-4efd-8fab-88d12fd94cbd node DatanodeRegistration(127.0.0.1:36096, datanodeUuid=8d396def-1786-4275-b49c-2ee91dd52fd8, infoPort=45461, infoSecurePort=0, ipcPort=33969, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:23,372 [Thread-1172] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:10:23,372 [Thread-1172] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:10:23,372 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd2c6bb90dda94f1a: Processing first storage report for DS-a9b6147c-75ea-43a4-9953-f4f29f656397 from datanode 8d396def-1786-4275-b49c-2ee91dd52fd8
2020-04-02 05:10:23,373 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd2c6bb90dda94f1a: from storage DS-a9b6147c-75ea-43a4-9953-f4f29f656397 node DatanodeRegistration(127.0.0.1:36096, datanodeUuid=8d396def-1786-4275-b49c-2ee91dd52fd8, infoPort=45461, infoSecurePort=0, ipcPort=33969, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:10:23,373 [IPC Server handler 5 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xd2c6bb90dda94f1a
2020-04-02 05:10:23,373 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:23,373 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xd2c6bb90dda94f1a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:23,374 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,375 [Thread-1172] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:23,375 [Thread-1172] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:10:23,376 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:23,377 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:23,377 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:10:23,377 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:23,377 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:23,378 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34806
2020-04-02 05:10:23,378 [Thread-1172] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:23,379 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@500a7e25{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:23,380 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2d5f2e22{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:23,382 [Thread-1281] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,383 [Thread-1281] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,383 [Thread-1281] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-371671733-172.17.0.14-1585804222598 is not formatted. Formatting ...
2020-04-02 05:10:23,383 [Thread-1281] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-371671733-172.17.0.14-1585804222598 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-371671733-172.17.0.14-1585804222598/current
2020-04-02 05:10:23,384 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@26485f8{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:10:23,389 [Thread-1172] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@27c0063f{HTTP/1.1,[http/1.1]}{localhost:34806}
2020-04-02 05:10:23,389 [Thread-1172] INFO  server.Server (Server.java:doStart(419)) - Started @93799ms
2020-04-02 05:10:23,405 [Thread-1172] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43021
2020-04-02 05:10:23,406 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:10:23,406 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:10:23,406 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@116de7e3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:23,406 [Thread-1172] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:23,407 [Socket Reader #1 for port 40151] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40151
2020-04-02 05:10:23,418 [Thread-1281] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,418 [Thread-1281] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,418 [Thread-1281] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-371671733-172.17.0.14-1585804222598 is not formatted. Formatting ...
2020-04-02 05:10:23,418 [Thread-1281] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-371671733-172.17.0.14-1585804222598 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-371671733-172.17.0.14-1585804222598/current
2020-04-02 05:10:23,419 [Thread-1172] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40151
2020-04-02 05:10:23,419 [Thread-1281] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1458863077;bpid=BP-371671733-172.17.0.14-1585804222598;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1458863077;c=1585804222598;bpid=BP-371671733-172.17.0.14-1585804222598;dnuuid=null
2020-04-02 05:10:23,419 [Thread-1297] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-371671733-172.17.0.14-1585804222598 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 76ms
2020-04-02 05:10:23,420 [Thread-1281] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 04baa337-8df0-4202-93da-4b177174abb6
2020-04-02 05:10:23,421 [Thread-1298] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-371671733-172.17.0.14-1585804222598 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 73ms
2020-04-02 05:10:23,421 [Thread-1251] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-371671733-172.17.0.14-1585804222598: 77ms
2020-04-02 05:10:23,469 [Thread-1311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:10:23,469 [Thread-1312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:10:23,469 [Thread-1311] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-371671733-172.17.0.14-1585804222598/current/replicas doesn't exist 
2020-04-02 05:10:23,469 [Thread-1312] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-371671733-172.17.0.14-1585804222598/current/replicas doesn't exist 
2020-04-02 05:10:23,469 [Thread-1311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-04-02 05:10:23,470 [Thread-1172] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:10:23,489 [Thread-1312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 20ms
2020-04-02 05:10:23,490 [Thread-1172] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:10:23,490 [Thread-1251] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-371671733-172.17.0.14-1585804222598: 69ms
2020-04-02 05:10:23,490 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:10:23,490 [Thread-1281] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-bcb950f9-3ce2-42ae-a83e-d747b2031f76
2020-04-02 05:10:23,490 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:10:23,490 [Thread-1315] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43680 starting to offer service
2020-04-02 05:10:23,494 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:23,491 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-6102d9c4-fc3c-4556-a85a-55fb22ecc86e): finished scanning block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,490 [Thread-1281] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:10:23,495 [Thread-1251] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:36 AM with interval of 21600000ms
2020-04-02 05:10:23,494 [IPC Server listener on 40151] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40151: starting
2020-04-02 05:10:23,495 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-7395567f-c8aa-40bc-8eb4-70a04630fe1b): finished scanning block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,506 [Thread-1172] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40151 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:23,506 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-6102d9c4-fc3c-4556-a85a-55fb22ecc86e): no suitable block pools found to scan.  Waiting 1814399984 ms.
2020-04-02 05:10:23,507 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid b9473e7d-eaa8-4cc2-95dd-6ef0e032a218) service to localhost/127.0.0.1:43680 beginning handshake with NN
2020-04-02 05:10:23,507 [Thread-1315] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43680
2020-04-02 05:10:23,507 [Thread-1281] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5ce73643-a35c-49a0-9b6f-3a559c673904
2020-04-02 05:10:23,507 [Thread-1281] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:10:23,507 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-7395567f-c8aa-40bc-8eb4-70a04630fe1b): no suitable block pools found to scan.  Waiting 1814399983 ms.
2020-04-02 05:10:23,507 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:10:23,510 [Thread-1281] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:10:23,510 [IPC Server handler 7 on 43680] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42705, datanodeUuid=b9473e7d-eaa8-4cc2-95dd-6ef0e032a218, infoPort=36323, infoSecurePort=0, ipcPort=36904, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598) storage b9473e7d-eaa8-4cc2-95dd-6ef0e032a218
2020-04-02 05:10:23,510 [Thread-1315] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:10:23,510 [IPC Server handler 7 on 43680] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42705
2020-04-02 05:10:23,510 [IPC Server handler 7 on 43680] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b9473e7d-eaa8-4cc2-95dd-6ef0e032a218 (127.0.0.1:42705).
2020-04-02 05:10:23,511 [Thread-1172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:10:23,511 [Thread-1281] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:10:23,511 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid b9473e7d-eaa8-4cc2-95dd-6ef0e032a218) service to localhost/127.0.0.1:43680 successfully registered with NN
2020-04-02 05:10:23,511 [Thread-1172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:10:23,511 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:43680 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:23,511 [Thread-1281] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:10:23,511 [Thread-1315] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:23,511 [Thread-1281] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:10:23,514 [Thread-1315] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1458863077. Formatting...
2020-04-02 05:10:23,514 [Thread-1281] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:10:23,514 [Thread-1315] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-27146415-ac5c-4ffe-9b04-744fa668348b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-04-02 05:10:23,514 [Thread-1172] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:10:23,514 [Thread-1281] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,534 [Thread-1172] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:10:23,533 [IPC Server handler 8 on 43680] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6102d9c4-fc3c-4556-a85a-55fb22ecc86e for DN 127.0.0.1:42705
2020-04-02 05:10:23,535 [Thread-1172] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:23,542 [IPC Server handler 8 on 43680] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7395567f-c8aa-40bc-8eb4-70a04630fe1b for DN 127.0.0.1:42705
2020-04-02 05:10:23,539 [Thread-1331] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:10:23,542 [Thread-1172] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:10:23,542 [Thread-1332] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:10:23,543 [Thread-1172] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:10:23,543 [Thread-1172] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:23,543 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:10:23,544 [IPC Server handler 9 on 43680] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:42705, datanodeUuid=b9473e7d-eaa8-4cc2-95dd-6ef0e032a218, infoPort=36323, infoSecurePort=0, ipcPort=36904, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), reports.length=2
2020-04-02 05:10:23,544 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5eb4542ede3a37d7: Processing first storage report for DS-6102d9c4-fc3c-4556-a85a-55fb22ecc86e from datanode b9473e7d-eaa8-4cc2-95dd-6ef0e032a218
2020-04-02 05:10:23,544 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5eb4542ede3a37d7: from storage DS-6102d9c4-fc3c-4556-a85a-55fb22ecc86e node DatanodeRegistration(127.0.0.1:42705, datanodeUuid=b9473e7d-eaa8-4cc2-95dd-6ef0e032a218, infoPort=36323, infoSecurePort=0, ipcPort=36904, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:23,544 [Thread-1172] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:44235
2020-04-02 05:10:23,544 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5eb4542ede3a37d7: Processing first storage report for DS-7395567f-c8aa-40bc-8eb4-70a04630fe1b from datanode b9473e7d-eaa8-4cc2-95dd-6ef0e032a218
2020-04-02 05:10:23,544 [Thread-1172] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:10:23,544 [Thread-1172] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:10:23,544 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5eb4542ede3a37d7: from storage DS-7395567f-c8aa-40bc-8eb4-70a04630fe1b node DatanodeRegistration(127.0.0.1:42705, datanodeUuid=b9473e7d-eaa8-4cc2-95dd-6ef0e032a218, infoPort=36323, infoSecurePort=0, ipcPort=36904, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:23,545 [IPC Server handler 9 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x5eb4542ede3a37d7
2020-04-02 05:10:23,545 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x5eb4542ede3a37d7,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:23,545 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,546 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:23,546 [Thread-1315] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:23,546 [Thread-1315] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1458863077. Formatting...
2020-04-02 05:10:23,546 [Thread-1315] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-063830f5-af19-402d-9b62-9e637faa8fe6 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-04-02 05:10:23,547 [Thread-1172] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:23,548 [Thread-1172] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:10:23,548 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:23,549 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:23,549 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:10:23,550 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:23,550 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:23,550 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43464
2020-04-02 05:10:23,550 [Thread-1172] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:23,552 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2729f69d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:23,552 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@683ba11a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:23,556 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6a243a35{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:10:23,557 [Thread-1172] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@74836950{HTTP/1.1,[http/1.1]}{localhost:43464}
2020-04-02 05:10:23,561 [Thread-1172] INFO  server.Server (Server.java:doStart(419)) - Started @93972ms
2020-04-02 05:10:23,562 [Thread-1315] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,563 [Thread-1315] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,563 [Thread-1315] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-371671733-172.17.0.14-1585804222598 is not formatted. Formatting ...
2020-04-02 05:10:23,563 [Thread-1315] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-371671733-172.17.0.14-1585804222598 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-371671733-172.17.0.14-1585804222598/current
2020-04-02 05:10:23,577 [Thread-1172] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42026
2020-04-02 05:10:23,578 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:10:23,578 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4bacc9d9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:23,578 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:10:23,579 [Thread-1172] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:23,579 [Socket Reader #1 for port 39043] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39043
2020-04-02 05:10:23,586 [Thread-1172] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:39043
2020-04-02 05:10:23,587 [Thread-1315] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,588 [Thread-1315] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,588 [Thread-1315] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-371671733-172.17.0.14-1585804222598 is not formatted. Formatting ...
2020-04-02 05:10:23,588 [Thread-1315] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-371671733-172.17.0.14-1585804222598 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-371671733-172.17.0.14-1585804222598/current
2020-04-02 05:10:23,589 [Thread-1315] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1458863077;bpid=BP-371671733-172.17.0.14-1585804222598;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1458863077;c=1585804222598;bpid=BP-371671733-172.17.0.14-1585804222598;dnuuid=null
2020-04-02 05:10:23,591 [Thread-1315] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID f52e3635-95c4-4878-9344-a0dc0c102c00
2020-04-02 05:10:23,645 [Thread-1172] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:10:23,645 [Thread-1172] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:10:23,646 [Thread-1347] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43680 starting to offer service
2020-04-02 05:10:23,651 [Thread-1315] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-27146415-ac5c-4ffe-9b04-744fa668348b
2020-04-02 05:10:23,651 [Thread-1315] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:10:23,652 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:23,652 [IPC Server listener on 39043] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39043: starting
2020-04-02 05:10:23,657 [Thread-1347] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43680
2020-04-02 05:10:23,658 [Thread-1315] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-063830f5-af19-402d-9b62-9e637faa8fe6
2020-04-02 05:10:23,663 [Thread-1172] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 39043 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:23,663 [Thread-1347] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:10:23,667 [Thread-1315] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:10:23,667 [Thread-1315] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:10:23,667 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:10:23,668 [Thread-1172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:10:23,668 [Thread-1315] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:10:23,669 [Thread-1172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:10:23,669 [Thread-1347] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:23,669 [Thread-1315] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:10:23,669 [Thread-1347] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 1458863077. Formatting...
2020-04-02 05:10:23,669 [Thread-1315] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:10:23,670 [Thread-1347] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d07cda12-37b0-4b92-8197-783f0f0639e7 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-04-02 05:10:23,670 [Thread-1315] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:10:23,670 [Thread-1172] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:10:23,674 [Thread-1172] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:10:23,674 [Thread-1172] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:23,674 [Thread-1172] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:10:23,674 [Thread-1315] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,675 [Thread-1172] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:10:23,675 [Thread-1172] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:23,675 [Thread-1361] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:10:23,675 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:10:23,675 [Thread-1362] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:10:23,675 [Thread-1172] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:33892
2020-04-02 05:10:23,676 [Thread-1172] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:10:23,676 [Thread-1172] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:10:23,676 [Thread-1347] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:23,676 [Thread-1347] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 1458863077. Formatting...
2020-04-02 05:10:23,677 [Thread-1347] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0788a838-b00d-4ed5-8779-e005bcd7dea3 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-04-02 05:10:23,677 [Thread-1332] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-371671733-172.17.0.14-1585804222598 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 134ms
2020-04-02 05:10:23,681 [Thread-1331] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-371671733-172.17.0.14-1585804222598 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 138ms
2020-04-02 05:10:23,681 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:23,681 [Thread-1281] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-371671733-172.17.0.14-1585804222598: 146ms
2020-04-02 05:10:23,682 [Thread-1365] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:10:23,682 [Thread-1366] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:10:23,682 [Thread-1365] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-371671733-172.17.0.14-1585804222598/current/replicas doesn't exist 
2020-04-02 05:10:23,682 [Thread-1366] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-371671733-172.17.0.14-1585804222598/current/replicas doesn't exist 
2020-04-02 05:10:23,682 [Thread-1365] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 0ms
2020-04-02 05:10:23,682 [Thread-1366] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 0ms
2020-04-02 05:10:23,683 [Thread-1281] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-371671733-172.17.0.14-1585804222598: 2ms
2020-04-02 05:10:23,683 [Thread-1172] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:23,683 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:10:23,683 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:10:23,683 [Thread-1281] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:06 AM with interval of 21600000ms
2020-04-02 05:10:23,683 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-bcb950f9-3ce2-42ae-a83e-d747b2031f76): finished scanning block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,683 [Thread-1172] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:10:23,683 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-5ce73643-a35c-49a0-9b6f-3a559c673904): finished scanning block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,688 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:23,688 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 04baa337-8df0-4202-93da-4b177174abb6) service to localhost/127.0.0.1:43680 beginning handshake with NN
2020-04-02 05:10:23,689 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-bcb950f9-3ce2-42ae-a83e-d747b2031f76): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-04-02 05:10:23,689 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-5ce73643-a35c-49a0-9b6f-3a559c673904): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-04-02 05:10:23,689 [IPC Server handler 1 on 43680] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34608, datanodeUuid=04baa337-8df0-4202-93da-4b177174abb6, infoPort=34402, infoSecurePort=0, ipcPort=42140, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598) storage 04baa337-8df0-4202-93da-4b177174abb6
2020-04-02 05:10:23,689 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:23,690 [IPC Server handler 1 on 43680] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34608
2020-04-02 05:10:23,690 [IPC Server handler 1 on 43680] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 04baa337-8df0-4202-93da-4b177174abb6 (127.0.0.1:34608).
2020-04-02 05:10:23,690 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:10:23,690 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:23,690 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:23,691 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 04baa337-8df0-4202-93da-4b177174abb6) service to localhost/127.0.0.1:43680 successfully registered with NN
2020-04-02 05:10:23,691 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:43680 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:23,695 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42474
2020-04-02 05:10:23,696 [Thread-1172] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:23,700 [IPC Server handler 3 on 43680] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bcb950f9-3ce2-42ae-a83e-d747b2031f76 for DN 127.0.0.1:34608
2020-04-02 05:10:23,700 [IPC Server handler 3 on 43680] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5ce73643-a35c-49a0-9b6f-3a559c673904 for DN 127.0.0.1:34608
2020-04-02 05:10:23,701 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@67268f1f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:23,701 [IPC Server handler 2 on 43680] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:34608, datanodeUuid=04baa337-8df0-4202-93da-4b177174abb6, infoPort=34402, infoSecurePort=0, ipcPort=42140, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), reports.length=2
2020-04-02 05:10:23,702 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x38a2641236d5b664: Processing first storage report for DS-bcb950f9-3ce2-42ae-a83e-d747b2031f76 from datanode 04baa337-8df0-4202-93da-4b177174abb6
2020-04-02 05:10:23,702 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x38a2641236d5b664: from storage DS-bcb950f9-3ce2-42ae-a83e-d747b2031f76 node DatanodeRegistration(127.0.0.1:34608, datanodeUuid=04baa337-8df0-4202-93da-4b177174abb6, infoPort=34402, infoSecurePort=0, ipcPort=42140, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:23,702 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x38a2641236d5b664: Processing first storage report for DS-5ce73643-a35c-49a0-9b6f-3a559c673904 from datanode 04baa337-8df0-4202-93da-4b177174abb6
2020-04-02 05:10:23,702 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x38a2641236d5b664: from storage DS-5ce73643-a35c-49a0-9b6f-3a559c673904 node DatanodeRegistration(127.0.0.1:34608, datanodeUuid=04baa337-8df0-4202-93da-4b177174abb6, infoPort=34402, infoSecurePort=0, ipcPort=42140, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:23,702 [IPC Server handler 2 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x38a2641236d5b664
2020-04-02 05:10:23,702 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4e95246f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:23,703 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x38a2641236d5b664,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:23,703 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,707 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@63272552{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:10:23,707 [Thread-1347] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,711 [Thread-1172] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@21103a39{HTTP/1.1,[http/1.1]}{localhost:42474}
2020-04-02 05:10:23,711 [Thread-1347] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,711 [Thread-1172] INFO  server.Server (Server.java:doStart(419)) - Started @94121ms
2020-04-02 05:10:23,711 [Thread-1347] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-371671733-172.17.0.14-1585804222598 is not formatted. Formatting ...
2020-04-02 05:10:23,711 [Thread-1347] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-371671733-172.17.0.14-1585804222598 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-371671733-172.17.0.14-1585804222598/current
2020-04-02 05:10:23,729 [Thread-1172] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45414
2020-04-02 05:10:23,732 [Thread-1347] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,732 [Thread-1347] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,732 [Thread-1347] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-371671733-172.17.0.14-1585804222598 is not formatted. Formatting ...
2020-04-02 05:10:23,732 [Thread-1347] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-371671733-172.17.0.14-1585804222598 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-371671733-172.17.0.14-1585804222598/current
2020-04-02 05:10:23,734 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:10:23,734 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@538d7dd4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:23,734 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:10:23,734 [Thread-1347] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1458863077;bpid=BP-371671733-172.17.0.14-1585804222598;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1458863077;c=1585804222598;bpid=BP-371671733-172.17.0.14-1585804222598;dnuuid=null
2020-04-02 05:10:23,734 [Thread-1172] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:23,735 [Socket Reader #1 for port 39819] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39819
2020-04-02 05:10:23,740 [Thread-1347] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 214c05a0-4d79-4137-ab66-e06c6cc0851e
2020-04-02 05:10:23,740 [Thread-1361] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-371671733-172.17.0.14-1585804222598 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 66ms
2020-04-02 05:10:23,741 [Thread-1172] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:39819
2020-04-02 05:10:23,742 [Thread-1347] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-d07cda12-37b0-4b92-8197-783f0f0639e7
2020-04-02 05:10:23,742 [Thread-1347] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-04-02 05:10:23,747 [Thread-1362] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-371671733-172.17.0.14-1585804222598 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 72ms
2020-04-02 05:10:23,747 [Thread-1315] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-371671733-172.17.0.14-1585804222598: 72ms
2020-04-02 05:10:23,806 [Thread-1380] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:10:23,806 [Thread-1381] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:10:23,806 [Thread-1380] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-371671733-172.17.0.14-1585804222598/current/replicas doesn't exist 
2020-04-02 05:10:23,806 [Thread-1381] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-371671733-172.17.0.14-1585804222598/current/replicas doesn't exist 
2020-04-02 05:10:23,806 [Thread-1380] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 0ms
2020-04-02 05:10:23,806 [Thread-1381] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 0ms
2020-04-02 05:10:23,807 [Thread-1315] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-371671733-172.17.0.14-1585804222598: 59ms
2020-04-02 05:10:23,807 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:10:23,807 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:10:23,807 [Thread-1315] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:54 AM with interval of 21600000ms
2020-04-02 05:10:23,807 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-27146415-ac5c-4ffe-9b04-744fa668348b): finished scanning block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,807 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-063830f5-af19-402d-9b62-9e637faa8fe6): finished scanning block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,808 [Thread-1172] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:10:23,812 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid f52e3635-95c4-4878-9344-a0dc0c102c00) service to localhost/127.0.0.1:43680 beginning handshake with NN
2020-04-02 05:10:23,812 [Thread-1172] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:10:23,812 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-27146415-ac5c-4ffe-9b04-744fa668348b): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:10:23,812 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-063830f5-af19-402d-9b62-9e637faa8fe6): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:10:23,813 [Thread-1387] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43680 starting to offer service
2020-04-02 05:10:23,821 [Thread-1347] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-0788a838-b00d-4ed5-8779-e005bcd7dea3
2020-04-02 05:10:23,827 [Thread-1347] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-04-02 05:10:23,827 [IPC Server handler 4 on 43680] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36035, datanodeUuid=f52e3635-95c4-4878-9344-a0dc0c102c00, infoPort=43021, infoSecurePort=0, ipcPort=40151, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598) storage f52e3635-95c4-4878-9344-a0dc0c102c00
2020-04-02 05:10:23,828 [Thread-1387] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43680
2020-04-02 05:10:23,828 [Thread-1347] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:10:23,828 [IPC Server handler 4 on 43680] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36035
2020-04-02 05:10:23,828 [IPC Server handler 4 on 43680] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f52e3635-95c4-4878-9344-a0dc0c102c00 (127.0.0.1:36035).
2020-04-02 05:10:23,829 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid f52e3635-95c4-4878-9344-a0dc0c102c00) service to localhost/127.0.0.1:43680 successfully registered with NN
2020-04-02 05:10:23,829 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:43680 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:23,830 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:23,829 [Thread-1347] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:10:23,833 [Thread-1387] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:10:23,833 [IPC Server listener on 39819] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39819: starting
2020-04-02 05:10:23,841 [IPC Server handler 6 on 43680] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-27146415-ac5c-4ffe-9b04-744fa668348b for DN 127.0.0.1:36035
2020-04-02 05:10:23,844 [IPC Server handler 6 on 43680] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-063830f5-af19-402d-9b62-9e637faa8fe6 for DN 127.0.0.1:36035
2020-04-02 05:10:23,844 [Thread-1172] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 39819 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:23,844 [Thread-1347] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:10:23,844 [Thread-1347] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:10:23,845 [Thread-1347] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:10:23,845 [Thread-1347] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,845 [Thread-1387] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:23,845 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:10:23,848 [Thread-1399] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:10:23,848 [Thread-1387] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 1458863077. Formatting...
2020-04-02 05:10:23,848 [Thread-1400] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:10:23,848 [IPC Server handler 7 on 43680] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:36035, datanodeUuid=f52e3635-95c4-4878-9344-a0dc0c102c00, infoPort=43021, infoSecurePort=0, ipcPort=40151, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), reports.length=2
2020-04-02 05:10:23,848 [Thread-1387] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b2ae87b0-816b-4ad4-9683-21682c26c189 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-04-02 05:10:23,848 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x19b1bcda7f7b0abf: Processing first storage report for DS-27146415-ac5c-4ffe-9b04-744fa668348b from datanode f52e3635-95c4-4878-9344-a0dc0c102c00
2020-04-02 05:10:23,848 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x19b1bcda7f7b0abf: from storage DS-27146415-ac5c-4ffe-9b04-744fa668348b node DatanodeRegistration(127.0.0.1:36035, datanodeUuid=f52e3635-95c4-4878-9344-a0dc0c102c00, infoPort=43021, infoSecurePort=0, ipcPort=40151, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:10:23,849 [Thread-1172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:10:23,849 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x19b1bcda7f7b0abf: Processing first storage report for DS-063830f5-af19-402d-9b62-9e637faa8fe6 from datanode f52e3635-95c4-4878-9344-a0dc0c102c00
2020-04-02 05:10:23,849 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x19b1bcda7f7b0abf: from storage DS-063830f5-af19-402d-9b62-9e637faa8fe6 node DatanodeRegistration(127.0.0.1:36035, datanodeUuid=f52e3635-95c4-4878-9344-a0dc0c102c00, infoPort=43021, infoSecurePort=0, ipcPort=40151, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:23,849 [Thread-1172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:10:23,849 [IPC Server handler 7 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x19b1bcda7f7b0abf
2020-04-02 05:10:23,850 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x19b1bcda7f7b0abf,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:23,850 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,850 [Thread-1172] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:10:23,852 [Thread-1172] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:10:23,853 [Thread-1172] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:23,853 [Thread-1172] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:10:23,853 [Thread-1172] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:10:23,853 [Thread-1172] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:23,853 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:10:23,854 [Thread-1387] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:23,854 [Thread-1172] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:41426
2020-04-02 05:10:23,854 [Thread-1387] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 1458863077. Formatting...
2020-04-02 05:10:23,854 [Thread-1172] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:10:23,854 [Thread-1172] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:10:23,854 [Thread-1387] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e5f50d86-b76f-4131-b16c-5367cd79c8ac for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-04-02 05:10:23,855 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:23,857 [Thread-1172] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:23,857 [Thread-1172] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:10:23,858 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:23,858 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:23,859 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:10:23,859 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:23,859 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:23,860 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41829
2020-04-02 05:10:23,860 [Thread-1172] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:23,861 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1d8b029a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:23,862 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@787a031{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:23,866 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2d9bfe07{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:10:23,866 [Thread-1387] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,866 [Thread-1387] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,871 [Thread-1172] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@75e647c5{HTTP/1.1,[http/1.1]}{localhost:41829}
2020-04-02 05:10:23,872 [Thread-1387] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-371671733-172.17.0.14-1585804222598 is not formatted. Formatting ...
2020-04-02 05:10:23,872 [Thread-1387] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-371671733-172.17.0.14-1585804222598 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-371671733-172.17.0.14-1585804222598/current
2020-04-02 05:10:23,872 [Thread-1172] INFO  server.Server (Server.java:doStart(419)) - Started @94282ms
2020-04-02 05:10:23,891 [Thread-1172] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38075
2020-04-02 05:10:23,891 [Thread-1387] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,892 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:10:23,892 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4137a0ae] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:23,892 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:10:23,892 [Thread-1387] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,892 [Thread-1387] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-371671733-172.17.0.14-1585804222598 is not formatted. Formatting ...
2020-04-02 05:10:23,892 [Thread-1387] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-371671733-172.17.0.14-1585804222598 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-371671733-172.17.0.14-1585804222598/current
2020-04-02 05:10:23,893 [Thread-1172] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:23,893 [Socket Reader #1 for port 39048] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39048
2020-04-02 05:10:23,899 [Thread-1387] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1458863077;bpid=BP-371671733-172.17.0.14-1585804222598;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1458863077;c=1585804222598;bpid=BP-371671733-172.17.0.14-1585804222598;dnuuid=null
2020-04-02 05:10:23,900 [Thread-1172] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:39048
2020-04-02 05:10:23,901 [Thread-1387] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 922de900-ed97-41ff-b822-20bb82158b34
2020-04-02 05:10:23,966 [Thread-1387] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-b2ae87b0-816b-4ad4-9683-21682c26c189
2020-04-02 05:10:23,971 [Thread-1387] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-04-02 05:10:23,971 [Thread-1172] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:10:23,971 [Thread-1172] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:10:23,972 [Thread-1416] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43680 starting to offer service
2020-04-02 05:10:23,977 [IPC Server listener on 39048] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39048: starting
2020-04-02 05:10:23,977 [Thread-1387] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-e5f50d86-b76f-4131-b16c-5367cd79c8ac
2020-04-02 05:10:23,977 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:23,977 [Thread-1387] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-04-02 05:10:23,987 [Thread-1416] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43680
2020-04-02 05:10:23,991 [Thread-1416] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:10:23,991 [Thread-1172] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 39048 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:23,991 [Thread-1387] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:10:23,993 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:10:23,993 [Thread-1416] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:23,993 [Thread-1387] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:10:23,993 [Thread-1416] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 1458863077. Formatting...
2020-04-02 05:10:23,993 [Thread-1416] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f9117091-6dc7-4177-8fa4-a57c9232310e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-04-02 05:10:23,993 [Thread-1387] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:10:23,993 [Thread-1172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:10:23,994 [Thread-1387] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:10:23,994 [Thread-1387] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:10:23,994 [Thread-1172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:10:23,994 [Thread-1387] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:23,995 [Thread-1428] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:10:23,995 [Thread-1429] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:10:23,995 [Thread-1172] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:10:24,000 [Thread-1172] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:10:24,001 [Thread-1172] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:24,002 [Thread-1172] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:10:24,002 [Thread-1172] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:10:24,002 [Thread-1172] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:24,002 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:10:24,003 [Thread-1172] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37472
2020-04-02 05:10:24,003 [Thread-1172] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:10:24,003 [Thread-1172] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:10:24,003 [Thread-1416] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:24,003 [Thread-1416] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 1458863077. Formatting...
2020-04-02 05:10:24,004 [Thread-1416] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-51ff9be9-01b1-46f0-bad0-adba582f1208 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-04-02 05:10:24,004 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:24,005 [Thread-1400] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-371671733-172.17.0.14-1585804222598 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 157ms
2020-04-02 05:10:24,008 [Thread-1399] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-371671733-172.17.0.14-1585804222598 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 160ms
2020-04-02 05:10:24,008 [Thread-1347] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-371671733-172.17.0.14-1585804222598: 163ms
2020-04-02 05:10:24,009 [Thread-1172] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:24,009 [Thread-1433] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:10:24,009 [Thread-1434] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:10:24,009 [Thread-1433] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-371671733-172.17.0.14-1585804222598/current/replicas doesn't exist 
2020-04-02 05:10:24,009 [Thread-1434] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-371671733-172.17.0.14-1585804222598/current/replicas doesn't exist 
2020-04-02 05:10:24,009 [Thread-1172] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:10:24,009 [Thread-1433] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 0ms
2020-04-02 05:10:24,009 [Thread-1434] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 0ms
2020-04-02 05:10:24,009 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:24,010 [Thread-1347] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-371671733-172.17.0.14-1585804222598: 1ms
2020-04-02 05:10:24,010 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:10:24,010 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:10:24,010 [Thread-1347] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:39 AM with interval of 21600000ms
2020-04-02 05:10:24,010 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-0788a838-b00d-4ed5-8779-e005bcd7dea3): finished scanning block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,010 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-d07cda12-37b0-4b92-8197-783f0f0639e7): finished scanning block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,010 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:24,015 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 214c05a0-4d79-4137-ab66-e06c6cc0851e) service to localhost/127.0.0.1:43680 beginning handshake with NN
2020-04-02 05:10:24,016 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-0788a838-b00d-4ed5-8779-e005bcd7dea3): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-04-02 05:10:24,016 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-d07cda12-37b0-4b92-8197-783f0f0639e7): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-04-02 05:10:24,016 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:10:24,016 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:24,016 [IPC Server handler 9 on 43680] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44235, datanodeUuid=214c05a0-4d79-4137-ab66-e06c6cc0851e, infoPort=42026, infoSecurePort=0, ipcPort=39043, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598) storage 214c05a0-4d79-4137-ab66-e06c6cc0851e
2020-04-02 05:10:24,016 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:24,016 [IPC Server handler 9 on 43680] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44235
2020-04-02 05:10:24,017 [IPC Server handler 9 on 43680] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 214c05a0-4d79-4137-ab66-e06c6cc0851e (127.0.0.1:44235).
2020-04-02 05:10:24,017 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37746
2020-04-02 05:10:24,017 [Thread-1172] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:24,017 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 214c05a0-4d79-4137-ab66-e06c6cc0851e) service to localhost/127.0.0.1:43680 successfully registered with NN
2020-04-02 05:10:24,017 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:43680 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:24,027 [IPC Server handler 0 on 43680] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d07cda12-37b0-4b92-8197-783f0f0639e7 for DN 127.0.0.1:44235
2020-04-02 05:10:24,027 [IPC Server handler 0 on 43680] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0788a838-b00d-4ed5-8779-e005bcd7dea3 for DN 127.0.0.1:44235
2020-04-02 05:10:24,028 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@52e6f3de{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:24,028 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@46a03aa0{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:24,029 [IPC Server handler 1 on 43680] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:44235, datanodeUuid=214c05a0-4d79-4137-ab66-e06c6cc0851e, infoPort=42026, infoSecurePort=0, ipcPort=39043, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), reports.length=2
2020-04-02 05:10:24,029 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf4557ee9289e196d: Processing first storage report for DS-d07cda12-37b0-4b92-8197-783f0f0639e7 from datanode 214c05a0-4d79-4137-ab66-e06c6cc0851e
2020-04-02 05:10:24,029 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf4557ee9289e196d: from storage DS-d07cda12-37b0-4b92-8197-783f0f0639e7 node DatanodeRegistration(127.0.0.1:44235, datanodeUuid=214c05a0-4d79-4137-ab66-e06c6cc0851e, infoPort=42026, infoSecurePort=0, ipcPort=39043, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:24,029 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf4557ee9289e196d: Processing first storage report for DS-0788a838-b00d-4ed5-8779-e005bcd7dea3 from datanode 214c05a0-4d79-4137-ab66-e06c6cc0851e
2020-04-02 05:10:24,029 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf4557ee9289e196d: from storage DS-0788a838-b00d-4ed5-8779-e005bcd7dea3 node DatanodeRegistration(127.0.0.1:44235, datanodeUuid=214c05a0-4d79-4137-ab66-e06c6cc0851e, infoPort=42026, infoSecurePort=0, ipcPort=39043, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:24,029 [IPC Server handler 1 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xf4557ee9289e196d
2020-04-02 05:10:24,030 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xf4557ee9289e196d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:24,030 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,032 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@79f3e1cb{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:10:24,037 [Thread-1172] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@41c25538{HTTP/1.1,[http/1.1]}{localhost:37746}
2020-04-02 05:10:24,037 [Thread-1416] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,037 [Thread-1172] INFO  server.Server (Server.java:doStart(419)) - Started @94447ms
2020-04-02 05:10:24,037 [Thread-1416] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,038 [Thread-1416] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-371671733-172.17.0.14-1585804222598 is not formatted. Formatting ...
2020-04-02 05:10:24,038 [Thread-1416] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-371671733-172.17.0.14-1585804222598 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-371671733-172.17.0.14-1585804222598/current
2020-04-02 05:10:24,056 [Thread-1172] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:32949
2020-04-02 05:10:24,057 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:10:24,057 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:10:24,057 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@19386336] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:24,057 [Thread-1172] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:24,058 [Socket Reader #1 for port 33165] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33165
2020-04-02 05:10:24,064 [Thread-1172] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:33165
2020-04-02 05:10:24,065 [Thread-1416] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,065 [Thread-1416] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,065 [Thread-1416] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-371671733-172.17.0.14-1585804222598 is not formatted. Formatting ...
2020-04-02 05:10:24,066 [Thread-1416] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-371671733-172.17.0.14-1585804222598 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-371671733-172.17.0.14-1585804222598/current
2020-04-02 05:10:24,067 [Thread-1416] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1458863077;bpid=BP-371671733-172.17.0.14-1585804222598;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1458863077;c=1585804222598;bpid=BP-371671733-172.17.0.14-1585804222598;dnuuid=null
2020-04-02 05:10:24,068 [Thread-1416] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 08b7258b-a01a-4143-b75b-25e5e0b0f184
2020-04-02 05:10:24,071 [Thread-1429] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-371671733-172.17.0.14-1585804222598 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 71ms
2020-04-02 05:10:24,071 [Thread-1428] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-371671733-172.17.0.14-1585804222598 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 76ms
2020-04-02 05:10:24,131 [Thread-1387] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-371671733-172.17.0.14-1585804222598: 137ms
2020-04-02 05:10:24,136 [Thread-1447] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:10:24,136 [Thread-1448] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:10:24,136 [Thread-1447] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-371671733-172.17.0.14-1585804222598/current/replicas doesn't exist 
2020-04-02 05:10:24,136 [Thread-1448] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-371671733-172.17.0.14-1585804222598/current/replicas doesn't exist 
2020-04-02 05:10:24,136 [Thread-1447] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 0ms
2020-04-02 05:10:24,136 [Thread-1448] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 0ms
2020-04-02 05:10:24,136 [Thread-1387] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-371671733-172.17.0.14-1585804222598: 5ms
2020-04-02 05:10:24,137 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:10:24,137 [Thread-1387] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:25 AM with interval of 21600000ms
2020-04-02 05:10:24,137 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:10:24,137 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-e5f50d86-b76f-4131-b16c-5367cd79c8ac): finished scanning block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,141 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 922de900-ed97-41ff-b822-20bb82158b34) service to localhost/127.0.0.1:43680 beginning handshake with NN
2020-04-02 05:10:24,141 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-b2ae87b0-816b-4ad4-9683-21682c26c189): finished scanning block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,141 [Thread-1172] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:10:24,141 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-b2ae87b0-816b-4ad4-9683-21682c26c189): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:10:24,141 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-e5f50d86-b76f-4131-b16c-5367cd79c8ac): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:10:24,142 [IPC Server handler 3 on 43680] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33892, datanodeUuid=922de900-ed97-41ff-b822-20bb82158b34, infoPort=45414, infoSecurePort=0, ipcPort=39819, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598) storage 922de900-ed97-41ff-b822-20bb82158b34
2020-04-02 05:10:24,142 [Thread-1172] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:10:24,142 [IPC Server handler 3 on 43680] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33892
2020-04-02 05:10:24,142 [Thread-1416] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-f9117091-6dc7-4177-8fa4-a57c9232310e
2020-04-02 05:10:24,142 [IPC Server handler 3 on 43680] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 922de900-ed97-41ff-b822-20bb82158b34 (127.0.0.1:33892).
2020-04-02 05:10:24,146 [Thread-1416] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-04-02 05:10:24,147 [Thread-1455] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43680 starting to offer service
2020-04-02 05:10:24,147 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:24,147 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 922de900-ed97-41ff-b822-20bb82158b34) service to localhost/127.0.0.1:43680 successfully registered with NN
2020-04-02 05:10:24,147 [IPC Server listener on 33165] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33165: starting
2020-04-02 05:10:24,151 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:43680 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:24,155 [Thread-1416] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-51ff9be9-01b1-46f0-bad0-adba582f1208
2020-04-02 05:10:24,155 [Thread-1416] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-04-02 05:10:24,158 [Thread-1416] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:10:24,162 [IPC Server handler 5 on 43680] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b2ae87b0-816b-4ad4-9683-21682c26c189 for DN 127.0.0.1:33892
2020-04-02 05:10:24,162 [Thread-1455] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43680
2020-04-02 05:10:24,162 [IPC Server handler 5 on 43680] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e5f50d86-b76f-4131-b16c-5367cd79c8ac for DN 127.0.0.1:33892
2020-04-02 05:10:24,162 [Thread-1172] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 33165 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:24,164 [Thread-1455] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:10:24,165 [Thread-1416] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:10:24,165 [Thread-1416] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:10:24,165 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:10:24,165 [Thread-1416] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:10:24,166 [IPC Server handler 4 on 43680] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:33892, datanodeUuid=922de900-ed97-41ff-b822-20bb82158b34, infoPort=45414, infoSecurePort=0, ipcPort=39819, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), reports.length=2
2020-04-02 05:10:24,168 [Thread-1455] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:24,168 [Thread-1416] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:10:24,168 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x73d8a8a90d87f986: Processing first storage report for DS-e5f50d86-b76f-4131-b16c-5367cd79c8ac from datanode 922de900-ed97-41ff-b822-20bb82158b34
2020-04-02 05:10:24,169 [Thread-1416] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,169 [Thread-1455] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 1458863077. Formatting...
2020-04-02 05:10:24,169 [Thread-1172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:10:24,169 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x73d8a8a90d87f986: from storage DS-e5f50d86-b76f-4131-b16c-5367cd79c8ac node DatanodeRegistration(127.0.0.1:33892, datanodeUuid=922de900-ed97-41ff-b822-20bb82158b34, infoPort=45414, infoSecurePort=0, ipcPort=39819, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:10:24,169 [Thread-1467] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:10:24,169 [Thread-1455] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-725ad767-aa1e-4967-8c34-f66e9ab24ac1 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-04-02 05:10:24,169 [Thread-1172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:10:24,169 [Thread-1468] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:10:24,169 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x73d8a8a90d87f986: Processing first storage report for DS-b2ae87b0-816b-4ad4-9683-21682c26c189 from datanode 922de900-ed97-41ff-b822-20bb82158b34
2020-04-02 05:10:24,170 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x73d8a8a90d87f986: from storage DS-b2ae87b0-816b-4ad4-9683-21682c26c189 node DatanodeRegistration(127.0.0.1:33892, datanodeUuid=922de900-ed97-41ff-b822-20bb82158b34, infoPort=45414, infoSecurePort=0, ipcPort=39819, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:10:24,170 [IPC Server handler 4 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x73d8a8a90d87f986
2020-04-02 05:10:24,170 [Thread-1172] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:10:24,173 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x73d8a8a90d87f986,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 8 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:24,173 [Thread-1172] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:10:24,173 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,174 [Thread-1172] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:24,175 [Thread-1172] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:10:24,175 [Thread-1172] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:10:24,175 [Thread-1172] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:24,175 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:10:24,176 [Thread-1455] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:24,176 [Thread-1172] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:43395
2020-04-02 05:10:24,176 [Thread-1455] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 1458863077. Formatting...
2020-04-02 05:10:24,176 [Thread-1172] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:10:24,176 [Thread-1172] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:10:24,176 [Thread-1455] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-447584f6-17aa-4d49-9afb-79bedb14b998 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-04-02 05:10:24,178 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:24,179 [Thread-1172] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:24,182 [Thread-1172] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:10:24,210 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:24,211 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:24,212 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:10:24,212 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:24,212 [Thread-1455] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,212 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:24,212 [Thread-1455] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,213 [Thread-1455] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-371671733-172.17.0.14-1585804222598 is not formatted. Formatting ...
2020-04-02 05:10:24,213 [Thread-1455] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-371671733-172.17.0.14-1585804222598 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-371671733-172.17.0.14-1585804222598/current
2020-04-02 05:10:24,213 [Thread-1172] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34916
2020-04-02 05:10:24,213 [Thread-1172] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:24,222 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2b53acbb{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:24,222 [Thread-1455] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,222 [Thread-1455] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,222 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1aca3375{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:24,222 [Thread-1455] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-371671733-172.17.0.14-1585804222598 is not formatted. Formatting ...
2020-04-02 05:10:24,222 [Thread-1455] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-371671733-172.17.0.14-1585804222598 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-371671733-172.17.0.14-1585804222598/current
2020-04-02 05:10:24,224 [Thread-1455] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1458863077;bpid=BP-371671733-172.17.0.14-1585804222598;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1458863077;c=1585804222598;bpid=BP-371671733-172.17.0.14-1585804222598;dnuuid=null
2020-04-02 05:10:24,225 [Thread-1455] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 3b0d66d2-d295-4441-b698-cc5b0796233f
2020-04-02 05:10:24,226 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@18e87a5e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:10:24,226 [Thread-1455] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-725ad767-aa1e-4967-8c34-f66e9ab24ac1
2020-04-02 05:10:24,230 [Thread-1455] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-04-02 05:10:24,230 [Thread-1172] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@197f5ad0{HTTP/1.1,[http/1.1]}{localhost:34916}
2020-04-02 05:10:24,234 [Thread-1172] INFO  server.Server (Server.java:doStart(419)) - Started @94644ms
2020-04-02 05:10:24,234 [Thread-1455] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-447584f6-17aa-4d49-9afb-79bedb14b998
2020-04-02 05:10:24,234 [Thread-1455] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-04-02 05:10:24,238 [Thread-1455] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:10:24,239 [Thread-1455] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:10:24,239 [Thread-1455] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:10:24,239 [Thread-1455] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:10:24,240 [Thread-1455] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:10:24,246 [Thread-1455] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,247 [Thread-1479] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:10:24,248 [Thread-1480] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:10:24,251 [Thread-1468] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-371671733-172.17.0.14-1585804222598 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 81ms
2020-04-02 05:10:24,261 [Thread-1467] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-371671733-172.17.0.14-1585804222598 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 92ms
2020-04-02 05:10:24,261 [Thread-1416] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-371671733-172.17.0.14-1585804222598: 92ms
2020-04-02 05:10:24,265 [Thread-1481] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:10:24,265 [Thread-1481] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-371671733-172.17.0.14-1585804222598/current/replicas doesn't exist 
2020-04-02 05:10:24,265 [Thread-1482] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:10:24,266 [Thread-1482] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-371671733-172.17.0.14-1585804222598/current/replicas doesn't exist 
2020-04-02 05:10:24,266 [Thread-1481] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 1ms
2020-04-02 05:10:24,266 [Thread-1482] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 0ms
2020-04-02 05:10:24,266 [Thread-1416] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-371671733-172.17.0.14-1585804222598: 4ms
2020-04-02 05:10:24,266 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:10:24,267 [Thread-1416] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:48 AM with interval of 21600000ms
2020-04-02 05:10:24,266 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:10:24,267 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-51ff9be9-01b1-46f0-bad0-adba582f1208): finished scanning block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,271 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 08b7258b-a01a-4143-b75b-25e5e0b0f184) service to localhost/127.0.0.1:43680 beginning handshake with NN
2020-04-02 05:10:24,271 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-f9117091-6dc7-4177-8fa4-a57c9232310e): finished scanning block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,271 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-51ff9be9-01b1-46f0-bad0-adba582f1208): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:10:24,272 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-f9117091-6dc7-4177-8fa4-a57c9232310e): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-04-02 05:10:24,272 [IPC Server handler 6 on 43680] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41426, datanodeUuid=08b7258b-a01a-4143-b75b-25e5e0b0f184, infoPort=38075, infoSecurePort=0, ipcPort=39048, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598) storage 08b7258b-a01a-4143-b75b-25e5e0b0f184
2020-04-02 05:10:24,272 [IPC Server handler 6 on 43680] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41426
2020-04-02 05:10:24,273 [IPC Server handler 6 on 43680] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 08b7258b-a01a-4143-b75b-25e5e0b0f184 (127.0.0.1:41426).
2020-04-02 05:10:24,273 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 08b7258b-a01a-4143-b75b-25e5e0b0f184) service to localhost/127.0.0.1:43680 successfully registered with NN
2020-04-02 05:10:24,273 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:43680 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:24,281 [IPC Server handler 7 on 43680] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f9117091-6dc7-4177-8fa4-a57c9232310e for DN 127.0.0.1:41426
2020-04-02 05:10:24,281 [IPC Server handler 7 on 43680] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-51ff9be9-01b1-46f0-bad0-adba582f1208 for DN 127.0.0.1:41426
2020-04-02 05:10:24,282 [IPC Server handler 8 on 43680] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:41426, datanodeUuid=08b7258b-a01a-4143-b75b-25e5e0b0f184, infoPort=38075, infoSecurePort=0, ipcPort=39048, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), reports.length=2
2020-04-02 05:10:24,282 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa5936d5a781dbd19: Processing first storage report for DS-51ff9be9-01b1-46f0-bad0-adba582f1208 from datanode 08b7258b-a01a-4143-b75b-25e5e0b0f184
2020-04-02 05:10:24,282 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa5936d5a781dbd19: from storage DS-51ff9be9-01b1-46f0-bad0-adba582f1208 node DatanodeRegistration(127.0.0.1:41426, datanodeUuid=08b7258b-a01a-4143-b75b-25e5e0b0f184, infoPort=38075, infoSecurePort=0, ipcPort=39048, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:24,282 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa5936d5a781dbd19: Processing first storage report for DS-f9117091-6dc7-4177-8fa4-a57c9232310e from datanode 08b7258b-a01a-4143-b75b-25e5e0b0f184
2020-04-02 05:10:24,282 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa5936d5a781dbd19: from storage DS-f9117091-6dc7-4177-8fa4-a57c9232310e node DatanodeRegistration(127.0.0.1:41426, datanodeUuid=08b7258b-a01a-4143-b75b-25e5e0b0f184, infoPort=38075, infoSecurePort=0, ipcPort=39048, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:10:24,283 [IPC Server handler 8 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xa5936d5a781dbd19
2020-04-02 05:10:24,283 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xa5936d5a781dbd19,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:24,283 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,288 [Thread-1172] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41443
2020-04-02 05:10:24,288 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@d9570a5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:24,288 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:10:24,288 [Thread-1172] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:10:24,288 [Thread-1172] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:24,289 [Socket Reader #1 for port 45201] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45201
2020-04-02 05:10:24,311 [Thread-1172] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:45201
2020-04-02 05:10:24,314 [Thread-1480] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-371671733-172.17.0.14-1585804222598 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 66ms
2020-04-02 05:10:24,318 [Thread-1479] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-371671733-172.17.0.14-1585804222598 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 71ms
2020-04-02 05:10:24,374 [Thread-1455] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-371671733-172.17.0.14-1585804222598: 128ms
2020-04-02 05:10:24,374 [Thread-1494] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:10:24,374 [Thread-1172] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:10:24,374 [Thread-1494] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-371671733-172.17.0.14-1585804222598/current/replicas doesn't exist 
2020-04-02 05:10:24,375 [Thread-1495] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:10:24,375 [Thread-1172] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:10:24,375 [Thread-1495] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-371671733-172.17.0.14-1585804222598/current/replicas doesn't exist 
2020-04-02 05:10:24,375 [Thread-1494] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 1ms
2020-04-02 05:10:24,378 [Thread-1495] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 3ms
2020-04-02 05:10:24,378 [Thread-1455] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-371671733-172.17.0.14-1585804222598: 4ms
2020-04-02 05:10:24,378 [Thread-1496] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43680 starting to offer service
2020-04-02 05:10:24,383 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:10:24,383 [Thread-1496] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43680
2020-04-02 05:10:24,383 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:10:24,384 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-447584f6-17aa-4d49-9afb-79bedb14b998): finished scanning block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,384 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-725ad767-aa1e-4967-8c34-f66e9ab24ac1): finished scanning block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,388 [Thread-1496] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:10:24,389 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-447584f6-17aa-4d49-9afb-79bedb14b998): no suitable block pools found to scan.  Waiting 1814399989 ms.
2020-04-02 05:10:24,389 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-725ad767-aa1e-4967-8c34-f66e9ab24ac1): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-04-02 05:10:24,389 [Thread-1496] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:24,390 [Thread-1455] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:05 AM with interval of 21600000ms
2020-04-02 05:10:24,390 [Thread-1496] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 1458863077. Formatting...
2020-04-02 05:10:24,390 [Thread-1496] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-104fd78f-8716-4b94-878b-716023c6b5f0 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-04-02 05:10:24,393 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:24,393 [Thread-1496] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:24,393 [Thread-1496] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 1458863077. Formatting...
2020-04-02 05:10:24,393 [Thread-1496] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-16d7ca75-c4fc-4d94-853e-e985eec7fbdd for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-04-02 05:10:24,408 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 3b0d66d2-d295-4441-b698-cc5b0796233f) service to localhost/127.0.0.1:43680 beginning handshake with NN
2020-04-02 05:10:24,409 [IPC Server listener on 45201] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45201: starting
2020-04-02 05:10:24,418 [IPC Server handler 0 on 43680] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37472, datanodeUuid=3b0d66d2-d295-4441-b698-cc5b0796233f, infoPort=32949, infoSecurePort=0, ipcPort=33165, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598) storage 3b0d66d2-d295-4441-b698-cc5b0796233f
2020-04-02 05:10:24,418 [Thread-1172] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 45201 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:24,418 [IPC Server handler 0 on 43680] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37472
2020-04-02 05:10:24,418 [IPC Server handler 0 on 43680] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3b0d66d2-d295-4441-b698-cc5b0796233f (127.0.0.1:37472).
2020-04-02 05:10:24,419 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 3b0d66d2-d295-4441-b698-cc5b0796233f) service to localhost/127.0.0.1:43680 successfully registered with NN
2020-04-02 05:10:24,419 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:43680 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:24,423 [IPC Server handler 1 on 43680] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-725ad767-aa1e-4967-8c34-f66e9ab24ac1 for DN 127.0.0.1:37472
2020-04-02 05:10:24,428 [IPC Server handler 1 on 43680] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-447584f6-17aa-4d49-9afb-79bedb14b998 for DN 127.0.0.1:37472
2020-04-02 05:10:24,430 [IPC Server handler 3 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:10:24,430 [IPC Server handler 2 on 43680] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:37472, datanodeUuid=3b0d66d2-d295-4441-b698-cc5b0796233f, infoPort=32949, infoSecurePort=0, ipcPort=33165, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), reports.length=2
2020-04-02 05:10:24,430 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xda1b55881bfba87b: Processing first storage report for DS-447584f6-17aa-4d49-9afb-79bedb14b998 from datanode 3b0d66d2-d295-4441-b698-cc5b0796233f
2020-04-02 05:10:24,431 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xda1b55881bfba87b: from storage DS-447584f6-17aa-4d49-9afb-79bedb14b998 node DatanodeRegistration(127.0.0.1:37472, datanodeUuid=3b0d66d2-d295-4441-b698-cc5b0796233f, infoPort=32949, infoSecurePort=0, ipcPort=33165, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:10:24,431 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:10:24,431 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:10:24,431 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xda1b55881bfba87b: Processing first storage report for DS-725ad767-aa1e-4967-8c34-f66e9ab24ac1 from datanode 3b0d66d2-d295-4441-b698-cc5b0796233f
2020-04-02 05:10:24,431 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xda1b55881bfba87b: from storage DS-725ad767-aa1e-4967-8c34-f66e9ab24ac1 node DatanodeRegistration(127.0.0.1:37472, datanodeUuid=3b0d66d2-d295-4441-b698-cc5b0796233f, infoPort=32949, infoSecurePort=0, ipcPort=33165, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:24,431 [IPC Server handler 2 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xda1b55881bfba87b
2020-04-02 05:10:24,432 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xda1b55881bfba87b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:24,432 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,432 [Thread-1496] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,433 [Thread-1496] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,433 [Thread-1496] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-371671733-172.17.0.14-1585804222598 is not formatted. Formatting ...
2020-04-02 05:10:24,433 [Thread-1496] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-371671733-172.17.0.14-1585804222598 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-371671733-172.17.0.14-1585804222598/current
2020-04-02 05:10:24,445 [Thread-1496] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,445 [Thread-1496] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,445 [Thread-1496] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-371671733-172.17.0.14-1585804222598 is not formatted. Formatting ...
2020-04-02 05:10:24,445 [Thread-1496] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-371671733-172.17.0.14-1585804222598 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-371671733-172.17.0.14-1585804222598/current
2020-04-02 05:10:24,447 [Thread-1496] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1458863077;bpid=BP-371671733-172.17.0.14-1585804222598;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1458863077;c=1585804222598;bpid=BP-371671733-172.17.0.14-1585804222598;dnuuid=null
2020-04-02 05:10:24,448 [Thread-1496] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 5b6058c3-0ef8-40d2-8f41-c8d902696834
2020-04-02 05:10:24,449 [Thread-1496] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-104fd78f-8716-4b94-878b-716023c6b5f0
2020-04-02 05:10:24,449 [Thread-1496] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-04-02 05:10:24,454 [Thread-1496] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-16d7ca75-c4fc-4d94-853e-e985eec7fbdd
2020-04-02 05:10:24,454 [Thread-1496] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-04-02 05:10:24,456 [Thread-1496] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:10:24,457 [Thread-1496] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:10:24,458 [Thread-1496] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:10:24,458 [Thread-1496] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:10:24,458 [Thread-1496] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:10:24,461 [Thread-1496] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,467 [Thread-1513] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:10:24,468 [Thread-1514] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:10:24,524 [Thread-1514] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-371671733-172.17.0.14-1585804222598 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 56ms
2020-04-02 05:10:24,527 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:24,528 [Thread-1513] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-371671733-172.17.0.14-1585804222598 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 60ms
2020-04-02 05:10:24,528 [Thread-1496] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-371671733-172.17.0.14-1585804222598: 67ms
2020-04-02 05:10:24,529 [Thread-1517] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:10:24,529 [Thread-1518] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:10:24,529 [Thread-1517] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-371671733-172.17.0.14-1585804222598/current/replicas doesn't exist 
2020-04-02 05:10:24,529 [Thread-1518] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-371671733-172.17.0.14-1585804222598/current/replicas doesn't exist 
2020-04-02 05:10:24,544 [Thread-1518] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 15ms
2020-04-02 05:10:24,547 [IPC Server handler 5 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:10:24,547 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:10:24,548 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:10:24,551 [Thread-1517] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 22ms
2020-04-02 05:10:24,551 [Thread-1496] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-371671733-172.17.0.14-1585804222598: 23ms
2020-04-02 05:10:24,552 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:10:24,552 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-371671733-172.17.0.14-1585804222598 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:10:24,552 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-104fd78f-8716-4b94-878b-716023c6b5f0): finished scanning block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,552 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-16d7ca75-c4fc-4d94-853e-e985eec7fbdd): finished scanning block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,553 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-104fd78f-8716-4b94-878b-716023c6b5f0): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:10:24,553 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-16d7ca75-c4fc-4d94-853e-e985eec7fbdd): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:10:24,555 [Thread-1496] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:03 AM with interval of 21600000ms
2020-04-02 05:10:24,557 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 5b6058c3-0ef8-40d2-8f41-c8d902696834) service to localhost/127.0.0.1:43680 beginning handshake with NN
2020-04-02 05:10:24,558 [IPC Server handler 4 on 43680] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43395, datanodeUuid=5b6058c3-0ef8-40d2-8f41-c8d902696834, infoPort=41443, infoSecurePort=0, ipcPort=45201, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598) storage 5b6058c3-0ef8-40d2-8f41-c8d902696834
2020-04-02 05:10:24,558 [IPC Server handler 4 on 43680] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43395
2020-04-02 05:10:24,559 [IPC Server handler 4 on 43680] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5b6058c3-0ef8-40d2-8f41-c8d902696834 (127.0.0.1:43395).
2020-04-02 05:10:24,559 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 5b6058c3-0ef8-40d2-8f41-c8d902696834) service to localhost/127.0.0.1:43680 successfully registered with NN
2020-04-02 05:10:24,559 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:43680 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:24,563 [IPC Server handler 6 on 43680] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-104fd78f-8716-4b94-878b-716023c6b5f0 for DN 127.0.0.1:43395
2020-04-02 05:10:24,564 [IPC Server handler 6 on 43680] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-16d7ca75-c4fc-4d94-853e-e985eec7fbdd for DN 127.0.0.1:43395
2020-04-02 05:10:24,565 [IPC Server handler 7 on 43680] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:43395, datanodeUuid=5b6058c3-0ef8-40d2-8f41-c8d902696834, infoPort=41443, infoSecurePort=0, ipcPort=45201, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), reports.length=2
2020-04-02 05:10:24,565 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x7ef8f887ff918052: Processing first storage report for DS-16d7ca75-c4fc-4d94-853e-e985eec7fbdd from datanode 5b6058c3-0ef8-40d2-8f41-c8d902696834
2020-04-02 05:10:24,565 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x7ef8f887ff918052: from storage DS-16d7ca75-c4fc-4d94-853e-e985eec7fbdd node DatanodeRegistration(127.0.0.1:43395, datanodeUuid=5b6058c3-0ef8-40d2-8f41-c8d902696834, infoPort=41443, infoSecurePort=0, ipcPort=45201, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:24,565 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x7ef8f887ff918052: Processing first storage report for DS-104fd78f-8716-4b94-878b-716023c6b5f0 from datanode 5b6058c3-0ef8-40d2-8f41-c8d902696834
2020-04-02 05:10:24,565 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x7ef8f887ff918052: from storage DS-104fd78f-8716-4b94-878b-716023c6b5f0 node DatanodeRegistration(127.0.0.1:43395, datanodeUuid=5b6058c3-0ef8-40d2-8f41-c8d902696834, infoPort=41443, infoSecurePort=0, ipcPort=45201, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:24,565 [IPC Server handler 7 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x7ef8f887ff918052
2020-04-02 05:10:24,566 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x7ef8f887ff918052,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:24,566 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:24,649 [IPC Server handler 8 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:10:24,649 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:10:24,653 [IPC Server handler 9 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-04-02 05:10:24,660 [IPC Server handler 0 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:10:24,662 [Thread-1172] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithDNFailure(160)) - testReadWithDNFailure: file = /dnFailure_3_smallFile, fileSize = 25165701, dnFailureNum = 3
2020-04-02 05:10:24,712 [IPC Server handler 1 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dnFailure_3_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:24,713 [IPC Server handler 3 on 43680] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /dnFailure_3_smallFile for DFSClient_NONMAPREDUCE_-1674974693_5940 at 127.0.0.1
2020-04-02 05:10:24,713 [IPC Server handler 3 on 43680] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/dnFailure_3_smallFile, holder=DFSClient_NONMAPREDUCE_-1674974693_5940, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:10:24,714 [IPC Server handler 3 on 43680] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: dnFailure_3_smallFile is added
2020-04-02 05:10:24,714 [IPC Server handler 3 on 43680] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /dnFailure_3_smallFile inode 16386 DFSClient_NONMAPREDUCE_-1674974693_5940
2020-04-02 05:10:24,714 [IPC Server handler 3 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/dnFailure_3_smallFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:10:24,734 [IPC Server handler 2 on 43680] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /dnFailure_3_smallFile  inodeId 16386 for DFSClient_NONMAPREDUCE_-1674974693_5940
2020-04-02 05:10:24,735 [IPC Server handler 2 on 43680] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:10:24,737 [IPC Server handler 2 on 43680] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /dnFailure_3_smallFile with blk_-9223372036854775792_1001 block is added to the in-memory file system
2020-04-02 05:10:24,737 [IPC Server handler 2 on 43680] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:44235, 127.0.0.1:43395, 127.0.0.1:41426, 127.0.0.1:37472, 127.0.0.1:34608, 127.0.0.1:33892, 127.0.0.1:42705, 127.0.0.1:36035, 127.0.0.1:36096 for /dnFailure_3_smallFile
2020-04-02 05:10:24,737 [IPC Server handler 2 on 43680] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /dnFailure_3_smallFile with new block blk_-9223372036854775792_1001, current total block count is 1
2020-04-02 05:10:24,746 [DataXceiver for client DFSClient_NONMAPREDUCE_-1674974693_5940 at /127.0.0.1:44564 [Receiving block BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775792_1001 src: /127.0.0.1:44564 dest: /127.0.0.1:44235
2020-04-02 05:10:24,759 [DataXceiver for client DFSClient_NONMAPREDUCE_-1674974693_5940 at /127.0.0.1:48260 [Receiving block BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775791_1001 src: /127.0.0.1:48260 dest: /127.0.0.1:43395
2020-04-02 05:10:24,787 [DataXceiver for client DFSClient_NONMAPREDUCE_-1674974693_5940 at /127.0.0.1:34840 [Receiving block BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775790_1001 src: /127.0.0.1:34840 dest: /127.0.0.1:41426
2020-04-02 05:10:24,800 [DataXceiver for client DFSClient_NONMAPREDUCE_-1674974693_5940 at /127.0.0.1:48486 [Receiving block BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775789_1001 src: /127.0.0.1:48486 dest: /127.0.0.1:37472
2020-04-02 05:10:24,811 [DataXceiver for client DFSClient_NONMAPREDUCE_-1674974693_5940 at /127.0.0.1:54856 [Receiving block BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775788_1001 src: /127.0.0.1:54856 dest: /127.0.0.1:34608
2020-04-02 05:10:24,822 [DataXceiver for client DFSClient_NONMAPREDUCE_-1674974693_5940 at /127.0.0.1:35078 [Receiving block BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775787_1001 src: /127.0.0.1:35078 dest: /127.0.0.1:33892
2020-04-02 05:10:24,884 [DataXceiver for client DFSClient_NONMAPREDUCE_-1674974693_5940 at /127.0.0.1:42834 [Receiving block BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775786_1001 src: /127.0.0.1:42834 dest: /127.0.0.1:42705
2020-04-02 05:10:24,904 [DataXceiver for client DFSClient_NONMAPREDUCE_-1674974693_5940 at /127.0.0.1:49210 [Receiving block BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775785_1001 src: /127.0.0.1:49210 dest: /127.0.0.1:36035
2020-04-02 05:10:24,919 [DataXceiver for client DFSClient_NONMAPREDUCE_-1674974693_5940 at /127.0.0.1:52650 [Receiving block BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775784_1001 src: /127.0.0.1:52650 dest: /127.0.0.1:36096
2020-04-02 05:10:25,135 [PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44564, dest: /127.0.0.1:44235, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1674974693_5940, offset: 0, srvID: 214c05a0-4d79-4137-ab66-e06c6cc0851e, blockid: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775792_1001, duration(ns): 374207919
2020-04-02 05:10:25,135 [PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:25,136 [IPC Server handler 4 on 43680] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:44235, datanodeUuid=214c05a0-4d79-4137-ab66-e06c6cc0851e, infoPort=42026, infoSecurePort=0, ipcPort=39043, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598) 1 blocks.
2020-04-02 05:10:25,140 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775792_1001 on 127.0.0.1:44235 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:25,140 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:25,144 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:44235 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:10:25,144 [PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48260, dest: /127.0.0.1:43395, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1674974693_5940, offset: 0, srvID: 5b6058c3-0ef8-40d2-8f41-c8d902696834, blockid: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775791_1001, duration(ns): 367854652
2020-04-02 05:10:25,144 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775792_1001 is received from 127.0.0.1:44235
2020-04-02 05:10:25,144 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:44235 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:25,144 [PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:25,144 [IPC Server handler 6 on 43680] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:43395, datanodeUuid=5b6058c3-0ef8-40d2-8f41-c8d902696834, infoPort=41443, infoSecurePort=0, ipcPort=45201, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598) 1 blocks.
2020-04-02 05:10:25,145 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775791_1001 on 127.0.0.1:43395 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:25,145 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:25,146 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:43395 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:10:25,146 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775791_1001 is received from 127.0.0.1:43395
2020-04-02 05:10:25,146 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:43395 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:25,146 [PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34840, dest: /127.0.0.1:41426, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1674974693_5940, offset: 0, srvID: 08b7258b-a01a-4143-b75b-25e5e0b0f184, blockid: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775790_1001, duration(ns): 357425791
2020-04-02 05:10:25,146 [PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:25,147 [IPC Server handler 7 on 43680] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41426, datanodeUuid=08b7258b-a01a-4143-b75b-25e5e0b0f184, infoPort=38075, infoSecurePort=0, ipcPort=39048, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598) 1 blocks.
2020-04-02 05:10:25,148 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775790_1001 on 127.0.0.1:41426 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:25,148 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:25,148 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:41426 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:10:25,148 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775790_1001 is received from 127.0.0.1:41426
2020-04-02 05:10:25,148 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41426 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:25,148 [PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48486, dest: /127.0.0.1:37472, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1674974693_5940, offset: 0, srvID: 3b0d66d2-d295-4441-b698-cc5b0796233f, blockid: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775789_1001, duration(ns): 343514641
2020-04-02 05:10:25,149 [PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:25,149 [IPC Server handler 8 on 43680] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37472, datanodeUuid=3b0d66d2-d295-4441-b698-cc5b0796233f, infoPort=32949, infoSecurePort=0, ipcPort=33165, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598) 1 blocks.
2020-04-02 05:10:25,150 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775789_1001 on 127.0.0.1:37472 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:25,150 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:25,150 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37472 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:10:25,150 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775789_1001 is received from 127.0.0.1:37472
2020-04-02 05:10:25,150 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37472 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:25,151 [PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54856, dest: /127.0.0.1:34608, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1674974693_5940, offset: 0, srvID: 04baa337-8df0-4202-93da-4b177174abb6, blockid: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775788_1001, duration(ns): 337561708
2020-04-02 05:10:25,151 [PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:25,152 [IPC Server handler 9 on 43680] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34608, datanodeUuid=04baa337-8df0-4202-93da-4b177174abb6, infoPort=34402, infoSecurePort=0, ipcPort=42140, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598) 1 blocks.
2020-04-02 05:10:25,152 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:34608 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:25,152 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:25,152 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34608 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:10:25,153 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775788_1001 is received from 127.0.0.1:34608
2020-04-02 05:10:25,153 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34608 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:25,153 [PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35078, dest: /127.0.0.1:33892, bytes: 4194181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1674974693_5940, offset: 0, srvID: 922de900-ed97-41ff-b822-20bb82158b34, blockid: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775787_1001, duration(ns): 327831008
2020-04-02 05:10:25,153 [PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:25,153 [IPC Server handler 0 on 43680] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33892, datanodeUuid=922de900-ed97-41ff-b822-20bb82158b34, infoPort=45414, infoSecurePort=0, ipcPort=39819, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598) 1 blocks.
2020-04-02 05:10:25,156 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775787_1001 on 127.0.0.1:33892 size 4194181 replicaState = FINALIZED
2020-04-02 05:10:25,156 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:25,156 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33892 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:10:25,156 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775787_1001 is received from 127.0.0.1:33892
2020-04-02 05:10:25,156 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33892 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:25,156 [PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42834, dest: /127.0.0.1:42705, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1674974693_5940, offset: 0, srvID: b9473e7d-eaa8-4cc2-95dd-6ef0e032a218, blockid: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775786_1001, duration(ns): 268878601
2020-04-02 05:10:25,156 [PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:25,158 [IPC Server handler 1 on 43680] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:42705, datanodeUuid=b9473e7d-eaa8-4cc2-95dd-6ef0e032a218, infoPort=36323, infoSecurePort=0, ipcPort=36904, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598) 1 blocks.
2020-04-02 05:10:25,158 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775786_1001 on 127.0.0.1:42705 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:25,158 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:25,159 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:42705 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:10:25,159 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775786_1001 is received from 127.0.0.1:42705
2020-04-02 05:10:25,159 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:42705 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:25,159 [PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49210, dest: /127.0.0.1:36035, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1674974693_5940, offset: 0, srvID: f52e3635-95c4-4878-9344-a0dc0c102c00, blockid: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775785_1001, duration(ns): 251513636
2020-04-02 05:10:25,159 [PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:25,159 [IPC Server handler 3 on 43680] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:36035, datanodeUuid=f52e3635-95c4-4878-9344-a0dc0c102c00, infoPort=43021, infoSecurePort=0, ipcPort=40151, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598) 1 blocks.
2020-04-02 05:10:25,165 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775785_1001 on 127.0.0.1:36035 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:25,165 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:25,165 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:36035 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:10:25,165 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775785_1001 is received from 127.0.0.1:36035
2020-04-02 05:10:25,165 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:36035 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:25,165 [PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52650, dest: /127.0.0.1:36096, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1674974693_5940, offset: 0, srvID: 8d396def-1786-4275-b49c-2ee91dd52fd8, blockid: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775784_1001, duration(ns): 243256000
2020-04-02 05:10:25,166 [PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:25,167 [IPC Server handler 2 on 43680] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:36096, datanodeUuid=8d396def-1786-4275-b49c-2ee91dd52fd8, infoPort=45461, infoSecurePort=0, ipcPort=33969, storageInfo=lv=-57;cid=testClusterID;nsid=1458863077;c=1585804222598) 1 blocks.
2020-04-02 05:10:25,174 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775784_1001 on 127.0.0.1:36096 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:25,177 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:25,179 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:36096 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:10:25,179 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775784_1001 is received from 127.0.0.1:36096
2020-04-02 05:10:25,179 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:36096 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:25,179 [IPC Server handler 5 on 43680] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /dnFailure_3_smallFile for DFSClient_NONMAPREDUCE_-1674974693_5940
2020-04-02 05:10:25,183 [IPC Server handler 5 on 43680] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /dnFailure_3_smallFile with 1 blocks is persisted to the file system
2020-04-02 05:10:25,184 [IPC Server handler 5 on 43680] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /dnFailure_3_smallFile is closed by DFSClient_NONMAPREDUCE_-1674974693_5940
2020-04-02 05:10:25,186 [IPC Server handler 4 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:10:25,187 [IPC Server handler 6 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:25,187 [IPC Server handler 6 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:25,189 [Thread-1172] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:waitBlockGroupsReported(290)) - All blockGroups of file /dnFailure_3_smallFile verified to have all internalBlocks.
2020-04-02 05:10:25,190 [IPC Server handler 7 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:25,190 [IPC Server handler 7 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:25,191 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 39043 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:25,192 [Thread-1172] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:25,192 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@27cb07f7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:25,194 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-0788a838-b00d-4ed5-8779-e005bcd7dea3) exiting.
2020-04-02 05:10:25,194 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-d07cda12-37b0-4b92-8197-783f0f0639e7) exiting.
2020-04-02 05:10:25,208 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6a243a35{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:25,209 [Thread-1172] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@74836950{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:25,209 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@683ba11a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:25,209 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2729f69d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:25,210 [Thread-1172] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39043
2020-04-02 05:10:25,213 [IPC Server listener on 39043] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39043
2020-04-02 05:10:25,213 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:25,213 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:25,215 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 214c05a0-4d79-4137-ab66-e06c6cc0851e) service to localhost/127.0.0.1:43680
2020-04-02 05:10:25,215 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 214c05a0-4d79-4137-ab66-e06c6cc0851e)
2020-04-02 05:10:25,215 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:25,225 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-371671733-172.17.0.14-1585804222598] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:25,232 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-371671733-172.17.0.14-1585804222598] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:25,236 [Thread-1172] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:25,236 [Thread-1172] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:25,238 [Thread-1172] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:25,238 [Thread-1172] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:25,241 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:25,241 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 45201 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:25,241 [Thread-1172] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:25,242 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@316f0552] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:25,247 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-104fd78f-8716-4b94-878b-716023c6b5f0) exiting.
2020-04-02 05:10:25,247 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-16d7ca75-c4fc-4d94-853e-e985eec7fbdd) exiting.
2020-04-02 05:10:25,262 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@18e87a5e{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:25,263 [Thread-1172] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@197f5ad0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:25,263 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1aca3375{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:25,263 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2b53acbb{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:25,264 [Thread-1172] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45201
2020-04-02 05:10:25,264 [IPC Server listener on 45201] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45201
2020-04-02 05:10:25,270 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:25,270 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:25,272 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 5b6058c3-0ef8-40d2-8f41-c8d902696834) service to localhost/127.0.0.1:43680
2020-04-02 05:10:25,272 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 5b6058c3-0ef8-40d2-8f41-c8d902696834)
2020-04-02 05:10:25,273 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:25,284 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-371671733-172.17.0.14-1585804222598] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:25,303 [Thread-1172] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:25,303 [Thread-1172] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:25,308 [Thread-1172] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:25,308 [Thread-1172] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:25,309 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-371671733-172.17.0.14-1585804222598] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:25,311 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:25,312 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 39048 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:25,312 [Thread-1172] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:25,312 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6a8fcecf] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:25,313 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-f9117091-6dc7-4177-8fa4-a57c9232310e) exiting.
2020-04-02 05:10:25,313 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-51ff9be9-01b1-46f0-bad0-adba582f1208) exiting.
2020-04-02 05:10:25,325 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2d9bfe07{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:25,325 [Thread-1172] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@75e647c5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:25,325 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@787a031{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:25,326 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1d8b029a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:25,326 [Thread-1172] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39048
2020-04-02 05:10:25,328 [IPC Server listener on 39048] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39048
2020-04-02 05:10:25,328 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:25,329 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:25,332 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 08b7258b-a01a-4143-b75b-25e5e0b0f184) service to localhost/127.0.0.1:43680
2020-04-02 05:10:25,332 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 08b7258b-a01a-4143-b75b-25e5e0b0f184)
2020-04-02 05:10:25,334 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:25,345 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-371671733-172.17.0.14-1585804222598] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:25,353 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-371671733-172.17.0.14-1585804222598] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:25,353 [Thread-1172] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:25,353 [Thread-1172] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:25,353 [Thread-1172] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:25,353 [Thread-1172] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:25,358 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:25,358 [Thread-1172] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /dnFailure_3_smallFile
2020-04-02 05:10:25,363 [Thread-1172] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /dnFailure_3_smallFile
2020-04-02 05:10:25,364 [IPC Server handler 8 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dnFailure_3_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:25,365 [Thread-1172] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /dnFailure_3_smallFile
2020-04-02 05:10:25,366 [IPC Server handler 9 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:10:25,367 [IPC Server handler 0 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:25,367 [IPC Server handler 0 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:25,374 [Thread-1172] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:25,374 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:44235 for blockBP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:25,375 [IPC Server handler 1 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:25,375 [IPC Server handler 1 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:25,377 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:44235,DS-d07cda12-37b0-4b92-8197-783f0f0639e7,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:25,377 [Thread-1172] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:25,378 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:43395 for blockBP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775791_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:25,379 [IPC Server handler 3 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:25,379 [IPC Server handler 3 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:25,381 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:43395,DS-104fd78f-8716-4b94-878b-716023c6b5f0,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:25,381 [Thread-1172] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:25,381 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:41426 for blockBP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775790_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:25,382 [IPC Server handler 2 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:25,383 [IPC Server handler 2 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:25,384 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:41426,DS-f9117091-6dc7-4177-8fa4-a57c9232310e,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:25,961 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:27,528 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:28,968 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:30,529 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:31,969 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:33,529 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:34,969 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:36,529 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:37,969 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:39,100 [Thread-1172] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /dnFailure_3_smallFile
2020-04-02 05:10:39,106 [IPC Server handler 0 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:39,109 [IPC Server handler 0 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:39,119 [Thread-1172] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:39,120 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:44235 for blockBP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:39,121 [IPC Server handler 1 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:39,123 [IPC Server handler 1 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:39,124 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:44235,DS-d07cda12-37b0-4b92-8197-783f0f0639e7,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:39,124 [Thread-1172] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:39,125 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:43395 for blockBP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775791_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:39,125 [IPC Server handler 2 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:39,125 [IPC Server handler 2 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:39,126 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:43395,DS-104fd78f-8716-4b94-878b-716023c6b5f0,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:39,127 [Thread-1172] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:39,127 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:41426 for blockBP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775790_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:39,128 [IPC Server handler 3 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:39,128 [IPC Server handler 3 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:39,129 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:41426,DS-f9117091-6dc7-4177-8fa4-a57c9232310e,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:39,530 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:40,992 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:42,530 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:42,578 [Thread-1172] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /dnFailure_3_smallFile
2020-04-02 05:10:42,582 [IPC Server handler 8 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:42,583 [IPC Server handler 8 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:42,588 [Thread-1172] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:42,589 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:44235 for blockBP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:42,589 [IPC Server handler 9 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:42,590 [IPC Server handler 9 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:42,591 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:44235,DS-d07cda12-37b0-4b92-8197-783f0f0639e7,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:42,592 [Thread-1172] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:42,596 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:43395 for blockBP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775791_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:42,597 [IPC Server handler 0 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:42,597 [IPC Server handler 0 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:42,599 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:43395,DS-104fd78f-8716-4b94-878b-716023c6b5f0,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:42,599 [Thread-1172] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:42,600 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:41426 for blockBP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775790_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:42,600 [IPC Server handler 1 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:42,601 [IPC Server handler 1 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:42,602 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:41426,DS-f9117091-6dc7-4177-8fa4-a57c9232310e,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:43,992 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:45,530 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:46,052 [Thread-1172] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /dnFailure_3_smallFile
2020-04-02 05:10:46,052 [IPC Server handler 5 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:46,053 [IPC Server handler 5 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:46,057 [Thread-1172] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:46,058 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:44235 for blockBP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:46,058 [IPC Server handler 4 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:46,059 [IPC Server handler 4 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:46,060 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:44235,DS-d07cda12-37b0-4b92-8197-783f0f0639e7,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:46,060 [Thread-1172] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:46,060 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:43395 for blockBP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775791_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:46,061 [IPC Server handler 6 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:46,061 [IPC Server handler 6 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:46,062 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:43395,DS-104fd78f-8716-4b94-878b-716023c6b5f0,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:46,063 [Thread-1172] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:46,063 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:41426 for blockBP-371671733-172.17.0.14-1585804222598:blk_-9223372036854775790_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:46,063 [IPC Server handler 7 on 43680] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:10:46,064 [IPC Server handler 7 on 43680] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_smallFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:46,065 [Thread-1172] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:41426,DS-f9117091-6dc7-4177-8fa4-a57c9232310e,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:46,992 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:48,531 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:49,993 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:51,321 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:10:51,321 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 8
2020-04-02 05:10:51,321 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 45201 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:51,321 [Thread-1172] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(340)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-04-02 05:10:51,322 [Thread-1172] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45201
2020-04-02 05:10:51,322 [Thread-1172] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-5b6058c3-0ef8-40d2-8f41-c8d902696834
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-5b6058c3-0ef8-40d2-8f41-c8d902696834
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2146)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2048)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2038)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2017)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1991)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1984)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.tearDownCluster(ReadStripedFileWithDecodingHelper.java:97)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.tearDown(TestReadStripedFileWithDNFailure.java:64)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:105)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:51,323 [Thread-1172] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(190)) - AsyncDiskService has already shut down.
2020-04-02 05:10:51,323 [Thread-1172] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(174)) - AsyncLazyPersistService has already shut down.
2020-04-02 05:10:51,323 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:51,323 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 7
2020-04-02 05:10:51,323 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33165 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:51,323 [Thread-1172] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:51,323 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@51bd0e0a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:51,324 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-725ad767-aa1e-4967-8c34-f66e9ab24ac1) exiting.
2020-04-02 05:10:51,324 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-447584f6-17aa-4d49-9afb-79bedb14b998) exiting.
2020-04-02 05:10:51,343 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@79f3e1cb{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:51,344 [Thread-1172] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@41c25538{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:51,345 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@46a03aa0{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:51,345 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@52e6f3de{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:51,347 [Thread-1172] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33165
2020-04-02 05:10:51,352 [IPC Server listener on 33165] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33165
2020-04-02 05:10:51,352 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:51,352 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:51,353 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 3b0d66d2-d295-4441-b698-cc5b0796233f) service to localhost/127.0.0.1:43680
2020-04-02 05:10:51,355 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 3b0d66d2-d295-4441-b698-cc5b0796233f)
2020-04-02 05:10:51,356 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:51,368 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-371671733-172.17.0.14-1585804222598] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:51,376 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-371671733-172.17.0.14-1585804222598] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:51,377 [Thread-1172] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:51,377 [Thread-1172] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:51,377 [Thread-1172] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:51,377 [Thread-1172] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:51,381 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:51,381 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 6
2020-04-02 05:10:51,381 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 39048 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:51,381 [Thread-1172] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(340)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-04-02 05:10:51,382 [Thread-1172] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39048
2020-04-02 05:10:51,382 [Thread-1172] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-08b7258b-a01a-4143-b75b-25e5e0b0f184
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-08b7258b-a01a-4143-b75b-25e5e0b0f184
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2146)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2048)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2038)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2017)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1991)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1984)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.tearDownCluster(ReadStripedFileWithDecodingHelper.java:97)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.tearDown(TestReadStripedFileWithDNFailure.java:64)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:105)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:51,383 [Thread-1172] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(190)) - AsyncDiskService has already shut down.
2020-04-02 05:10:51,383 [Thread-1172] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(174)) - AsyncLazyPersistService has already shut down.
2020-04-02 05:10:51,383 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:51,383 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 5
2020-04-02 05:10:51,383 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 39819 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:51,384 [Thread-1172] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:51,384 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1a44d05] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:51,384 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-b2ae87b0-816b-4ad4-9683-21682c26c189) exiting.
2020-04-02 05:10:51,384 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-e5f50d86-b76f-4131-b16c-5367cd79c8ac) exiting.
2020-04-02 05:10:51,403 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@63272552{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:51,404 [Thread-1172] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@21103a39{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:51,404 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4e95246f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:51,405 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@67268f1f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:51,406 [Thread-1172] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39819
2020-04-02 05:10:51,411 [IPC Server listener on 39819] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39819
2020-04-02 05:10:51,412 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:51,412 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:51,413 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 922de900-ed97-41ff-b822-20bb82158b34) service to localhost/127.0.0.1:43680
2020-04-02 05:10:51,414 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 922de900-ed97-41ff-b822-20bb82158b34)
2020-04-02 05:10:51,415 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:51,426 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-371671733-172.17.0.14-1585804222598] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:51,435 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-371671733-172.17.0.14-1585804222598] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:51,435 [Thread-1172] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:51,435 [Thread-1172] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:51,435 [Thread-1172] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:51,435 [Thread-1172] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:51,439 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:51,439 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 4
2020-04-02 05:10:51,439 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 39043 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:51,439 [Thread-1172] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(340)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-04-02 05:10:51,440 [Thread-1172] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39043
2020-04-02 05:10:51,440 [Thread-1172] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-214c05a0-4d79-4137-ab66-e06c6cc0851e
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-214c05a0-4d79-4137-ab66-e06c6cc0851e
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2146)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2048)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2038)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2017)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1991)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1984)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.tearDownCluster(ReadStripedFileWithDecodingHelper.java:97)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.tearDown(TestReadStripedFileWithDNFailure.java:64)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:105)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:51,441 [Thread-1172] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(190)) - AsyncDiskService has already shut down.
2020-04-02 05:10:51,441 [Thread-1172] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(174)) - AsyncLazyPersistService has already shut down.
2020-04-02 05:10:51,441 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:51,441 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 3
2020-04-02 05:10:51,441 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40151 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:51,441 [Thread-1172] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:51,441 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@785d6bea] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:51,442 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-063830f5-af19-402d-9b62-9e637faa8fe6) exiting.
2020-04-02 05:10:51,442 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-27146415-ac5c-4ffe-9b04-744fa668348b) exiting.
2020-04-02 05:10:51,459 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@26485f8{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:51,460 [Thread-1172] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@27c0063f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:51,460 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2d5f2e22{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:51,460 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@500a7e25{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:51,461 [Thread-1172] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40151
2020-04-02 05:10:51,469 [IPC Server listener on 40151] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40151
2020-04-02 05:10:51,469 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:51,469 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:51,469 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid f52e3635-95c4-4878-9344-a0dc0c102c00) service to localhost/127.0.0.1:43680
2020-04-02 05:10:51,471 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid f52e3635-95c4-4878-9344-a0dc0c102c00)
2020-04-02 05:10:51,473 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:51,481 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-371671733-172.17.0.14-1585804222598] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:51,487 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-371671733-172.17.0.14-1585804222598] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:51,487 [Thread-1172] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:51,487 [Thread-1172] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:51,488 [Thread-1172] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:51,488 [Thread-1172] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:51,492 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:51,492 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:10:51,492 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 42140 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:51,493 [Thread-1172] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:51,493 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7480fbd1] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:51,493 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-bcb950f9-3ce2-42ae-a83e-d747b2031f76) exiting.
2020-04-02 05:10:51,493 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-5ce73643-a35c-49a0-9b6f-3a559c673904) exiting.
2020-04-02 05:10:51,511 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1fa55103{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:51,512 [Thread-1172] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@761f442d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:51,512 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1f61d4f7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:51,513 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@48c9621f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:51,514 [Thread-1172] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42140
2020-04-02 05:10:51,522 [IPC Server listener on 42140] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42140
2020-04-02 05:10:51,522 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:51,522 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:51,524 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 04baa337-8df0-4202-93da-4b177174abb6) service to localhost/127.0.0.1:43680
2020-04-02 05:10:51,524 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 04baa337-8df0-4202-93da-4b177174abb6)
2020-04-02 05:10:51,526 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:51,531 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:51,537 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-371671733-172.17.0.14-1585804222598] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:51,546 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-371671733-172.17.0.14-1585804222598] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:51,546 [Thread-1172] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:51,546 [Thread-1172] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:51,546 [Thread-1172] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:51,546 [Thread-1172] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:51,551 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:51,551 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:10:51,551 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 36904 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:51,552 [Thread-1172] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:51,552 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3a4b95a9] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:51,552 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-6102d9c4-fc3c-4556-a85a-55fb22ecc86e) exiting.
2020-04-02 05:10:51,552 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-7395567f-c8aa-40bc-8eb4-70a04630fe1b) exiting.
2020-04-02 05:10:51,569 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1ccd9b06{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:51,570 [Thread-1172] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2fda0093{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:51,570 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@49cc3ab1{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:51,570 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2076cbe7{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:51,571 [Thread-1172] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36904
2020-04-02 05:10:51,580 [IPC Server listener on 36904] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36904
2020-04-02 05:10:51,580 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:51,580 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:51,583 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid b9473e7d-eaa8-4cc2-95dd-6ef0e032a218) service to localhost/127.0.0.1:43680
2020-04-02 05:10:51,583 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid b9473e7d-eaa8-4cc2-95dd-6ef0e032a218)
2020-04-02 05:10:51,585 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:51,595 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-371671733-172.17.0.14-1585804222598] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:51,604 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-371671733-172.17.0.14-1585804222598] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:51,604 [Thread-1172] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:51,604 [Thread-1172] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:51,604 [Thread-1172] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:51,604 [Thread-1172] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:51,609 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:51,610 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:10:51,610 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33969 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:51,610 [Thread-1172] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:51,610 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3c3b5a44] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:51,610 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-a9b6147c-75ea-43a4-9953-f4f29f656397) exiting.
2020-04-02 05:10:51,611 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-eb5022ac-fa0b-4efd-8fab-88d12fd94cbd) exiting.
2020-04-02 05:10:51,628 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@64957205{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:51,629 [Thread-1172] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6850e306{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:51,629 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1e45f3fd{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:51,629 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@19634994{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:51,631 [Thread-1172] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33969
2020-04-02 05:10:51,638 [IPC Server listener on 33969] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33969
2020-04-02 05:10:51,638 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:51,641 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:51,641 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 8d396def-1786-4275-b49c-2ee91dd52fd8) service to localhost/127.0.0.1:43680
2020-04-02 05:10:51,641 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-371671733-172.17.0.14-1585804222598 (Datanode Uuid 8d396def-1786-4275-b49c-2ee91dd52fd8)
2020-04-02 05:10:51,644 [BP-371671733-172.17.0.14-1585804222598 heartbeating to localhost/127.0.0.1:43680] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-371671733-172.17.0.14-1585804222598
2020-04-02 05:10:51,654 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-371671733-172.17.0.14-1585804222598] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:51,662 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-371671733-172.17.0.14-1585804222598] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:51,662 [Thread-1172] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:51,662 [Thread-1172] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:51,662 [Thread-1172] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:51,662 [Thread-1172] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:51,668 [Thread-1172] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:51,669 [Thread-1172] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:10:51,669 [Thread-1172] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 43680 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:51,669 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:10:51,669 [Thread-1172] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 8
2020-04-02 05:10:51,669 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@427a1c8] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:10:51,669 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3cff41ef] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:10:51,670 [Thread-1172] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 9 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 1 Number of syncs: 9 SyncTimes(ms): 5 3 
2020-04-02 05:10:51,671 [Thread-1172] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:10:51,671 [Thread-1172] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:10:51,672 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:10:51,672 [CacheReplicationMonitor(638488801)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:10:51,680 [Thread-1172] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43680
2020-04-02 05:10:51,684 [IPC Server listener on 43680] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43680
2020-04-02 05:10:51,684 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:51,684 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:10:51,687 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:10:51,691 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@230d72f] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:10:51,713 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:10:51,714 [Thread-1172] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:10:51,714 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@808a07e{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:10:51,715 [Thread-1172] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5abcf100{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:51,716 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3b003940{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:51,716 [Thread-1172] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@38630fb9{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure#testReadWithDNFailure[2]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure#testReadWithDNFailure[2]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure#testReadWithDNFailure[3]
[msx] perform reset as unitTestCounterInClass 3 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] before_class
2020-04-02 05:10:51,746 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=9
Formatting using clusterid: testClusterID
2020-04-02 05:10:51,748 [Thread-1566] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:10:51,749 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:10:51,749 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:10:51,749 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:10:51,749 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:10:51,749 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:10:51,749 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:10:51,749 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:10:51,750 [Thread-1566] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:51,750 [Thread-1566] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:10:51,750 [Thread-1566] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:10:51,750 [Thread-1566] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:10:51,751 [Thread-1566] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:10:51
2020-04-02 05:10:51,751 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:10:51,751 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:51,751 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 2.0 GB = 40.3 MB
2020-04-02 05:10:51,751 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:10:51,754 [Thread-1566] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:10:51,755 [Thread-1566] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:10:51,755 [Thread-1566] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:10:51,755 [Thread-1566] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:10:51,755 [Thread-1566] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:10:51,755 [Thread-1566] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:10:51,755 [Thread-1566] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:10:51,755 [Thread-1566] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:10:51,755 [Thread-1566] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 0
2020-04-02 05:10:51,755 [Thread-1566] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:10:51,755 [Thread-1566] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:10:51,755 [Thread-1566] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:10:51,756 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:10:51,756 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:51,756 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 2.0 GB = 20.2 MB
2020-04-02 05:10:51,756 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:10:51,757 [Thread-1566] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:10:51,757 [Thread-1566] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:10:51,757 [Thread-1566] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:10:51,757 [Thread-1566] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:10:51,758 [Thread-1566] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:10:51,758 [Thread-1566] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:10:51,758 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:10:51,758 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:51,758 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 2.0 GB = 5.0 MB
2020-04-02 05:10:51,758 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:10:51,758 [Thread-1566] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:10:51,758 [Thread-1566] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:10:51,759 [Thread-1566] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:10:51,759 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:10:51,759 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:10:51,759 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:10:51,759 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:51,759 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 2.0 GB = 619.3 KB
2020-04-02 05:10:51,759 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:10:51,760 [Thread-1566] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:51,763 [Thread-1566] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:10:51,764 [Thread-1566] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:10:51,765 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:10:51,770 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:10:51,772 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 426 bytes saved in 0 seconds .
2020-04-02 05:10:51,779 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 426 bytes saved in 0 seconds .
2020-04-02 05:10:51,781 [Thread-1566] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:10:51,783 [Thread-1566] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:10:51,783 [Thread-1566] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:10:51,783 [Thread-1566] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:10:51,784 [Thread-1566] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:10:51,822 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@46d7262] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:51,822 [Thread-1566] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:10:51,823 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:51,824 [Thread-1566] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:51,824 [Thread-1566] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:10:51,824 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:51,825 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:51,825 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:10:51,825 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:51,825 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:51,826 [Thread-1566] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:10:51,826 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:10:51,827 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42671
2020-04-02 05:10:51,827 [Thread-1566] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:51,828 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@19901873{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:51,828 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7a8a19df{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:51,831 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@36515d44{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:10:51,831 [Thread-1566] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@22f4d73e{HTTP/1.1,[http/1.1]}{localhost:42671}
2020-04-02 05:10:51,831 [Thread-1566] INFO  server.Server (Server.java:doStart(419)) - Started @122242ms
2020-04-02 05:10:51,849 [Thread-1566] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:10:51,849 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:10:51,849 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:10:51,850 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:10:51,850 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:10:51,850 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:10:51,850 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:10:51,850 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:10:51,850 [Thread-1566] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:51,850 [Thread-1566] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:10:51,850 [Thread-1566] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:10:51,850 [Thread-1566] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:10:51,851 [Thread-1566] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:10:51
2020-04-02 05:10:51,851 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:10:51,851 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:51,851 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 2.0 GB = 40.3 MB
2020-04-02 05:10:51,851 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:10:51,854 [Thread-1566] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:10:51,854 [Thread-1566] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:10:51,854 [Thread-1566] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:10:51,854 [Thread-1566] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:10:51,854 [Thread-1566] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:10:51,854 [Thread-1566] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:10:51,854 [Thread-1566] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:10:51,855 [Thread-1566] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:10:51,855 [Thread-1566] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 0
2020-04-02 05:10:51,855 [Thread-1566] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:10:51,855 [Thread-1566] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:10:51,855 [Thread-1566] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:10:51,855 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:10:51,855 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:51,856 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 2.0 GB = 20.2 MB
2020-04-02 05:10:51,856 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:10:51,857 [Thread-1566] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:10:51,857 [Thread-1566] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:10:51,857 [Thread-1566] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:10:51,858 [Thread-1566] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:10:51,858 [Thread-1566] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:10:51,858 [Thread-1566] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:10:51,858 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:10:51,858 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:51,858 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 2.0 GB = 5.0 MB
2020-04-02 05:10:51,858 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:10:51,859 [Thread-1566] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:10:51,859 [Thread-1566] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:10:51,859 [Thread-1566] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:10:51,859 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:10:51,859 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:10:51,859 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:10:51,859 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:51,859 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 2.0 GB = 619.3 KB
2020-04-02 05:10:51,860 [Thread-1566] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:10:51,861 [Thread-1566] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:51,862 [Thread-1566] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:51,863 [Thread-1566] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:10:51,863 [Thread-1566] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:10:51,864 [Thread-1566] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:10:51,864 [Thread-1566] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:10:51,865 [Thread-1566] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:10:51,865 [Thread-1566] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:10:51,865 [Thread-1566] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:10:51,866 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:10:51,866 [Thread-1566] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:10:51,881 [Thread-1566] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:10:51,881 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 22 msecs
2020-04-02 05:10:51,882 [Thread-1566] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:10:51,882 [Thread-1566] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:51,883 [Socket Reader #1 for port 33192] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33192
2020-04-02 05:10:51,888 [Thread-1566] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:33192 to access this namenode/service.
2020-04-02 05:10:51,889 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:10:51,966 [Thread-1566] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:10:51,966 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@7b16e52c] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:10:51,967 [Thread-1566] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:10:51,967 [Thread-1566] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:10:51,967 [Thread-1566] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:10:51,967 [Thread-1566] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:10:51,976 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:10:51,976 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:10:51,976 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:10:51,976 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:10:51,976 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:10:51,976 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2020-04-02 05:10:51,978 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:51,982 [IPC Server listener on 33192] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33192: starting
2020-04-02 05:10:51,985 [Thread-1566] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:33192
2020-04-02 05:10:51,986 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:10:51,986 [Thread-1566] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:10:51,992 [Thread-1566] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 3 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:10:51,992 [Thread-1566] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 33192 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:51,999 [CacheReplicationMonitor(178078641)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:10:52,029 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:10:52,029 [Thread-1566] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:10:52,029 [Thread-1566] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:10:52,030 [Thread-1566] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:10:52,033 [Thread-1566] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:10:52,034 [Thread-1566] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:52,034 [Thread-1566] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:10:52,034 [Thread-1566] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:10:52,034 [Thread-1566] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:52,034 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:10:52,034 [Thread-1566] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37793
2020-04-02 05:10:52,034 [Thread-1566] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:10:52,034 [Thread-1566] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:10:52,035 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:52,036 [Thread-1566] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:52,036 [Thread-1566] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:10:52,036 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:52,037 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:52,037 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:10:52,037 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:52,037 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:52,037 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34546
2020-04-02 05:10:52,037 [Thread-1566] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:52,038 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2c02397b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:52,038 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4f4d34c9{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:52,040 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@77154e28{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:10:52,041 [Thread-1566] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@56b1ce12{HTTP/1.1,[http/1.1]}{localhost:34546}
2020-04-02 05:10:52,044 [Thread-1566] INFO  server.Server (Server.java:doStart(419)) - Started @122455ms
2020-04-02 05:10:52,056 [Thread-1566] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40700
2020-04-02 05:10:52,057 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:10:52,057 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:10:52,057 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3f690503] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:52,057 [Thread-1566] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:52,058 [Socket Reader #1 for port 36881] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36881
2020-04-02 05:10:52,062 [Thread-1566] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:36881
2020-04-02 05:10:52,098 [Thread-1566] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:10:52,099 [Thread-1566] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:10:52,099 [Thread-1620] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33192 starting to offer service
2020-04-02 05:10:52,103 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:52,103 [IPC Server listener on 36881] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36881: starting
2020-04-02 05:10:52,122 [Thread-1566] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 36881 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:52,122 [Thread-1620] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33192
2020-04-02 05:10:52,122 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:10:52,126 [Thread-1620] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:10:52,127 [Thread-1566] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:10:52,127 [Thread-1566] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:10:52,128 [Thread-1620] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:52,128 [Thread-1620] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1362547995. Formatting...
2020-04-02 05:10:52,128 [Thread-1566] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:10:52,131 [Thread-1620] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-46c7fa34-d414-4b4c-99c7-6190349b7c72 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:10:52,131 [Thread-1566] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:10:52,132 [Thread-1566] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:52,132 [Thread-1566] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:10:52,132 [Thread-1566] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:10:52,132 [Thread-1566] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:52,132 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:10:52,133 [Thread-1566] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:35998
2020-04-02 05:10:52,133 [Thread-1566] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:10:52,133 [Thread-1566] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:10:52,134 [Thread-1620] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:52,134 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:52,134 [Thread-1620] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1362547995. Formatting...
2020-04-02 05:10:52,134 [Thread-1620] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7201f093-3afa-49ae-83b4-ac5a5dd9b8f0 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:10:52,136 [Thread-1566] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:52,136 [Thread-1566] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:10:52,136 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:52,138 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:52,138 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:10:52,138 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:52,138 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:52,139 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38147
2020-04-02 05:10:52,139 [Thread-1566] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:52,140 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7c3a5217{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:52,141 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@35e295a8{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:52,144 [Thread-1620] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,144 [Thread-1620] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,144 [Thread-1620] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1825584050-172.17.0.14-1585804251760 is not formatted. Formatting ...
2020-04-02 05:10:52,144 [Thread-1620] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1825584050-172.17.0.14-1585804251760 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1825584050-172.17.0.14-1585804251760/current
2020-04-02 05:10:52,145 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@285297ec{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:10:52,146 [Thread-1566] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@52ab0242{HTTP/1.1,[http/1.1]}{localhost:38147}
2020-04-02 05:10:52,150 [Thread-1566] INFO  server.Server (Server.java:doStart(419)) - Started @122560ms
2020-04-02 05:10:52,166 [Thread-1620] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,166 [Thread-1566] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39556
2020-04-02 05:10:52,166 [Thread-1620] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,166 [Thread-1620] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1825584050-172.17.0.14-1585804251760 is not formatted. Formatting ...
2020-04-02 05:10:52,166 [Thread-1620] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1825584050-172.17.0.14-1585804251760 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1825584050-172.17.0.14-1585804251760/current
2020-04-02 05:10:52,167 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:10:52,167 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:10:52,167 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@76c555bf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:52,167 [Thread-1566] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:52,168 [Socket Reader #1 for port 38829] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38829
2020-04-02 05:10:52,168 [Thread-1620] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1362547995;bpid=BP-1825584050-172.17.0.14-1585804251760;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1362547995;c=1585804251760;bpid=BP-1825584050-172.17.0.14-1585804251760;dnuuid=null
2020-04-02 05:10:52,172 [Thread-1620] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID ef7a5af2-065c-4d9f-bd14-c3bfefed3f1a
2020-04-02 05:10:52,174 [Thread-1566] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:38829
2020-04-02 05:10:52,174 [Thread-1620] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-46c7fa34-d414-4b4c-99c7-6190349b7c72
2020-04-02 05:10:52,174 [Thread-1620] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:10:52,216 [Thread-1566] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:10:52,216 [Thread-1566] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:10:52,216 [Thread-1645] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33192 starting to offer service
2020-04-02 05:10:52,217 [Thread-1620] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-7201f093-3afa-49ae-83b4-ac5a5dd9b8f0
2020-04-02 05:10:52,217 [Thread-1620] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:10:52,217 [Thread-1620] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:10:52,217 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:52,222 [Thread-1620] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:10:52,223 [IPC Server listener on 38829] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38829: starting
2020-04-02 05:10:52,227 [Thread-1620] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:10:52,227 [Thread-1620] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:10:52,227 [Thread-1645] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33192
2020-04-02 05:10:52,228 [Thread-1620] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:10:52,230 [Thread-1645] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:10:52,230 [Thread-1620] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,230 [Thread-1566] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 38829 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:52,230 [Thread-1657] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:10:52,231 [Thread-1658] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:10:52,231 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:10:52,231 [Thread-1645] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:52,232 [Thread-1645] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1362547995. Formatting...
2020-04-02 05:10:52,232 [Thread-1645] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-15b45324-a78a-41f6-9bfa-459867e3b0d4 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:10:52,232 [Thread-1566] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:10:52,232 [Thread-1566] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:10:52,233 [Thread-1566] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:10:52,238 [Thread-1566] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:10:52,238 [Thread-1566] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:52,238 [Thread-1566] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:10:52,238 [Thread-1566] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:10:52,238 [Thread-1566] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:52,239 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:10:52,239 [Thread-1645] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:52,240 [Thread-1566] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42157
2020-04-02 05:10:52,240 [Thread-1645] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1362547995. Formatting...
2020-04-02 05:10:52,240 [Thread-1566] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:10:52,240 [Thread-1566] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:10:52,240 [Thread-1645] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0dd3d6d9-31c0-472a-86df-a834121a9690 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:10:52,241 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:52,244 [Thread-1566] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:52,245 [Thread-1566] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:10:52,245 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:52,246 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:52,247 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:10:52,247 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:52,247 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:52,248 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35884
2020-04-02 05:10:52,249 [Thread-1566] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:52,250 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@77582674{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:52,250 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@77f1bfd6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:52,252 [Thread-1645] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,252 [Thread-1645] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,253 [Thread-1645] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1825584050-172.17.0.14-1585804251760 is not formatted. Formatting ...
2020-04-02 05:10:52,253 [Thread-1645] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1825584050-172.17.0.14-1585804251760 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1825584050-172.17.0.14-1585804251760/current
2020-04-02 05:10:52,255 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@759962e6{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:10:52,255 [Thread-1566] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7507fae4{HTTP/1.1,[http/1.1]}{localhost:35884}
2020-04-02 05:10:52,260 [Thread-1566] INFO  server.Server (Server.java:doStart(419)) - Started @122670ms
2020-04-02 05:10:52,269 [Thread-1645] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,276 [Thread-1645] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,276 [Thread-1645] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1825584050-172.17.0.14-1585804251760 is not formatted. Formatting ...
2020-04-02 05:10:52,276 [Thread-1566] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33893
2020-04-02 05:10:52,276 [Thread-1645] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1825584050-172.17.0.14-1585804251760 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1825584050-172.17.0.14-1585804251760/current
2020-04-02 05:10:52,276 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:10:52,276 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:10:52,276 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@394b559b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:52,277 [Thread-1566] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:52,277 [Socket Reader #1 for port 38407] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38407
2020-04-02 05:10:52,280 [Thread-1645] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1362547995;bpid=BP-1825584050-172.17.0.14-1585804251760;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1362547995;c=1585804251760;bpid=BP-1825584050-172.17.0.14-1585804251760;dnuuid=null
2020-04-02 05:10:52,282 [Thread-1645] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 81d430fe-99fe-4cd9-9352-e7746c92b1dc
2020-04-02 05:10:52,283 [Thread-1566] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:38407
2020-04-02 05:10:52,283 [Thread-1645] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-15b45324-a78a-41f6-9bfa-459867e3b0d4
2020-04-02 05:10:52,283 [Thread-1645] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:10:52,290 [Thread-1658] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1825584050-172.17.0.14-1585804251760 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 59ms
2020-04-02 05:10:52,291 [Thread-1657] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1825584050-172.17.0.14-1585804251760 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 60ms
2020-04-02 05:10:52,336 [Thread-1620] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1825584050-172.17.0.14-1585804251760: 107ms
2020-04-02 05:10:52,337 [Thread-1672] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:10:52,337 [Thread-1673] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:10:52,337 [Thread-1672] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1825584050-172.17.0.14-1585804251760/current/replicas doesn't exist 
2020-04-02 05:10:52,337 [Thread-1673] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1825584050-172.17.0.14-1585804251760/current/replicas doesn't exist 
2020-04-02 05:10:52,338 [Thread-1673] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:10:52,338 [Thread-1672] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:10:52,338 [Thread-1620] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760: 1ms
2020-04-02 05:10:52,338 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:10:52,338 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:10:52,338 [Thread-1566] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:10:52,339 [Thread-1620] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:35 AM with interval of 21600000ms
2020-04-02 05:10:52,339 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-46c7fa34-d414-4b4c-99c7-6190349b7c72): finished scanning block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,339 [Thread-1566] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:10:52,339 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-7201f093-3afa-49ae-83b4-ac5a5dd9b8f0): finished scanning block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,339 [Thread-1645] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-0dd3d6d9-31c0-472a-86df-a834121a9690
2020-04-02 05:10:52,343 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid ef7a5af2-065c-4d9f-bd14-c3bfefed3f1a) service to localhost/127.0.0.1:33192 beginning handshake with NN
2020-04-02 05:10:52,346 [Thread-1680] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33192 starting to offer service
2020-04-02 05:10:52,346 [Thread-1645] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:10:52,346 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-46c7fa34-d414-4b4c-99c7-6190349b7c72): no suitable block pools found to scan.  Waiting 1814399992 ms.
2020-04-02 05:10:52,350 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:52,350 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-7201f093-3afa-49ae-83b4-ac5a5dd9b8f0): no suitable block pools found to scan.  Waiting 1814399988 ms.
2020-04-02 05:10:52,350 [IPC Server listener on 38407] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38407: starting
2020-04-02 05:10:52,351 [Thread-1645] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:10:52,355 [Thread-1566] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 38407 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:52,355 [Thread-1645] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:10:52,358 [IPC Server handler 1 on 33192] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37793, datanodeUuid=ef7a5af2-065c-4d9f-bd14-c3bfefed3f1a, infoPort=40700, infoSecurePort=0, ipcPort=36881, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760) storage ef7a5af2-065c-4d9f-bd14-c3bfefed3f1a
2020-04-02 05:10:52,359 [Thread-1680] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33192
2020-04-02 05:10:52,359 [Thread-1645] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:10:52,362 [IPC Server handler 1 on 33192] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37793
2020-04-02 05:10:52,363 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:10:52,362 [Thread-1680] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:10:52,363 [IPC Server handler 1 on 33192] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ef7a5af2-065c-4d9f-bd14-c3bfefed3f1a (127.0.0.1:37793).
2020-04-02 05:10:52,363 [Thread-1645] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:10:52,369 [Thread-1645] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:10:52,369 [Thread-1645] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,370 [Thread-1566] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:10:52,370 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid ef7a5af2-065c-4d9f-bd14-c3bfefed3f1a) service to localhost/127.0.0.1:33192 successfully registered with NN
2020-04-02 05:10:52,370 [Thread-1691] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:10:52,370 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33192 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:52,370 [Thread-1692] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:10:52,370 [Thread-1566] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:10:52,373 [Thread-1680] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:52,374 [Thread-1680] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1362547995. Formatting...
2020-04-02 05:10:52,377 [IPC Server handler 3 on 33192] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-46c7fa34-d414-4b4c-99c7-6190349b7c72 for DN 127.0.0.1:37793
2020-04-02 05:10:52,377 [Thread-1680] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-21e773fb-913d-412f-b6c4-3cd7a15b4115 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:10:52,377 [Thread-1566] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:10:52,377 [IPC Server handler 3 on 33192] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7201f093-3afa-49ae-83b4-ac5a5dd9b8f0 for DN 127.0.0.1:37793
2020-04-02 05:10:52,380 [Thread-1566] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:10:52,383 [Thread-1566] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:52,383 [Thread-1566] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:10:52,383 [Thread-1566] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:10:52,384 [Thread-1566] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:52,384 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:10:52,384 [IPC Server handler 6 on 33192] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:37793, datanodeUuid=ef7a5af2-065c-4d9f-bd14-c3bfefed3f1a, infoPort=40700, infoSecurePort=0, ipcPort=36881, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), reports.length=2
2020-04-02 05:10:52,384 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x1c2d8d45459e01b: Processing first storage report for DS-7201f093-3afa-49ae-83b4-ac5a5dd9b8f0 from datanode ef7a5af2-065c-4d9f-bd14-c3bfefed3f1a
2020-04-02 05:10:52,384 [Thread-1566] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:39262
2020-04-02 05:10:52,384 [Thread-1680] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:52,384 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x1c2d8d45459e01b: from storage DS-7201f093-3afa-49ae-83b4-ac5a5dd9b8f0 node DatanodeRegistration(127.0.0.1:37793, datanodeUuid=ef7a5af2-065c-4d9f-bd14-c3bfefed3f1a, infoPort=40700, infoSecurePort=0, ipcPort=36881, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:10:52,385 [Thread-1566] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:10:52,385 [Thread-1566] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:10:52,385 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x1c2d8d45459e01b: Processing first storage report for DS-46c7fa34-d414-4b4c-99c7-6190349b7c72 from datanode ef7a5af2-065c-4d9f-bd14-c3bfefed3f1a
2020-04-02 05:10:52,385 [Thread-1680] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1362547995. Formatting...
2020-04-02 05:10:52,385 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x1c2d8d45459e01b: from storage DS-46c7fa34-d414-4b4c-99c7-6190349b7c72 node DatanodeRegistration(127.0.0.1:37793, datanodeUuid=ef7a5af2-065c-4d9f-bd14-c3bfefed3f1a, infoPort=40700, infoSecurePort=0, ipcPort=36881, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:52,385 [Thread-1680] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3c042c06-aa2e-4955-ae1b-243e515da044 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:10:52,385 [IPC Server handler 6 on 33192] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x1c2d8d45459e01b
2020-04-02 05:10:52,386 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:52,387 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x1c2d8d45459e01b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:52,387 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,388 [Thread-1566] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:52,388 [Thread-1566] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:10:52,389 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:52,389 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:52,390 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:10:52,390 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:52,390 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:52,391 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42668
2020-04-02 05:10:52,391 [Thread-1566] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:52,392 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7b49d269{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:52,392 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@26b3b76c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:52,396 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@770c0a56{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:10:52,397 [Thread-1566] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5a088945{HTTP/1.1,[http/1.1]}{localhost:42668}
2020-04-02 05:10:52,401 [Thread-1680] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,401 [Thread-1566] INFO  server.Server (Server.java:doStart(419)) - Started @122811ms
2020-04-02 05:10:52,401 [Thread-1680] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,401 [Thread-1680] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1825584050-172.17.0.14-1585804251760 is not formatted. Formatting ...
2020-04-02 05:10:52,402 [Thread-1680] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1825584050-172.17.0.14-1585804251760 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1825584050-172.17.0.14-1585804251760/current
2020-04-02 05:10:52,415 [Thread-1566] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37609
2020-04-02 05:10:52,415 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:10:52,415 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:10:52,415 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4139ad3e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:52,415 [Thread-1566] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:52,416 [Socket Reader #1 for port 42997] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42997
2020-04-02 05:10:52,421 [Thread-1566] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:42997
2020-04-02 05:10:52,424 [Thread-1680] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,424 [Thread-1680] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,424 [Thread-1680] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1825584050-172.17.0.14-1585804251760 is not formatted. Formatting ...
2020-04-02 05:10:52,424 [Thread-1680] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1825584050-172.17.0.14-1585804251760 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1825584050-172.17.0.14-1585804251760/current
2020-04-02 05:10:52,426 [Thread-1680] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1362547995;bpid=BP-1825584050-172.17.0.14-1585804251760;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1362547995;c=1585804251760;bpid=BP-1825584050-172.17.0.14-1585804251760;dnuuid=null
2020-04-02 05:10:52,427 [Thread-1680] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID a46046db-b981-4c14-88c5-394d9b0fe4db
2020-04-02 05:10:52,432 [Thread-1692] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1825584050-172.17.0.14-1585804251760 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 62ms
2020-04-02 05:10:52,432 [Thread-1691] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1825584050-172.17.0.14-1585804251760 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 62ms
2020-04-02 05:10:52,468 [Thread-1645] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1825584050-172.17.0.14-1585804251760: 100ms
2020-04-02 05:10:52,469 [Thread-1705] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:10:52,469 [Thread-1705] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1825584050-172.17.0.14-1585804251760/current/replicas doesn't exist 
2020-04-02 05:10:52,469 [Thread-1706] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:10:52,472 [Thread-1705] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 4ms
2020-04-02 05:10:52,473 [Thread-1706] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1825584050-172.17.0.14-1585804251760/current/replicas doesn't exist 
2020-04-02 05:10:52,473 [Thread-1706] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 0ms
2020-04-02 05:10:52,473 [Thread-1645] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760: 4ms
2020-04-02 05:10:52,473 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:10:52,473 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:10:52,474 [Thread-1645] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:24 AM with interval of 21600000ms
2020-04-02 05:10:52,474 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-15b45324-a78a-41f6-9bfa-459867e3b0d4): finished scanning block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,474 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-0dd3d6d9-31c0-472a-86df-a834121a9690): finished scanning block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,474 [Thread-1680] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-21e773fb-913d-412f-b6c4-3cd7a15b4115
2020-04-02 05:10:52,477 [Thread-1680] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:10:52,481 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 81d430fe-99fe-4cd9-9352-e7746c92b1dc) service to localhost/127.0.0.1:33192 beginning handshake with NN
2020-04-02 05:10:52,481 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-15b45324-a78a-41f6-9bfa-459867e3b0d4): no suitable block pools found to scan.  Waiting 1814399992 ms.
2020-04-02 05:10:52,481 [Thread-1566] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:10:52,481 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-0dd3d6d9-31c0-472a-86df-a834121a9690): no suitable block pools found to scan.  Waiting 1814399992 ms.
2020-04-02 05:10:52,481 [Thread-1566] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:10:52,482 [Thread-1680] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-3c042c06-aa2e-4955-ae1b-243e515da044
2020-04-02 05:10:52,482 [IPC Server handler 5 on 33192] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35998, datanodeUuid=81d430fe-99fe-4cd9-9352-e7746c92b1dc, infoPort=39556, infoSecurePort=0, ipcPort=38829, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760) storage 81d430fe-99fe-4cd9-9352-e7746c92b1dc
2020-04-02 05:10:52,482 [Thread-1680] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:10:52,485 [IPC Server handler 5 on 33192] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35998
2020-04-02 05:10:52,486 [IPC Server handler 5 on 33192] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 81d430fe-99fe-4cd9-9352-e7746c92b1dc (127.0.0.1:35998).
2020-04-02 05:10:52,485 [Thread-1714] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33192 starting to offer service
2020-04-02 05:10:52,486 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 81d430fe-99fe-4cd9-9352-e7746c92b1dc) service to localhost/127.0.0.1:33192 successfully registered with NN
2020-04-02 05:10:52,486 [Thread-1680] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:10:52,486 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:52,486 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33192 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:52,490 [IPC Server listener on 42997] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42997: starting
2020-04-02 05:10:52,498 [Thread-1680] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:10:52,502 [IPC Server handler 8 on 33192] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-15b45324-a78a-41f6-9bfa-459867e3b0d4 for DN 127.0.0.1:35998
2020-04-02 05:10:52,507 [IPC Server handler 8 on 33192] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0dd3d6d9-31c0-472a-86df-a834121a9690 for DN 127.0.0.1:35998
2020-04-02 05:10:52,508 [Thread-1714] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33192
2020-04-02 05:10:52,510 [Thread-1714] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:10:52,511 [Thread-1566] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 42997 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:52,511 [Thread-1680] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:10:52,511 [IPC Server handler 9 on 33192] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:35998, datanodeUuid=81d430fe-99fe-4cd9-9352-e7746c92b1dc, infoPort=39556, infoSecurePort=0, ipcPort=38829, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), reports.length=2
2020-04-02 05:10:52,511 [Thread-1680] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:10:52,511 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x94872d621b3f4284: Processing first storage report for DS-15b45324-a78a-41f6-9bfa-459867e3b0d4 from datanode 81d430fe-99fe-4cd9-9352-e7746c92b1dc
2020-04-02 05:10:52,511 [Thread-1680] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:10:52,511 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x94872d621b3f4284: from storage DS-15b45324-a78a-41f6-9bfa-459867e3b0d4 node DatanodeRegistration(127.0.0.1:35998, datanodeUuid=81d430fe-99fe-4cd9-9352-e7746c92b1dc, infoPort=39556, infoSecurePort=0, ipcPort=38829, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:10:52,512 [Thread-1714] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:52,512 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:10:52,512 [Thread-1680] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,512 [Thread-1714] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1362547995. Formatting...
2020-04-02 05:10:52,512 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x94872d621b3f4284: Processing first storage report for DS-0dd3d6d9-31c0-472a-86df-a834121a9690 from datanode 81d430fe-99fe-4cd9-9352-e7746c92b1dc
2020-04-02 05:10:52,512 [Thread-1714] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8ddcf17d-bcd9-4ffb-8299-0cef43ba2231 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-04-02 05:10:52,512 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x94872d621b3f4284: from storage DS-0dd3d6d9-31c0-472a-86df-a834121a9690 node DatanodeRegistration(127.0.0.1:35998, datanodeUuid=81d430fe-99fe-4cd9-9352-e7746c92b1dc, infoPort=39556, infoSecurePort=0, ipcPort=38829, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:52,512 [Thread-1726] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:10:52,512 [IPC Server handler 9 on 33192] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x94872d621b3f4284
2020-04-02 05:10:52,512 [Thread-1725] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:10:52,513 [Thread-1566] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:10:52,513 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x94872d621b3f4284,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:52,513 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,513 [Thread-1566] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:10:52,514 [Thread-1566] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:10:52,517 [Thread-1566] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:10:52,517 [Thread-1566] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:52,517 [Thread-1566] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:10:52,518 [Thread-1714] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:52,518 [Thread-1566] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:10:52,518 [Thread-1714] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1362547995. Formatting...
2020-04-02 05:10:52,518 [Thread-1566] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:52,518 [Thread-1714] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d529772c-b95e-45f2-94c4-7c70fac21926 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-04-02 05:10:52,518 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:10:52,518 [Thread-1566] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42218
2020-04-02 05:10:52,519 [Thread-1566] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:10:52,519 [Thread-1566] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:10:52,520 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:52,521 [Thread-1566] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:52,522 [Thread-1566] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:10:52,522 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:52,523 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:52,523 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:10:52,523 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:52,523 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:52,524 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42925
2020-04-02 05:10:52,524 [Thread-1566] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:52,525 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@68b5251d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:52,526 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1af91a3a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:52,529 [Thread-1714] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,530 [Thread-1714] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,530 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@394dca72{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:10:52,530 [Thread-1714] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1825584050-172.17.0.14-1585804251760 is not formatted. Formatting ...
2020-04-02 05:10:52,530 [Thread-1714] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1825584050-172.17.0.14-1585804251760 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1825584050-172.17.0.14-1585804251760/current
2020-04-02 05:10:52,530 [Thread-1566] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@49d33174{HTTP/1.1,[http/1.1]}{localhost:42925}
2020-04-02 05:10:52,535 [Thread-1566] INFO  server.Server (Server.java:doStart(419)) - Started @122945ms
2020-04-02 05:10:52,547 [Thread-1566] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36633
2020-04-02 05:10:52,549 [Thread-1714] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,549 [Thread-1714] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,549 [Thread-1714] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1825584050-172.17.0.14-1585804251760 is not formatted. Formatting ...
2020-04-02 05:10:52,549 [Thread-1714] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1825584050-172.17.0.14-1585804251760 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1825584050-172.17.0.14-1585804251760/current
2020-04-02 05:10:52,550 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:10:52,550 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@38fa2374] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:52,550 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:10:52,550 [Thread-1566] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:52,551 [Thread-1714] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1362547995;bpid=BP-1825584050-172.17.0.14-1585804251760;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1362547995;c=1585804251760;bpid=BP-1825584050-172.17.0.14-1585804251760;dnuuid=null
2020-04-02 05:10:52,551 [Socket Reader #1 for port 40716] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40716
2020-04-02 05:10:52,555 [Thread-1714] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 7bfacc45-16b4-4536-9f0a-c362b8e9c2d8
2020-04-02 05:10:52,556 [Thread-1566] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40716
2020-04-02 05:10:52,557 [Thread-1714] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8ddcf17d-bcd9-4ffb-8299-0cef43ba2231
2020-04-02 05:10:52,557 [Thread-1714] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:10:52,609 [Thread-1714] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-d529772c-b95e-45f2-94c4-7c70fac21926
2020-04-02 05:10:52,609 [Thread-1714] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:10:52,614 [Thread-1566] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:10:52,614 [Thread-1714] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:10:52,614 [Thread-1566] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:10:52,614 [Thread-1743] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33192 starting to offer service
2020-04-02 05:10:52,615 [Thread-1714] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:10:52,618 [IPC Server listener on 40716] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40716: starting
2020-04-02 05:10:52,619 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:52,622 [Thread-1743] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33192
2020-04-02 05:10:52,624 [Thread-1743] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:10:52,624 [Thread-1566] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40716 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:52,624 [Thread-1714] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:10:52,624 [Thread-1714] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:10:52,625 [Thread-1714] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:10:52,625 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:10:52,625 [Thread-1714] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,625 [Thread-1754] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:10:52,625 [Thread-1743] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:52,625 [Thread-1755] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:10:52,625 [Thread-1566] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:10:52,625 [Thread-1743] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 1362547995. Formatting...
2020-04-02 05:10:52,626 [Thread-1566] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:10:52,626 [Thread-1743] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-df249783-84ef-42cc-bd14-74acad083d63 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-04-02 05:10:52,627 [Thread-1566] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:10:52,629 [Thread-1566] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:10:52,629 [Thread-1566] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:52,629 [Thread-1566] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:10:52,630 [Thread-1566] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:10:52,630 [Thread-1566] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:52,630 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:10:52,630 [Thread-1566] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:33561
2020-04-02 05:10:52,631 [Thread-1566] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:10:52,631 [Thread-1566] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:10:52,631 [Thread-1743] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:52,631 [Thread-1743] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 1362547995. Formatting...
2020-04-02 05:10:52,631 [Thread-1743] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-376cb285-b919-481f-bb69-7ffe3094f1d2 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-04-02 05:10:52,632 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:52,632 [Thread-1726] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1825584050-172.17.0.14-1585804251760 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 120ms
2020-04-02 05:10:52,632 [Thread-1725] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1825584050-172.17.0.14-1585804251760 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 120ms
2020-04-02 05:10:52,636 [Thread-1680] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1825584050-172.17.0.14-1585804251760: 124ms
2020-04-02 05:10:52,636 [Thread-1759] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:10:52,636 [Thread-1759] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1825584050-172.17.0.14-1585804251760/current/replicas doesn't exist 
2020-04-02 05:10:52,636 [Thread-1759] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 1ms
2020-04-02 05:10:52,636 [Thread-1760] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:10:52,637 [Thread-1760] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1825584050-172.17.0.14-1585804251760/current/replicas doesn't exist 
2020-04-02 05:10:52,637 [Thread-1566] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:52,637 [Thread-1760] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 0ms
2020-04-02 05:10:52,637 [Thread-1680] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760: 1ms
2020-04-02 05:10:52,637 [Thread-1566] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:10:52,637 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:10:52,638 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:52,637 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:10:52,638 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-3c042c06-aa2e-4955-ae1b-243e515da044): finished scanning block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,638 [Thread-1680] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:40 AM with interval of 21600000ms
2020-04-02 05:10:52,638 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-21e773fb-913d-412f-b6c4-3cd7a15b4115): finished scanning block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,642 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid a46046db-b981-4c14-88c5-394d9b0fe4db) service to localhost/127.0.0.1:33192 beginning handshake with NN
2020-04-02 05:10:52,642 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-21e773fb-913d-412f-b6c4-3cd7a15b4115): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:10:52,642 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-3c042c06-aa2e-4955-ae1b-243e515da044): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:10:52,642 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:52,642 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:10:52,643 [IPC Server handler 7 on 33192] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42157, datanodeUuid=a46046db-b981-4c14-88c5-394d9b0fe4db, infoPort=33893, infoSecurePort=0, ipcPort=38407, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760) storage a46046db-b981-4c14-88c5-394d9b0fe4db
2020-04-02 05:10:52,643 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:52,643 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:52,643 [IPC Server handler 7 on 33192] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42157
2020-04-02 05:10:52,643 [IPC Server handler 7 on 33192] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a46046db-b981-4c14-88c5-394d9b0fe4db (127.0.0.1:42157).
2020-04-02 05:10:52,644 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33575
2020-04-02 05:10:52,644 [Thread-1566] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:52,644 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid a46046db-b981-4c14-88c5-394d9b0fe4db) service to localhost/127.0.0.1:33192 successfully registered with NN
2020-04-02 05:10:52,644 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33192 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:52,652 [IPC Server handler 2 on 33192] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-21e773fb-913d-412f-b6c4-3cd7a15b4115 for DN 127.0.0.1:42157
2020-04-02 05:10:52,652 [IPC Server handler 2 on 33192] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3c042c06-aa2e-4955-ae1b-243e515da044 for DN 127.0.0.1:42157
2020-04-02 05:10:52,653 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2d164abf{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:52,653 [IPC Server handler 1 on 33192] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:42157, datanodeUuid=a46046db-b981-4c14-88c5-394d9b0fe4db, infoPort=33893, infoSecurePort=0, ipcPort=38407, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), reports.length=2
2020-04-02 05:10:52,653 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@763221f0{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:52,653 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc8eeef10f63c05a2: Processing first storage report for DS-21e773fb-913d-412f-b6c4-3cd7a15b4115 from datanode a46046db-b981-4c14-88c5-394d9b0fe4db
2020-04-02 05:10:52,654 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc8eeef10f63c05a2: from storage DS-21e773fb-913d-412f-b6c4-3cd7a15b4115 node DatanodeRegistration(127.0.0.1:42157, datanodeUuid=a46046db-b981-4c14-88c5-394d9b0fe4db, infoPort=33893, infoSecurePort=0, ipcPort=38407, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:52,654 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc8eeef10f63c05a2: Processing first storage report for DS-3c042c06-aa2e-4955-ae1b-243e515da044 from datanode a46046db-b981-4c14-88c5-394d9b0fe4db
2020-04-02 05:10:52,654 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc8eeef10f63c05a2: from storage DS-3c042c06-aa2e-4955-ae1b-243e515da044 node DatanodeRegistration(127.0.0.1:42157, datanodeUuid=a46046db-b981-4c14-88c5-394d9b0fe4db, infoPort=33893, infoSecurePort=0, ipcPort=38407, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:52,654 [IPC Server handler 1 on 33192] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xc8eeef10f63c05a2
2020-04-02 05:10:52,655 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xc8eeef10f63c05a2,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:52,655 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,656 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@124e2a55{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:10:52,656 [Thread-1566] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2039a694{HTTP/1.1,[http/1.1]}{localhost:33575}
2020-04-02 05:10:52,683 [Thread-1566] INFO  server.Server (Server.java:doStart(419)) - Started @123093ms
2020-04-02 05:10:52,685 [Thread-1743] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,686 [Thread-1743] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,686 [Thread-1755] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1825584050-172.17.0.14-1585804251760 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 61ms
2020-04-02 05:10:52,686 [Thread-1743] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-1825584050-172.17.0.14-1585804251760 is not formatted. Formatting ...
2020-04-02 05:10:52,690 [Thread-1743] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1825584050-172.17.0.14-1585804251760 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1825584050-172.17.0.14-1585804251760/current
2020-04-02 05:10:52,696 [Thread-1754] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1825584050-172.17.0.14-1585804251760 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 71ms
2020-04-02 05:10:52,696 [Thread-1714] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1825584050-172.17.0.14-1585804251760: 71ms
2020-04-02 05:10:52,697 [Thread-1769] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:10:52,697 [Thread-1770] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:10:52,704 [Thread-1769] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1825584050-172.17.0.14-1585804251760/current/replicas doesn't exist 
2020-04-02 05:10:52,704 [Thread-1566] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43128
2020-04-02 05:10:52,704 [Thread-1770] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1825584050-172.17.0.14-1585804251760/current/replicas doesn't exist 
2020-04-02 05:10:52,705 [Thread-1769] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 8ms
2020-04-02 05:10:52,705 [Thread-1770] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 1ms
2020-04-02 05:10:52,705 [Thread-1714] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760: 8ms
2020-04-02 05:10:52,705 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:10:52,705 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:10:52,705 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@704590d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:52,705 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:10:52,705 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:10:52,705 [Thread-1566] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:52,705 [Thread-1714] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:31 AM with interval of 21600000ms
2020-04-02 05:10:52,709 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-8ddcf17d-bcd9-4ffb-8299-0cef43ba2231): finished scanning block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,709 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-d529772c-b95e-45f2-94c4-7c70fac21926): finished scanning block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,713 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 7bfacc45-16b4-4536-9f0a-c362b8e9c2d8) service to localhost/127.0.0.1:33192 beginning handshake with NN
2020-04-02 05:10:52,713 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-d529772c-b95e-45f2-94c4-7c70fac21926): no suitable block pools found to scan.  Waiting 1814399992 ms.
2020-04-02 05:10:52,713 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-8ddcf17d-bcd9-4ffb-8299-0cef43ba2231): no suitable block pools found to scan.  Waiting 1814399992 ms.
2020-04-02 05:10:52,713 [Socket Reader #1 for port 38380] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38380
2020-04-02 05:10:52,718 [IPC Server handler 3 on 33192] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39262, datanodeUuid=7bfacc45-16b4-4536-9f0a-c362b8e9c2d8, infoPort=37609, infoSecurePort=0, ipcPort=42997, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760) storage 7bfacc45-16b4-4536-9f0a-c362b8e9c2d8
2020-04-02 05:10:52,718 [IPC Server handler 3 on 33192] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39262
2020-04-02 05:10:52,718 [IPC Server handler 3 on 33192] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7bfacc45-16b4-4536-9f0a-c362b8e9c2d8 (127.0.0.1:39262).
2020-04-02 05:10:52,718 [Thread-1743] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,718 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 7bfacc45-16b4-4536-9f0a-c362b8e9c2d8) service to localhost/127.0.0.1:33192 successfully registered with NN
2020-04-02 05:10:52,719 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33192 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:52,719 [Thread-1743] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,719 [Thread-1743] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-1825584050-172.17.0.14-1585804251760 is not formatted. Formatting ...
2020-04-02 05:10:52,723 [Thread-1743] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1825584050-172.17.0.14-1585804251760 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1825584050-172.17.0.14-1585804251760/current
2020-04-02 05:10:52,726 [IPC Server handler 6 on 33192] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8ddcf17d-bcd9-4ffb-8299-0cef43ba2231 for DN 127.0.0.1:39262
2020-04-02 05:10:52,727 [IPC Server handler 6 on 33192] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d529772c-b95e-45f2-94c4-7c70fac21926 for DN 127.0.0.1:39262
2020-04-02 05:10:52,727 [Thread-1566] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:38380
2020-04-02 05:10:52,728 [IPC Server handler 5 on 33192] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:39262, datanodeUuid=7bfacc45-16b4-4536-9f0a-c362b8e9c2d8, infoPort=37609, infoSecurePort=0, ipcPort=42997, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), reports.length=2
2020-04-02 05:10:52,728 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xace98dd9a480315e: Processing first storage report for DS-d529772c-b95e-45f2-94c4-7c70fac21926 from datanode 7bfacc45-16b4-4536-9f0a-c362b8e9c2d8
2020-04-02 05:10:52,728 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xace98dd9a480315e: from storage DS-d529772c-b95e-45f2-94c4-7c70fac21926 node DatanodeRegistration(127.0.0.1:39262, datanodeUuid=7bfacc45-16b4-4536-9f0a-c362b8e9c2d8, infoPort=37609, infoSecurePort=0, ipcPort=42997, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:52,728 [Thread-1743] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1362547995;bpid=BP-1825584050-172.17.0.14-1585804251760;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1362547995;c=1585804251760;bpid=BP-1825584050-172.17.0.14-1585804251760;dnuuid=null
2020-04-02 05:10:52,728 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xace98dd9a480315e: Processing first storage report for DS-8ddcf17d-bcd9-4ffb-8299-0cef43ba2231 from datanode 7bfacc45-16b4-4536-9f0a-c362b8e9c2d8
2020-04-02 05:10:52,728 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xace98dd9a480315e: from storage DS-8ddcf17d-bcd9-4ffb-8299-0cef43ba2231 node DatanodeRegistration(127.0.0.1:39262, datanodeUuid=7bfacc45-16b4-4536-9f0a-c362b8e9c2d8, infoPort=37609, infoSecurePort=0, ipcPort=42997, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:52,728 [IPC Server handler 5 on 33192] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xace98dd9a480315e
2020-04-02 05:10:52,729 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xace98dd9a480315e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:52,729 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,729 [Thread-1743] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 1e7d20d4-7343-45c7-97d6-ad56bfe86d64
2020-04-02 05:10:52,779 [Thread-1743] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-df249783-84ef-42cc-bd14-74acad083d63
2020-04-02 05:10:52,779 [Thread-1743] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-04-02 05:10:52,785 [Thread-1566] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:10:52,785 [Thread-1566] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:10:52,786 [Thread-1743] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-376cb285-b919-481f-bb69-7ffe3094f1d2
2020-04-02 05:10:52,786 [Thread-1743] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-04-02 05:10:52,791 [Thread-1782] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33192 starting to offer service
2020-04-02 05:10:52,791 [Thread-1743] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:10:52,796 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:52,796 [Thread-1743] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:10:52,796 [IPC Server listener on 38380] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38380: starting
2020-04-02 05:10:52,801 [Thread-1782] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33192
2020-04-02 05:10:52,805 [Thread-1782] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:10:52,805 [Thread-1743] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:10:52,805 [Thread-1566] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 38380 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:52,805 [Thread-1743] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:10:52,806 [Thread-1743] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:10:52,806 [Thread-1743] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,806 [Thread-1782] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:52,806 [Thread-1782] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 1362547995. Formatting...
2020-04-02 05:10:52,806 [Thread-1793] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:10:52,806 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:10:52,806 [Thread-1782] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-aa95a871-7b21-4bea-9ae1-baba6f2d158d for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-04-02 05:10:52,806 [Thread-1794] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:10:52,807 [Thread-1566] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:10:52,807 [Thread-1566] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:10:52,808 [Thread-1566] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:10:52,812 [Thread-1566] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:10:52,812 [Thread-1566] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:52,813 [Thread-1566] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:10:52,813 [Thread-1566] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:10:52,813 [Thread-1566] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:52,813 [Thread-1782] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:52,813 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:10:52,813 [Thread-1782] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 1362547995. Formatting...
2020-04-02 05:10:52,813 [Thread-1782] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a7eebb61-b3a8-458e-853f-64f8b271e2c2 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-04-02 05:10:52,814 [Thread-1566] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34730
2020-04-02 05:10:52,814 [Thread-1566] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:10:52,814 [Thread-1566] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:10:52,815 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:52,816 [Thread-1566] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:52,817 [Thread-1566] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:10:52,817 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:52,818 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:52,818 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:10:52,819 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:52,819 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:52,819 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42074
2020-04-02 05:10:52,819 [Thread-1566] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:52,821 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5d7570e3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:52,821 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3ff253ae{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:52,825 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@352ead05{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:10:52,826 [Thread-1566] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1d357e5{HTTP/1.1,[http/1.1]}{localhost:42074}
2020-04-02 05:10:52,831 [Thread-1782] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,831 [Thread-1566] INFO  server.Server (Server.java:doStart(419)) - Started @123241ms
2020-04-02 05:10:52,831 [Thread-1782] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,832 [Thread-1782] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-1825584050-172.17.0.14-1585804251760 is not formatted. Formatting ...
2020-04-02 05:10:52,832 [Thread-1782] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1825584050-172.17.0.14-1585804251760 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1825584050-172.17.0.14-1585804251760/current
2020-04-02 05:10:52,849 [Thread-1566] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39404
2020-04-02 05:10:52,850 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:10:52,850 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5ad95e32] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:52,850 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:10:52,850 [Thread-1566] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:52,851 [Socket Reader #1 for port 36031] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36031
2020-04-02 05:10:52,856 [Thread-1782] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,856 [Thread-1782] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,856 [Thread-1566] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:36031
2020-04-02 05:10:52,857 [Thread-1782] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-1825584050-172.17.0.14-1585804251760 is not formatted. Formatting ...
2020-04-02 05:10:52,857 [Thread-1782] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1825584050-172.17.0.14-1585804251760 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1825584050-172.17.0.14-1585804251760/current
2020-04-02 05:10:52,858 [Thread-1782] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1362547995;bpid=BP-1825584050-172.17.0.14-1585804251760;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1362547995;c=1585804251760;bpid=BP-1825584050-172.17.0.14-1585804251760;dnuuid=null
2020-04-02 05:10:52,859 [Thread-1782] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 83c81ef5-4f74-4d67-91c2-91999625a62c
2020-04-02 05:10:52,863 [Thread-1793] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1825584050-172.17.0.14-1585804251760 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 57ms
2020-04-02 05:10:52,864 [Thread-1794] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1825584050-172.17.0.14-1585804251760 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 57ms
2020-04-02 05:10:52,864 [Thread-1743] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1825584050-172.17.0.14-1585804251760: 58ms
2020-04-02 05:10:52,908 [Thread-1807] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:10:52,908 [Thread-1807] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1825584050-172.17.0.14-1585804251760/current/replicas doesn't exist 
2020-04-02 05:10:52,908 [Thread-1808] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:10:52,908 [Thread-1807] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 1ms
2020-04-02 05:10:52,909 [Thread-1808] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1825584050-172.17.0.14-1585804251760/current/replicas doesn't exist 
2020-04-02 05:10:52,909 [Thread-1808] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 0ms
2020-04-02 05:10:52,909 [Thread-1743] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760: 45ms
2020-04-02 05:10:52,909 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:10:52,909 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:10:52,910 [Thread-1743] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:11 AM with interval of 21600000ms
2020-04-02 05:10:52,910 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-376cb285-b919-481f-bb69-7ffe3094f1d2): finished scanning block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,910 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-df249783-84ef-42cc-bd14-74acad083d63): finished scanning block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,915 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 1e7d20d4-7343-45c7-97d6-ad56bfe86d64) service to localhost/127.0.0.1:33192 beginning handshake with NN
2020-04-02 05:10:52,916 [Thread-1566] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:10:52,916 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-376cb285-b919-481f-bb69-7ffe3094f1d2): no suitable block pools found to scan.  Waiting 1814399993 ms.
2020-04-02 05:10:52,916 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-df249783-84ef-42cc-bd14-74acad083d63): no suitable block pools found to scan.  Waiting 1814399993 ms.
2020-04-02 05:10:52,916 [Thread-1566] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:10:52,916 [IPC Server handler 8 on 33192] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42218, datanodeUuid=1e7d20d4-7343-45c7-97d6-ad56bfe86d64, infoPort=36633, infoSecurePort=0, ipcPort=40716, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760) storage 1e7d20d4-7343-45c7-97d6-ad56bfe86d64
2020-04-02 05:10:52,916 [Thread-1782] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-aa95a871-7b21-4bea-9ae1-baba6f2d158d
2020-04-02 05:10:52,916 [Thread-1782] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-04-02 05:10:52,921 [Thread-1815] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33192 starting to offer service
2020-04-02 05:10:52,921 [IPC Server handler 8 on 33192] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42218
2020-04-02 05:10:52,926 [IPC Server handler 8 on 33192] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1e7d20d4-7343-45c7-97d6-ad56bfe86d64 (127.0.0.1:42218).
2020-04-02 05:10:52,927 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 1e7d20d4-7343-45c7-97d6-ad56bfe86d64) service to localhost/127.0.0.1:33192 successfully registered with NN
2020-04-02 05:10:52,927 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33192 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:52,930 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:52,930 [IPC Server listener on 36031] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36031: starting
2020-04-02 05:10:52,932 [Thread-1566] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 36031 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:52,933 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:10:52,933 [Thread-1566] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:10:52,934 [Thread-1566] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:10:52,953 [Thread-1782] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-a7eebb61-b3a8-458e-853f-64f8b271e2c2
2020-04-02 05:10:52,953 [Thread-1815] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33192
2020-04-02 05:10:52,958 [Thread-1782] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-04-02 05:10:52,963 [Thread-1815] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:10:52,963 [IPC Server handler 0 on 33192] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-df249783-84ef-42cc-bd14-74acad083d63 for DN 127.0.0.1:42218
2020-04-02 05:10:52,963 [Thread-1566] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:10:52,967 [Thread-1566] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:10:52,967 [Thread-1566] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:52,967 [Thread-1566] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:10:52,968 [IPC Server handler 0 on 33192] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-376cb285-b919-481f-bb69-7ffe3094f1d2 for DN 127.0.0.1:42218
2020-04-02 05:10:52,968 [Thread-1782] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:10:52,968 [Thread-1566] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:10:52,968 [Thread-1566] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:52,968 [Thread-1815] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:52,968 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:10:52,968 [Thread-1815] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 1362547995. Formatting...
2020-04-02 05:10:52,968 [Thread-1782] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:10:52,968 [Thread-1815] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-44478220-5f36-49f0-9c52-b823fbd61f54 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-04-02 05:10:52,969 [Thread-1566] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:44863
2020-04-02 05:10:52,969 [IPC Server handler 7 on 33192] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:42218, datanodeUuid=1e7d20d4-7343-45c7-97d6-ad56bfe86d64, infoPort=36633, infoSecurePort=0, ipcPort=40716, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), reports.length=2
2020-04-02 05:10:52,969 [Thread-1782] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:10:52,969 [Thread-1566] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:10:52,969 [Thread-1566] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:10:52,969 [Thread-1782] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:10:52,969 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe66340f817f6e516: Processing first storage report for DS-376cb285-b919-481f-bb69-7ffe3094f1d2 from datanode 1e7d20d4-7343-45c7-97d6-ad56bfe86d64
2020-04-02 05:10:52,974 [Thread-1782] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:10:52,974 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe66340f817f6e516: from storage DS-376cb285-b919-481f-bb69-7ffe3094f1d2 node DatanodeRegistration(127.0.0.1:42218, datanodeUuid=1e7d20d4-7343-45c7-97d6-ad56bfe86d64, infoPort=36633, infoSecurePort=0, ipcPort=40716, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), blocks: 0, hasStaleStorage: true, processing time: 5 msecs, invalidatedBlocks: 0
2020-04-02 05:10:52,974 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe66340f817f6e516: Processing first storage report for DS-df249783-84ef-42cc-bd14-74acad083d63 from datanode 1e7d20d4-7343-45c7-97d6-ad56bfe86d64
2020-04-02 05:10:52,974 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:52,974 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe66340f817f6e516: from storage DS-df249783-84ef-42cc-bd14-74acad083d63 node DatanodeRegistration(127.0.0.1:42218, datanodeUuid=1e7d20d4-7343-45c7-97d6-ad56bfe86d64, infoPort=36633, infoSecurePort=0, ipcPort=40716, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:52,974 [Thread-1782] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,974 [IPC Server handler 7 on 33192] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xe66340f817f6e516
2020-04-02 05:10:52,975 [Thread-1830] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:10:52,975 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xe66340f817f6e516,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:52,975 [Thread-1831] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:10:52,975 [Thread-1815] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:52,975 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,975 [Thread-1815] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 1362547995. Formatting...
2020-04-02 05:10:52,976 [Thread-1815] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c0584930-4f4c-46d0-9193-75d5f9fe4c77 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-04-02 05:10:52,977 [Thread-1566] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:52,977 [Thread-1566] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:10:52,977 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:52,978 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:52,978 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:10:52,979 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:52,979 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:52,979 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41648
2020-04-02 05:10:52,979 [Thread-1566] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:52,981 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@60169a5a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:52,981 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5abb8dda{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:52,985 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7aa7ab7a{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:10:52,985 [Thread-1566] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6bd1a4ba{HTTP/1.1,[http/1.1]}{localhost:41648}
2020-04-02 05:10:52,990 [Thread-1566] INFO  server.Server (Server.java:doStart(419)) - Started @123400ms
2020-04-02 05:10:52,993 [Thread-1815] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,994 [Thread-1815] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:52,994 [Thread-1815] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-1825584050-172.17.0.14-1585804251760 is not formatted. Formatting ...
2020-04-02 05:10:52,994 [Thread-1815] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1825584050-172.17.0.14-1585804251760 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1825584050-172.17.0.14-1585804251760/current
2020-04-02 05:10:53,006 [Thread-1566] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44870
2020-04-02 05:10:53,006 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:10:53,006 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:10:53,006 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5405115] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:53,007 [Thread-1566] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:53,008 [Socket Reader #1 for port 42839] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42839
2020-04-02 05:10:53,013 [Thread-1566] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:42839
2020-04-02 05:10:53,016 [Thread-1815] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,016 [Thread-1815] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,017 [Thread-1815] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-1825584050-172.17.0.14-1585804251760 is not formatted. Formatting ...
2020-04-02 05:10:53,017 [Thread-1815] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1825584050-172.17.0.14-1585804251760 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1825584050-172.17.0.14-1585804251760/current
2020-04-02 05:10:53,018 [Thread-1815] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1362547995;bpid=BP-1825584050-172.17.0.14-1585804251760;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1362547995;c=1585804251760;bpid=BP-1825584050-172.17.0.14-1585804251760;dnuuid=null
2020-04-02 05:10:53,019 [Thread-1815] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 16488b6b-53c7-4acd-b664-a044af5a2079
2020-04-02 05:10:53,067 [Thread-1815] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-44478220-5f36-49f0-9c52-b823fbd61f54
2020-04-02 05:10:53,067 [Thread-1815] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-04-02 05:10:53,071 [Thread-1566] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:10:53,072 [Thread-1566] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:10:53,072 [Thread-1844] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33192 starting to offer service
2020-04-02 05:10:53,076 [Thread-1815] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c0584930-4f4c-46d0-9193-75d5f9fe4c77
2020-04-02 05:10:53,076 [Thread-1815] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-04-02 05:10:53,076 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:53,076 [IPC Server listener on 42839] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42839: starting
2020-04-02 05:10:53,076 [Thread-1815] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:10:53,081 [Thread-1844] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33192
2020-04-02 05:10:53,086 [Thread-1844] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:10:53,086 [Thread-1815] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:10:53,087 [Thread-1566] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 42839 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:53,087 [Thread-1844] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:53,087 [Thread-1815] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:10:53,087 [Thread-1815] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:10:53,087 [Thread-1844] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 1362547995. Formatting...
2020-04-02 05:10:53,087 [Thread-1815] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:10:53,087 [Thread-1844] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5a7bc7a2-105e-4c14-b21f-480e8f36f181 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-04-02 05:10:53,088 [Thread-1815] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,088 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:10:53,088 [Thread-1856] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:10:53,088 [Thread-1857] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:10:53,089 [Thread-1566] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:10:53,089 [Thread-1566] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:10:53,090 [Thread-1566] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:10:53,095 [Thread-1566] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:10:53,095 [Thread-1566] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:53,095 [Thread-1566] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:10:53,095 [Thread-1844] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:53,095 [Thread-1566] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:10:53,095 [Thread-1844] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 1362547995. Formatting...
2020-04-02 05:10:53,095 [Thread-1566] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:53,096 [Thread-1844] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-71b87dbe-79a6-441a-948a-c66886268d8a for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-04-02 05:10:53,096 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:10:53,096 [Thread-1830] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1825584050-172.17.0.14-1585804251760 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 121ms
2020-04-02 05:10:53,097 [Thread-1566] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40271
2020-04-02 05:10:53,097 [Thread-1566] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:10:53,097 [Thread-1566] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:10:53,097 [Thread-1831] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1825584050-172.17.0.14-1585804251760 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 122ms
2020-04-02 05:10:53,097 [Thread-1782] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1825584050-172.17.0.14-1585804251760: 122ms
2020-04-02 05:10:53,098 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:53,098 [Thread-1861] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:10:53,098 [Thread-1862] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:10:53,098 [Thread-1861] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1825584050-172.17.0.14-1585804251760/current/replicas doesn't exist 
2020-04-02 05:10:53,115 [Thread-1862] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1825584050-172.17.0.14-1585804251760/current/replicas doesn't exist 
2020-04-02 05:10:53,115 [Thread-1862] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 17ms
2020-04-02 05:10:53,115 [Thread-1861] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 17ms
2020-04-02 05:10:53,115 [Thread-1782] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760: 17ms
2020-04-02 05:10:53,116 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:10:53,116 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:10:53,116 [Thread-1782] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:04 AM with interval of 21600000ms
2020-04-02 05:10:53,116 [Thread-1566] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:53,116 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-aa95a871-7b21-4bea-9ae1-baba6f2d158d): finished scanning block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,116 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-a7eebb61-b3a8-458e-853f-64f8b271e2c2): finished scanning block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,117 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-aa95a871-7b21-4bea-9ae1-baba6f2d158d): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:10:53,117 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-a7eebb61-b3a8-458e-853f-64f8b271e2c2): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:10:53,123 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 83c81ef5-4f74-4d67-91c2-91999625a62c) service to localhost/127.0.0.1:33192 beginning handshake with NN
2020-04-02 05:10:53,123 [Thread-1566] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:10:53,123 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:53,124 [IPC Server handler 1 on 33192] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33561, datanodeUuid=83c81ef5-4f74-4d67-91c2-91999625a62c, infoPort=43128, infoSecurePort=0, ipcPort=38380, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760) storage 83c81ef5-4f74-4d67-91c2-91999625a62c
2020-04-02 05:10:53,124 [IPC Server handler 1 on 33192] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33561
2020-04-02 05:10:53,124 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:53,124 [IPC Server handler 1 on 33192] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 83c81ef5-4f74-4d67-91c2-91999625a62c (127.0.0.1:33561).
2020-04-02 05:10:53,125 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:10:53,125 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:53,125 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 83c81ef5-4f74-4d67-91c2-91999625a62c) service to localhost/127.0.0.1:33192 successfully registered with NN
2020-04-02 05:10:53,125 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:53,125 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33192 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:53,130 [Thread-1566] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33857
2020-04-02 05:10:53,130 [Thread-1566] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:53,135 [IPC Server handler 3 on 33192] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-aa95a871-7b21-4bea-9ae1-baba6f2d158d for DN 127.0.0.1:33561
2020-04-02 05:10:53,135 [IPC Server handler 3 on 33192] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a7eebb61-b3a8-458e-853f-64f8b271e2c2 for DN 127.0.0.1:33561
2020-04-02 05:10:53,136 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@515d6bf5{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:53,136 [IPC Server handler 6 on 33192] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:33561, datanodeUuid=83c81ef5-4f74-4d67-91c2-91999625a62c, infoPort=43128, infoSecurePort=0, ipcPort=38380, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), reports.length=2
2020-04-02 05:10:53,136 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc8dab630158baec3: Processing first storage report for DS-aa95a871-7b21-4bea-9ae1-baba6f2d158d from datanode 83c81ef5-4f74-4d67-91c2-91999625a62c
2020-04-02 05:10:53,136 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@56a26dbe{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:53,136 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc8dab630158baec3: from storage DS-aa95a871-7b21-4bea-9ae1-baba6f2d158d node DatanodeRegistration(127.0.0.1:33561, datanodeUuid=83c81ef5-4f74-4d67-91c2-91999625a62c, infoPort=43128, infoSecurePort=0, ipcPort=38380, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:53,137 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc8dab630158baec3: Processing first storage report for DS-a7eebb61-b3a8-458e-853f-64f8b271e2c2 from datanode 83c81ef5-4f74-4d67-91c2-91999625a62c
2020-04-02 05:10:53,137 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc8dab630158baec3: from storage DS-a7eebb61-b3a8-458e-853f-64f8b271e2c2 node DatanodeRegistration(127.0.0.1:33561, datanodeUuid=83c81ef5-4f74-4d67-91c2-91999625a62c, infoPort=43128, infoSecurePort=0, ipcPort=38380, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:53,137 [IPC Server handler 6 on 33192] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xc8dab630158baec3
2020-04-02 05:10:53,137 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xc8dab630158baec3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:53,137 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,139 [Thread-1844] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,139 [Thread-1844] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,139 [Thread-1844] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-1825584050-172.17.0.14-1585804251760 is not formatted. Formatting ...
2020-04-02 05:10:53,139 [Thread-1844] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1825584050-172.17.0.14-1585804251760 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1825584050-172.17.0.14-1585804251760/current
2020-04-02 05:10:53,146 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@28986821{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:10:53,147 [Thread-1566] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@36b3f486{HTTP/1.1,[http/1.1]}{localhost:33857}
2020-04-02 05:10:53,152 [Thread-1566] INFO  server.Server (Server.java:doStart(419)) - Started @123562ms
2020-04-02 05:10:53,152 [Thread-1856] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1825584050-172.17.0.14-1585804251760 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 64ms
2020-04-02 05:10:53,153 [Thread-1857] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1825584050-172.17.0.14-1585804251760 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 65ms
2020-04-02 05:10:53,153 [Thread-1815] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1825584050-172.17.0.14-1585804251760: 65ms
2020-04-02 05:10:53,154 [Thread-1871] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:10:53,154 [Thread-1872] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:10:53,154 [Thread-1871] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1825584050-172.17.0.14-1585804251760/current/replicas doesn't exist 
2020-04-02 05:10:53,154 [Thread-1872] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1825584050-172.17.0.14-1585804251760/current/replicas doesn't exist 
2020-04-02 05:10:53,154 [Thread-1871] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 0ms
2020-04-02 05:10:53,154 [Thread-1872] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 0ms
2020-04-02 05:10:53,154 [Thread-1815] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760: 1ms
2020-04-02 05:10:53,154 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:10:53,155 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:10:53,155 [Thread-1815] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:46 AM with interval of 21600000ms
2020-04-02 05:10:53,155 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-c0584930-4f4c-46d0-9193-75d5f9fe4c77): finished scanning block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,160 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 16488b6b-53c7-4acd-b664-a044af5a2079) service to localhost/127.0.0.1:33192 beginning handshake with NN
2020-04-02 05:10:53,160 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-44478220-5f36-49f0-9c52-b823fbd61f54): finished scanning block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,160 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-c0584930-4f4c-46d0-9193-75d5f9fe4c77): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:10:53,161 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-44478220-5f36-49f0-9c52-b823fbd61f54): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-04-02 05:10:53,161 [IPC Server handler 5 on 33192] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34730, datanodeUuid=16488b6b-53c7-4acd-b664-a044af5a2079, infoPort=39404, infoSecurePort=0, ipcPort=36031, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760) storage 16488b6b-53c7-4acd-b664-a044af5a2079
2020-04-02 05:10:53,161 [IPC Server handler 5 on 33192] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34730
2020-04-02 05:10:53,161 [IPC Server handler 5 on 33192] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 16488b6b-53c7-4acd-b664-a044af5a2079 (127.0.0.1:34730).
2020-04-02 05:10:53,161 [Thread-1844] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,162 [Thread-1844] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,162 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 16488b6b-53c7-4acd-b664-a044af5a2079) service to localhost/127.0.0.1:33192 successfully registered with NN
2020-04-02 05:10:53,162 [Thread-1844] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-1825584050-172.17.0.14-1585804251760 is not formatted. Formatting ...
2020-04-02 05:10:53,162 [Thread-1844] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1825584050-172.17.0.14-1585804251760 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1825584050-172.17.0.14-1585804251760/current
2020-04-02 05:10:53,162 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33192 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:53,171 [IPC Server handler 4 on 33192] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-44478220-5f36-49f0-9c52-b823fbd61f54 for DN 127.0.0.1:34730
2020-04-02 05:10:53,171 [Thread-1844] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1362547995;bpid=BP-1825584050-172.17.0.14-1585804251760;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1362547995;c=1585804251760;bpid=BP-1825584050-172.17.0.14-1585804251760;dnuuid=null
2020-04-02 05:10:53,171 [IPC Server handler 4 on 33192] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c0584930-4f4c-46d0-9193-75d5f9fe4c77 for DN 127.0.0.1:34730
2020-04-02 05:10:53,172 [Thread-1844] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 3ff577c3-573b-43a0-b836-3b2ab1d06173
2020-04-02 05:10:53,173 [IPC Server handler 8 on 33192] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:34730, datanodeUuid=16488b6b-53c7-4acd-b664-a044af5a2079, infoPort=39404, infoSecurePort=0, ipcPort=36031, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), reports.length=2
2020-04-02 05:10:53,173 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc73c4965b7f1f325: Processing first storage report for DS-44478220-5f36-49f0-9c52-b823fbd61f54 from datanode 16488b6b-53c7-4acd-b664-a044af5a2079
2020-04-02 05:10:53,173 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc73c4965b7f1f325: from storage DS-44478220-5f36-49f0-9c52-b823fbd61f54 node DatanodeRegistration(127.0.0.1:34730, datanodeUuid=16488b6b-53c7-4acd-b664-a044af5a2079, infoPort=39404, infoSecurePort=0, ipcPort=36031, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:53,173 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc73c4965b7f1f325: Processing first storage report for DS-c0584930-4f4c-46d0-9193-75d5f9fe4c77 from datanode 16488b6b-53c7-4acd-b664-a044af5a2079
2020-04-02 05:10:53,173 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc73c4965b7f1f325: from storage DS-c0584930-4f4c-46d0-9193-75d5f9fe4c77 node DatanodeRegistration(127.0.0.1:34730, datanodeUuid=16488b6b-53c7-4acd-b664-a044af5a2079, infoPort=39404, infoSecurePort=0, ipcPort=36031, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:53,173 [IPC Server handler 8 on 33192] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xc73c4965b7f1f325
2020-04-02 05:10:53,174 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xc73c4965b7f1f325,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:53,174 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,174 [Thread-1844] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5a7bc7a2-105e-4c14-b21f-480e8f36f181
2020-04-02 05:10:53,174 [Thread-1844] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-04-02 05:10:53,180 [Thread-1844] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-71b87dbe-79a6-441a-948a-c66886268d8a
2020-04-02 05:10:53,180 [Thread-1844] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-04-02 05:10:53,184 [Thread-1844] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:10:53,193 [Thread-1566] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43901
2020-04-02 05:10:53,194 [Thread-1844] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:10:53,194 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:10:53,194 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@20073326] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:53,194 [Thread-1566] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:10:53,194 [Thread-1844] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:10:53,194 [Thread-1844] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:10:53,194 [Thread-1566] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:53,195 [Thread-1844] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:10:53,195 [Thread-1844] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,195 [Thread-1880] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:10:53,195 [Thread-1881] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:10:53,195 [Socket Reader #1 for port 43897] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43897
2020-04-02 05:10:53,202 [Thread-1566] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43897
2020-04-02 05:10:53,269 [Thread-1566] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:10:53,269 [Thread-1566] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:10:53,270 [Thread-1888] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33192 starting to offer service
2020-04-02 05:10:53,275 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:53,275 [IPC Server listener on 43897] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43897: starting
2020-04-02 05:10:53,280 [Thread-1566] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43897 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:53,284 [Thread-1888] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33192
2020-04-02 05:10:53,288 [Thread-1888] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:10:53,293 [Thread-1888] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:53,298 [Thread-1888] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 1362547995. Formatting...
2020-04-02 05:10:53,298 [Thread-1888] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6113bee5-864c-4f1e-9e94-f7678df6d211 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-04-02 05:10:53,303 [IPC Server handler 0 on 33192] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:10:53,304 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:10:53,304 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:10:53,306 [Thread-1881] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1825584050-172.17.0.14-1585804251760 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 111ms
2020-04-02 05:10:53,311 [Thread-1880] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1825584050-172.17.0.14-1585804251760 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 116ms
2020-04-02 05:10:53,312 [Thread-1844] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1825584050-172.17.0.14-1585804251760: 117ms
2020-04-02 05:10:53,312 [Thread-1900] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:10:53,312 [Thread-1901] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:10:53,375 [Thread-1901] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1825584050-172.17.0.14-1585804251760/current/replicas doesn't exist 
2020-04-02 05:10:53,375 [Thread-1900] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1825584050-172.17.0.14-1585804251760/current/replicas doesn't exist 
2020-04-02 05:10:53,375 [Thread-1901] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 64ms
2020-04-02 05:10:53,375 [Thread-1900] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 64ms
2020-04-02 05:10:53,376 [Thread-1844] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760: 64ms
2020-04-02 05:10:53,376 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:10:53,376 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:10:53,376 [Thread-1844] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:17 AM with interval of 21600000ms
2020-04-02 05:10:53,376 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-5a7bc7a2-105e-4c14-b21f-480e8f36f181): finished scanning block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,376 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-71b87dbe-79a6-441a-948a-c66886268d8a): finished scanning block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,393 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 3ff577c3-573b-43a0-b836-3b2ab1d06173) service to localhost/127.0.0.1:33192 beginning handshake with NN
2020-04-02 05:10:53,393 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-5a7bc7a2-105e-4c14-b21f-480e8f36f181): no suitable block pools found to scan.  Waiting 1814399983 ms.
2020-04-02 05:10:53,393 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-71b87dbe-79a6-441a-948a-c66886268d8a): no suitable block pools found to scan.  Waiting 1814399983 ms.
2020-04-02 05:10:53,393 [IPC Server handler 7 on 33192] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44863, datanodeUuid=3ff577c3-573b-43a0-b836-3b2ab1d06173, infoPort=44870, infoSecurePort=0, ipcPort=42839, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760) storage 3ff577c3-573b-43a0-b836-3b2ab1d06173
2020-04-02 05:10:53,394 [IPC Server handler 7 on 33192] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44863
2020-04-02 05:10:53,394 [IPC Server handler 7 on 33192] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3ff577c3-573b-43a0-b836-3b2ab1d06173 (127.0.0.1:44863).
2020-04-02 05:10:53,395 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 3ff577c3-573b-43a0-b836-3b2ab1d06173) service to localhost/127.0.0.1:33192 successfully registered with NN
2020-04-02 05:10:53,395 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33192 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:53,395 [Thread-1888] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:10:53,400 [Thread-1888] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 1362547995. Formatting...
2020-04-02 05:10:53,403 [IPC Server handler 2 on 33192] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5a7bc7a2-105e-4c14-b21f-480e8f36f181 for DN 127.0.0.1:44863
2020-04-02 05:10:53,403 [Thread-1888] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0f6418d6-54d0-400a-baf5-ce11dcc0a36a for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-04-02 05:10:53,403 [IPC Server handler 2 on 33192] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-71b87dbe-79a6-441a-948a-c66886268d8a for DN 127.0.0.1:44863
2020-04-02 05:10:53,408 [IPC Server handler 1 on 33192] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:10:53,408 [IPC Server handler 3 on 33192] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:44863, datanodeUuid=3ff577c3-573b-43a0-b836-3b2ab1d06173, infoPort=44870, infoSecurePort=0, ipcPort=42839, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), reports.length=2
2020-04-02 05:10:53,408 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x9c4e0bf9fcdda8e3: Processing first storage report for DS-71b87dbe-79a6-441a-948a-c66886268d8a from datanode 3ff577c3-573b-43a0-b836-3b2ab1d06173
2020-04-02 05:10:53,409 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x9c4e0bf9fcdda8e3: from storage DS-71b87dbe-79a6-441a-948a-c66886268d8a node DatanodeRegistration(127.0.0.1:44863, datanodeUuid=3ff577c3-573b-43a0-b836-3b2ab1d06173, infoPort=44870, infoSecurePort=0, ipcPort=42839, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:53,409 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x9c4e0bf9fcdda8e3: Processing first storage report for DS-5a7bc7a2-105e-4c14-b21f-480e8f36f181 from datanode 3ff577c3-573b-43a0-b836-3b2ab1d06173
2020-04-02 05:10:53,409 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:10:53,409 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:10:53,409 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x9c4e0bf9fcdda8e3: from storage DS-5a7bc7a2-105e-4c14-b21f-480e8f36f181 node DatanodeRegistration(127.0.0.1:44863, datanodeUuid=3ff577c3-573b-43a0-b836-3b2ab1d06173, infoPort=44870, infoSecurePort=0, ipcPort=42839, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:53,409 [IPC Server handler 3 on 33192] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x9c4e0bf9fcdda8e3
2020-04-02 05:10:53,410 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x9c4e0bf9fcdda8e3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:53,410 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,419 [Thread-1888] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,419 [Thread-1888] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,419 [Thread-1888] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-1825584050-172.17.0.14-1585804251760 is not formatted. Formatting ...
2020-04-02 05:10:53,419 [Thread-1888] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1825584050-172.17.0.14-1585804251760 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1825584050-172.17.0.14-1585804251760/current
2020-04-02 05:10:53,430 [Thread-1888] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,430 [Thread-1888] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,431 [Thread-1888] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-1825584050-172.17.0.14-1585804251760 is not formatted. Formatting ...
2020-04-02 05:10:53,431 [Thread-1888] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1825584050-172.17.0.14-1585804251760 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1825584050-172.17.0.14-1585804251760/current
2020-04-02 05:10:53,432 [Thread-1888] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1362547995;bpid=BP-1825584050-172.17.0.14-1585804251760;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1362547995;c=1585804251760;bpid=BP-1825584050-172.17.0.14-1585804251760;dnuuid=null
2020-04-02 05:10:53,433 [Thread-1888] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 0b389016-dd5d-4a19-b656-862921b09d08
2020-04-02 05:10:53,435 [Thread-1888] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-6113bee5-864c-4f1e-9e94-f7678df6d211
2020-04-02 05:10:53,439 [Thread-1888] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-04-02 05:10:53,439 [Thread-1888] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-0f6418d6-54d0-400a-baf5-ce11dcc0a36a
2020-04-02 05:10:53,440 [Thread-1888] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-04-02 05:10:53,443 [Thread-1888] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:10:53,444 [Thread-1888] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:10:53,444 [Thread-1888] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:10:53,444 [Thread-1888] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:10:53,447 [Thread-1888] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:10:53,447 [Thread-1888] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,447 [Thread-1907] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:10:53,447 [Thread-1908] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:10:53,496 [Thread-1908] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1825584050-172.17.0.14-1585804251760 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 48ms
2020-04-02 05:10:53,511 [IPC Server handler 6 on 33192] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:10:53,512 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:10:53,512 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:10:53,518 [Thread-1907] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1825584050-172.17.0.14-1585804251760 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 71ms
2020-04-02 05:10:53,518 [Thread-1888] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1825584050-172.17.0.14-1585804251760: 71ms
2020-04-02 05:10:53,518 [Thread-1911] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:10:53,518 [Thread-1911] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1825584050-172.17.0.14-1585804251760/current/replicas doesn't exist 
2020-04-02 05:10:53,529 [Thread-1911] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 11ms
2020-04-02 05:10:53,529 [Thread-1912] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:10:53,529 [Thread-1912] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1825584050-172.17.0.14-1585804251760/current/replicas doesn't exist 
2020-04-02 05:10:53,530 [Thread-1912] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 1ms
2020-04-02 05:10:53,530 [Thread-1888] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1825584050-172.17.0.14-1585804251760: 12ms
2020-04-02 05:10:53,530 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:10:53,530 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1825584050-172.17.0.14-1585804251760 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:10:53,530 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-0f6418d6-54d0-400a-baf5-ce11dcc0a36a): finished scanning block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,530 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-6113bee5-864c-4f1e-9e94-f7678df6d211): finished scanning block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,531 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-0f6418d6-54d0-400a-baf5-ce11dcc0a36a): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:10:53,531 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-6113bee5-864c-4f1e-9e94-f7678df6d211): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:10:53,532 [Thread-1888] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:19 AM with interval of 21600000ms
2020-04-02 05:10:53,533 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 0b389016-dd5d-4a19-b656-862921b09d08) service to localhost/127.0.0.1:33192 beginning handshake with NN
2020-04-02 05:10:53,533 [IPC Server handler 5 on 33192] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40271, datanodeUuid=0b389016-dd5d-4a19-b656-862921b09d08, infoPort=43901, infoSecurePort=0, ipcPort=43897, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760) storage 0b389016-dd5d-4a19-b656-862921b09d08
2020-04-02 05:10:53,534 [IPC Server handler 5 on 33192] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40271
2020-04-02 05:10:53,534 [IPC Server handler 5 on 33192] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0b389016-dd5d-4a19-b656-862921b09d08 (127.0.0.1:40271).
2020-04-02 05:10:53,534 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 0b389016-dd5d-4a19-b656-862921b09d08) service to localhost/127.0.0.1:33192 successfully registered with NN
2020-04-02 05:10:53,535 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33192 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:53,548 [IPC Server handler 4 on 33192] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6113bee5-864c-4f1e-9e94-f7678df6d211 for DN 127.0.0.1:40271
2020-04-02 05:10:53,548 [IPC Server handler 4 on 33192] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0f6418d6-54d0-400a-baf5-ce11dcc0a36a for DN 127.0.0.1:40271
2020-04-02 05:10:53,549 [IPC Server handler 8 on 33192] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:40271, datanodeUuid=0b389016-dd5d-4a19-b656-862921b09d08, infoPort=43901, infoSecurePort=0, ipcPort=43897, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), reports.length=2
2020-04-02 05:10:53,549 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb83253691bf33916: Processing first storage report for DS-6113bee5-864c-4f1e-9e94-f7678df6d211 from datanode 0b389016-dd5d-4a19-b656-862921b09d08
2020-04-02 05:10:53,549 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb83253691bf33916: from storage DS-6113bee5-864c-4f1e-9e94-f7678df6d211 node DatanodeRegistration(127.0.0.1:40271, datanodeUuid=0b389016-dd5d-4a19-b656-862921b09d08, infoPort=43901, infoSecurePort=0, ipcPort=43897, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:53,550 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb83253691bf33916: Processing first storage report for DS-0f6418d6-54d0-400a-baf5-ce11dcc0a36a from datanode 0b389016-dd5d-4a19-b656-862921b09d08
2020-04-02 05:10:53,550 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb83253691bf33916: from storage DS-0f6418d6-54d0-400a-baf5-ce11dcc0a36a node DatanodeRegistration(127.0.0.1:40271, datanodeUuid=0b389016-dd5d-4a19-b656-862921b09d08, infoPort=43901, infoSecurePort=0, ipcPort=43897, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:53,550 [IPC Server handler 8 on 33192] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xb83253691bf33916
2020-04-02 05:10:53,550 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xb83253691bf33916,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:53,550 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:53,614 [IPC Server handler 9 on 33192] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:10:53,615 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:10:53,618 [IPC Server handler 0 on 33192] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-04-02 05:10:53,626 [IPC Server handler 7 on 33192] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:10:53,627 [Thread-1566] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithDNFailure(160)) - testReadWithDNFailure: file = /dnFailure_1_largeFile, fileSize = 25165947, dnFailureNum = 1
2020-04-02 05:10:53,732 [IPC Server handler 2 on 33192] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dnFailure_1_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:53,733 [IPC Server handler 1 on 33192] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /dnFailure_1_largeFile for DFSClient_NONMAPREDUCE_-1955295913_7909 at 127.0.0.1
2020-04-02 05:10:53,733 [IPC Server handler 1 on 33192] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/dnFailure_1_largeFile, holder=DFSClient_NONMAPREDUCE_-1955295913_7909, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:10:53,734 [IPC Server handler 1 on 33192] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: dnFailure_1_largeFile is added
2020-04-02 05:10:53,734 [IPC Server handler 1 on 33192] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /dnFailure_1_largeFile inode 16386 DFSClient_NONMAPREDUCE_-1955295913_7909
2020-04-02 05:10:53,735 [IPC Server handler 1 on 33192] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/dnFailure_1_largeFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:10:53,766 [IPC Server handler 3 on 33192] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /dnFailure_1_largeFile  inodeId 16386 for DFSClient_NONMAPREDUCE_-1955295913_7909
2020-04-02 05:10:53,767 [IPC Server handler 3 on 33192] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:10:53,769 [IPC Server handler 3 on 33192] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /dnFailure_1_largeFile with blk_-9223372036854775792_1001 block is added to the in-memory file system
2020-04-02 05:10:53,769 [IPC Server handler 3 on 33192] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:39262, 127.0.0.1:37793, 127.0.0.1:44863, 127.0.0.1:34730, 127.0.0.1:40271, 127.0.0.1:42218, 127.0.0.1:33561, 127.0.0.1:35998, 127.0.0.1:42157 for /dnFailure_1_largeFile
2020-04-02 05:10:53,769 [IPC Server handler 3 on 33192] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /dnFailure_1_largeFile with new block blk_-9223372036854775792_1001, current total block count is 1
2020-04-02 05:10:53,775 [DataXceiver for client DFSClient_NONMAPREDUCE_-1955295913_7909 at /127.0.0.1:59268 [Receiving block BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775792_1001 src: /127.0.0.1:59268 dest: /127.0.0.1:39262
2020-04-02 05:10:53,782 [DataXceiver for client DFSClient_NONMAPREDUCE_-1955295913_7909 at /127.0.0.1:52148 [Receiving block BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775791_1001 src: /127.0.0.1:52148 dest: /127.0.0.1:37793
2020-04-02 05:10:53,807 [DataXceiver for client DFSClient_NONMAPREDUCE_-1955295913_7909 at /127.0.0.1:60868 [Receiving block BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775790_1001 src: /127.0.0.1:60868 dest: /127.0.0.1:44863
2020-04-02 05:10:53,830 [DataXceiver for client DFSClient_NONMAPREDUCE_-1955295913_7909 at /127.0.0.1:57916 [Receiving block BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775789_1001 src: /127.0.0.1:57916 dest: /127.0.0.1:34730
2020-04-02 05:10:53,847 [DataXceiver for client DFSClient_NONMAPREDUCE_-1955295913_7909 at /127.0.0.1:60634 [Receiving block BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775788_1001 src: /127.0.0.1:60634 dest: /127.0.0.1:40271
2020-04-02 05:10:53,862 [DataXceiver for client DFSClient_NONMAPREDUCE_-1955295913_7909 at /127.0.0.1:56970 [Receiving block BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775787_1001 src: /127.0.0.1:56970 dest: /127.0.0.1:42218
2020-04-02 05:10:53,915 [DataXceiver for client DFSClient_NONMAPREDUCE_-1955295913_7909 at /127.0.0.1:41750 [Receiving block BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775786_1001 src: /127.0.0.1:41750 dest: /127.0.0.1:33561
2020-04-02 05:10:53,930 [DataXceiver for client DFSClient_NONMAPREDUCE_-1955295913_7909 at /127.0.0.1:57862 [Receiving block BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775785_1001 src: /127.0.0.1:57862 dest: /127.0.0.1:35998
2020-04-02 05:10:53,946 [DataXceiver for client DFSClient_NONMAPREDUCE_-1955295913_7909 at /127.0.0.1:37944 [Receiving block BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775784_1001 src: /127.0.0.1:37944 dest: /127.0.0.1:42157
2020-04-02 05:10:54,159 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52148, dest: /127.0.0.1:37793, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1955295913_7909, offset: 0, srvID: ef7a5af2-065c-4d9f-bd14-c3bfefed3f1a, blockid: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775791_1001, duration(ns): 363990159
2020-04-02 05:10:54,167 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60634, dest: /127.0.0.1:40271, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1955295913_7909, offset: 0, srvID: 0b389016-dd5d-4a19-b656-862921b09d08, blockid: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775788_1001, duration(ns): 304971585
2020-04-02 05:10:54,168 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60868, dest: /127.0.0.1:44863, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1955295913_7909, offset: 0, srvID: 3ff577c3-573b-43a0-b836-3b2ab1d06173, blockid: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775790_1001, duration(ns): 339939305
2020-04-02 05:10:54,170 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59268, dest: /127.0.0.1:39262, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1955295913_7909, offset: 0, srvID: 7bfacc45-16b4-4536-9f0a-c362b8e9c2d8, blockid: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775792_1001, duration(ns): 371696677
2020-04-02 05:10:54,168 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:54,175 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37944, dest: /127.0.0.1:42157, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1955295913_7909, offset: 0, srvID: a46046db-b981-4c14-88c5-394d9b0fe4db, blockid: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775784_1001, duration(ns): 216780034
2020-04-02 05:10:54,172 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:54,170 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:54,170 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:54,177 [IPC Server handler 2 on 33192] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33561, datanodeUuid=83c81ef5-4f74-4d67-91c2-91999625a62c, infoPort=43128, infoSecurePort=0, ipcPort=38380, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760) 1 blocks.
2020-04-02 05:10:54,177 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:54,177 [IPC Server handler 5 on 33192] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37793, datanodeUuid=ef7a5af2-065c-4d9f-bd14-c3bfefed3f1a, infoPort=40700, infoSecurePort=0, ipcPort=36881, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760) 1 blocks.
2020-04-02 05:10:54,177 [IPC Server handler 1 on 33192] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34730, datanodeUuid=16488b6b-53c7-4acd-b664-a044af5a2079, infoPort=39404, infoSecurePort=0, ipcPort=36031, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760) 1 blocks.
2020-04-02 05:10:54,177 [IPC Server handler 7 on 33192] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:42157, datanodeUuid=a46046db-b981-4c14-88c5-394d9b0fe4db, infoPort=33893, infoSecurePort=0, ipcPort=38407, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760) 1 blocks.
2020-04-02 05:10:54,177 [IPC Server handler 9 on 33192] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39262, datanodeUuid=7bfacc45-16b4-4536-9f0a-c362b8e9c2d8, infoPort=37609, infoSecurePort=0, ipcPort=42997, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760) 1 blocks.
2020-04-02 05:10:54,177 [IPC Server handler 0 on 33192] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:42218, datanodeUuid=1e7d20d4-7343-45c7-97d6-ad56bfe86d64, infoPort=36633, infoSecurePort=0, ipcPort=40716, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760) 1 blocks.
2020-04-02 05:10:54,177 [IPC Server handler 4 on 33192] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:44863, datanodeUuid=3ff577c3-573b-43a0-b836-3b2ab1d06173, infoPort=44870, infoSecurePort=0, ipcPort=42839, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760) 1 blocks.
2020-04-02 05:10:54,177 [IPC Server handler 8 on 33192] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40271, datanodeUuid=0b389016-dd5d-4a19-b656-862921b09d08, infoPort=43901, infoSecurePort=0, ipcPort=43897, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760) 1 blocks.
2020-04-02 05:10:54,177 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57862, dest: /127.0.0.1:35998, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1955295913_7909, offset: 0, srvID: 81d430fe-99fe-4cd9-9352-e7746c92b1dc, blockid: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775785_1001, duration(ns): 231467161
2020-04-02 05:10:54,177 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57916, dest: /127.0.0.1:34730, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1955295913_7909, offset: 0, srvID: 16488b6b-53c7-4acd-b664-a044af5a2079, blockid: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775789_1001, duration(ns): 330600803
2020-04-02 05:10:54,180 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:54,180 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:54,177 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41750, dest: /127.0.0.1:33561, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1955295913_7909, offset: 0, srvID: 83c81ef5-4f74-4d67-91c2-91999625a62c, blockid: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775786_1001, duration(ns): 241951709
2020-04-02 05:10:54,177 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56970, dest: /127.0.0.1:42218, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1955295913_7909, offset: 0, srvID: 1e7d20d4-7343-45c7-97d6-ad56bfe86d64, blockid: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775787_1001, duration(ns): 293163269
2020-04-02 05:10:54,181 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:54,181 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:54,179 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775786_1001 on 127.0.0.1:33561 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:54,178 [IPC Server handler 3 on 33192] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:35998, datanodeUuid=81d430fe-99fe-4cd9-9352-e7746c92b1dc, infoPort=39556, infoSecurePort=0, ipcPort=38829, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760) 1 blocks.
2020-04-02 05:10:54,181 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:54,181 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33561 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:10:54,182 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775786_1001 is received from 127.0.0.1:33561
2020-04-02 05:10:54,182 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33561 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:54,182 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775791_1001 on 127.0.0.1:37793 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:54,182 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:54,182 [IPC Server handler 6 on 33192] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /dnFailure_1_largeFile  inodeId 16386 for DFSClient_NONMAPREDUCE_-1955295913_7909
2020-04-02 05:10:54,182 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37793 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:10:54,182 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775791_1001 is received from 127.0.0.1:37793
2020-04-02 05:10:54,182 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37793 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:54,182 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775789_1001 on 127.0.0.1:34730 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:54,182 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:54,183 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34730 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:10:54,183 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775789_1001 is received from 127.0.0.1:34730
2020-04-02 05:10:54,183 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34730 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:54,183 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775784_1001 on 127.0.0.1:42157 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:54,183 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:54,183 [IPC Server handler 6 on 33192] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:10:54,183 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:42157 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:10:54,183 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775784_1001 is received from 127.0.0.1:42157
2020-04-02 05:10:54,183 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:42157 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:54,184 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775792_1001 on 127.0.0.1:39262 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:54,184 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:54,184 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39262 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:10:54,184 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775792_1001 is received from 127.0.0.1:39262
2020-04-02 05:10:54,184 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39262 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:54,184 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775787_1001 on 127.0.0.1:42218 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:54,184 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:54,184 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:42218 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:10:54,184 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775787_1001 is received from 127.0.0.1:42218
2020-04-02 05:10:54,184 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:42218 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:54,184 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775790_1001 on 127.0.0.1:44863 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:54,184 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:54,186 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:44863 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:10:54,186 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775790_1001 is received from 127.0.0.1:44863
2020-04-02 05:10:54,186 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:44863 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:54,186 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:40271 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:54,186 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:54,186 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:40271 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:10:54,187 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775788_1001 is received from 127.0.0.1:40271
2020-04-02 05:10:54,187 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40271 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:54,187 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775785_1001 on 127.0.0.1:35998 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:54,187 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:54,187 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:35998 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:10:54,187 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775785_1001 is received from 127.0.0.1:35998
2020-04-02 05:10:54,187 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:35998 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:54,191 [IPC Server handler 6 on 33192] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /dnFailure_1_largeFile with blk_-9223372036854775776_1002 block is added to the in-memory file system
2020-04-02 05:10:54,191 [IPC Server handler 6 on 33192] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775776_1002, replicas=127.0.0.1:42157, 127.0.0.1:35998, 127.0.0.1:34730, 127.0.0.1:39262, 127.0.0.1:42218, 127.0.0.1:44863, 127.0.0.1:33561, 127.0.0.1:37793, 127.0.0.1:40271 for /dnFailure_1_largeFile
2020-04-02 05:10:54,191 [IPC Server handler 6 on 33192] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /dnFailure_1_largeFile with new block blk_-9223372036854775776_1002, current total block count is 2
2020-04-02 05:10:54,194 [DataXceiver for client DFSClient_NONMAPREDUCE_-1955295913_7909 at /127.0.0.1:41756 [Receiving block BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775770_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775770_1002 src: /127.0.0.1:41756 dest: /127.0.0.1:33561
2020-04-02 05:10:54,194 [DataXceiver for client DFSClient_NONMAPREDUCE_-1955295913_7909 at /127.0.0.1:60644 [Receiving block BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775768_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775768_1002 src: /127.0.0.1:60644 dest: /127.0.0.1:40271
2020-04-02 05:10:54,194 [DataXceiver for client DFSClient_NONMAPREDUCE_-1955295913_7909 at /127.0.0.1:37946 [Receiving block BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775776_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775776_1002 src: /127.0.0.1:37946 dest: /127.0.0.1:42157
2020-04-02 05:10:54,194 [DataXceiver for client DFSClient_NONMAPREDUCE_-1955295913_7909 at /127.0.0.1:52164 [Receiving block BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775769_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775769_1002 src: /127.0.0.1:52164 dest: /127.0.0.1:37793
2020-04-02 05:10:54,212 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37946, dest: /127.0.0.1:42157, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1955295913_7909, offset: 0, srvID: a46046db-b981-4c14-88c5-394d9b0fe4db, blockid: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775776_1002, duration(ns): 14976424
2020-04-02 05:10:54,212 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:54,213 [IPC Server handler 2 on 33192] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:42157, datanodeUuid=a46046db-b981-4c14-88c5-394d9b0fe4db, infoPort=33893, infoSecurePort=0, ipcPort=38407, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760) 1 blocks.
2020-04-02 05:10:54,214 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775776_1002 on 127.0.0.1:42157 size 123 replicaState = FINALIZED
2020-04-02 05:10:54,214 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:54,215 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:42157 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:10:54,215 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775776_1002 is received from 127.0.0.1:42157
2020-04-02 05:10:54,215 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:42157 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:54,217 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41756, dest: /127.0.0.1:33561, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1955295913_7909, offset: 0, srvID: 83c81ef5-4f74-4d67-91c2-91999625a62c, blockid: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775770_1002, duration(ns): 19444558
2020-04-02 05:10:54,217 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:54,218 [IPC Server handler 5 on 33192] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33561, datanodeUuid=83c81ef5-4f74-4d67-91c2-91999625a62c, infoPort=43128, infoSecurePort=0, ipcPort=38380, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760) 1 blocks.
2020-04-02 05:10:54,219 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775770_1002 on 127.0.0.1:33561 size 123 replicaState = FINALIZED
2020-04-02 05:10:54,219 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:54,219 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33561 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:10:54,219 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775770_1002 is received from 127.0.0.1:33561
2020-04-02 05:10:54,219 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33561 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:54,221 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52164, dest: /127.0.0.1:37793, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1955295913_7909, offset: 0, srvID: ef7a5af2-065c-4d9f-bd14-c3bfefed3f1a, blockid: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775769_1002, duration(ns): 13234201
2020-04-02 05:10:54,221 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:54,221 [IPC Server handler 1 on 33192] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37793, datanodeUuid=ef7a5af2-065c-4d9f-bd14-c3bfefed3f1a, infoPort=40700, infoSecurePort=0, ipcPort=36881, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760) 1 blocks.
2020-04-02 05:10:54,223 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775769_1002 on 127.0.0.1:37793 size 123 replicaState = FINALIZED
2020-04-02 05:10:54,223 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:54,223 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37793 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:10:54,223 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775769_1002 is received from 127.0.0.1:37793
2020-04-02 05:10:54,223 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37793 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:54,225 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60644, dest: /127.0.0.1:40271, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1955295913_7909, offset: 0, srvID: 0b389016-dd5d-4a19-b656-862921b09d08, blockid: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775768_1002, duration(ns): 27927204
2020-04-02 05:10:54,225 [PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:54,226 [IPC Server handler 7 on 33192] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40271, datanodeUuid=0b389016-dd5d-4a19-b656-862921b09d08, infoPort=43901, infoSecurePort=0, ipcPort=43897, storageInfo=lv=-57;cid=testClusterID;nsid=1362547995;c=1585804251760) 1 blocks.
2020-04-02 05:10:54,226 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775768_1002 on 127.0.0.1:40271 size 123 replicaState = FINALIZED
2020-04-02 05:10:54,226 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:54,226 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:40271 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:10:54,226 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775768_1002 is received from 127.0.0.1:40271
2020-04-02 05:10:54,226 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40271 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:54,227 [IPC Server handler 9 on 33192] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /dnFailure_1_largeFile for DFSClient_NONMAPREDUCE_-1955295913_7909
2020-04-02 05:10:54,228 [IPC Server handler 9 on 33192] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /dnFailure_1_largeFile with 2 blocks is persisted to the file system
2020-04-02 05:10:54,228 [IPC Server handler 9 on 33192] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /dnFailure_1_largeFile is closed by DFSClient_NONMAPREDUCE_-1955295913_7909
2020-04-02 05:10:54,230 [IPC Server handler 0 on 33192] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:10:54,231 [IPC Server handler 4 on 33192] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:10:54,231 [IPC Server handler 4 on 33192] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_1_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:54,233 [Thread-1566] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:waitBlockGroupsReported(290)) - All blockGroups of file /dnFailure_1_largeFile verified to have all internalBlocks.
2020-04-02 05:10:54,233 [IPC Server handler 8 on 33192] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:10:54,234 [IPC Server handler 8 on 33192] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_1_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:54,235 [Thread-1566] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 42997 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:54,235 [Thread-1566] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:54,235 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4e3e57ac] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:54,237 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-8ddcf17d-bcd9-4ffb-8299-0cef43ba2231) exiting.
2020-04-02 05:10:54,237 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-d529772c-b95e-45f2-94c4-7c70fac21926) exiting.
2020-04-02 05:10:54,251 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@770c0a56{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:54,252 [Thread-1566] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5a088945{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:54,252 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@26b3b76c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:54,252 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7b49d269{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:54,253 [Thread-1566] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42997
2020-04-02 05:10:54,255 [IPC Server listener on 42997] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42997
2020-04-02 05:10:54,255 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:54,256 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:54,257 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 7bfacc45-16b4-4536-9f0a-c362b8e9c2d8) service to localhost/127.0.0.1:33192
2020-04-02 05:10:54,258 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 7bfacc45-16b4-4536-9f0a-c362b8e9c2d8)
2020-04-02 05:10:54,258 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:10:54,268 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1825584050-172.17.0.14-1585804251760] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:54,276 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1825584050-172.17.0.14-1585804251760] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:54,284 [Thread-1566] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:54,285 [Thread-1566] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:54,286 [Thread-1566] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:54,286 [Thread-1566] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:54,293 [Thread-1566] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:54,293 [Thread-1566] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /dnFailure_1_largeFile
2020-04-02 05:10:54,301 [Thread-1566] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /dnFailure_1_largeFile
2020-04-02 05:10:54,302 [IPC Server handler 3 on 33192] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dnFailure_1_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:54,303 [Thread-1566] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /dnFailure_1_largeFile
2020-04-02 05:10:54,303 [IPC Server handler 6 on 33192] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:10:54,304 [IPC Server handler 2 on 33192] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:10:54,305 [IPC Server handler 2 on 33192] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_1_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:54,311 [Thread-1566] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:54,312 [Thread-1566] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:39262 for blockBP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:54,313 [IPC Server handler 5 on 33192] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:10:54,313 [IPC Server handler 5 on 33192] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_1_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:10:54,315 [Thread-1566] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:39262,DS-8ddcf17d-bcd9-4ffb-8299-0cef43ba2231,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:54,584 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:54,967 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:57,592 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:10:57,975 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:00,592 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:00,975 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:03,593 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:03,975 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:06,593 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:06,976 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:07,734 [Thread-1566] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /dnFailure_1_largeFile
2020-04-02 05:11:07,740 [IPC Server handler 3 on 33192] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:07,742 [IPC Server handler 3 on 33192] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_1_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:07,748 [Thread-1566] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:07,749 [Thread-1566] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:39262 for blockBP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:07,749 [IPC Server handler 6 on 33192] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:07,752 [IPC Server handler 6 on 33192] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_1_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:07,753 [Thread-1566] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:39262,DS-8ddcf17d-bcd9-4ffb-8299-0cef43ba2231,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:11:09,594 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:09,976 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:11,149 [Thread-1566] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /dnFailure_1_largeFile
2020-04-02 05:11:11,164 [IPC Server handler 7 on 33192] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:11,165 [IPC Server handler 7 on 33192] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_1_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:11,181 [Thread-1566] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:11,181 [Thread-1566] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:39262 for blockBP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:11,182 [IPC Server handler 9 on 33192] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:11,182 [IPC Server handler 9 on 33192] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_1_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:11,184 [Thread-1566] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:39262,DS-8ddcf17d-bcd9-4ffb-8299-0cef43ba2231,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:11:12,595 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:12,977 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:14,622 [Thread-1566] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /dnFailure_1_largeFile
2020-04-02 05:11:14,624 [IPC Server handler 6 on 33192] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:14,625 [IPC Server handler 6 on 33192] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_1_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:14,636 [Thread-1566] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:14,637 [Thread-1566] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:39262 for blockBP-1825584050-172.17.0.14-1585804251760:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:14,638 [IPC Server handler 2 on 33192] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:14,638 [IPC Server handler 2 on 33192] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_1_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:14,640 [Thread-1566] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:39262,DS-8ddcf17d-bcd9-4ffb-8299-0cef43ba2231,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:11:15,595 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:15,977 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:18,601 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:18,977 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:19,744 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:11:19,744 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 8
2020-04-02 05:11:19,745 [Thread-1566] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43897 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:19,745 [Thread-1566] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:11:19,745 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@31280671] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:11:19,747 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-0f6418d6-54d0-400a-baf5-ce11dcc0a36a) exiting.
2020-04-02 05:11:19,747 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-6113bee5-864c-4f1e-9e94-f7678df6d211) exiting.
2020-04-02 05:11:19,768 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@28986821{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:11:19,768 [Thread-1566] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@36b3f486{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:11:19,769 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@56a26dbe{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:11:19,769 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@515d6bf5{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:11:19,772 [Thread-1566] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43897
2020-04-02 05:11:19,784 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:11:19,784 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:11:19,784 [IPC Server listener on 43897] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43897
2020-04-02 05:11:19,784 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 0b389016-dd5d-4a19-b656-862921b09d08) service to localhost/127.0.0.1:33192
2020-04-02 05:11:19,784 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 0b389016-dd5d-4a19-b656-862921b09d08)
2020-04-02 05:11:19,786 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:11:19,800 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1825584050-172.17.0.14-1585804251760] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:19,808 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1825584050-172.17.0.14-1585804251760] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:19,817 [Thread-1566] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:11:19,817 [Thread-1566] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:11:19,818 [Thread-1566] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:11:19,819 [Thread-1566] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:11:19,819 [Thread-1566] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:19,820 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 7
2020-04-02 05:11:19,820 [Thread-1566] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 42839 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:19,820 [Thread-1566] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:11:19,820 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@11c44c95] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:11:19,822 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-5a7bc7a2-105e-4c14-b21f-480e8f36f181) exiting.
2020-04-02 05:11:19,822 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-71b87dbe-79a6-441a-948a-c66886268d8a) exiting.
2020-04-02 05:11:19,841 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7aa7ab7a{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:11:19,841 [Thread-1566] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6bd1a4ba{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:11:19,842 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5abb8dda{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:11:19,842 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@60169a5a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:11:19,845 [Thread-1566] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42839
2020-04-02 05:11:19,863 [IPC Server listener on 42839] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42839
2020-04-02 05:11:19,863 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:11:19,863 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:11:19,866 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 3ff577c3-573b-43a0-b836-3b2ab1d06173) service to localhost/127.0.0.1:33192
2020-04-02 05:11:19,866 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 3ff577c3-573b-43a0-b836-3b2ab1d06173)
2020-04-02 05:11:19,866 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:11:19,876 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1825584050-172.17.0.14-1585804251760] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:19,886 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1825584050-172.17.0.14-1585804251760] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:19,893 [Thread-1566] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:11:19,893 [Thread-1566] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:11:19,895 [Thread-1566] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:11:19,895 [Thread-1566] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:11:19,896 [Thread-1566] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:19,896 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 6
2020-04-02 05:11:19,896 [Thread-1566] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 36031 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:19,896 [Thread-1566] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:11:19,896 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@42548a2] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:11:19,898 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-44478220-5f36-49f0-9c52-b823fbd61f54) exiting.
2020-04-02 05:11:19,898 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-c0584930-4f4c-46d0-9193-75d5f9fe4c77) exiting.
2020-04-02 05:11:19,916 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@352ead05{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:11:19,917 [Thread-1566] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1d357e5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:11:19,917 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3ff253ae{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:11:19,917 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5d7570e3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:11:19,918 [Thread-1566] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36031
2020-04-02 05:11:19,925 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:11:19,925 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:11:19,926 [IPC Server listener on 36031] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36031
2020-04-02 05:11:19,926 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 16488b6b-53c7-4acd-b664-a044af5a2079) service to localhost/127.0.0.1:33192
2020-04-02 05:11:19,926 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 16488b6b-53c7-4acd-b664-a044af5a2079)
2020-04-02 05:11:19,926 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:11:19,939 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1825584050-172.17.0.14-1585804251760] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:19,950 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1825584050-172.17.0.14-1585804251760] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:19,958 [Thread-1566] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:11:19,958 [Thread-1566] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:11:19,960 [Thread-1566] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:11:19,960 [Thread-1566] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:11:19,961 [Thread-1566] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:19,961 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 5
2020-04-02 05:11:19,961 [Thread-1566] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 38380 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:19,961 [Thread-1566] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:11:19,962 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@10ba9bed] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:11:19,964 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-a7eebb61-b3a8-458e-853f-64f8b271e2c2) exiting.
2020-04-02 05:11:19,964 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-aa95a871-7b21-4bea-9ae1-baba6f2d158d) exiting.
2020-04-02 05:11:19,982 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@124e2a55{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:11:19,985 [Thread-1566] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2039a694{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:11:19,985 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@763221f0{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:11:19,986 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2d164abf{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:11:19,987 [Thread-1566] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38380
2020-04-02 05:11:19,996 [IPC Server listener on 38380] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38380
2020-04-02 05:11:19,996 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:11:20,000 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:11:20,000 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 83c81ef5-4f74-4d67-91c2-91999625a62c) service to localhost/127.0.0.1:33192
2020-04-02 05:11:20,000 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 83c81ef5-4f74-4d67-91c2-91999625a62c)
2020-04-02 05:11:20,000 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:11:20,011 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1825584050-172.17.0.14-1585804251760] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:20,023 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1825584050-172.17.0.14-1585804251760] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:20,034 [Thread-1566] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:11:20,034 [Thread-1566] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:11:20,036 [Thread-1566] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:11:20,036 [Thread-1566] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:11:20,036 [Thread-1566] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:20,036 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 4
2020-04-02 05:11:20,037 [Thread-1566] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40716 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:20,037 [Thread-1566] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:11:20,037 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@54a22231] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:11:20,040 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-376cb285-b919-481f-bb69-7ffe3094f1d2) exiting.
2020-04-02 05:11:20,040 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-df249783-84ef-42cc-bd14-74acad083d63) exiting.
2020-04-02 05:11:20,056 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@394dca72{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:11:20,057 [Thread-1566] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@49d33174{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:11:20,057 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1af91a3a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:11:20,057 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@68b5251d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:11:20,059 [Thread-1566] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40716
2020-04-02 05:11:20,068 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:11:20,069 [IPC Server listener on 40716] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40716
2020-04-02 05:11:20,069 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:11:20,069 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 1e7d20d4-7343-45c7-97d6-ad56bfe86d64) service to localhost/127.0.0.1:33192
2020-04-02 05:11:20,072 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 1e7d20d4-7343-45c7-97d6-ad56bfe86d64)
2020-04-02 05:11:20,072 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:11:20,083 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1825584050-172.17.0.14-1585804251760] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:20,093 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1825584050-172.17.0.14-1585804251760] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:20,098 [Thread-1566] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:11:20,098 [Thread-1566] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:11:20,101 [Thread-1566] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:11:20,101 [Thread-1566] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:11:20,101 [Thread-1566] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:20,101 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 3
2020-04-02 05:11:20,101 [Thread-1566] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 42997 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:20,102 [Thread-1566] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(340)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-04-02 05:11:20,102 [Thread-1566] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42997
2020-04-02 05:11:20,102 [Thread-1566] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-7bfacc45-16b4-4536-9f0a-c362b8e9c2d8
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-7bfacc45-16b4-4536-9f0a-c362b8e9c2d8
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2146)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2048)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2038)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2017)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1991)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1984)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.tearDownCluster(ReadStripedFileWithDecodingHelper.java:97)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.tearDown(TestReadStripedFileWithDNFailure.java:64)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:105)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:20,103 [Thread-1566] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(190)) - AsyncDiskService has already shut down.
2020-04-02 05:11:20,103 [Thread-1566] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(174)) - AsyncLazyPersistService has already shut down.
2020-04-02 05:11:20,103 [Thread-1566] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:20,103 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:11:20,103 [Thread-1566] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 38407 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:20,103 [Thread-1566] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:11:20,104 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@42f8c61a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:11:20,107 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-21e773fb-913d-412f-b6c4-3cd7a15b4115) exiting.
2020-04-02 05:11:20,107 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-3c042c06-aa2e-4955-ae1b-243e515da044) exiting.
2020-04-02 05:11:20,127 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@759962e6{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:11:20,128 [Thread-1566] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7507fae4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:11:20,128 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@77f1bfd6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:11:20,128 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@77582674{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:11:20,130 [Thread-1566] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38407
2020-04-02 05:11:20,141 [IPC Server listener on 38407] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38407
2020-04-02 05:11:20,141 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:11:20,141 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:11:20,145 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid a46046db-b981-4c14-88c5-394d9b0fe4db) service to localhost/127.0.0.1:33192
2020-04-02 05:11:20,145 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid a46046db-b981-4c14-88c5-394d9b0fe4db)
2020-04-02 05:11:20,146 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:11:20,156 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1825584050-172.17.0.14-1585804251760] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:20,163 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1825584050-172.17.0.14-1585804251760] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:20,172 [Thread-1566] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:11:20,173 [Thread-1566] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:11:20,175 [Thread-1566] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:11:20,175 [Thread-1566] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:11:20,180 [Thread-1566] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:20,180 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:11:20,180 [Thread-1566] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 38829 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:20,181 [Thread-1566] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:11:20,181 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@56479ab8] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:11:20,184 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-0dd3d6d9-31c0-472a-86df-a834121a9690) exiting.
2020-04-02 05:11:20,184 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-15b45324-a78a-41f6-9bfa-459867e3b0d4) exiting.
2020-04-02 05:11:20,200 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@285297ec{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:11:20,201 [Thread-1566] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@52ab0242{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:11:20,201 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@35e295a8{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:11:20,201 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7c3a5217{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:11:20,202 [Thread-1566] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38829
2020-04-02 05:11:20,207 [IPC Server listener on 38829] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38829
2020-04-02 05:11:20,207 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:11:20,207 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:11:20,210 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 81d430fe-99fe-4cd9-9352-e7746c92b1dc) service to localhost/127.0.0.1:33192
2020-04-02 05:11:20,210 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid 81d430fe-99fe-4cd9-9352-e7746c92b1dc)
2020-04-02 05:11:20,210 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:11:20,216 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1825584050-172.17.0.14-1585804251760] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:20,226 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1825584050-172.17.0.14-1585804251760] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:20,228 [Thread-1566] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:11:20,228 [Thread-1566] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:11:20,230 [Thread-1566] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:11:20,230 [Thread-1566] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:11:20,231 [Thread-1566] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:20,231 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:11:20,231 [Thread-1566] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 36881 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:20,231 [Thread-1566] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:11:20,231 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@8004958] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:11:20,233 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-7201f093-3afa-49ae-83b4-ac5a5dd9b8f0) exiting.
2020-04-02 05:11:20,233 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-46c7fa34-d414-4b4c-99c7-6190349b7c72) exiting.
2020-04-02 05:11:20,252 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@77154e28{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:11:20,253 [Thread-1566] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@56b1ce12{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:11:20,253 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4f4d34c9{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:11:20,253 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2c02397b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:11:20,255 [Thread-1566] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36881
2020-04-02 05:11:20,266 [IPC Server listener on 36881] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36881
2020-04-02 05:11:20,266 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:11:20,266 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:11:20,269 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid ef7a5af2-065c-4d9f-bd14-c3bfefed3f1a) service to localhost/127.0.0.1:33192
2020-04-02 05:11:20,269 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1825584050-172.17.0.14-1585804251760 (Datanode Uuid ef7a5af2-065c-4d9f-bd14-c3bfefed3f1a)
2020-04-02 05:11:20,269 [BP-1825584050-172.17.0.14-1585804251760 heartbeating to localhost/127.0.0.1:33192] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1825584050-172.17.0.14-1585804251760
2020-04-02 05:11:20,280 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1825584050-172.17.0.14-1585804251760] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:20,289 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1825584050-172.17.0.14-1585804251760] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:20,318 [Thread-1566] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:11:20,319 [Thread-1566] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:11:20,321 [Thread-1566] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:11:20,321 [Thread-1566] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:11:20,322 [Thread-1566] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:20,322 [Thread-1566] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:11:20,322 [Thread-1566] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 33192 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:20,322 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:11:20,322 [Thread-1566] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 11
2020-04-02 05:11:20,322 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@51e6e7bb] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:11:20,322 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@6af1ec41] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:11:20,323 [Thread-1566] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 12 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 2 Number of syncs: 11 SyncTimes(ms): 3 3 
2020-04-02 05:11:20,324 [Thread-1566] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000012
2020-04-02 05:11:20,325 [Thread-1566] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000012
2020-04-02 05:11:20,325 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:11:20,325 [CacheReplicationMonitor(178078641)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:11:20,328 [Thread-1566] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33192
2020-04-02 05:11:20,331 [IPC Server listener on 33192] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33192
2020-04-02 05:11:20,331 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:11:20,331 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:11:20,334 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:11:20,337 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@7b16e52c] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:11:20,360 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:11:20,360 [Thread-1566] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:11:20,361 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@36515d44{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:11:20,370 [Thread-1566] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@22f4d73e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:11:20,370 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7a8a19df{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:11:20,370 [Thread-1566] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@19901873{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure#testReadWithDNFailure[3]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure#testReadWithDNFailure[3]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure#testReadWithDNFailure[4]
[msx] perform reset as unitTestCounterInClass 4 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] before_class
2020-04-02 05:11:20,399 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=9
Formatting using clusterid: testClusterID
2020-04-02 05:11:20,402 [Thread-1990] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:11:20,403 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:11:20,403 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:11:20,403 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:11:20,403 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:11:20,403 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:11:20,404 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:11:20,404 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:11:20,404 [Thread-1990] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:20,404 [Thread-1990] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:11:20,404 [Thread-1990] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:11:20,405 [Thread-1990] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:11:20,405 [Thread-1990] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:11:20
2020-04-02 05:11:20,405 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:11:20,405 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:11:20,405 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 2.0 GB = 40.1 MB
2020-04-02 05:11:20,406 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:11:20,409 [Thread-1990] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:11:20,409 [Thread-1990] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:11:20,409 [Thread-1990] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:11:20,409 [Thread-1990] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:11:20,409 [Thread-1990] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:11:20,409 [Thread-1990] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:11:20,409 [Thread-1990] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:11:20,409 [Thread-1990] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:11:20,409 [Thread-1990] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 0
2020-04-02 05:11:20,409 [Thread-1990] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:11:20,409 [Thread-1990] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:11:20,409 [Thread-1990] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:11:20,410 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:11:20,410 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:11:20,410 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 2.0 GB = 20.1 MB
2020-04-02 05:11:20,410 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:11:20,412 [Thread-1990] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:11:20,412 [Thread-1990] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:11:20,412 [Thread-1990] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:11:20,412 [Thread-1990] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:11:20,412 [Thread-1990] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:11:20,412 [Thread-1990] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:11:20,412 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:11:20,412 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:11:20,412 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 2.0 GB = 5.0 MB
2020-04-02 05:11:20,412 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:11:20,413 [Thread-1990] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:11:20,413 [Thread-1990] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:11:20,413 [Thread-1990] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:11:20,413 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:11:20,413 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:11:20,413 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:11:20,413 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:11:20,413 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 2.0 GB = 616.2 KB
2020-04-02 05:11:20,413 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:11:20,415 [Thread-1990] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:20,417 [Thread-1990] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:11:20,418 [Thread-1990] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:11:20,419 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:11:20,419 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:11:20,429 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 426 bytes saved in 0 seconds .
2020-04-02 05:11:20,430 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 426 bytes saved in 0 seconds .
2020-04-02 05:11:20,432 [Thread-1990] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:11:20,433 [Thread-1990] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:11:20,433 [Thread-1990] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:11:20,433 [Thread-1990] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:11:20,433 [Thread-1990] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:11:20,486 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@25aaae44] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:11:20,486 [Thread-1990] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:11:20,486 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:20,487 [Thread-1990] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:11:20,487 [Thread-1990] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:11:20,487 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:20,488 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:11:20,488 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:11:20,488 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:11:20,488 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:11:20,489 [Thread-1990] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:11:20,489 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:11:20,490 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44532
2020-04-02 05:11:20,490 [Thread-1990] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:11:20,491 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1711039f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:11:20,491 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@25905278{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:11:20,493 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@67ae4b43{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:11:20,494 [Thread-1990] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6c59b394{HTTP/1.1,[http/1.1]}{localhost:44532}
2020-04-02 05:11:20,499 [Thread-1990] INFO  server.Server (Server.java:doStart(419)) - Started @150909ms
2020-04-02 05:11:20,499 [Thread-1990] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:11:20,500 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:11:20,500 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:11:20,500 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:11:20,500 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:11:20,500 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:11:20,500 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:11:20,500 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:11:20,500 [Thread-1990] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:20,500 [Thread-1990] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:11:20,500 [Thread-1990] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:11:20,501 [Thread-1990] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:11:20,501 [Thread-1990] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:11:20
2020-04-02 05:11:20,501 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:11:20,501 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:11:20,501 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 2.0 GB = 40.1 MB
2020-04-02 05:11:20,501 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:11:20,504 [Thread-1990] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:11:20,504 [Thread-1990] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:11:20,504 [Thread-1990] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:11:20,504 [Thread-1990] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:11:20,504 [Thread-1990] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:11:20,504 [Thread-1990] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:11:20,504 [Thread-1990] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:11:20,504 [Thread-1990] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:11:20,504 [Thread-1990] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 0
2020-04-02 05:11:20,504 [Thread-1990] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:11:20,504 [Thread-1990] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:11:20,504 [Thread-1990] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:11:20,505 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:11:20,505 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:11:20,505 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 2.0 GB = 20.1 MB
2020-04-02 05:11:20,505 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:11:20,506 [Thread-1990] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:11:20,506 [Thread-1990] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:11:20,506 [Thread-1990] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:11:20,506 [Thread-1990] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:11:20,506 [Thread-1990] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:11:20,506 [Thread-1990] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:11:20,506 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:11:20,507 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:11:20,507 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 2.0 GB = 5.0 MB
2020-04-02 05:11:20,507 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:11:20,507 [Thread-1990] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:11:20,507 [Thread-1990] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:11:20,507 [Thread-1990] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:11:20,507 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:11:20,507 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:11:20,507 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:11:20,507 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:11:20,508 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 2.0 GB = 616.2 KB
2020-04-02 05:11:20,508 [Thread-1990] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:11:20,509 [Thread-1990] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:20,510 [Thread-1990] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:20,511 [Thread-1990] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:11:20,511 [Thread-1990] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:11:20,511 [Thread-1990] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:11:20,511 [Thread-1990] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:11:20,512 [Thread-1990] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:11:20,512 [Thread-1990] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:11:20,512 [Thread-1990] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:11:20,512 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:11:20,513 [Thread-1990] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:11:20,531 [Thread-1990] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:11:20,531 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 23 msecs
2020-04-02 05:11:20,532 [Thread-1990] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:11:20,532 [Thread-1990] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:11:20,532 [Socket Reader #1 for port 36901] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36901
2020-04-02 05:11:20,541 [Thread-1990] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:36901 to access this namenode/service.
2020-04-02 05:11:20,541 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:11:20,630 [Thread-1990] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:11:20,631 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@4c3efe50] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:11:20,631 [Thread-1990] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:11:20,631 [Thread-1990] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:11:20,632 [Thread-1990] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:11:20,632 [Thread-1990] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:11:20,641 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:11:20,641 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:11:20,641 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:11:20,641 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:11:20,641 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:11:20,641 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2020-04-02 05:11:20,643 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:11:20,647 [IPC Server listener on 36901] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36901: starting
2020-04-02 05:11:20,651 [Thread-1990] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:36901
2020-04-02 05:11:20,651 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:11:20,651 [Thread-1990] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:11:20,655 [Thread-1990] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:11:20,659 [Thread-1990] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 36901 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:20,665 [CacheReplicationMonitor(1687016777)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:11:20,697 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:11:20,697 [Thread-1990] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:11:20,697 [Thread-1990] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:11:20,698 [Thread-1990] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:11:20,702 [Thread-1990] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:11:20,702 [Thread-1990] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:20,703 [Thread-1990] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:11:20,703 [Thread-1990] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:11:20,703 [Thread-1990] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:20,703 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:11:20,703 [Thread-1990] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:43692
2020-04-02 05:11:20,703 [Thread-1990] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:11:20,703 [Thread-1990] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:11:20,704 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:20,705 [Thread-1990] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:11:20,705 [Thread-1990] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:11:20,705 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:20,705 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:11:20,706 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:11:20,706 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:11:20,706 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:11:20,706 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34009
2020-04-02 05:11:20,706 [Thread-1990] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:11:20,707 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@61b61cbe{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:11:20,707 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5d981ca1{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:11:20,711 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@70953f9d{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:11:20,712 [Thread-1990] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5e885d42{HTTP/1.1,[http/1.1]}{localhost:34009}
2020-04-02 05:11:20,718 [Thread-1990] INFO  server.Server (Server.java:doStart(419)) - Started @151129ms
2020-04-02 05:11:20,737 [Thread-1990] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34089
2020-04-02 05:11:20,738 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:11:20,738 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:11:20,738 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4bda9337] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:11:20,739 [Thread-1990] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:11:20,739 [Socket Reader #1 for port 36669] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36669
2020-04-02 05:11:20,745 [Thread-1990] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:36669
2020-04-02 05:11:20,807 [Thread-1990] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:11:20,807 [Thread-1990] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:11:20,808 [Thread-2044] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36901 starting to offer service
2020-04-02 05:11:20,813 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:11:20,813 [IPC Server listener on 36669] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36669: starting
2020-04-02 05:11:20,818 [Thread-1990] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 36669 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:20,825 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:11:20,825 [Thread-1990] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:11:20,825 [Thread-1990] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:11:20,826 [Thread-2044] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36901
2020-04-02 05:11:20,828 [Thread-2044] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:11:20,828 [Thread-1990] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:11:20,830 [Thread-1990] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:11:20,830 [Thread-1990] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:20,830 [Thread-1990] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:11:20,831 [Thread-1990] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:11:20,831 [Thread-1990] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:20,831 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:11:20,841 [Thread-2044] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:20,841 [Thread-1990] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:45686
2020-04-02 05:11:20,841 [Thread-2044] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 532641025. Formatting...
2020-04-02 05:11:20,841 [Thread-1990] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:11:20,841 [Thread-1990] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:11:20,841 [Thread-2044] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-17ea0ea3-2f89-4443-9a73-c1fa148db75e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:11:20,842 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:20,844 [Thread-2044] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:20,844 [Thread-1990] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:11:20,844 [Thread-2044] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 532641025. Formatting...
2020-04-02 05:11:20,844 [Thread-2044] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b35b0a2a-6443-43b5-bcc2-20c8cc6e8d8b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:11:20,844 [Thread-1990] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:11:20,845 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:20,846 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:11:20,846 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:11:20,846 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:11:20,846 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:11:20,847 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 36130
2020-04-02 05:11:20,847 [Thread-1990] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:11:20,848 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5ffcf450{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:11:20,849 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@71768790{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:11:20,852 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5de4cab2{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:11:20,853 [Thread-1990] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@265489b5{HTTP/1.1,[http/1.1]}{localhost:36130}
2020-04-02 05:11:20,856 [Thread-1990] INFO  server.Server (Server.java:doStart(419)) - Started @151266ms
2020-04-02 05:11:20,860 [Thread-2044] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:20,860 [Thread-2044] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:20,860 [Thread-2044] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-737821685-172.17.0.14-1585804280415 is not formatted. Formatting ...
2020-04-02 05:11:20,860 [Thread-2044] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-737821685-172.17.0.14-1585804280415 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-737821685-172.17.0.14-1585804280415/current
2020-04-02 05:11:20,900 [Thread-1990] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42450
2020-04-02 05:11:20,901 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:11:20,901 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4ffe3ede] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:11:20,901 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:11:20,901 [Thread-1990] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:11:20,902 [Socket Reader #1 for port 37534] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37534
2020-04-02 05:11:20,906 [Thread-1990] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:37534
2020-04-02 05:11:20,911 [Thread-2044] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:20,911 [Thread-2044] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:20,911 [Thread-2044] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-737821685-172.17.0.14-1585804280415 is not formatted. Formatting ...
2020-04-02 05:11:20,911 [Thread-2044] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-737821685-172.17.0.14-1585804280415 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-737821685-172.17.0.14-1585804280415/current
2020-04-02 05:11:20,913 [Thread-2044] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=532641025;bpid=BP-737821685-172.17.0.14-1585804280415;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=532641025;c=1585804280415;bpid=BP-737821685-172.17.0.14-1585804280415;dnuuid=null
2020-04-02 05:11:20,914 [Thread-2044] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID c8957254-ba7d-4227-8a90-4c7cb808d6a0
2020-04-02 05:11:20,971 [Thread-2044] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-17ea0ea3-2f89-4443-9a73-c1fa148db75e
2020-04-02 05:11:20,971 [Thread-1990] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:11:20,975 [Thread-2044] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:11:20,975 [Thread-1990] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:11:20,975 [Thread-2069] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36901 starting to offer service
2020-04-02 05:11:20,990 [Thread-2069] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36901
2020-04-02 05:11:20,990 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:11:20,990 [Thread-2044] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-b35b0a2a-6443-43b5-bcc2-20c8cc6e8d8b
2020-04-02 05:11:20,990 [IPC Server listener on 37534] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37534: starting
2020-04-02 05:11:20,990 [Thread-2044] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:11:21,010 [Thread-2069] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:11:21,011 [Thread-2044] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:11:21,011 [Thread-1990] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 37534 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:21,011 [Thread-2044] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:11:21,011 [Thread-2069] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:21,012 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:11:21,012 [Thread-2069] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 532641025. Formatting...
2020-04-02 05:11:21,012 [Thread-2069] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-24812541-6797-476a-a0ae-a497f78acf13 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:11:21,012 [Thread-1990] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:11:21,012 [Thread-2044] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:11:21,013 [Thread-2044] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:11:21,013 [Thread-1990] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:11:21,018 [Thread-2044] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:11:21,019 [Thread-2044] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,019 [Thread-2081] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:11:21,019 [Thread-2082] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:11:21,019 [Thread-1990] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:11:21,024 [Thread-1990] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:11:21,024 [Thread-1990] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:21,025 [Thread-1990] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:11:21,025 [Thread-1990] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:11:21,025 [Thread-2069] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:21,025 [Thread-1990] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:21,025 [Thread-2069] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 532641025. Formatting...
2020-04-02 05:11:21,025 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:11:21,025 [Thread-2069] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7dc0ecf5-a517-46d9-889e-d582832b1234 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:11:21,026 [Thread-1990] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42190
2020-04-02 05:11:21,026 [Thread-1990] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:11:21,026 [Thread-1990] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:11:21,027 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:21,029 [Thread-1990] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:11:21,029 [Thread-1990] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:11:21,030 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:21,030 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:11:21,031 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:11:21,031 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:11:21,031 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:11:21,032 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44794
2020-04-02 05:11:21,032 [Thread-1990] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:11:21,033 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@45388e04{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:11:21,034 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6c62f012{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:11:21,037 [Thread-2069] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,037 [Thread-2069] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,038 [Thread-2069] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-737821685-172.17.0.14-1585804280415 is not formatted. Formatting ...
2020-04-02 05:11:21,038 [Thread-2069] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-737821685-172.17.0.14-1585804280415 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-737821685-172.17.0.14-1585804280415/current
2020-04-02 05:11:21,038 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@37c54c80{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:11:21,038 [Thread-1990] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@266f8d3d{HTTP/1.1,[http/1.1]}{localhost:44794}
2020-04-02 05:11:21,044 [Thread-1990] INFO  server.Server (Server.java:doStart(419)) - Started @151454ms
2020-04-02 05:11:21,061 [Thread-1990] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45068
2020-04-02 05:11:21,064 [Thread-2069] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,064 [Thread-2069] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,064 [Thread-2069] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-737821685-172.17.0.14-1585804280415 is not formatted. Formatting ...
2020-04-02 05:11:21,064 [Thread-2069] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-737821685-172.17.0.14-1585804280415 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-737821685-172.17.0.14-1585804280415/current
2020-04-02 05:11:21,066 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:11:21,066 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:11:21,066 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1116fbf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:11:21,066 [Thread-2069] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=532641025;bpid=BP-737821685-172.17.0.14-1585804280415;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=532641025;c=1585804280415;bpid=BP-737821685-172.17.0.14-1585804280415;dnuuid=null
2020-04-02 05:11:21,066 [Thread-1990] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:11:21,067 [Socket Reader #1 for port 35778] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35778
2020-04-02 05:11:21,072 [Thread-2069] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 553835c2-8006-459e-ad32-9c7c65e27cf0
2020-04-02 05:11:21,074 [Thread-2069] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-24812541-6797-476a-a0ae-a497f78acf13
2020-04-02 05:11:21,074 [Thread-2069] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:11:21,081 [Thread-1990] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:35778
2020-04-02 05:11:21,081 [Thread-2069] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-7dc0ecf5-a517-46d9-889e-d582832b1234
2020-04-02 05:11:21,081 [Thread-2069] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:11:21,087 [Thread-2069] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:11:21,092 [Thread-2081] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-737821685-172.17.0.14-1585804280415 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 73ms
2020-04-02 05:11:21,094 [Thread-2082] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-737821685-172.17.0.14-1585804280415 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 71ms
2020-04-02 05:11:21,095 [Thread-2044] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-737821685-172.17.0.14-1585804280415: 76ms
2020-04-02 05:11:21,152 [Thread-2097] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:11:21,152 [Thread-2097] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-737821685-172.17.0.14-1585804280415/current/replicas doesn't exist 
2020-04-02 05:11:21,152 [Thread-2098] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:11:21,152 [Thread-2098] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-737821685-172.17.0.14-1585804280415/current/replicas doesn't exist 
2020-04-02 05:11:21,152 [Thread-2097] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:11:21,153 [Thread-2098] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:11:21,153 [Thread-2044] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-737821685-172.17.0.14-1585804280415: 58ms
2020-04-02 05:11:21,153 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:11:21,153 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:11:21,153 [Thread-2044] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:07 AM with interval of 21600000ms
2020-04-02 05:11:21,153 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-17ea0ea3-2f89-4443-9a73-c1fa148db75e): finished scanning block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,153 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-b35b0a2a-6443-43b5-bcc2-20c8cc6e8d8b): finished scanning block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,159 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid c8957254-ba7d-4227-8a90-4c7cb808d6a0) service to localhost/127.0.0.1:36901 beginning handshake with NN
2020-04-02 05:11:21,159 [Thread-2069] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:11:21,159 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-b35b0a2a-6443-43b5-bcc2-20c8cc6e8d8b): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-04-02 05:11:21,159 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-17ea0ea3-2f89-4443-9a73-c1fa148db75e): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-04-02 05:11:21,163 [IPC Server handler 4 on 36901] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43692, datanodeUuid=c8957254-ba7d-4227-8a90-4c7cb808d6a0, infoPort=34089, infoSecurePort=0, ipcPort=36669, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415) storage c8957254-ba7d-4227-8a90-4c7cb808d6a0
2020-04-02 05:11:21,163 [Thread-1990] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:11:21,163 [Thread-2069] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:11:21,163 [Thread-1990] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:11:21,163 [IPC Server handler 4 on 36901] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43692
2020-04-02 05:11:21,163 [Thread-2069] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:11:21,163 [IPC Server handler 4 on 36901] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c8957254-ba7d-4227-8a90-4c7cb808d6a0 (127.0.0.1:43692).
2020-04-02 05:11:21,163 [Thread-2104] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36901 starting to offer service
2020-04-02 05:11:21,169 [Thread-2069] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:11:21,169 [Thread-2069] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,174 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid c8957254-ba7d-4227-8a90-4c7cb808d6a0) service to localhost/127.0.0.1:36901 successfully registered with NN
2020-04-02 05:11:21,174 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:36901 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:11:21,174 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:11:21,178 [Thread-2105] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:11:21,179 [Thread-2104] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36901
2020-04-02 05:11:21,179 [Thread-2106] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:11:21,179 [IPC Server listener on 35778] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35778: starting
2020-04-02 05:11:21,184 [Thread-2104] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:11:21,188 [IPC Server handler 5 on 36901] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-17ea0ea3-2f89-4443-9a73-c1fa148db75e for DN 127.0.0.1:43692
2020-04-02 05:11:21,188 [IPC Server handler 5 on 36901] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b35b0a2a-6443-43b5-bcc2-20c8cc6e8d8b for DN 127.0.0.1:43692
2020-04-02 05:11:21,193 [IPC Server handler 2 on 36901] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:43692, datanodeUuid=c8957254-ba7d-4227-8a90-4c7cb808d6a0, infoPort=34089, infoSecurePort=0, ipcPort=36669, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), reports.length=2
2020-04-02 05:11:21,193 [Thread-1990] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 35778 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:21,194 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x268bfe1d60a92688: Processing first storage report for DS-b35b0a2a-6443-43b5-bcc2-20c8cc6e8d8b from datanode c8957254-ba7d-4227-8a90-4c7cb808d6a0
2020-04-02 05:11:21,194 [Thread-2104] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:21,194 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x268bfe1d60a92688: from storage DS-b35b0a2a-6443-43b5-bcc2-20c8cc6e8d8b node DatanodeRegistration(127.0.0.1:43692, datanodeUuid=c8957254-ba7d-4227-8a90-4c7cb808d6a0, infoPort=34089, infoSecurePort=0, ipcPort=36669, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:21,194 [Thread-2104] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 532641025. Formatting...
2020-04-02 05:11:21,194 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x268bfe1d60a92688: Processing first storage report for DS-17ea0ea3-2f89-4443-9a73-c1fa148db75e from datanode c8957254-ba7d-4227-8a90-4c7cb808d6a0
2020-04-02 05:11:21,194 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:11:21,194 [Thread-2104] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-11749287-1476-46ce-b1c7-4f7f7cb5d693 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:11:21,194 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x268bfe1d60a92688: from storage DS-17ea0ea3-2f89-4443-9a73-c1fa148db75e node DatanodeRegistration(127.0.0.1:43692, datanodeUuid=c8957254-ba7d-4227-8a90-4c7cb808d6a0, infoPort=34089, infoSecurePort=0, ipcPort=36669, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:21,195 [IPC Server handler 2 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x268bfe1d60a92688
2020-04-02 05:11:21,195 [Thread-1990] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:11:21,195 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x268bfe1d60a92688,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:11:21,195 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,195 [Thread-1990] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:11:21,196 [Thread-1990] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:11:21,200 [Thread-1990] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:11:21,200 [Thread-1990] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:21,200 [Thread-1990] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:11:21,200 [Thread-2104] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:21,200 [Thread-1990] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:11:21,201 [Thread-2104] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 532641025. Formatting...
2020-04-02 05:11:21,201 [Thread-1990] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:21,201 [Thread-2104] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f470c58f-426a-4c49-a3f0-8bc9ff1087fa for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:11:21,201 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:11:21,201 [Thread-1990] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42406
2020-04-02 05:11:21,201 [Thread-1990] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:11:21,202 [Thread-1990] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:11:21,202 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:21,204 [Thread-1990] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:11:21,205 [Thread-1990] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:11:21,205 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:21,206 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:11:21,206 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:11:21,206 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:11:21,206 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:11:21,207 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40378
2020-04-02 05:11:21,207 [Thread-1990] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:11:21,208 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7647d3e4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:11:21,208 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6cfc3b7a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:11:21,217 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5ee0e5a8{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:11:21,217 [Thread-2104] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,217 [Thread-1990] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@582fb352{HTTP/1.1,[http/1.1]}{localhost:40378}
2020-04-02 05:11:21,222 [Thread-2104] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,222 [Thread-1990] INFO  server.Server (Server.java:doStart(419)) - Started @151632ms
2020-04-02 05:11:21,222 [Thread-2104] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-737821685-172.17.0.14-1585804280415 is not formatted. Formatting ...
2020-04-02 05:11:21,222 [Thread-2104] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-737821685-172.17.0.14-1585804280415 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-737821685-172.17.0.14-1585804280415/current
2020-04-02 05:11:21,229 [Thread-2104] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,236 [Thread-2104] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,236 [Thread-2104] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-737821685-172.17.0.14-1585804280415 is not formatted. Formatting ...
2020-04-02 05:11:21,236 [Thread-2104] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-737821685-172.17.0.14-1585804280415 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-737821685-172.17.0.14-1585804280415/current
2020-04-02 05:11:21,236 [Thread-1990] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40849
2020-04-02 05:11:21,236 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:11:21,237 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:11:21,237 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@59af528a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:11:21,237 [Thread-1990] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:11:21,237 [Thread-2104] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=532641025;bpid=BP-737821685-172.17.0.14-1585804280415;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=532641025;c=1585804280415;bpid=BP-737821685-172.17.0.14-1585804280415;dnuuid=null
2020-04-02 05:11:21,237 [Socket Reader #1 for port 40631] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40631
2020-04-02 05:11:21,240 [Thread-2104] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 6b834b40-8ca0-4fca-a564-6bb4046cd449
2020-04-02 05:11:21,241 [Thread-2104] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-11749287-1476-46ce-b1c7-4f7f7cb5d693
2020-04-02 05:11:21,242 [Thread-2104] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:11:21,245 [Thread-1990] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40631
2020-04-02 05:11:21,245 [Thread-2104] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-f470c58f-426a-4c49-a3f0-8bc9ff1087fa
2020-04-02 05:11:21,248 [Thread-2104] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:11:21,248 [Thread-2104] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:11:21,254 [Thread-2105] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-737821685-172.17.0.14-1585804280415 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 76ms
2020-04-02 05:11:21,315 [Thread-1990] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:11:21,316 [Thread-1990] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:11:21,316 [Thread-2104] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:11:21,316 [Thread-2133] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36901 starting to offer service
2020-04-02 05:11:21,316 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:11:21,322 [IPC Server listener on 40631] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40631: starting
2020-04-02 05:11:21,322 [Thread-2133] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36901
2020-04-02 05:11:21,327 [Thread-1990] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40631 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:21,329 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:11:21,329 [Thread-1990] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:11:21,334 [Thread-2133] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:11:21,334 [Thread-2104] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:11:21,334 [Thread-2104] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:11:21,335 [Thread-2133] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:21,335 [Thread-2133] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 532641025. Formatting...
2020-04-02 05:11:21,335 [Thread-2133] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9b0f67b6-b69b-4045-b1a6-abcfd7a33f64 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-04-02 05:11:21,337 [Thread-2133] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:21,337 [Thread-2104] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:11:21,337 [Thread-1990] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:11:21,342 [Thread-2104] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,342 [Thread-2133] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 532641025. Formatting...
2020-04-02 05:11:21,342 [Thread-2133] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7672bfd9-de4f-46fd-91d8-65dfd959e2be for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-04-02 05:11:21,343 [Thread-2144] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:11:21,343 [Thread-1990] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:11:21,347 [Thread-2145] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:11:21,347 [Thread-2106] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-737821685-172.17.0.14-1585804280415 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 169ms
2020-04-02 05:11:21,347 [Thread-1990] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:11:21,348 [Thread-2069] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-737821685-172.17.0.14-1585804280415: 179ms
2020-04-02 05:11:21,348 [Thread-2146] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:11:21,348 [Thread-2147] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:11:21,348 [Thread-2146] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-737821685-172.17.0.14-1585804280415/current/replicas doesn't exist 
2020-04-02 05:11:21,348 [Thread-2147] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-737821685-172.17.0.14-1585804280415/current/replicas doesn't exist 
2020-04-02 05:11:21,349 [Thread-2146] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-04-02 05:11:21,349 [Thread-2147] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-04-02 05:11:21,349 [Thread-1990] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:21,349 [Thread-2069] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-737821685-172.17.0.14-1585804280415: 1ms
2020-04-02 05:11:21,349 [Thread-1990] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:11:21,349 [Thread-1990] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:11:21,350 [Thread-1990] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:21,350 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:11:21,350 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:11:21,350 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:11:21,350 [Thread-2069] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:14 AM with interval of 21600000ms
2020-04-02 05:11:21,350 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-24812541-6797-476a-a0ae-a497f78acf13): finished scanning block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,350 [Thread-1990] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:46723
2020-04-02 05:11:21,350 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-7dc0ecf5-a517-46d9-889e-d582832b1234): finished scanning block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,355 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 553835c2-8006-459e-ad32-9c7c65e27cf0) service to localhost/127.0.0.1:36901 beginning handshake with NN
2020-04-02 05:11:21,355 [Thread-1990] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:11:21,355 [Thread-1990] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:11:21,355 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-7dc0ecf5-a517-46d9-889e-d582832b1234): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:11:21,355 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-24812541-6797-476a-a0ae-a497f78acf13): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:11:21,356 [IPC Server handler 7 on 36901] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45686, datanodeUuid=553835c2-8006-459e-ad32-9c7c65e27cf0, infoPort=42450, infoSecurePort=0, ipcPort=37534, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415) storage 553835c2-8006-459e-ad32-9c7c65e27cf0
2020-04-02 05:11:21,356 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:21,356 [IPC Server handler 7 on 36901] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45686
2020-04-02 05:11:21,356 [IPC Server handler 7 on 36901] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 553835c2-8006-459e-ad32-9c7c65e27cf0 (127.0.0.1:45686).
2020-04-02 05:11:21,357 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 553835c2-8006-459e-ad32-9c7c65e27cf0) service to localhost/127.0.0.1:36901 successfully registered with NN
2020-04-02 05:11:21,357 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:36901 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:11:21,375 [IPC Server handler 8 on 36901] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-24812541-6797-476a-a0ae-a497f78acf13 for DN 127.0.0.1:45686
2020-04-02 05:11:21,375 [Thread-1990] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:11:21,380 [IPC Server handler 8 on 36901] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7dc0ecf5-a517-46d9-889e-d582832b1234 for DN 127.0.0.1:45686
2020-04-02 05:11:21,381 [Thread-1990] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:11:21,381 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:21,381 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:11:21,382 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:11:21,382 [IPC Server handler 9 on 36901] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:45686, datanodeUuid=553835c2-8006-459e-ad32-9c7c65e27cf0, infoPort=42450, infoSecurePort=0, ipcPort=37534, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), reports.length=2
2020-04-02 05:11:21,382 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:11:21,382 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:11:21,382 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x930781294f68fd6: Processing first storage report for DS-24812541-6797-476a-a0ae-a497f78acf13 from datanode 553835c2-8006-459e-ad32-9c7c65e27cf0
2020-04-02 05:11:21,382 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x930781294f68fd6: from storage DS-24812541-6797-476a-a0ae-a497f78acf13 node DatanodeRegistration(127.0.0.1:45686, datanodeUuid=553835c2-8006-459e-ad32-9c7c65e27cf0, infoPort=42450, infoSecurePort=0, ipcPort=37534, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:21,382 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x930781294f68fd6: Processing first storage report for DS-7dc0ecf5-a517-46d9-889e-d582832b1234 from datanode 553835c2-8006-459e-ad32-9c7c65e27cf0
2020-04-02 05:11:21,382 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45126
2020-04-02 05:11:21,382 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x930781294f68fd6: from storage DS-7dc0ecf5-a517-46d9-889e-d582832b1234 node DatanodeRegistration(127.0.0.1:45686, datanodeUuid=553835c2-8006-459e-ad32-9c7c65e27cf0, infoPort=42450, infoSecurePort=0, ipcPort=37534, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:21,382 [Thread-1990] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:11:21,382 [IPC Server handler 9 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x930781294f68fd6
2020-04-02 05:11:21,383 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x930781294f68fd6,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:11:21,383 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,393 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@9534b22{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:11:21,394 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@766de0a8{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:11:21,396 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7f851e30{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:11:21,396 [Thread-1990] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7a3314d{HTTP/1.1,[http/1.1]}{localhost:45126}
2020-04-02 05:11:21,399 [Thread-1990] INFO  server.Server (Server.java:doStart(419)) - Started @151809ms
2020-04-02 05:11:21,399 [Thread-2133] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,399 [Thread-2133] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,399 [Thread-2133] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-737821685-172.17.0.14-1585804280415 is not formatted. Formatting ...
2020-04-02 05:11:21,400 [Thread-2133] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-737821685-172.17.0.14-1585804280415 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-737821685-172.17.0.14-1585804280415/current
2020-04-02 05:11:21,472 [Thread-1990] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:32914
2020-04-02 05:11:21,472 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:11:21,472 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3cbf4ba3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:11:21,472 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:11:21,473 [Thread-1990] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:11:21,473 [Socket Reader #1 for port 40623] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40623
2020-04-02 05:11:21,477 [Thread-1990] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40623
2020-04-02 05:11:21,478 [Thread-2133] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,479 [Thread-2133] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,479 [Thread-2133] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-737821685-172.17.0.14-1585804280415 is not formatted. Formatting ...
2020-04-02 05:11:21,479 [Thread-2145] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-737821685-172.17.0.14-1585804280415 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 131ms
2020-04-02 05:11:21,479 [Thread-2133] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-737821685-172.17.0.14-1585804280415 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-737821685-172.17.0.14-1585804280415/current
2020-04-02 05:11:21,479 [Thread-2144] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-737821685-172.17.0.14-1585804280415 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 136ms
2020-04-02 05:11:21,480 [Thread-2133] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=532641025;bpid=BP-737821685-172.17.0.14-1585804280415;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=532641025;c=1585804280415;bpid=BP-737821685-172.17.0.14-1585804280415;dnuuid=null
2020-04-02 05:11:21,481 [Thread-2133] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID a247be67-ce61-4605-8cd9-5984ebfb0201
2020-04-02 05:11:21,543 [Thread-2104] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-737821685-172.17.0.14-1585804280415: 201ms
2020-04-02 05:11:21,544 [Thread-2163] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:11:21,544 [Thread-2164] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:11:21,544 [Thread-2163] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-737821685-172.17.0.14-1585804280415/current/replicas doesn't exist 
2020-04-02 05:11:21,544 [Thread-2164] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-737821685-172.17.0.14-1585804280415/current/replicas doesn't exist 
2020-04-02 05:11:21,544 [Thread-2163] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 0ms
2020-04-02 05:11:21,544 [Thread-2164] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 0ms
2020-04-02 05:11:21,544 [Thread-2104] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-737821685-172.17.0.14-1585804280415: 1ms
2020-04-02 05:11:21,544 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:11:21,545 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:11:21,545 [Thread-2104] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:39 AM with interval of 21600000ms
2020-04-02 05:11:21,545 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-f470c58f-426a-4c49-a3f0-8bc9ff1087fa): finished scanning block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,545 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-11749287-1476-46ce-b1c7-4f7f7cb5d693): finished scanning block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,549 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 6b834b40-8ca0-4fca-a564-6bb4046cd449) service to localhost/127.0.0.1:36901 beginning handshake with NN
2020-04-02 05:11:21,549 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-f470c58f-426a-4c49-a3f0-8bc9ff1087fa): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:11:21,549 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-11749287-1476-46ce-b1c7-4f7f7cb5d693): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:11:21,549 [Thread-1990] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:11:21,550 [Thread-1990] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:11:21,550 [IPC Server handler 0 on 36901] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42190, datanodeUuid=6b834b40-8ca0-4fca-a564-6bb4046cd449, infoPort=45068, infoSecurePort=0, ipcPort=35778, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415) storage 6b834b40-8ca0-4fca-a564-6bb4046cd449
2020-04-02 05:11:21,550 [Thread-2170] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36901 starting to offer service
2020-04-02 05:11:21,550 [IPC Server handler 0 on 36901] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42190
2020-04-02 05:11:21,555 [IPC Server listener on 40623] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40623: starting
2020-04-02 05:11:21,555 [Thread-2133] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-9b0f67b6-b69b-4045-b1a6-abcfd7a33f64
2020-04-02 05:11:21,555 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:11:21,555 [Thread-2133] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:11:21,555 [IPC Server handler 0 on 36901] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 6b834b40-8ca0-4fca-a564-6bb4046cd449 (127.0.0.1:42190).
2020-04-02 05:11:21,560 [Thread-1990] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40623 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:21,560 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 6b834b40-8ca0-4fca-a564-6bb4046cd449) service to localhost/127.0.0.1:36901 successfully registered with NN
2020-04-02 05:11:21,561 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:36901 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:11:21,561 [Thread-2170] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36901
2020-04-02 05:11:21,564 [Thread-2170] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:11:21,564 [Thread-2133] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-7672bfd9-de4f-46fd-91d8-65dfd959e2be
2020-04-02 05:11:21,564 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:11:21,564 [Thread-2133] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:11:21,572 [Thread-2170] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:21,572 [IPC Server handler 4 on 36901] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-11749287-1476-46ce-b1c7-4f7f7cb5d693 for DN 127.0.0.1:42190
2020-04-02 05:11:21,573 [Thread-2170] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 532641025. Formatting...
2020-04-02 05:11:21,573 [Thread-2133] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:11:21,573 [Thread-2170] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ea514346-939e-41eb-9868-bdfe6bf112a3 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-04-02 05:11:21,573 [IPC Server handler 4 on 36901] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f470c58f-426a-4c49-a3f0-8bc9ff1087fa for DN 127.0.0.1:42190
2020-04-02 05:11:21,573 [Thread-1990] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:11:21,574 [Thread-2133] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:11:21,574 [Thread-1990] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:11:21,575 [IPC Server handler 3 on 36901] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:42190, datanodeUuid=6b834b40-8ca0-4fca-a564-6bb4046cd449, infoPort=45068, infoSecurePort=0, ipcPort=35778, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), reports.length=2
2020-04-02 05:11:21,575 [Thread-2133] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:11:21,575 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x306083651694748e: Processing first storage report for DS-f470c58f-426a-4c49-a3f0-8bc9ff1087fa from datanode 6b834b40-8ca0-4fca-a564-6bb4046cd449
2020-04-02 05:11:21,575 [Thread-2133] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:11:21,575 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x306083651694748e: from storage DS-f470c58f-426a-4c49-a3f0-8bc9ff1087fa node DatanodeRegistration(127.0.0.1:42190, datanodeUuid=6b834b40-8ca0-4fca-a564-6bb4046cd449, infoPort=45068, infoSecurePort=0, ipcPort=35778, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:21,591 [Thread-2170] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:21,575 [Thread-1990] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:11:21,575 [Thread-2133] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:11:21,591 [Thread-1990] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:11:21,591 [Thread-2170] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 532641025. Formatting...
2020-04-02 05:11:21,591 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x306083651694748e: Processing first storage report for DS-11749287-1476-46ce-b1c7-4f7f7cb5d693 from datanode 6b834b40-8ca0-4fca-a564-6bb4046cd449
2020-04-02 05:11:21,591 [Thread-2133] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,592 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x306083651694748e: from storage DS-11749287-1476-46ce-b1c7-4f7f7cb5d693 node DatanodeRegistration(127.0.0.1:42190, datanodeUuid=6b834b40-8ca0-4fca-a564-6bb4046cd449, infoPort=45068, infoSecurePort=0, ipcPort=35778, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:11:21,591 [Thread-2170] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f890b652-532b-4cee-b75c-219f716632ef for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-04-02 05:11:21,591 [Thread-1990] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:21,592 [IPC Server handler 3 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x306083651694748e
2020-04-02 05:11:21,592 [Thread-2184] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:11:21,592 [Thread-1990] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:11:21,592 [Thread-2183] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:11:21,592 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x306083651694748e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 18 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:11:21,592 [Thread-1990] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:11:21,592 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,593 [Thread-1990] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:21,593 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:11:21,594 [Thread-1990] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:36299
2020-04-02 05:11:21,594 [Thread-1990] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:11:21,594 [Thread-1990] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:11:21,595 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:21,597 [Thread-1990] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:11:21,597 [Thread-1990] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:11:21,598 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:21,598 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:11:21,599 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:11:21,599 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:11:21,599 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:11:21,600 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44825
2020-04-02 05:11:21,600 [Thread-1990] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:11:21,601 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7a52e880{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:11:21,601 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:21,602 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@12158d61{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:11:21,604 [Thread-2170] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,604 [Thread-2170] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,604 [Thread-2170] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-737821685-172.17.0.14-1585804280415 is not formatted. Formatting ...
2020-04-02 05:11:21,604 [Thread-2170] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-737821685-172.17.0.14-1585804280415 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-737821685-172.17.0.14-1585804280415/current
2020-04-02 05:11:21,605 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@157a1250{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:11:21,606 [Thread-1990] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7c12a188{HTTP/1.1,[http/1.1]}{localhost:44825}
2020-04-02 05:11:21,613 [Thread-1990] INFO  server.Server (Server.java:doStart(419)) - Started @152023ms
2020-04-02 05:11:21,623 [Thread-2170] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,637 [Thread-2170] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,637 [Thread-1990] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41519
2020-04-02 05:11:21,637 [Thread-2170] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-737821685-172.17.0.14-1585804280415 is not formatted. Formatting ...
2020-04-02 05:11:21,638 [Thread-2170] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-737821685-172.17.0.14-1585804280415 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-737821685-172.17.0.14-1585804280415/current
2020-04-02 05:11:21,638 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:11:21,638 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@48ed51a9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:11:21,638 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:11:21,638 [Thread-1990] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:11:21,639 [Socket Reader #1 for port 35688] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35688
2020-04-02 05:11:21,646 [Thread-2170] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=532641025;bpid=BP-737821685-172.17.0.14-1585804280415;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=532641025;c=1585804280415;bpid=BP-737821685-172.17.0.14-1585804280415;dnuuid=null
2020-04-02 05:11:21,647 [Thread-2170] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 70924816-98e6-4162-8461-fc7fac066b04
2020-04-02 05:11:21,654 [Thread-2184] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-737821685-172.17.0.14-1585804280415 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 62ms
2020-04-02 05:11:21,659 [Thread-2170] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-ea514346-939e-41eb-9868-bdfe6bf112a3
2020-04-02 05:11:21,664 [Thread-2170] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-04-02 05:11:21,664 [Thread-1990] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:35688
2020-04-02 05:11:21,665 [Thread-2170] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-f890b652-532b-4cee-b75c-219f716632ef
2020-04-02 05:11:21,665 [Thread-2170] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-04-02 05:11:21,669 [Thread-2170] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:11:21,676 [Thread-2183] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-737821685-172.17.0.14-1585804280415 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 84ms
2020-04-02 05:11:21,676 [Thread-2133] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-737821685-172.17.0.14-1585804280415: 84ms
2020-04-02 05:11:21,742 [Thread-2199] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:11:21,742 [Thread-2199] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-737821685-172.17.0.14-1585804280415/current/replicas doesn't exist 
2020-04-02 05:11:21,742 [Thread-2199] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 0ms
2020-04-02 05:11:21,742 [Thread-2200] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:11:21,742 [Thread-2200] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-737821685-172.17.0.14-1585804280415/current/replicas doesn't exist 
2020-04-02 05:11:21,743 [Thread-2200] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 1ms
2020-04-02 05:11:21,743 [Thread-2133] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-737821685-172.17.0.14-1585804280415: 67ms
2020-04-02 05:11:21,743 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:11:21,743 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:11:21,743 [Thread-2133] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:24 AM with interval of 21600000ms
2020-04-02 05:11:21,743 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-7672bfd9-de4f-46fd-91d8-65dfd959e2be): finished scanning block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,743 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-9b0f67b6-b69b-4045-b1a6-abcfd7a33f64): finished scanning block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,744 [Thread-1990] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:11:21,748 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid a247be67-ce61-4605-8cd9-5984ebfb0201) service to localhost/127.0.0.1:36901 beginning handshake with NN
2020-04-02 05:11:21,748 [Thread-1990] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:11:21,748 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-9b0f67b6-b69b-4045-b1a6-abcfd7a33f64): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:11:21,748 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-7672bfd9-de4f-46fd-91d8-65dfd959e2be): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:11:21,748 [Thread-2170] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:11:21,749 [Thread-2206] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36901 starting to offer service
2020-04-02 05:11:21,753 [Thread-2170] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:11:21,753 [Thread-2170] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:11:21,753 [IPC Server handler 5 on 36901] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42406, datanodeUuid=a247be67-ce61-4605-8cd9-5984ebfb0201, infoPort=40849, infoSecurePort=0, ipcPort=40631, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415) storage a247be67-ce61-4605-8cd9-5984ebfb0201
2020-04-02 05:11:21,754 [IPC Server handler 5 on 36901] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42406
2020-04-02 05:11:21,754 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:11:21,758 [Thread-2170] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:11:21,762 [IPC Server listener on 35688] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35688: starting
2020-04-02 05:11:21,762 [IPC Server handler 5 on 36901] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a247be67-ce61-4605-8cd9-5984ebfb0201 (127.0.0.1:42406).
2020-04-02 05:11:21,763 [Thread-2170] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,768 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid a247be67-ce61-4605-8cd9-5984ebfb0201) service to localhost/127.0.0.1:36901 successfully registered with NN
2020-04-02 05:11:21,768 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:36901 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:11:21,768 [Thread-2206] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36901
2020-04-02 05:11:21,768 [Thread-2209] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:11:21,768 [Thread-2210] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:11:21,773 [IPC Server handler 6 on 36901] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9b0f67b6-b69b-4045-b1a6-abcfd7a33f64 for DN 127.0.0.1:42406
2020-04-02 05:11:21,773 [IPC Server handler 6 on 36901] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7672bfd9-de4f-46fd-91d8-65dfd959e2be for DN 127.0.0.1:42406
2020-04-02 05:11:21,774 [Thread-2206] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:11:21,775 [IPC Server handler 7 on 36901] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:42406, datanodeUuid=a247be67-ce61-4605-8cd9-5984ebfb0201, infoPort=40849, infoSecurePort=0, ipcPort=40631, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), reports.length=2
2020-04-02 05:11:21,775 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x140ffe9006931280: Processing first storage report for DS-7672bfd9-de4f-46fd-91d8-65dfd959e2be from datanode a247be67-ce61-4605-8cd9-5984ebfb0201
2020-04-02 05:11:21,775 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x140ffe9006931280: from storage DS-7672bfd9-de4f-46fd-91d8-65dfd959e2be node DatanodeRegistration(127.0.0.1:42406, datanodeUuid=a247be67-ce61-4605-8cd9-5984ebfb0201, infoPort=40849, infoSecurePort=0, ipcPort=40631, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:11:21,776 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x140ffe9006931280: Processing first storage report for DS-9b0f67b6-b69b-4045-b1a6-abcfd7a33f64 from datanode a247be67-ce61-4605-8cd9-5984ebfb0201
2020-04-02 05:11:21,776 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x140ffe9006931280: from storage DS-9b0f67b6-b69b-4045-b1a6-abcfd7a33f64 node DatanodeRegistration(127.0.0.1:42406, datanodeUuid=a247be67-ce61-4605-8cd9-5984ebfb0201, infoPort=40849, infoSecurePort=0, ipcPort=40631, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:21,776 [IPC Server handler 7 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x140ffe9006931280
2020-04-02 05:11:21,776 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x140ffe9006931280,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:11:21,776 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,776 [Thread-2206] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:21,776 [Thread-2206] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 532641025. Formatting...
2020-04-02 05:11:21,777 [Thread-2206] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-be01dd15-3d0f-4491-af22-bcb280b454cc for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-04-02 05:11:21,778 [Thread-2206] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:21,779 [Thread-2206] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 532641025. Formatting...
2020-04-02 05:11:21,779 [Thread-2206] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-aefab964-a540-4bbb-93ac-26ada6ec71a6 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-04-02 05:11:21,786 [Thread-2206] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,786 [Thread-2206] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,786 [Thread-2206] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-737821685-172.17.0.14-1585804280415 is not formatted. Formatting ...
2020-04-02 05:11:21,786 [Thread-2206] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-737821685-172.17.0.14-1585804280415 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-737821685-172.17.0.14-1585804280415/current
2020-04-02 05:11:21,793 [Thread-2206] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,793 [Thread-2206] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,793 [Thread-2206] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-737821685-172.17.0.14-1585804280415 is not formatted. Formatting ...
2020-04-02 05:11:21,793 [Thread-2206] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-737821685-172.17.0.14-1585804280415 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-737821685-172.17.0.14-1585804280415/current
2020-04-02 05:11:21,794 [Thread-2206] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=532641025;bpid=BP-737821685-172.17.0.14-1585804280415;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=532641025;c=1585804280415;bpid=BP-737821685-172.17.0.14-1585804280415;dnuuid=null
2020-04-02 05:11:21,795 [Thread-2206] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID be788e49-c7e8-4353-9d82-5f56ca74f939
2020-04-02 05:11:21,796 [Thread-2206] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-be01dd15-3d0f-4491-af22-bcb280b454cc
2020-04-02 05:11:21,796 [Thread-2206] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-04-02 05:11:21,796 [Thread-1990] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 35688 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:21,800 [Thread-2206] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-aefab964-a540-4bbb-93ac-26ada6ec71a6
2020-04-02 05:11:21,800 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:11:21,800 [Thread-2206] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-04-02 05:11:21,803 [Thread-2206] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:11:21,803 [Thread-1990] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:11:21,803 [Thread-1990] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:11:21,803 [Thread-2206] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:11:21,804 [Thread-2206] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:11:21,804 [Thread-1990] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:11:21,807 [Thread-2206] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:11:21,807 [Thread-1990] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:11:21,807 [Thread-2206] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:11:21,807 [Thread-2206] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,807 [Thread-1990] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:21,807 [Thread-1990] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:11:21,807 [Thread-2221] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:11:21,807 [Thread-2222] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:11:21,807 [Thread-1990] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:11:21,807 [Thread-1990] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:21,808 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:11:21,809 [Thread-1990] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37326
2020-04-02 05:11:21,809 [Thread-1990] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:11:21,809 [Thread-1990] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:11:21,810 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:21,811 [Thread-1990] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:11:21,811 [Thread-1990] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:11:21,811 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:21,812 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:11:21,812 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:11:21,812 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:11:21,812 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:11:21,813 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37867
2020-04-02 05:11:21,813 [Thread-1990] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:11:21,814 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5fa55ff6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:11:21,814 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@10c2bb35{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:11:21,817 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4584d55c{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:11:21,817 [Thread-1990] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@536d69f9{HTTP/1.1,[http/1.1]}{localhost:37867}
2020-04-02 05:11:21,822 [Thread-1990] INFO  server.Server (Server.java:doStart(419)) - Started @152232ms
2020-04-02 05:11:21,836 [Thread-1990] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36143
2020-04-02 05:11:21,837 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:11:21,837 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6edb9898] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:11:21,837 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:11:21,837 [Thread-1990] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:11:21,838 [Socket Reader #1 for port 46401] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46401
2020-04-02 05:11:21,844 [Thread-1990] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:46401
2020-04-02 05:11:21,847 [Thread-2209] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-737821685-172.17.0.14-1585804280415 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 78ms
2020-04-02 05:11:21,922 [Thread-1990] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:11:21,922 [Thread-1990] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:11:21,922 [Thread-2239] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36901 starting to offer service
2020-04-02 05:11:21,928 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:11:21,928 [IPC Server listener on 46401] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46401: starting
2020-04-02 05:11:21,934 [Thread-1990] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 46401 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:21,939 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:11:21,939 [Thread-2239] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36901
2020-04-02 05:11:21,943 [Thread-2239] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:11:21,943 [Thread-1990] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:11:21,943 [Thread-1990] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:11:21,944 [Thread-1990] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:11:21,948 [Thread-2239] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:21,948 [Thread-1990] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:11:21,948 [Thread-2239] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 532641025. Formatting...
2020-04-02 05:11:21,949 [Thread-1990] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:21,949 [Thread-2239] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a3206c16-1220-4224-a543-5f3c37bbaed9 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-04-02 05:11:21,949 [Thread-1990] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:11:21,949 [Thread-1990] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:11:21,949 [Thread-1990] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:21,949 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:11:21,950 [Thread-1990] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:46176
2020-04-02 05:11:21,950 [Thread-1990] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:11:21,950 [Thread-1990] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:11:21,951 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:21,951 [Thread-2239] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:21,952 [Thread-2239] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 532641025. Formatting...
2020-04-02 05:11:21,952 [Thread-2239] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-956c1afb-64ef-47eb-bd45-2d6f5b52308a for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-04-02 05:11:21,952 [Thread-1990] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:11:21,952 [Thread-2210] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-737821685-172.17.0.14-1585804280415 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 183ms
2020-04-02 05:11:21,952 [Thread-2170] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-737821685-172.17.0.14-1585804280415: 185ms
2020-04-02 05:11:21,953 [Thread-1990] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:11:21,953 [Thread-2253] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:11:21,953 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:21,953 [Thread-2254] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:11:21,953 [Thread-2253] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-737821685-172.17.0.14-1585804280415/current/replicas doesn't exist 
2020-04-02 05:11:21,953 [Thread-2254] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-737821685-172.17.0.14-1585804280415/current/replicas doesn't exist 
2020-04-02 05:11:21,953 [Thread-2253] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 1ms
2020-04-02 05:11:21,954 [Thread-2254] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 1ms
2020-04-02 05:11:21,954 [Thread-2170] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-737821685-172.17.0.14-1585804280415: 1ms
2020-04-02 05:11:21,954 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:11:21,954 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:11:21,954 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:11:21,954 [Thread-2170] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:49 AM with interval of 21600000ms
2020-04-02 05:11:21,954 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-ea514346-939e-41eb-9868-bdfe6bf112a3): finished scanning block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,954 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:11:21,959 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 70924816-98e6-4162-8461-fc7fac066b04) service to localhost/127.0.0.1:36901 beginning handshake with NN
2020-04-02 05:11:21,954 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-f890b652-532b-4cee-b75c-219f716632ef): finished scanning block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,959 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-ea514346-939e-41eb-9868-bdfe6bf112a3): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:11:21,959 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:11:21,959 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:11:21,959 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-f890b652-532b-4cee-b75c-219f716632ef): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:11:21,960 [IPC Server handler 9 on 36901] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46723, datanodeUuid=70924816-98e6-4162-8461-fc7fac066b04, infoPort=32914, infoSecurePort=0, ipcPort=40623, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415) storage 70924816-98e6-4162-8461-fc7fac066b04
2020-04-02 05:11:21,960 [IPC Server handler 9 on 36901] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46723
2020-04-02 05:11:21,960 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42548
2020-04-02 05:11:21,960 [IPC Server handler 9 on 36901] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 70924816-98e6-4162-8461-fc7fac066b04 (127.0.0.1:46723).
2020-04-02 05:11:21,960 [Thread-1990] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:11:21,960 [Thread-2222] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-737821685-172.17.0.14-1585804280415 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 154ms
2020-04-02 05:11:21,960 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 70924816-98e6-4162-8461-fc7fac066b04) service to localhost/127.0.0.1:36901 successfully registered with NN
2020-04-02 05:11:21,960 [Thread-2221] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-737821685-172.17.0.14-1585804280415 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 154ms
2020-04-02 05:11:21,970 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:36901 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:11:21,970 [Thread-2206] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-737821685-172.17.0.14-1585804280415: 163ms
2020-04-02 05:11:21,981 [Thread-2261] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:11:21,982 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@72fe25fa{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:11:21,986 [Thread-2261] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-737821685-172.17.0.14-1585804280415/current/replicas doesn't exist 
2020-04-02 05:11:21,986 [Thread-2262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:11:21,986 [IPC Server handler 0 on 36901] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ea514346-939e-41eb-9868-bdfe6bf112a3 for DN 127.0.0.1:46723
2020-04-02 05:11:21,986 [Thread-2262] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-737821685-172.17.0.14-1585804280415/current/replicas doesn't exist 
2020-04-02 05:11:21,986 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6696d46f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:11:21,987 [Thread-2262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 1ms
2020-04-02 05:11:21,986 [Thread-2261] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 0ms
2020-04-02 05:11:21,986 [Thread-2239] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,986 [IPC Server handler 0 on 36901] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f890b652-532b-4cee-b75c-219f716632ef for DN 127.0.0.1:46723
2020-04-02 05:11:21,987 [Thread-2239] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,987 [Thread-2206] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-737821685-172.17.0.14-1585804280415: 17ms
2020-04-02 05:11:21,987 [Thread-2239] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-737821685-172.17.0.14-1585804280415 is not formatted. Formatting ...
2020-04-02 05:11:21,987 [Thread-2239] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-737821685-172.17.0.14-1585804280415 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-737821685-172.17.0.14-1585804280415/current
2020-04-02 05:11:21,987 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:11:21,987 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:11:21,988 [Thread-2206] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:38 AM with interval of 21600000ms
2020-04-02 05:11:21,988 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-be01dd15-3d0f-4491-af22-bcb280b454cc): finished scanning block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,988 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-aefab964-a540-4bbb-93ac-26ada6ec71a6): finished scanning block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:21,988 [IPC Server handler 1 on 36901] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:46723, datanodeUuid=70924816-98e6-4162-8461-fc7fac066b04, infoPort=32914, infoSecurePort=0, ipcPort=40623, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), reports.length=2
2020-04-02 05:11:21,992 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid be788e49-c7e8-4353-9d82-5f56ca74f939) service to localhost/127.0.0.1:36901 beginning handshake with NN
2020-04-02 05:11:21,993 [IPC Server handler 4 on 36901] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36299, datanodeUuid=be788e49-c7e8-4353-9d82-5f56ca74f939, infoPort=41519, infoSecurePort=0, ipcPort=35688, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415) storage be788e49-c7e8-4353-9d82-5f56ca74f939
2020-04-02 05:11:21,993 [IPC Server handler 4 on 36901] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36299
2020-04-02 05:11:21,993 [IPC Server handler 4 on 36901] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN be788e49-c7e8-4353-9d82-5f56ca74f939 (127.0.0.1:36299).
2020-04-02 05:11:21,994 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid be788e49-c7e8-4353-9d82-5f56ca74f939) service to localhost/127.0.0.1:36901 successfully registered with NN
2020-04-02 05:11:21,994 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:36901 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:11:21,998 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x60a65c794eef4ed0: Processing first storage report for DS-f890b652-532b-4cee-b75c-219f716632ef from datanode 70924816-98e6-4162-8461-fc7fac066b04
2020-04-02 05:11:21,998 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x60a65c794eef4ed0: from storage DS-f890b652-532b-4cee-b75c-219f716632ef node DatanodeRegistration(127.0.0.1:46723, datanodeUuid=70924816-98e6-4162-8461-fc7fac066b04, infoPort=32914, infoSecurePort=0, ipcPort=40623, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:11:21,999 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-aefab964-a540-4bbb-93ac-26ada6ec71a6): no suitable block pools found to scan.  Waiting 1814399988 ms.
2020-04-02 05:11:21,999 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-be01dd15-3d0f-4491-af22-bcb280b454cc): no suitable block pools found to scan.  Waiting 1814399988 ms.
2020-04-02 05:11:22,005 [IPC Server handler 3 on 36901] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-be01dd15-3d0f-4491-af22-bcb280b454cc for DN 127.0.0.1:36299
2020-04-02 05:11:22,006 [IPC Server handler 3 on 36901] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-aefab964-a540-4bbb-93ac-26ada6ec71a6 for DN 127.0.0.1:36299
2020-04-02 05:11:22,006 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x60a65c794eef4ed0: Processing first storage report for DS-ea514346-939e-41eb-9868-bdfe6bf112a3 from datanode 70924816-98e6-4162-8461-fc7fac066b04
2020-04-02 05:11:22,006 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x60a65c794eef4ed0: from storage DS-ea514346-939e-41eb-9868-bdfe6bf112a3 node DatanodeRegistration(127.0.0.1:46723, datanodeUuid=70924816-98e6-4162-8461-fc7fac066b04, infoPort=32914, infoSecurePort=0, ipcPort=40623, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:22,006 [IPC Server handler 1 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x60a65c794eef4ed0
2020-04-02 05:11:22,006 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5a42432b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:11:22,007 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x60a65c794eef4ed0,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 20 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:11:22,007 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,007 [IPC Server handler 5 on 36901] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:36299, datanodeUuid=be788e49-c7e8-4353-9d82-5f56ca74f939, infoPort=41519, infoSecurePort=0, ipcPort=35688, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), reports.length=2
2020-04-02 05:11:22,007 [Thread-1990] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3c0947ab{HTTP/1.1,[http/1.1]}{localhost:42548}
2020-04-02 05:11:22,011 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xfbec2ebe569bbf5f: Processing first storage report for DS-be01dd15-3d0f-4491-af22-bcb280b454cc from datanode be788e49-c7e8-4353-9d82-5f56ca74f939
2020-04-02 05:11:22,011 [Thread-1990] INFO  server.Server (Server.java:doStart(419)) - Started @152422ms
2020-04-02 05:11:22,012 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xfbec2ebe569bbf5f: from storage DS-be01dd15-3d0f-4491-af22-bcb280b454cc node DatanodeRegistration(127.0.0.1:36299, datanodeUuid=be788e49-c7e8-4353-9d82-5f56ca74f939, infoPort=41519, infoSecurePort=0, ipcPort=35688, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:11:22,012 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xfbec2ebe569bbf5f: Processing first storage report for DS-aefab964-a540-4bbb-93ac-26ada6ec71a6 from datanode be788e49-c7e8-4353-9d82-5f56ca74f939
2020-04-02 05:11:22,012 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xfbec2ebe569bbf5f: from storage DS-aefab964-a540-4bbb-93ac-26ada6ec71a6 node DatanodeRegistration(127.0.0.1:36299, datanodeUuid=be788e49-c7e8-4353-9d82-5f56ca74f939, infoPort=41519, infoSecurePort=0, ipcPort=35688, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:22,012 [IPC Server handler 5 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xfbec2ebe569bbf5f
2020-04-02 05:11:22,012 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xfbec2ebe569bbf5f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:11:22,013 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,018 [Thread-2239] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,018 [Thread-2239] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,018 [Thread-2239] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-737821685-172.17.0.14-1585804280415 is not formatted. Formatting ...
2020-04-02 05:11:22,018 [Thread-2239] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-737821685-172.17.0.14-1585804280415 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-737821685-172.17.0.14-1585804280415/current
2020-04-02 05:11:22,020 [Thread-2239] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=532641025;bpid=BP-737821685-172.17.0.14-1585804280415;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=532641025;c=1585804280415;bpid=BP-737821685-172.17.0.14-1585804280415;dnuuid=null
2020-04-02 05:11:22,029 [Thread-1990] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37378
2020-04-02 05:11:22,031 [Thread-2239] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 3ab5d7c8-56c0-4e53-adef-4c8e2270bd45
2020-04-02 05:11:22,036 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:11:22,036 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7cbab24b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:11:22,036 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:11:22,037 [Thread-1990] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:11:22,040 [Thread-2239] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-a3206c16-1220-4224-a543-5f3c37bbaed9
2020-04-02 05:11:22,040 [Thread-2239] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-04-02 05:11:22,048 [Socket Reader #1 for port 41767] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41767
2020-04-02 05:11:22,053 [Thread-2239] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-956c1afb-64ef-47eb-bd45-2d6f5b52308a
2020-04-02 05:11:22,053 [Thread-2239] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-04-02 05:11:22,056 [Thread-2239] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:11:22,057 [Thread-1990] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:41767
2020-04-02 05:11:22,057 [Thread-2239] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:11:22,058 [Thread-2239] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:11:22,058 [Thread-2239] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:11:22,115 [Thread-2239] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:11:22,115 [Thread-2239] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,123 [Thread-1990] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:11:22,123 [Thread-1990] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:11:22,123 [Thread-2273] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:11:22,123 [Thread-2275] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:11:22,123 [Thread-2276] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36901 starting to offer service
2020-04-02 05:11:22,127 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:11:22,127 [IPC Server listener on 41767] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41767: starting
2020-04-02 05:11:22,130 [Thread-1990] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 41767 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:22,133 [Thread-2276] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36901
2020-04-02 05:11:22,137 [Thread-2276] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:11:22,138 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:11:22,139 [Thread-2276] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:22,139 [Thread-1990] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:11:22,139 [Thread-2276] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 532641025. Formatting...
2020-04-02 05:11:22,139 [Thread-1990] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:11:22,139 [Thread-2276] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-75208cb9-9a5c-45ff-a1da-2c9560af3622 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-04-02 05:11:22,140 [Thread-1990] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:11:22,144 [Thread-1990] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:11:22,144 [Thread-1990] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:22,144 [Thread-1990] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:11:22,144 [Thread-1990] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:11:22,144 [Thread-1990] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:22,145 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:11:22,145 [Thread-1990] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:35261
2020-04-02 05:11:22,145 [Thread-2276] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:22,145 [Thread-1990] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:11:22,145 [Thread-1990] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:11:22,145 [Thread-2276] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 532641025. Formatting...
2020-04-02 05:11:22,146 [Thread-2276] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-eacb6f69-2bb8-41bb-9b47-316eeaaf59d1 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-04-02 05:11:22,146 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:22,148 [Thread-1990] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:11:22,148 [Thread-1990] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:11:22,149 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:22,149 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:11:22,150 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:11:22,150 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:11:22,150 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:11:22,150 [Thread-1990] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35832
2020-04-02 05:11:22,151 [Thread-1990] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:11:22,151 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4d865687{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:11:22,152 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5485a37e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:11:22,156 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@16f3293f{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:11:22,156 [Thread-1990] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@22691ea2{HTTP/1.1,[http/1.1]}{localhost:35832}
2020-04-02 05:11:22,159 [Thread-1990] INFO  server.Server (Server.java:doStart(419)) - Started @152570ms
2020-04-02 05:11:22,160 [Thread-2276] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,161 [Thread-2276] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,161 [Thread-2276] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-737821685-172.17.0.14-1585804280415 is not formatted. Formatting ...
2020-04-02 05:11:22,161 [Thread-2276] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-737821685-172.17.0.14-1585804280415 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-737821685-172.17.0.14-1585804280415/current
2020-04-02 05:11:22,174 [Thread-1990] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38314
2020-04-02 05:11:22,175 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:11:22,175 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@62936eee] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:11:22,175 [Thread-1990] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:11:22,175 [Thread-1990] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:11:22,176 [Socket Reader #1 for port 33545] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33545
2020-04-02 05:11:22,206 [Thread-2276] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,206 [Thread-2276] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,206 [Thread-2276] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-737821685-172.17.0.14-1585804280415 is not formatted. Formatting ...
2020-04-02 05:11:22,206 [Thread-2276] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-737821685-172.17.0.14-1585804280415 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-737821685-172.17.0.14-1585804280415/current
2020-04-02 05:11:22,208 [Thread-2276] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=532641025;bpid=BP-737821685-172.17.0.14-1585804280415;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=532641025;c=1585804280415;bpid=BP-737821685-172.17.0.14-1585804280415;dnuuid=null
2020-04-02 05:11:22,209 [Thread-1990] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:33545
2020-04-02 05:11:22,209 [Thread-2276] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 151acd8e-6535-42dc-aaa5-dd6251fd470e
2020-04-02 05:11:22,214 [Thread-2275] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-737821685-172.17.0.14-1585804280415 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 91ms
2020-04-02 05:11:22,214 [Thread-2273] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-737821685-172.17.0.14-1585804280415 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 91ms
2020-04-02 05:11:22,245 [Thread-2239] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-737821685-172.17.0.14-1585804280415: 130ms
2020-04-02 05:11:22,245 [Thread-2299] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:11:22,245 [Thread-2300] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:11:22,245 [Thread-2299] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-737821685-172.17.0.14-1585804280415/current/replicas doesn't exist 
2020-04-02 05:11:22,245 [Thread-2300] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-737821685-172.17.0.14-1585804280415/current/replicas doesn't exist 
2020-04-02 05:11:22,258 [Thread-2299] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 13ms
2020-04-02 05:11:22,258 [Thread-2300] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 13ms
2020-04-02 05:11:22,258 [Thread-2239] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-737821685-172.17.0.14-1585804280415: 13ms
2020-04-02 05:11:22,258 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:11:22,258 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:11:22,258 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-956c1afb-64ef-47eb-bd45-2d6f5b52308a): finished scanning block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,258 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-a3206c16-1220-4224-a543-5f3c37bbaed9): finished scanning block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,259 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-956c1afb-64ef-47eb-bd45-2d6f5b52308a): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:11:22,259 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-a3206c16-1220-4224-a543-5f3c37bbaed9): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:11:22,264 [Thread-2276] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-75208cb9-9a5c-45ff-a1da-2c9560af3622
2020-04-02 05:11:22,264 [Thread-1990] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:11:22,264 [Thread-2239] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 11:03 AM with interval of 21600000ms
2020-04-02 05:11:22,264 [Thread-2276] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-04-02 05:11:22,267 [Thread-1990] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:11:22,269 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 3ab5d7c8-56c0-4e53-adef-4c8e2270bd45) service to localhost/127.0.0.1:36901 beginning handshake with NN
2020-04-02 05:11:22,270 [Thread-2307] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36901 starting to offer service
2020-04-02 05:11:22,272 [IPC Server handler 6 on 36901] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37326, datanodeUuid=3ab5d7c8-56c0-4e53-adef-4c8e2270bd45, infoPort=36143, infoSecurePort=0, ipcPort=46401, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415) storage 3ab5d7c8-56c0-4e53-adef-4c8e2270bd45
2020-04-02 05:11:22,272 [Thread-2276] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-eacb6f69-2bb8-41bb-9b47-316eeaaf59d1
2020-04-02 05:11:22,273 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:11:22,273 [Thread-2276] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-04-02 05:11:22,275 [IPC Server listener on 33545] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33545: starting
2020-04-02 05:11:22,275 [IPC Server handler 6 on 36901] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37326
2020-04-02 05:11:22,285 [Thread-2276] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:11:22,285 [IPC Server handler 6 on 36901] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3ab5d7c8-56c0-4e53-adef-4c8e2270bd45 (127.0.0.1:37326).
2020-04-02 05:11:22,294 [Thread-1990] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 33545 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:22,294 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 3ab5d7c8-56c0-4e53-adef-4c8e2270bd45) service to localhost/127.0.0.1:36901 successfully registered with NN
2020-04-02 05:11:22,295 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:36901 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:11:22,295 [Thread-2307] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36901
2020-04-02 05:11:22,295 [Thread-2276] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:11:22,298 [Thread-2307] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:11:22,301 [Thread-2276] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:11:22,304 [IPC Server handler 8 on 36901] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a3206c16-1220-4224-a543-5f3c37bbaed9 for DN 127.0.0.1:37326
2020-04-02 05:11:22,304 [Thread-2276] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:11:22,304 [IPC Server handler 8 on 36901] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-956c1afb-64ef-47eb-bd45-2d6f5b52308a for DN 127.0.0.1:37326
2020-04-02 05:11:22,304 [Thread-2276] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:11:22,304 [Thread-2276] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,310 [Thread-2307] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:22,313 [Thread-2321] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:11:22,313 [Thread-2320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:11:22,314 [Thread-2307] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 532641025. Formatting...
2020-04-02 05:11:22,314 [IPC Server handler 0 on 36901] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:37326, datanodeUuid=3ab5d7c8-56c0-4e53-adef-4c8e2270bd45, infoPort=36143, infoSecurePort=0, ipcPort=46401, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), reports.length=2
2020-04-02 05:11:22,315 [Thread-2307] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9fb1f019-4364-48c3-98f6-320aac9da009 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-04-02 05:11:22,318 [IPC Server handler 9 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:11:22,319 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb8221e9bcf5531f3: Processing first storage report for DS-956c1afb-64ef-47eb-bd45-2d6f5b52308a from datanode 3ab5d7c8-56c0-4e53-adef-4c8e2270bd45
2020-04-02 05:11:22,319 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb8221e9bcf5531f3: from storage DS-956c1afb-64ef-47eb-bd45-2d6f5b52308a node DatanodeRegistration(127.0.0.1:37326, datanodeUuid=3ab5d7c8-56c0-4e53-adef-4c8e2270bd45, infoPort=36143, infoSecurePort=0, ipcPort=46401, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), blocks: 0, hasStaleStorage: true, processing time: 4 msecs, invalidatedBlocks: 0
2020-04-02 05:11:22,319 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb8221e9bcf5531f3: Processing first storage report for DS-a3206c16-1220-4224-a543-5f3c37bbaed9 from datanode 3ab5d7c8-56c0-4e53-adef-4c8e2270bd45
2020-04-02 05:11:22,319 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb8221e9bcf5531f3: from storage DS-a3206c16-1220-4224-a543-5f3c37bbaed9 node DatanodeRegistration(127.0.0.1:37326, datanodeUuid=3ab5d7c8-56c0-4e53-adef-4c8e2270bd45, infoPort=36143, infoSecurePort=0, ipcPort=46401, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:22,319 [IPC Server handler 0 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xb8221e9bcf5531f3
2020-04-02 05:11:22,321 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:11:22,321 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:11:22,322 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xb8221e9bcf5531f3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 8 msec to generate and 9 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:11:22,322 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,323 [Thread-2307] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:22,324 [Thread-2307] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 532641025. Formatting...
2020-04-02 05:11:22,324 [Thread-2307] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-96ceeaeb-3486-4a38-a415-a4d4fb76925e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-04-02 05:11:22,336 [Thread-2307] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,336 [Thread-2307] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,336 [Thread-2307] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-737821685-172.17.0.14-1585804280415 is not formatted. Formatting ...
2020-04-02 05:11:22,336 [Thread-2307] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-737821685-172.17.0.14-1585804280415 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-737821685-172.17.0.14-1585804280415/current
2020-04-02 05:11:22,344 [Thread-2307] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,345 [Thread-2307] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,345 [Thread-2307] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-737821685-172.17.0.14-1585804280415 is not formatted. Formatting ...
2020-04-02 05:11:22,345 [Thread-2307] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-737821685-172.17.0.14-1585804280415 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-737821685-172.17.0.14-1585804280415/current
2020-04-02 05:11:22,346 [Thread-2307] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=532641025;bpid=BP-737821685-172.17.0.14-1585804280415;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=532641025;c=1585804280415;bpid=BP-737821685-172.17.0.14-1585804280415;dnuuid=null
2020-04-02 05:11:22,347 [Thread-2307] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 541f6320-dc70-4672-b00a-2db7cb1030b8
2020-04-02 05:11:22,348 [Thread-2307] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-9fb1f019-4364-48c3-98f6-320aac9da009
2020-04-02 05:11:22,348 [Thread-2307] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-04-02 05:11:22,350 [Thread-2307] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-96ceeaeb-3486-4a38-a415-a4d4fb76925e
2020-04-02 05:11:22,350 [Thread-2307] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-04-02 05:11:22,351 [Thread-2307] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:11:22,352 [Thread-2307] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:11:22,352 [Thread-2307] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:11:22,352 [Thread-2307] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:11:22,352 [Thread-2307] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:11:22,354 [Thread-2307] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,355 [Thread-2326] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:11:22,355 [Thread-2327] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:11:22,368 [Thread-2321] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-737821685-172.17.0.14-1585804280415 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 54ms
2020-04-02 05:11:22,375 [Thread-2320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-737821685-172.17.0.14-1585804280415 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 61ms
2020-04-02 05:11:22,375 [Thread-2276] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-737821685-172.17.0.14-1585804280415: 70ms
2020-04-02 05:11:22,375 [Thread-2328] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:11:22,375 [Thread-2329] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:11:22,375 [Thread-2328] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-737821685-172.17.0.14-1585804280415/current/replicas doesn't exist 
2020-04-02 05:11:22,375 [Thread-2329] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-737821685-172.17.0.14-1585804280415/current/replicas doesn't exist 
2020-04-02 05:11:22,375 [Thread-2328] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 1ms
2020-04-02 05:11:22,376 [Thread-2329] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 1ms
2020-04-02 05:11:22,376 [Thread-2276] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-737821685-172.17.0.14-1585804280415: 1ms
2020-04-02 05:11:22,376 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:11:22,376 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:11:22,376 [Thread-2276] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:32 AM with interval of 21600000ms
2020-04-02 05:11:22,376 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-75208cb9-9a5c-45ff-a1da-2c9560af3622): finished scanning block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,376 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-eacb6f69-2bb8-41bb-9b47-316eeaaf59d1): finished scanning block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,378 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 151acd8e-6535-42dc-aaa5-dd6251fd470e) service to localhost/127.0.0.1:36901 beginning handshake with NN
2020-04-02 05:11:22,378 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-75208cb9-9a5c-45ff-a1da-2c9560af3622): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:11:22,378 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-eacb6f69-2bb8-41bb-9b47-316eeaaf59d1): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:11:22,378 [IPC Server handler 4 on 36901] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46176, datanodeUuid=151acd8e-6535-42dc-aaa5-dd6251fd470e, infoPort=37378, infoSecurePort=0, ipcPort=41767, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415) storage 151acd8e-6535-42dc-aaa5-dd6251fd470e
2020-04-02 05:11:22,379 [IPC Server handler 4 on 36901] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46176
2020-04-02 05:11:22,379 [IPC Server handler 4 on 36901] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 151acd8e-6535-42dc-aaa5-dd6251fd470e (127.0.0.1:46176).
2020-04-02 05:11:22,379 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 151acd8e-6535-42dc-aaa5-dd6251fd470e) service to localhost/127.0.0.1:36901 successfully registered with NN
2020-04-02 05:11:22,380 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:36901 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:11:22,384 [IPC Server handler 3 on 36901] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-75208cb9-9a5c-45ff-a1da-2c9560af3622 for DN 127.0.0.1:46176
2020-04-02 05:11:22,385 [IPC Server handler 3 on 36901] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-eacb6f69-2bb8-41bb-9b47-316eeaaf59d1 for DN 127.0.0.1:46176
2020-04-02 05:11:22,386 [IPC Server handler 1 on 36901] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:46176, datanodeUuid=151acd8e-6535-42dc-aaa5-dd6251fd470e, infoPort=37378, infoSecurePort=0, ipcPort=41767, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), reports.length=2
2020-04-02 05:11:22,386 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x4d636cb7c29903e5: Processing first storage report for DS-75208cb9-9a5c-45ff-a1da-2c9560af3622 from datanode 151acd8e-6535-42dc-aaa5-dd6251fd470e
2020-04-02 05:11:22,386 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x4d636cb7c29903e5: from storage DS-75208cb9-9a5c-45ff-a1da-2c9560af3622 node DatanodeRegistration(127.0.0.1:46176, datanodeUuid=151acd8e-6535-42dc-aaa5-dd6251fd470e, infoPort=37378, infoSecurePort=0, ipcPort=41767, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:22,386 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x4d636cb7c29903e5: Processing first storage report for DS-eacb6f69-2bb8-41bb-9b47-316eeaaf59d1 from datanode 151acd8e-6535-42dc-aaa5-dd6251fd470e
2020-04-02 05:11:22,386 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x4d636cb7c29903e5: from storage DS-eacb6f69-2bb8-41bb-9b47-316eeaaf59d1 node DatanodeRegistration(127.0.0.1:46176, datanodeUuid=151acd8e-6535-42dc-aaa5-dd6251fd470e, infoPort=37378, infoSecurePort=0, ipcPort=41767, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:22,386 [IPC Server handler 1 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x4d636cb7c29903e5
2020-04-02 05:11:22,387 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x4d636cb7c29903e5,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:11:22,387 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,407 [Thread-2327] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-737821685-172.17.0.14-1585804280415 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 52ms
2020-04-02 05:11:22,418 [Thread-2326] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-737821685-172.17.0.14-1585804280415 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 64ms
2020-04-02 05:11:22,419 [Thread-2307] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-737821685-172.17.0.14-1585804280415: 64ms
2020-04-02 05:11:22,419 [Thread-2335] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:11:22,419 [Thread-2336] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:11:22,419 [Thread-2335] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-737821685-172.17.0.14-1585804280415/current/replicas doesn't exist 
2020-04-02 05:11:22,419 [Thread-2336] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-737821685-172.17.0.14-1585804280415/current/replicas doesn't exist 
2020-04-02 05:11:22,419 [Thread-2335] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 1ms
2020-04-02 05:11:22,419 [Thread-2336] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 1ms
2020-04-02 05:11:22,420 [Thread-2307] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-737821685-172.17.0.14-1585804280415: 1ms
2020-04-02 05:11:22,420 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:11:22,420 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-737821685-172.17.0.14-1585804280415 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:11:22,420 [Thread-2307] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:38 AM with interval of 21600000ms
2020-04-02 05:11:22,420 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-96ceeaeb-3486-4a38-a415-a4d4fb76925e): finished scanning block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,420 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-9fb1f019-4364-48c3-98f6-320aac9da009): finished scanning block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,423 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 541f6320-dc70-4672-b00a-2db7cb1030b8) service to localhost/127.0.0.1:36901 beginning handshake with NN
2020-04-02 05:11:22,423 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-96ceeaeb-3486-4a38-a415-a4d4fb76925e): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:11:22,423 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-9fb1f019-4364-48c3-98f6-320aac9da009): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:11:22,423 [IPC Server handler 2 on 36901] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35261, datanodeUuid=541f6320-dc70-4672-b00a-2db7cb1030b8, infoPort=38314, infoSecurePort=0, ipcPort=33545, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415) storage 541f6320-dc70-4672-b00a-2db7cb1030b8
2020-04-02 05:11:22,425 [IPC Server handler 5 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:11:22,425 [IPC Server handler 2 on 36901] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35261
2020-04-02 05:11:22,426 [IPC Server handler 2 on 36901] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 541f6320-dc70-4672-b00a-2db7cb1030b8 (127.0.0.1:35261).
2020-04-02 05:11:22,426 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:11:22,426 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:11:22,426 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 541f6320-dc70-4672-b00a-2db7cb1030b8) service to localhost/127.0.0.1:36901 successfully registered with NN
2020-04-02 05:11:22,426 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:36901 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:11:22,431 [IPC Server handler 6 on 36901] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9fb1f019-4364-48c3-98f6-320aac9da009 for DN 127.0.0.1:35261
2020-04-02 05:11:22,431 [IPC Server handler 6 on 36901] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-96ceeaeb-3486-4a38-a415-a4d4fb76925e for DN 127.0.0.1:35261
2020-04-02 05:11:22,432 [IPC Server handler 7 on 36901] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:35261, datanodeUuid=541f6320-dc70-4672-b00a-2db7cb1030b8, infoPort=38314, infoSecurePort=0, ipcPort=33545, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), reports.length=2
2020-04-02 05:11:22,432 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xde1e8c38d23a2516: Processing first storage report for DS-96ceeaeb-3486-4a38-a415-a4d4fb76925e from datanode 541f6320-dc70-4672-b00a-2db7cb1030b8
2020-04-02 05:11:22,432 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xde1e8c38d23a2516: from storage DS-96ceeaeb-3486-4a38-a415-a4d4fb76925e node DatanodeRegistration(127.0.0.1:35261, datanodeUuid=541f6320-dc70-4672-b00a-2db7cb1030b8, infoPort=38314, infoSecurePort=0, ipcPort=33545, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:11:22,433 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xde1e8c38d23a2516: Processing first storage report for DS-9fb1f019-4364-48c3-98f6-320aac9da009 from datanode 541f6320-dc70-4672-b00a-2db7cb1030b8
2020-04-02 05:11:22,433 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xde1e8c38d23a2516: from storage DS-9fb1f019-4364-48c3-98f6-320aac9da009 node DatanodeRegistration(127.0.0.1:35261, datanodeUuid=541f6320-dc70-4672-b00a-2db7cb1030b8, infoPort=38314, infoSecurePort=0, ipcPort=33545, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:22,433 [IPC Server handler 7 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xde1e8c38d23a2516
2020-04-02 05:11:22,433 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xde1e8c38d23a2516,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:11:22,433 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:22,527 [IPC Server handler 8 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:11:22,528 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:11:22,531 [IPC Server handler 9 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-04-02 05:11:22,544 [IPC Server handler 0 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:11:22,545 [Thread-1990] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithDNFailure(160)) - testReadWithDNFailure: file = /dnFailure_2_largeFile, fileSize = 25165947, dnFailureNum = 2
2020-04-02 05:11:22,601 [IPC Server handler 4 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dnFailure_2_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:22,602 [IPC Server handler 3 on 36901] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /dnFailure_2_largeFile for DFSClient_NONMAPREDUCE_-1511708323_9908 at 127.0.0.1
2020-04-02 05:11:22,602 [IPC Server handler 3 on 36901] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/dnFailure_2_largeFile, holder=DFSClient_NONMAPREDUCE_-1511708323_9908, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:11:22,602 [IPC Server handler 3 on 36901] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: dnFailure_2_largeFile is added
2020-04-02 05:11:22,603 [IPC Server handler 3 on 36901] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /dnFailure_2_largeFile inode 16386 DFSClient_NONMAPREDUCE_-1511708323_9908
2020-04-02 05:11:22,603 [IPC Server handler 3 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/dnFailure_2_largeFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:11:22,626 [IPC Server handler 1 on 36901] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /dnFailure_2_largeFile  inodeId 16386 for DFSClient_NONMAPREDUCE_-1511708323_9908
2020-04-02 05:11:22,626 [IPC Server handler 1 on 36901] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:11:22,628 [IPC Server handler 1 on 36901] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /dnFailure_2_largeFile with blk_-9223372036854775792_1001 block is added to the in-memory file system
2020-04-02 05:11:22,628 [IPC Server handler 1 on 36901] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:35261, 127.0.0.1:36299, 127.0.0.1:46176, 127.0.0.1:45686, 127.0.0.1:37326, 127.0.0.1:42406, 127.0.0.1:43692, 127.0.0.1:42190, 127.0.0.1:46723 for /dnFailure_2_largeFile
2020-04-02 05:11:22,628 [IPC Server handler 1 on 36901] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /dnFailure_2_largeFile with new block blk_-9223372036854775792_1001, current total block count is 1
2020-04-02 05:11:22,633 [DataXceiver for client DFSClient_NONMAPREDUCE_-1511708323_9908 at /127.0.0.1:42630 [Receiving block BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775792_1001 src: /127.0.0.1:42630 dest: /127.0.0.1:35261
2020-04-02 05:11:22,643 [DataXceiver for client DFSClient_NONMAPREDUCE_-1511708323_9908 at /127.0.0.1:57632 [Receiving block BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775791_1001 src: /127.0.0.1:57632 dest: /127.0.0.1:36299
2020-04-02 05:11:22,654 [DataXceiver for client DFSClient_NONMAPREDUCE_-1511708323_9908 at /127.0.0.1:42558 [Receiving block BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775790_1001 src: /127.0.0.1:42558 dest: /127.0.0.1:46176
2020-04-02 05:11:22,667 [DataXceiver for client DFSClient_NONMAPREDUCE_-1511708323_9908 at /127.0.0.1:38926 [Receiving block BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775789_1001 src: /127.0.0.1:38926 dest: /127.0.0.1:45686
2020-04-02 05:11:22,677 [DataXceiver for client DFSClient_NONMAPREDUCE_-1511708323_9908 at /127.0.0.1:37504 [Receiving block BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775788_1001 src: /127.0.0.1:37504 dest: /127.0.0.1:37326
2020-04-02 05:11:22,696 [DataXceiver for client DFSClient_NONMAPREDUCE_-1511708323_9908 at /127.0.0.1:43406 [Receiving block BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775787_1001 src: /127.0.0.1:43406 dest: /127.0.0.1:42406
2020-04-02 05:11:22,744 [DataXceiver for client DFSClient_NONMAPREDUCE_-1511708323_9908 at /127.0.0.1:40772 [Receiving block BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775786_1001 src: /127.0.0.1:40772 dest: /127.0.0.1:43692
2020-04-02 05:11:22,767 [DataXceiver for client DFSClient_NONMAPREDUCE_-1511708323_9908 at /127.0.0.1:40938 [Receiving block BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775785_1001 src: /127.0.0.1:40938 dest: /127.0.0.1:42190
2020-04-02 05:11:22,783 [DataXceiver for client DFSClient_NONMAPREDUCE_-1511708323_9908 at /127.0.0.1:59920 [Receiving block BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775784_1001 src: /127.0.0.1:59920 dest: /127.0.0.1:46723
2020-04-02 05:11:23,011 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42630, dest: /127.0.0.1:35261, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1511708323_9908, offset: 0, srvID: 541f6320-dc70-4672-b00a-2db7cb1030b8, blockid: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775792_1001, duration(ns): 368338381
2020-04-02 05:11:23,011 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:23,016 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38926, dest: /127.0.0.1:45686, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1511708323_9908, offset: 0, srvID: 553835c2-8006-459e-ad32-9c7c65e27cf0, blockid: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775789_1001, duration(ns): 334999124
2020-04-02 05:11:23,016 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40938, dest: /127.0.0.1:42190, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1511708323_9908, offset: 0, srvID: 6b834b40-8ca0-4fca-a564-6bb4046cd449, blockid: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775785_1001, duration(ns): 239670645
2020-04-02 05:11:23,021 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:23,021 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37504, dest: /127.0.0.1:37326, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1511708323_9908, offset: 0, srvID: 3ab5d7c8-56c0-4e53-adef-4c8e2270bd45, blockid: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775788_1001, duration(ns): 324376308
2020-04-02 05:11:23,016 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42558, dest: /127.0.0.1:46176, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1511708323_9908, offset: 0, srvID: 151acd8e-6535-42dc-aaa5-dd6251fd470e, blockid: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775790_1001, duration(ns): 352466754
2020-04-02 05:11:23,027 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:23,027 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:23,021 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:23,021 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59920, dest: /127.0.0.1:46723, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1511708323_9908, offset: 0, srvID: 70924816-98e6-4162-8461-fc7fac066b04, blockid: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775784_1001, duration(ns): 223712074
2020-04-02 05:11:23,021 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57632, dest: /127.0.0.1:36299, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1511708323_9908, offset: 0, srvID: be788e49-c7e8-4353-9d82-5f56ca74f939, blockid: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775791_1001, duration(ns): 355105666
2020-04-02 05:11:23,021 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40772, dest: /127.0.0.1:43692, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1511708323_9908, offset: 0, srvID: c8957254-ba7d-4227-8a90-4c7cb808d6a0, blockid: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775786_1001, duration(ns): 257158988
2020-04-02 05:11:23,016 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43406, dest: /127.0.0.1:42406, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1511708323_9908, offset: 0, srvID: a247be67-ce61-4605-8cd9-5984ebfb0201, blockid: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775787_1001, duration(ns): 305665363
2020-04-02 05:11:23,028 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:23,028 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:23,028 [IPC Server handler 1 on 36901] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:42190, datanodeUuid=6b834b40-8ca0-4fca-a564-6bb4046cd449, infoPort=45068, infoSecurePort=0, ipcPort=35778, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415) 1 blocks.
2020-04-02 05:11:23,028 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:23,028 [IPC Server handler 3 on 36901] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45686, datanodeUuid=553835c2-8006-459e-ad32-9c7c65e27cf0, infoPort=42450, infoSecurePort=0, ipcPort=37534, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415) 1 blocks.
2020-04-02 05:11:23,028 [IPC Server handler 9 on 36901] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37326, datanodeUuid=3ab5d7c8-56c0-4e53-adef-4c8e2270bd45, infoPort=36143, infoSecurePort=0, ipcPort=46401, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415) 1 blocks.
2020-04-02 05:11:23,028 [IPC Server handler 4 on 36901] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:46176, datanodeUuid=151acd8e-6535-42dc-aaa5-dd6251fd470e, infoPort=37378, infoSecurePort=0, ipcPort=41767, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415) 1 blocks.
2020-04-02 05:11:23,028 [IPC Server handler 0 on 36901] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:42406, datanodeUuid=a247be67-ce61-4605-8cd9-5984ebfb0201, infoPort=40849, infoSecurePort=0, ipcPort=40631, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415) 1 blocks.
2020-04-02 05:11:23,028 [IPC Server handler 6 on 36901] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:43692, datanodeUuid=c8957254-ba7d-4227-8a90-4c7cb808d6a0, infoPort=34089, infoSecurePort=0, ipcPort=36669, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415) 1 blocks.
2020-04-02 05:11:23,028 [IPC Server handler 8 on 36901] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:35261, datanodeUuid=541f6320-dc70-4672-b00a-2db7cb1030b8, infoPort=38314, infoSecurePort=0, ipcPort=33545, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415) 1 blocks.
2020-04-02 05:11:23,028 [IPC Server handler 2 on 36901] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:36299, datanodeUuid=be788e49-c7e8-4353-9d82-5f56ca74f939, infoPort=41519, infoSecurePort=0, ipcPort=35688, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415) 1 blocks.
2020-04-02 05:11:23,028 [IPC Server handler 7 on 36901] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:46723, datanodeUuid=70924816-98e6-4162-8461-fc7fac066b04, infoPort=32914, infoSecurePort=0, ipcPort=40623, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415) 1 blocks.
2020-04-02 05:11:23,033 [IPC Server handler 1 on 36901] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /dnFailure_2_largeFile  inodeId 16386 for DFSClient_NONMAPREDUCE_-1511708323_9908
2020-04-02 05:11:23,033 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775785_1001 on 127.0.0.1:42190 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:23,028 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:23,034 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:23,034 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:42190 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:11:23,035 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775785_1001 is received from 127.0.0.1:42190
2020-04-02 05:11:23,035 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:42190 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:23,035 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775789_1001 on 127.0.0.1:45686 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:23,035 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:23,035 [IPC Server handler 1 on 36901] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:11:23,035 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45686 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:11:23,035 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775789_1001 is received from 127.0.0.1:45686
2020-04-02 05:11:23,035 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45686 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:23,036 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:37326 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:23,036 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:23,036 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37326 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:11:23,036 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775788_1001 is received from 127.0.0.1:37326
2020-04-02 05:11:23,036 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37326 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:23,036 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775790_1001 on 127.0.0.1:46176 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:23,036 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:23,036 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:46176 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:11:23,036 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775790_1001 is received from 127.0.0.1:46176
2020-04-02 05:11:23,036 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:46176 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:23,036 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775787_1001 on 127.0.0.1:42406 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:23,036 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:23,036 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:42406 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:11:23,037 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775787_1001 is received from 127.0.0.1:42406
2020-04-02 05:11:23,037 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:42406 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:23,037 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775786_1001 on 127.0.0.1:43692 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:23,037 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:23,037 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:43692 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:11:23,037 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775786_1001 is received from 127.0.0.1:43692
2020-04-02 05:11:23,037 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:43692 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:23,037 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775792_1001 on 127.0.0.1:35261 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:23,037 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:23,037 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:35261 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:11:23,037 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775792_1001 is received from 127.0.0.1:35261
2020-04-02 05:11:23,037 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:35261 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:23,037 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775791_1001 on 127.0.0.1:36299 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:23,038 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:23,038 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:36299 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:11:23,038 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775791_1001 is received from 127.0.0.1:36299
2020-04-02 05:11:23,038 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:36299 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:23,038 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775784_1001 on 127.0.0.1:46723 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:23,038 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:23,038 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:46723 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:11:23,038 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775784_1001 is received from 127.0.0.1:46723
2020-04-02 05:11:23,038 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:46723 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:23,042 [IPC Server handler 1 on 36901] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /dnFailure_2_largeFile with blk_-9223372036854775776_1002 block is added to the in-memory file system
2020-04-02 05:11:23,042 [IPC Server handler 1 on 36901] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775776_1002, replicas=127.0.0.1:35261, 127.0.0.1:42406, 127.0.0.1:37326, 127.0.0.1:36299, 127.0.0.1:43692, 127.0.0.1:46176, 127.0.0.1:46723, 127.0.0.1:45686, 127.0.0.1:42190 for /dnFailure_2_largeFile
2020-04-02 05:11:23,042 [IPC Server handler 1 on 36901] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /dnFailure_2_largeFile with new block blk_-9223372036854775776_1002, current total block count is 2
2020-04-02 05:11:23,044 [DataXceiver for client DFSClient_NONMAPREDUCE_-1511708323_9908 at /127.0.0.1:38940 [Receiving block BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775769_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775769_1002 src: /127.0.0.1:38940 dest: /127.0.0.1:45686
2020-04-02 05:11:23,044 [DataXceiver for client DFSClient_NONMAPREDUCE_-1511708323_9908 at /127.0.0.1:59922 [Receiving block BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775770_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775770_1002 src: /127.0.0.1:59922 dest: /127.0.0.1:46723
2020-04-02 05:11:23,044 [DataXceiver for client DFSClient_NONMAPREDUCE_-1511708323_9908 at /127.0.0.1:42654 [Receiving block BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775776_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775776_1002 src: /127.0.0.1:42654 dest: /127.0.0.1:35261
2020-04-02 05:11:23,044 [DataXceiver for client DFSClient_NONMAPREDUCE_-1511708323_9908 at /127.0.0.1:40944 [Receiving block BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775768_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775768_1002 src: /127.0.0.1:40944 dest: /127.0.0.1:42190
2020-04-02 05:11:23,062 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42654, dest: /127.0.0.1:35261, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1511708323_9908, offset: 0, srvID: 541f6320-dc70-4672-b00a-2db7cb1030b8, blockid: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775776_1002, duration(ns): 5653480
2020-04-02 05:11:23,063 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:23,064 [IPC Server handler 5 on 36901] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:35261, datanodeUuid=541f6320-dc70-4672-b00a-2db7cb1030b8, infoPort=38314, infoSecurePort=0, ipcPort=33545, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415) 1 blocks.
2020-04-02 05:11:23,065 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775776_1002 on 127.0.0.1:35261 size 123 replicaState = FINALIZED
2020-04-02 05:11:23,065 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:23,065 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:35261 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:11:23,065 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775776_1002 is received from 127.0.0.1:35261
2020-04-02 05:11:23,065 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:35261 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:23,066 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59922, dest: /127.0.0.1:46723, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1511708323_9908, offset: 0, srvID: 70924816-98e6-4162-8461-fc7fac066b04, blockid: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775770_1002, duration(ns): 15596162
2020-04-02 05:11:23,067 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:23,068 [IPC Server handler 3 on 36901] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:46723, datanodeUuid=70924816-98e6-4162-8461-fc7fac066b04, infoPort=32914, infoSecurePort=0, ipcPort=40623, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415) 1 blocks.
2020-04-02 05:11:23,069 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775770_1002 on 127.0.0.1:46723 size 123 replicaState = FINALIZED
2020-04-02 05:11:23,069 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:23,069 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:46723 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:11:23,069 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775770_1002 is received from 127.0.0.1:46723
2020-04-02 05:11:23,069 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:46723 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:23,071 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38940, dest: /127.0.0.1:45686, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1511708323_9908, offset: 0, srvID: 553835c2-8006-459e-ad32-9c7c65e27cf0, blockid: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775769_1002, duration(ns): 23266625
2020-04-02 05:11:23,071 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:23,071 [IPC Server handler 9 on 36901] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45686, datanodeUuid=553835c2-8006-459e-ad32-9c7c65e27cf0, infoPort=42450, infoSecurePort=0, ipcPort=37534, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415) 1 blocks.
2020-04-02 05:11:23,074 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775769_1002 on 127.0.0.1:45686 size 123 replicaState = FINALIZED
2020-04-02 05:11:23,074 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:23,074 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45686 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:11:23,075 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775769_1002 is received from 127.0.0.1:45686
2020-04-02 05:11:23,075 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45686 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:23,075 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40944, dest: /127.0.0.1:42190, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1511708323_9908, offset: 0, srvID: 6b834b40-8ca0-4fca-a564-6bb4046cd449, blockid: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775768_1002, duration(ns): 25719526
2020-04-02 05:11:23,076 [PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:23,076 [IPC Server handler 4 on 36901] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:42190, datanodeUuid=6b834b40-8ca0-4fca-a564-6bb4046cd449, infoPort=45068, infoSecurePort=0, ipcPort=35778, storageInfo=lv=-57;cid=testClusterID;nsid=532641025;c=1585804280415) 1 blocks.
2020-04-02 05:11:23,076 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775768_1002 on 127.0.0.1:42190 size 123 replicaState = FINALIZED
2020-04-02 05:11:23,076 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:23,077 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:42190 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:11:23,077 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775768_1002 is received from 127.0.0.1:42190
2020-04-02 05:11:23,077 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:42190 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:23,077 [IPC Server handler 0 on 36901] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /dnFailure_2_largeFile for DFSClient_NONMAPREDUCE_-1511708323_9908
2020-04-02 05:11:23,078 [IPC Server handler 0 on 36901] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /dnFailure_2_largeFile with 2 blocks is persisted to the file system
2020-04-02 05:11:23,080 [IPC Server handler 0 on 36901] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /dnFailure_2_largeFile is closed by DFSClient_NONMAPREDUCE_-1511708323_9908
2020-04-02 05:11:23,081 [IPC Server handler 6 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:11:23,082 [IPC Server handler 8 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:23,083 [IPC Server handler 8 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:23,084 [Thread-1990] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:waitBlockGroupsReported(290)) - All blockGroups of file /dnFailure_2_largeFile verified to have all internalBlocks.
2020-04-02 05:11:23,085 [IPC Server handler 2 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:23,085 [IPC Server handler 2 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:23,086 [Thread-1990] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33545 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:23,087 [Thread-1990] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:11:23,087 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7485e17c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:11:23,088 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-96ceeaeb-3486-4a38-a415-a4d4fb76925e) exiting.
2020-04-02 05:11:23,088 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-9fb1f019-4364-48c3-98f6-320aac9da009) exiting.
2020-04-02 05:11:23,103 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@16f3293f{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:11:23,104 [Thread-1990] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@22691ea2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:11:23,104 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5485a37e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:11:23,104 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4d865687{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:11:23,105 [Thread-1990] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33545
2020-04-02 05:11:23,107 [IPC Server listener on 33545] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33545
2020-04-02 05:11:23,112 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:11:23,112 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:11:23,112 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 541f6320-dc70-4672-b00a-2db7cb1030b8) service to localhost/127.0.0.1:36901
2020-04-02 05:11:23,112 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 541f6320-dc70-4672-b00a-2db7cb1030b8)
2020-04-02 05:11:23,113 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:23,124 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-737821685-172.17.0.14-1585804280415] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:23,132 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-737821685-172.17.0.14-1585804280415] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:23,140 [Thread-1990] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:11:23,142 [Thread-1990] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:11:23,145 [Thread-1990] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:11:23,147 [Thread-1990] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:11:23,151 [Thread-1990] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:23,151 [Thread-1990] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 35688 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:23,151 [Thread-1990] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:11:23,152 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2fe64264] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:11:23,154 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-aefab964-a540-4bbb-93ac-26ada6ec71a6) exiting.
2020-04-02 05:11:23,155 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-be01dd15-3d0f-4491-af22-bcb280b454cc) exiting.
2020-04-02 05:11:23,167 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@157a1250{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:11:23,167 [Thread-1990] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7c12a188{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:11:23,167 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@12158d61{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:11:23,167 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7a52e880{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:11:23,168 [Thread-1990] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35688
2020-04-02 05:11:23,175 [IPC Server listener on 35688] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35688
2020-04-02 05:11:23,175 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:11:23,176 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:11:23,178 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid be788e49-c7e8-4353-9d82-5f56ca74f939) service to localhost/127.0.0.1:36901
2020-04-02 05:11:23,178 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid be788e49-c7e8-4353-9d82-5f56ca74f939)
2020-04-02 05:11:23,178 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:23,186 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-737821685-172.17.0.14-1585804280415] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:23,193 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-737821685-172.17.0.14-1585804280415] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:23,202 [Thread-1990] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:11:23,202 [Thread-1990] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:11:23,204 [Thread-1990] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:11:23,204 [Thread-1990] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:11:23,207 [Thread-1990] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:23,207 [Thread-1990] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /dnFailure_2_largeFile
2020-04-02 05:11:23,229 [Thread-1990] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /dnFailure_2_largeFile
2020-04-02 05:11:23,230 [IPC Server handler 7 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dnFailure_2_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:23,231 [Thread-1990] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /dnFailure_2_largeFile
2020-04-02 05:11:23,232 [IPC Server handler 1 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:11:23,233 [IPC Server handler 5 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:23,233 [IPC Server handler 5 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:23,251 [Thread-1990] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:23,255 [Thread-1990] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:35261 for blockBP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:23,257 [IPC Server handler 3 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:23,257 [IPC Server handler 3 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:23,259 [Thread-1990] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:35261,DS-9fb1f019-4364-48c3-98f6-320aac9da009,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:11:23,260 [Thread-1990] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:23,261 [Thread-1990] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:36299 for blockBP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775791_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:23,261 [IPC Server handler 9 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:23,262 [IPC Server handler 9 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:23,263 [Thread-1990] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:36299,DS-be01dd15-3d0f-4491-af22-bcb280b454cc,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:11:23,834 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:24,602 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:26,846 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:27,603 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:29,846 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:30,603 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:32,847 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:33,609 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:35,847 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:36,610 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:37,343 [Thread-1990] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /dnFailure_2_largeFile
2020-04-02 05:11:37,350 [IPC Server handler 6 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:37,352 [IPC Server handler 6 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:37,360 [Thread-1990] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:37,360 [Thread-1990] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:35261 for blockBP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:37,361 [IPC Server handler 8 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:37,364 [IPC Server handler 8 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:37,365 [Thread-1990] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:35261,DS-9fb1f019-4364-48c3-98f6-320aac9da009,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:11:37,366 [Thread-1990] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:37,366 [Thread-1990] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:36299 for blockBP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775791_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:37,367 [IPC Server handler 2 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:37,367 [IPC Server handler 2 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:37,368 [Thread-1990] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:36299,DS-be01dd15-3d0f-4491-af22-bcb280b454cc,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:11:38,848 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:39,610 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:40,898 [Thread-1990] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /dnFailure_2_largeFile
2020-04-02 05:11:40,913 [IPC Server handler 3 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:40,914 [IPC Server handler 3 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:40,931 [Thread-1990] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,932 [Thread-1990] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:35261 for blockBP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,932 [IPC Server handler 9 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:40,933 [IPC Server handler 9 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:40,934 [Thread-1990] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:35261,DS-9fb1f019-4364-48c3-98f6-320aac9da009,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:11:40,934 [Thread-1990] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,934 [Thread-1990] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:36299 for blockBP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775791_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,935 [IPC Server handler 4 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:40,935 [IPC Server handler 4 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:40,936 [Thread-1990] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:36299,DS-be01dd15-3d0f-4491-af22-bcb280b454cc,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:11:41,849 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:42,611 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:44,499 [Thread-1990] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /dnFailure_2_largeFile
2020-04-02 05:11:44,501 [IPC Server handler 3 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:44,502 [IPC Server handler 3 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:44,511 [Thread-1990] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:44,512 [Thread-1990] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:36299 for blockBP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775791_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:44,512 [IPC Server handler 9 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:44,513 [IPC Server handler 9 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:44,513 [Thread-1990] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:36299,DS-be01dd15-3d0f-4491-af22-bcb280b454cc,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:11:44,518 [Thread-1990] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readDataForDecoding(StripeReader.java:191)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:338)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:44,518 [Thread-1990] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:35261 for blockBP-737821685-172.17.0.14-1585804280415:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readDataForDecoding(StripeReader.java:191)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:338)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:44,519 [IPC Server handler 4 on 36901] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:44,519 [IPC Server handler 4 on 36901] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_2_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:44,520 [Thread-1990] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:35261,DS-9fb1f019-4364-48c3-98f6-320aac9da009,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:11:44,849 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:45,611 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:47,850 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:48,612 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:49,798 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:11:49,798 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 8
2020-04-02 05:11:49,798 [Thread-1990] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33545 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:49,798 [Thread-1990] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(340)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-04-02 05:11:49,799 [Thread-1990] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33545
2020-04-02 05:11:49,799 [Thread-1990] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-541f6320-dc70-4672-b00a-2db7cb1030b8
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-541f6320-dc70-4672-b00a-2db7cb1030b8
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2146)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2048)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2038)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2017)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1991)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1984)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.tearDownCluster(ReadStripedFileWithDecodingHelper.java:97)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.tearDown(TestReadStripedFileWithDNFailure.java:64)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:105)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:49,799 [Thread-1990] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(190)) - AsyncDiskService has already shut down.
2020-04-02 05:11:49,800 [Thread-1990] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(174)) - AsyncLazyPersistService has already shut down.
2020-04-02 05:11:49,800 [Thread-1990] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:49,800 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 7
2020-04-02 05:11:49,800 [Thread-1990] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 41767 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:49,800 [Thread-1990] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:11:49,800 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2ff99b25] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:11:49,802 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-75208cb9-9a5c-45ff-a1da-2c9560af3622) exiting.
2020-04-02 05:11:49,802 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-eacb6f69-2bb8-41bb-9b47-316eeaaf59d1) exiting.
2020-04-02 05:11:49,818 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5a42432b{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:11:49,819 [Thread-1990] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3c0947ab{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:11:49,819 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6696d46f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:11:49,820 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@72fe25fa{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:11:49,833 [Thread-1990] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41767
2020-04-02 05:11:49,837 [IPC Server listener on 41767] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41767
2020-04-02 05:11:49,838 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:11:49,838 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:11:49,844 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 151acd8e-6535-42dc-aaa5-dd6251fd470e) service to localhost/127.0.0.1:36901
2020-04-02 05:11:49,844 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 151acd8e-6535-42dc-aaa5-dd6251fd470e)
2020-04-02 05:11:49,844 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:49,857 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-737821685-172.17.0.14-1585804280415] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:49,863 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-737821685-172.17.0.14-1585804280415] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:49,870 [Thread-1990] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:11:49,870 [Thread-1990] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:11:49,872 [Thread-1990] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:11:49,872 [Thread-1990] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:11:49,875 [Thread-1990] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:49,875 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 6
2020-04-02 05:11:49,875 [Thread-1990] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 46401 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:49,875 [Thread-1990] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:11:49,875 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@68c56ad1] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:11:49,877 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-956c1afb-64ef-47eb-bd45-2d6f5b52308a) exiting.
2020-04-02 05:11:49,877 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-a3206c16-1220-4224-a543-5f3c37bbaed9) exiting.
2020-04-02 05:11:49,896 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4584d55c{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:11:49,896 [Thread-1990] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@536d69f9{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:11:49,896 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@10c2bb35{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:11:49,897 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5fa55ff6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:11:49,898 [Thread-1990] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46401
2020-04-02 05:11:49,901 [IPC Server listener on 46401] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46401
2020-04-02 05:11:49,901 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:11:49,901 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:11:49,902 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 3ab5d7c8-56c0-4e53-adef-4c8e2270bd45) service to localhost/127.0.0.1:36901
2020-04-02 05:11:49,902 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 3ab5d7c8-56c0-4e53-adef-4c8e2270bd45)
2020-04-02 05:11:49,902 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:49,912 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-737821685-172.17.0.14-1585804280415] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:49,922 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-737821685-172.17.0.14-1585804280415] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:49,928 [Thread-1990] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:11:49,928 [Thread-1990] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:11:49,930 [Thread-1990] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:11:49,930 [Thread-1990] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:11:49,934 [Thread-1990] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:49,934 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 5
2020-04-02 05:11:49,934 [Thread-1990] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 35688 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:49,934 [Thread-1990] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(340)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-04-02 05:11:49,935 [Thread-1990] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35688
2020-04-02 05:11:49,935 [Thread-1990] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-be788e49-c7e8-4353-9d82-5f56ca74f939
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-be788e49-c7e8-4353-9d82-5f56ca74f939
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2146)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2048)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2038)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2017)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1991)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1984)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.tearDownCluster(ReadStripedFileWithDecodingHelper.java:97)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.tearDown(TestReadStripedFileWithDNFailure.java:64)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:105)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:49,935 [Thread-1990] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(190)) - AsyncDiskService has already shut down.
2020-04-02 05:11:49,935 [Thread-1990] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(174)) - AsyncLazyPersistService has already shut down.
2020-04-02 05:11:49,935 [Thread-1990] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:49,935 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 4
2020-04-02 05:11:49,936 [Thread-1990] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40623 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:49,936 [Thread-1990] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:11:49,936 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7e8600a6] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:11:49,943 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-ea514346-939e-41eb-9868-bdfe6bf112a3) exiting.
2020-04-02 05:11:49,943 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-f890b652-532b-4cee-b75c-219f716632ef) exiting.
2020-04-02 05:11:49,960 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7f851e30{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:11:49,961 [Thread-1990] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7a3314d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:11:49,961 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@766de0a8{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:11:49,961 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@9534b22{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:11:49,962 [Thread-1990] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40623
2020-04-02 05:11:49,967 [IPC Server listener on 40623] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40623
2020-04-02 05:11:49,967 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:11:49,967 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:11:49,967 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 70924816-98e6-4162-8461-fc7fac066b04) service to localhost/127.0.0.1:36901
2020-04-02 05:11:49,967 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 70924816-98e6-4162-8461-fc7fac066b04)
2020-04-02 05:11:49,969 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:49,980 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-737821685-172.17.0.14-1585804280415] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:49,996 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-737821685-172.17.0.14-1585804280415] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:49,998 [Thread-1990] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:11:49,998 [Thread-1990] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:11:50,001 [Thread-1990] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:11:50,001 [Thread-1990] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:11:50,005 [Thread-1990] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:50,005 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 3
2020-04-02 05:11:50,005 [Thread-1990] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40631 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:50,005 [Thread-1990] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:11:50,005 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1e22432a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:11:50,005 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-7672bfd9-de4f-46fd-91d8-65dfd959e2be) exiting.
2020-04-02 05:11:50,005 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-9b0f67b6-b69b-4045-b1a6-abcfd7a33f64) exiting.
2020-04-02 05:11:50,024 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5ee0e5a8{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:11:50,025 [Thread-1990] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@582fb352{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:11:50,025 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6cfc3b7a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:11:50,025 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7647d3e4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:11:50,027 [Thread-1990] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40631
2020-04-02 05:11:50,033 [IPC Server listener on 40631] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40631
2020-04-02 05:11:50,034 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:11:50,034 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:11:50,034 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid a247be67-ce61-4605-8cd9-5984ebfb0201) service to localhost/127.0.0.1:36901
2020-04-02 05:11:50,034 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid a247be67-ce61-4605-8cd9-5984ebfb0201)
2020-04-02 05:11:50,037 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:50,055 [Thread-1990] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:11:50,055 [Thread-1990] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:11:50,056 [Thread-1990] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:11:50,056 [Thread-1990] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:11:50,057 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-737821685-172.17.0.14-1585804280415] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:50,063 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-737821685-172.17.0.14-1585804280415] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:50,068 [Thread-1990] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:50,068 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:11:50,068 [Thread-1990] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 35778 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:50,068 [Thread-1990] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:11:50,068 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2b82a747] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:11:50,069 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-11749287-1476-46ce-b1c7-4f7f7cb5d693) exiting.
2020-04-02 05:11:50,069 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-f470c58f-426a-4c49-a3f0-8bc9ff1087fa) exiting.
2020-04-02 05:11:50,081 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@37c54c80{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:11:50,082 [Thread-1990] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@266f8d3d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:11:50,082 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6c62f012{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:11:50,082 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@45388e04{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:11:50,083 [Thread-1990] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35778
2020-04-02 05:11:50,083 [IPC Server listener on 35778] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35778
2020-04-02 05:11:50,086 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:11:50,086 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:11:50,086 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 6b834b40-8ca0-4fca-a564-6bb4046cd449) service to localhost/127.0.0.1:36901
2020-04-02 05:11:50,087 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 6b834b40-8ca0-4fca-a564-6bb4046cd449)
2020-04-02 05:11:50,088 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:50,095 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-737821685-172.17.0.14-1585804280415] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:50,103 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-737821685-172.17.0.14-1585804280415] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:50,110 [Thread-1990] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:11:50,110 [Thread-1990] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:11:50,112 [Thread-1990] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:11:50,112 [Thread-1990] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:11:50,117 [Thread-1990] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:50,117 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:11:50,117 [Thread-1990] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 37534 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:50,118 [Thread-1990] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:11:50,118 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@619b2bfd] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:11:50,118 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-24812541-6797-476a-a0ae-a497f78acf13) exiting.
2020-04-02 05:11:50,118 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-7dc0ecf5-a517-46d9-889e-d582832b1234) exiting.
2020-04-02 05:11:50,136 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5de4cab2{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:11:50,136 [Thread-1990] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@265489b5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:11:50,136 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@71768790{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:11:50,137 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5ffcf450{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:11:50,138 [Thread-1990] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37534
2020-04-02 05:11:50,145 [IPC Server listener on 37534] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37534
2020-04-02 05:11:50,145 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:11:50,145 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:11:50,145 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 553835c2-8006-459e-ad32-9c7c65e27cf0) service to localhost/127.0.0.1:36901
2020-04-02 05:11:50,145 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid 553835c2-8006-459e-ad32-9c7c65e27cf0)
2020-04-02 05:11:50,148 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:50,158 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-737821685-172.17.0.14-1585804280415] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:50,167 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-737821685-172.17.0.14-1585804280415] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:50,179 [Thread-1990] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:11:50,180 [Thread-1990] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:11:50,182 [Thread-1990] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:11:50,182 [Thread-1990] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:11:50,187 [Thread-1990] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:50,187 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:11:50,187 [Thread-1990] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 36669 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:50,187 [Thread-1990] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:11:50,187 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1689485f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:11:50,187 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-17ea0ea3-2f89-4443-9a73-c1fa148db75e) exiting.
2020-04-02 05:11:50,188 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-b35b0a2a-6443-43b5-bcc2-20c8cc6e8d8b) exiting.
2020-04-02 05:11:50,266 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@70953f9d{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:11:50,267 [Thread-1990] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5e885d42{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:11:50,267 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5d981ca1{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:11:50,267 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@61b61cbe{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:11:50,269 [Thread-1990] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36669
2020-04-02 05:11:50,272 [IPC Server listener on 36669] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36669
2020-04-02 05:11:50,276 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:11:50,276 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:11:50,276 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid c8957254-ba7d-4227-8a90-4c7cb808d6a0) service to localhost/127.0.0.1:36901
2020-04-02 05:11:50,276 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-737821685-172.17.0.14-1585804280415 (Datanode Uuid c8957254-ba7d-4227-8a90-4c7cb808d6a0)
2020-04-02 05:11:50,279 [BP-737821685-172.17.0.14-1585804280415 heartbeating to localhost/127.0.0.1:36901] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-737821685-172.17.0.14-1585804280415
2020-04-02 05:11:50,290 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-737821685-172.17.0.14-1585804280415] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:50,305 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-737821685-172.17.0.14-1585804280415] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:50,313 [Thread-1990] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:11:50,313 [Thread-1990] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:11:50,316 [Thread-1990] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:11:50,316 [Thread-1990] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:11:50,321 [Thread-1990] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:50,321 [Thread-1990] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:11:50,321 [Thread-1990] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 36901 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:50,321 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:11:50,322 [Thread-1990] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 11
2020-04-02 05:11:50,322 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@da9dec0] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:11:50,322 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3d3e1da4] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:11:50,322 [Thread-1990] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 12 Total time for transactions(ms): 24 Number of transactions batched in Syncs: 2 Number of syncs: 11 SyncTimes(ms): 4 5 
2020-04-02 05:11:50,323 [Thread-1990] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000012
2020-04-02 05:11:50,324 [Thread-1990] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000012
2020-04-02 05:11:50,324 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:11:50,324 [CacheReplicationMonitor(1687016777)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:11:50,324 [Thread-1990] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36901
2020-04-02 05:11:50,325 [IPC Server listener on 36901] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36901
2020-04-02 05:11:50,325 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:11:50,326 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:11:50,326 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:11:50,329 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@4c3efe50] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:11:50,352 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:11:50,353 [Thread-1990] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:11:50,353 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@67ae4b43{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:11:50,354 [Thread-1990] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6c59b394{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:11:50,354 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@25905278{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:11:50,354 [Thread-1990] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1711039f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure#testReadWithDNFailure[4]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure#testReadWithDNFailure[4]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure#testReadWithDNFailure[5]
[msx] perform reset as unitTestCounterInClass 5 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] before_class
2020-04-02 05:11:50,375 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=9
Formatting using clusterid: testClusterID
2020-04-02 05:11:50,377 [Thread-2409] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:11:50,377 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:11:50,377 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:11:50,377 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:11:50,377 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:11:50,377 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:11:50,377 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:11:50,377 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:11:50,378 [Thread-2409] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:50,378 [Thread-2409] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:11:50,378 [Thread-2409] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:11:50,378 [Thread-2409] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:11:50,378 [Thread-2409] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:11:50
2020-04-02 05:11:50,378 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:11:50,378 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:11:50,378 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 2.0 GB = 40.2 MB
2020-04-02 05:11:50,378 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:11:50,381 [Thread-2409] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:11:50,381 [Thread-2409] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:11:50,381 [Thread-2409] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:11:50,381 [Thread-2409] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:11:50,381 [Thread-2409] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:11:50,381 [Thread-2409] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:11:50,381 [Thread-2409] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:11:50,382 [Thread-2409] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:11:50,382 [Thread-2409] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 0
2020-04-02 05:11:50,382 [Thread-2409] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:11:50,382 [Thread-2409] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:11:50,382 [Thread-2409] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:11:50,382 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:11:50,382 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:11:50,382 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 2.0 GB = 20.1 MB
2020-04-02 05:11:50,382 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:11:50,384 [Thread-2409] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:11:50,384 [Thread-2409] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:11:50,384 [Thread-2409] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:11:50,384 [Thread-2409] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:11:50,384 [Thread-2409] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:11:50,384 [Thread-2409] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:11:50,384 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:11:50,384 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:11:50,384 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 2.0 GB = 5.0 MB
2020-04-02 05:11:50,384 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:11:50,385 [Thread-2409] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:11:50,385 [Thread-2409] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:11:50,385 [Thread-2409] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:11:50,385 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:11:50,385 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:11:50,385 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:11:50,385 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:11:50,385 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 2.0 GB = 617.0 KB
2020-04-02 05:11:50,385 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:11:50,386 [Thread-2409] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:50,389 [Thread-2409] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:11:50,392 [Thread-2409] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:11:50,393 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:11:50,393 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:11:50,404 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 426 bytes saved in 0 seconds .
2020-04-02 05:11:50,404 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 426 bytes saved in 0 seconds .
2020-04-02 05:11:50,406 [Thread-2409] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:11:50,408 [Thread-2409] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:11:50,408 [Thread-2409] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:11:50,408 [Thread-2409] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:11:50,409 [Thread-2409] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:11:50,457 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2bba0ef5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:11:50,457 [Thread-2409] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:11:50,457 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:50,459 [Thread-2409] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:11:50,459 [Thread-2409] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:11:50,459 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:50,460 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:11:50,460 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:11:50,460 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:11:50,460 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:11:50,461 [Thread-2409] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:11:50,461 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:11:50,461 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34844
2020-04-02 05:11:50,461 [Thread-2409] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:11:50,463 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3e32540c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:11:50,463 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@76348f8e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:11:50,468 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@68176271{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:11:50,468 [Thread-2409] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@41d7d149{HTTP/1.1,[http/1.1]}{localhost:34844}
2020-04-02 05:11:50,472 [Thread-2409] INFO  server.Server (Server.java:doStart(419)) - Started @180883ms
2020-04-02 05:11:50,473 [Thread-2409] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:11:50,474 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:11:50,474 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:11:50,474 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:11:50,474 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:11:50,474 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:11:50,474 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:11:50,475 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:11:50,475 [Thread-2409] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:50,475 [Thread-2409] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:11:50,475 [Thread-2409] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:11:50,476 [Thread-2409] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:11:50,476 [Thread-2409] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:11:50
2020-04-02 05:11:50,476 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:11:50,476 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:11:50,476 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 2.0 GB = 40.2 MB
2020-04-02 05:11:50,477 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:11:50,480 [Thread-2409] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:11:50,480 [Thread-2409] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:11:50,480 [Thread-2409] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:11:50,480 [Thread-2409] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:11:50,480 [Thread-2409] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:11:50,481 [Thread-2409] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:11:50,481 [Thread-2409] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:11:50,481 [Thread-2409] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:11:50,481 [Thread-2409] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 0
2020-04-02 05:11:50,481 [Thread-2409] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:11:50,481 [Thread-2409] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:11:50,481 [Thread-2409] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:11:50,481 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:11:50,482 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:11:50,482 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 2.0 GB = 20.1 MB
2020-04-02 05:11:50,482 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:11:50,484 [Thread-2409] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:11:50,484 [Thread-2409] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:11:50,484 [Thread-2409] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:11:50,484 [Thread-2409] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:11:50,484 [Thread-2409] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:11:50,484 [Thread-2409] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:11:50,484 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:11:50,484 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:11:50,485 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 2.0 GB = 5.0 MB
2020-04-02 05:11:50,485 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:11:50,485 [Thread-2409] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:11:50,486 [Thread-2409] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:11:50,486 [Thread-2409] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:11:50,486 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:11:50,486 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:11:50,486 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:11:50,486 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:11:50,486 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 2.0 GB = 617.0 KB
2020-04-02 05:11:50,486 [Thread-2409] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:11:50,488 [Thread-2409] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:50,489 [Thread-2409] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:50,490 [Thread-2409] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:11:50,491 [Thread-2409] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:11:50,491 [Thread-2409] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:11:50,491 [Thread-2409] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:11:50,492 [Thread-2409] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:11:50,492 [Thread-2409] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:11:50,492 [Thread-2409] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:11:50,493 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:11:50,493 [Thread-2409] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:11:50,512 [Thread-2409] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:11:50,512 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 25 msecs
2020-04-02 05:11:50,513 [Thread-2409] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:11:50,513 [Thread-2409] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:11:50,514 [Socket Reader #1 for port 37479] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37479
2020-04-02 05:11:50,521 [Thread-2409] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:37479 to access this namenode/service.
2020-04-02 05:11:50,522 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:11:50,605 [Thread-2409] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:11:50,606 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@4b0bf0f] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:11:50,606 [Thread-2409] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:11:50,606 [Thread-2409] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:11:50,607 [Thread-2409] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:11:50,607 [Thread-2409] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:11:50,616 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:11:50,616 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:11:50,616 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:11:50,616 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:11:50,616 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:11:50,616 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2020-04-02 05:11:50,618 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:11:50,618 [IPC Server listener on 37479] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37479: starting
2020-04-02 05:11:50,622 [Thread-2409] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:37479
2020-04-02 05:11:50,622 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:11:50,622 [Thread-2409] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:11:50,623 [Thread-2409] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:11:50,624 [Thread-2409] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 37479 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:50,631 [CacheReplicationMonitor(1243575866)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:11:50,664 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:11:50,665 [Thread-2409] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:11:50,665 [Thread-2409] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:11:50,665 [Thread-2409] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:11:50,669 [Thread-2409] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:11:50,669 [Thread-2409] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:50,669 [Thread-2409] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:11:50,669 [Thread-2409] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:11:50,670 [Thread-2409] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:50,670 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:11:50,670 [Thread-2409] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34202
2020-04-02 05:11:50,670 [Thread-2409] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:11:50,670 [Thread-2409] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:11:50,671 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:50,671 [Thread-2409] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:11:50,672 [Thread-2409] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:11:50,672 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:50,672 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:11:50,673 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:11:50,673 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:11:50,673 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:11:50,673 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41735
2020-04-02 05:11:50,673 [Thread-2409] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:11:50,674 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@863cfd{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:11:50,674 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@37b6073f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:11:50,676 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6a6f5eac{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:11:50,676 [Thread-2409] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5503a9a2{HTTP/1.1,[http/1.1]}{localhost:41735}
2020-04-02 05:11:50,677 [Thread-2409] INFO  server.Server (Server.java:doStart(419)) - Started @181087ms
2020-04-02 05:11:50,692 [Thread-2409] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35559
2020-04-02 05:11:50,692 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:11:50,693 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:11:50,693 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@65eaca0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:11:50,693 [Thread-2409] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:11:50,693 [Socket Reader #1 for port 46001] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46001
2020-04-02 05:11:50,698 [Thread-2409] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:46001
2020-04-02 05:11:50,747 [Thread-2409] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:11:50,747 [Thread-2409] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:11:50,747 [Thread-2463] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37479 starting to offer service
2020-04-02 05:11:50,750 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:11:50,753 [IPC Server listener on 46001] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46001: starting
2020-04-02 05:11:50,762 [Thread-2409] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 46001 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:50,763 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:11:50,763 [Thread-2463] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37479
2020-04-02 05:11:50,765 [Thread-2463] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:11:50,765 [Thread-2409] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:11:50,766 [Thread-2409] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:11:50,766 [Thread-2409] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:11:50,768 [Thread-2463] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:50,768 [Thread-2409] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:11:50,769 [Thread-2463] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1957767157. Formatting...
2020-04-02 05:11:50,769 [Thread-2409] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:50,769 [Thread-2463] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3da0dd79-074b-4b01-ae85-8b3621c7ea94 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:11:50,769 [Thread-2409] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:11:50,769 [Thread-2409] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:11:50,769 [Thread-2409] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:50,769 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:11:50,769 [Thread-2409] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:41739
2020-04-02 05:11:50,770 [Thread-2409] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:11:50,770 [Thread-2409] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:11:50,770 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:50,771 [Thread-2463] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:50,771 [Thread-2463] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1957767157. Formatting...
2020-04-02 05:11:50,771 [Thread-2463] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-83832e4f-631c-49e5-9c88-fe887fa0b6c4 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:11:50,772 [Thread-2409] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:11:50,772 [Thread-2409] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:11:50,772 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:50,773 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:11:50,773 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:11:50,773 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:11:50,774 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:11:50,774 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38406
2020-04-02 05:11:50,774 [Thread-2409] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:11:50,775 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7189dfed{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:11:50,776 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@12b8a869{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:11:50,780 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@437289e7{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:11:50,780 [Thread-2409] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@119c720c{HTTP/1.1,[http/1.1]}{localhost:38406}
2020-04-02 05:11:50,784 [Thread-2409] INFO  server.Server (Server.java:doStart(419)) - Started @181194ms
2020-04-02 05:11:50,787 [Thread-2463] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:50,787 [Thread-2463] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:50,787 [Thread-2463] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-200169212-172.17.0.14-1585804310386 is not formatted. Formatting ...
2020-04-02 05:11:50,787 [Thread-2463] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-200169212-172.17.0.14-1585804310386 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-200169212-172.17.0.14-1585804310386/current
2020-04-02 05:11:50,797 [Thread-2409] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46542
2020-04-02 05:11:50,797 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:11:50,797 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:11:50,797 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1246551e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:11:50,798 [Thread-2409] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:11:50,798 [Socket Reader #1 for port 42643] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42643
2020-04-02 05:11:50,803 [Thread-2409] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:42643
2020-04-02 05:11:50,809 [Thread-2463] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:50,809 [Thread-2463] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:50,809 [Thread-2463] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-200169212-172.17.0.14-1585804310386 is not formatted. Formatting ...
2020-04-02 05:11:50,809 [Thread-2463] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-200169212-172.17.0.14-1585804310386 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-200169212-172.17.0.14-1585804310386/current
2020-04-02 05:11:50,811 [Thread-2463] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1957767157;bpid=BP-200169212-172.17.0.14-1585804310386;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1957767157;c=1585804310386;bpid=BP-200169212-172.17.0.14-1585804310386;dnuuid=null
2020-04-02 05:11:50,812 [Thread-2463] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 60cdc7b1-1e99-459f-b5d3-e894178bb3bb
2020-04-02 05:11:50,854 [Thread-2463] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-3da0dd79-074b-4b01-ae85-8b3621c7ea94
2020-04-02 05:11:50,854 [Thread-2409] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:11:50,854 [Thread-2463] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:11:50,858 [Thread-2409] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:11:50,859 [Thread-2488] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37479 starting to offer service
2020-04-02 05:11:50,859 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:11:50,863 [IPC Server listener on 42643] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42643: starting
2020-04-02 05:11:50,865 [Thread-2463] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-83832e4f-631c-49e5-9c88-fe887fa0b6c4
2020-04-02 05:11:50,869 [Thread-2463] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:11:50,873 [Thread-2463] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:11:50,873 [Thread-2409] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 42643 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:50,873 [Thread-2488] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37479
2020-04-02 05:11:50,876 [Thread-2488] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:11:50,876 [Thread-2463] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:11:50,877 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:11:50,877 [Thread-2463] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:11:50,877 [Thread-2463] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:11:50,877 [Thread-2463] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:11:50,877 [Thread-2463] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:50,877 [Thread-2409] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:11:50,877 [Thread-2488] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:50,878 [Thread-2500] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:11:50,878 [Thread-2488] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1957767157. Formatting...
2020-04-02 05:11:50,878 [Thread-2501] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:11:50,878 [Thread-2409] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:11:50,878 [Thread-2488] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e1a645e3-f3a4-413a-b489-5a2a07f0d88a for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:11:50,879 [Thread-2409] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:11:50,882 [Thread-2409] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:11:50,883 [Thread-2409] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:50,884 [Thread-2409] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:11:50,884 [Thread-2409] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:11:50,884 [Thread-2409] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:50,884 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:11:50,884 [Thread-2409] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:44321
2020-04-02 05:11:50,885 [Thread-2409] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:11:50,885 [Thread-2409] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:11:50,885 [Thread-2488] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:50,885 [Thread-2488] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1957767157. Formatting...
2020-04-02 05:11:50,885 [Thread-2488] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-dd2fc9e6-10fe-4937-8f52-a079f3b5b192 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:11:50,885 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:50,887 [Thread-2409] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:11:50,888 [Thread-2409] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:11:50,888 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:50,889 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:11:50,889 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:11:50,889 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:11:50,889 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:11:50,890 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46259
2020-04-02 05:11:50,890 [Thread-2409] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:11:50,891 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5fa4b125{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:11:50,892 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@27882b9f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:11:50,895 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@18c61b9f{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:11:50,895 [Thread-2409] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2c91a188{HTTP/1.1,[http/1.1]}{localhost:46259}
2020-04-02 05:11:50,900 [Thread-2409] INFO  server.Server (Server.java:doStart(419)) - Started @181310ms
2020-04-02 05:11:50,903 [Thread-2488] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:50,903 [Thread-2488] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:50,903 [Thread-2488] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-200169212-172.17.0.14-1585804310386 is not formatted. Formatting ...
2020-04-02 05:11:50,903 [Thread-2488] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-200169212-172.17.0.14-1585804310386 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-200169212-172.17.0.14-1585804310386/current
2020-04-02 05:11:50,920 [Thread-2409] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41301
2020-04-02 05:11:50,921 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:11:50,921 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@9f5ab80] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:11:50,921 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:11:50,922 [Thread-2409] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:11:50,923 [Socket Reader #1 for port 43411] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43411
2020-04-02 05:11:50,926 [Thread-2488] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:50,926 [Thread-2488] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:50,926 [Thread-2488] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-200169212-172.17.0.14-1585804310386 is not formatted. Formatting ...
2020-04-02 05:11:50,926 [Thread-2488] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-200169212-172.17.0.14-1585804310386 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-200169212-172.17.0.14-1585804310386/current
2020-04-02 05:11:50,928 [Thread-2488] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1957767157;bpid=BP-200169212-172.17.0.14-1585804310386;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1957767157;c=1585804310386;bpid=BP-200169212-172.17.0.14-1585804310386;dnuuid=null
2020-04-02 05:11:50,928 [Thread-2409] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43411
2020-04-02 05:11:50,929 [Thread-2488] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 6011b007-0ddb-49cc-8c21-7b2c265a459d
2020-04-02 05:11:50,935 [Thread-2500] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-200169212-172.17.0.14-1585804310386 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 58ms
2020-04-02 05:11:50,980 [Thread-2488] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-e1a645e3-f3a4-413a-b489-5a2a07f0d88a
2020-04-02 05:11:50,980 [Thread-2488] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:11:50,985 [Thread-2409] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:11:50,985 [Thread-2409] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:11:50,986 [Thread-2517] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37479 starting to offer service
2020-04-02 05:11:50,989 [Thread-2488] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-dd2fc9e6-10fe-4937-8f52-a079f3b5b192
2020-04-02 05:11:50,989 [Thread-2488] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:11:50,993 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:11:50,993 [IPC Server listener on 43411] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43411: starting
2020-04-02 05:11:50,997 [Thread-2488] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:11:50,997 [Thread-2517] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37479
2020-04-02 05:11:51,000 [Thread-2517] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:11:51,001 [Thread-2488] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:11:51,001 [Thread-2409] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43411 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:51,001 [Thread-2488] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:11:51,001 [Thread-2488] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:11:51,001 [Thread-2488] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:11:51,001 [Thread-2488] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,001 [Thread-2517] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:51,001 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:11:51,002 [Thread-2517] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1957767157. Formatting...
2020-04-02 05:11:51,002 [Thread-2529] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:11:51,002 [Thread-2517] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1697a81d-1e20-43dd-9e69-d931ceeea2ac for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:11:51,002 [Thread-2409] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:11:51,002 [Thread-2530] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:11:51,002 [Thread-2409] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:11:51,003 [Thread-2409] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:11:51,007 [Thread-2409] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:11:51,008 [Thread-2409] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:51,008 [Thread-2409] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:11:51,008 [Thread-2409] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:11:51,008 [Thread-2409] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:51,008 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:11:51,009 [Thread-2517] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:51,009 [Thread-2409] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:39924
2020-04-02 05:11:51,009 [Thread-2517] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1957767157. Formatting...
2020-04-02 05:11:51,009 [Thread-2409] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:11:51,009 [Thread-2409] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:11:51,009 [Thread-2517] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6909d84d-d5f8-4237-ba60-22f2133e4ca2 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:11:51,010 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:51,011 [Thread-2501] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-200169212-172.17.0.14-1585804310386 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 133ms
2020-04-02 05:11:51,011 [Thread-2463] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-200169212-172.17.0.14-1585804310386: 134ms
2020-04-02 05:11:51,012 [Thread-2534] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:11:51,012 [Thread-2409] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:11:51,012 [Thread-2534] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-200169212-172.17.0.14-1585804310386/current/replicas doesn't exist 
2020-04-02 05:11:51,012 [Thread-2535] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:11:51,012 [Thread-2535] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-200169212-172.17.0.14-1585804310386/current/replicas doesn't exist 
2020-04-02 05:11:51,012 [Thread-2409] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:11:51,012 [Thread-2535] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:11:51,012 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:51,012 [Thread-2534] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:11:51,013 [Thread-2463] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-200169212-172.17.0.14-1585804310386: 2ms
2020-04-02 05:11:51,013 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:11:51,013 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:11:51,013 [Thread-2463] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:34 AM with interval of 21600000ms
2020-04-02 05:11:51,013 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-3da0dd79-074b-4b01-ae85-8b3621c7ea94): finished scanning block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,013 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:11:51,013 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-83832e4f-631c-49e5-9c88-fe887fa0b6c4): finished scanning block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,014 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-3da0dd79-074b-4b01-ae85-8b3621c7ea94): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:11:51,014 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:11:51,014 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-83832e4f-631c-49e5-9c88-fe887fa0b6c4): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:11:51,018 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 60cdc7b1-1e99-459f-b5d3-e894178bb3bb) service to localhost/127.0.0.1:37479 beginning handshake with NN
2020-04-02 05:11:51,014 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:11:51,018 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:11:51,019 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43915
2020-04-02 05:11:51,022 [IPC Server handler 3 on 37479] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34202, datanodeUuid=60cdc7b1-1e99-459f-b5d3-e894178bb3bb, infoPort=35559, infoSecurePort=0, ipcPort=46001, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386) storage 60cdc7b1-1e99-459f-b5d3-e894178bb3bb
2020-04-02 05:11:51,024 [Thread-2409] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:11:51,024 [IPC Server handler 3 on 37479] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34202
2020-04-02 05:11:51,024 [IPC Server handler 3 on 37479] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 60cdc7b1-1e99-459f-b5d3-e894178bb3bb (127.0.0.1:34202).
2020-04-02 05:11:51,032 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 60cdc7b1-1e99-459f-b5d3-e894178bb3bb) service to localhost/127.0.0.1:37479 successfully registered with NN
2020-04-02 05:11:51,032 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37479 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:11:51,032 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6c2af4c4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:11:51,039 [IPC Server handler 4 on 37479] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3da0dd79-074b-4b01-ae85-8b3621c7ea94 for DN 127.0.0.1:34202
2020-04-02 05:11:51,039 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@a0fb737{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:11:51,039 [IPC Server handler 4 on 37479] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-83832e4f-631c-49e5-9c88-fe887fa0b6c4 for DN 127.0.0.1:34202
2020-04-02 05:11:51,044 [IPC Server handler 5 on 37479] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:34202, datanodeUuid=60cdc7b1-1e99-459f-b5d3-e894178bb3bb, infoPort=35559, infoSecurePort=0, ipcPort=46001, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), reports.length=2
2020-04-02 05:11:51,044 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x624f5a97a37cd50d: Processing first storage report for DS-83832e4f-631c-49e5-9c88-fe887fa0b6c4 from datanode 60cdc7b1-1e99-459f-b5d3-e894178bb3bb
2020-04-02 05:11:51,044 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x624f5a97a37cd50d: from storage DS-83832e4f-631c-49e5-9c88-fe887fa0b6c4 node DatanodeRegistration(127.0.0.1:34202, datanodeUuid=60cdc7b1-1e99-459f-b5d3-e894178bb3bb, infoPort=35559, infoSecurePort=0, ipcPort=46001, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:51,044 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x624f5a97a37cd50d: Processing first storage report for DS-3da0dd79-074b-4b01-ae85-8b3621c7ea94 from datanode 60cdc7b1-1e99-459f-b5d3-e894178bb3bb
2020-04-02 05:11:51,044 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x624f5a97a37cd50d: from storage DS-3da0dd79-074b-4b01-ae85-8b3621c7ea94 node DatanodeRegistration(127.0.0.1:34202, datanodeUuid=60cdc7b1-1e99-459f-b5d3-e894178bb3bb, infoPort=35559, infoSecurePort=0, ipcPort=46001, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:51,044 [IPC Server handler 5 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x624f5a97a37cd50d
2020-04-02 05:11:51,045 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x624f5a97a37cd50d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:11:51,045 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,046 [Thread-2517] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,046 [Thread-2517] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,046 [Thread-2517] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-200169212-172.17.0.14-1585804310386 is not formatted. Formatting ...
2020-04-02 05:11:51,046 [Thread-2517] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-200169212-172.17.0.14-1585804310386 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-200169212-172.17.0.14-1585804310386/current
2020-04-02 05:11:51,047 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@70ad58a4{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:11:51,050 [Thread-2409] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@f176214{HTTP/1.1,[http/1.1]}{localhost:43915}
2020-04-02 05:11:51,051 [Thread-2409] INFO  server.Server (Server.java:doStart(419)) - Started @181461ms
2020-04-02 05:11:51,056 [Thread-2517] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,057 [Thread-2517] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,057 [Thread-2517] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-200169212-172.17.0.14-1585804310386 is not formatted. Formatting ...
2020-04-02 05:11:51,057 [Thread-2517] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-200169212-172.17.0.14-1585804310386 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-200169212-172.17.0.14-1585804310386/current
2020-04-02 05:11:51,057 [Thread-2530] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-200169212-172.17.0.14-1585804310386 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 56ms
2020-04-02 05:11:51,062 [Thread-2517] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1957767157;bpid=BP-200169212-172.17.0.14-1585804310386;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1957767157;c=1585804310386;bpid=BP-200169212-172.17.0.14-1585804310386;dnuuid=null
2020-04-02 05:11:51,062 [Thread-2529] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-200169212-172.17.0.14-1585804310386 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 60ms
2020-04-02 05:11:51,062 [Thread-2488] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-200169212-172.17.0.14-1585804310386: 60ms
2020-04-02 05:11:51,062 [Thread-2544] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:11:51,062 [Thread-2544] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-200169212-172.17.0.14-1585804310386/current/replicas doesn't exist 
2020-04-02 05:11:51,063 [Thread-2545] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:11:51,063 [Thread-2544] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-04-02 05:11:51,063 [Thread-2545] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-200169212-172.17.0.14-1585804310386/current/replicas doesn't exist 
2020-04-02 05:11:51,063 [Thread-2545] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 0ms
2020-04-02 05:11:51,063 [Thread-2488] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-200169212-172.17.0.14-1585804310386: 1ms
2020-04-02 05:11:51,063 [Thread-2517] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 7c675719-1fa9-4768-a92e-74a0d01cd633
2020-04-02 05:11:51,063 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:11:51,063 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:11:51,063 [Thread-2488] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:44 AM with interval of 21600000ms
2020-04-02 05:11:51,063 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-dd2fc9e6-10fe-4937-8f52-a079f3b5b192): finished scanning block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,064 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-e1a645e3-f3a4-413a-b489-5a2a07f0d88a): finished scanning block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,067 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 6011b007-0ddb-49cc-8c21-7b2c265a459d) service to localhost/127.0.0.1:37479 beginning handshake with NN
2020-04-02 05:11:51,068 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-dd2fc9e6-10fe-4937-8f52-a079f3b5b192): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:11:51,068 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-e1a645e3-f3a4-413a-b489-5a2a07f0d88a): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:11:51,068 [Thread-2517] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-1697a81d-1e20-43dd-9e69-d931ceeea2ac
2020-04-02 05:11:51,068 [Thread-2517] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:11:51,072 [IPC Server handler 6 on 37479] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41739, datanodeUuid=6011b007-0ddb-49cc-8c21-7b2c265a459d, infoPort=46542, infoSecurePort=0, ipcPort=42643, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386) storage 6011b007-0ddb-49cc-8c21-7b2c265a459d
2020-04-02 05:11:51,079 [Thread-2409] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38766
2020-04-02 05:11:51,079 [IPC Server handler 6 on 37479] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41739
2020-04-02 05:11:51,079 [IPC Server handler 6 on 37479] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 6011b007-0ddb-49cc-8c21-7b2c265a459d (127.0.0.1:41739).
2020-04-02 05:11:51,079 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:11:51,080 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:11:51,080 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4c19d651] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:11:51,080 [Thread-2517] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-6909d84d-d5f8-4237-ba60-22f2133e4ca2
2020-04-02 05:11:51,083 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 6011b007-0ddb-49cc-8c21-7b2c265a459d) service to localhost/127.0.0.1:37479 successfully registered with NN
2020-04-02 05:11:51,083 [Thread-2409] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:11:51,083 [Thread-2517] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:11:51,083 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37479 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:11:51,084 [Thread-2517] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:11:51,094 [IPC Server handler 7 on 37479] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e1a645e3-f3a4-413a-b489-5a2a07f0d88a for DN 127.0.0.1:41739
2020-04-02 05:11:51,094 [Socket Reader #1 for port 43691] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43691
2020-04-02 05:11:51,100 [IPC Server handler 7 on 37479] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-dd2fc9e6-10fe-4937-8f52-a079f3b5b192 for DN 127.0.0.1:41739
2020-04-02 05:11:51,100 [Thread-2517] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:11:51,101 [Thread-2517] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:11:51,101 [Thread-2517] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:11:51,101 [Thread-2517] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:11:51,101 [Thread-2517] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,101 [IPC Server handler 8 on 37479] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:41739, datanodeUuid=6011b007-0ddb-49cc-8c21-7b2c265a459d, infoPort=46542, infoSecurePort=0, ipcPort=42643, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), reports.length=2
2020-04-02 05:11:51,101 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x836e0fc7f18c82f: Processing first storage report for DS-dd2fc9e6-10fe-4937-8f52-a079f3b5b192 from datanode 6011b007-0ddb-49cc-8c21-7b2c265a459d
2020-04-02 05:11:51,101 [Thread-2554] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:11:51,101 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x836e0fc7f18c82f: from storage DS-dd2fc9e6-10fe-4937-8f52-a079f3b5b192 node DatanodeRegistration(127.0.0.1:41739, datanodeUuid=6011b007-0ddb-49cc-8c21-7b2c265a459d, infoPort=46542, infoSecurePort=0, ipcPort=42643, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:51,101 [Thread-2556] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:11:51,101 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x836e0fc7f18c82f: Processing first storage report for DS-e1a645e3-f3a4-413a-b489-5a2a07f0d88a from datanode 6011b007-0ddb-49cc-8c21-7b2c265a459d
2020-04-02 05:11:51,102 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x836e0fc7f18c82f: from storage DS-e1a645e3-f3a4-413a-b489-5a2a07f0d88a node DatanodeRegistration(127.0.0.1:41739, datanodeUuid=6011b007-0ddb-49cc-8c21-7b2c265a459d, infoPort=46542, infoSecurePort=0, ipcPort=42643, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:51,102 [Thread-2409] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43691
2020-04-02 05:11:51,102 [IPC Server handler 8 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x836e0fc7f18c82f
2020-04-02 05:11:51,102 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x836e0fc7f18c82f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:11:51,102 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,157 [Thread-2409] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:11:51,157 [Thread-2409] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:11:51,157 [Thread-2561] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37479 starting to offer service
2020-04-02 05:11:51,162 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:11:51,162 [IPC Server listener on 43691] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43691: starting
2020-04-02 05:11:51,167 [Thread-2561] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37479
2020-04-02 05:11:51,171 [Thread-2561] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:11:51,171 [Thread-2409] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43691 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:51,172 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:11:51,172 [Thread-2561] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:51,172 [Thread-2561] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1957767157. Formatting...
2020-04-02 05:11:51,172 [Thread-2561] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-528bafe7-46b7-43d4-a1d4-d3d9b290c9be for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-04-02 05:11:51,173 [Thread-2409] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:11:51,173 [Thread-2409] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:11:51,174 [Thread-2409] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:11:51,177 [Thread-2409] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:11:51,178 [Thread-2409] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:51,178 [Thread-2409] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:11:51,178 [Thread-2409] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:11:51,178 [Thread-2409] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:51,178 [Thread-2561] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:51,178 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:11:51,178 [Thread-2561] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1957767157. Formatting...
2020-04-02 05:11:51,178 [Thread-2561] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-91f3d47c-595b-497c-b517-03934afd2a8a for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-04-02 05:11:51,179 [Thread-2409] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:39788
2020-04-02 05:11:51,179 [Thread-2409] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:11:51,179 [Thread-2409] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:11:51,180 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:51,181 [Thread-2409] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:11:51,181 [Thread-2409] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:11:51,182 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:51,182 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:11:51,183 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:11:51,183 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:11:51,183 [Thread-2556] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-200169212-172.17.0.14-1585804310386 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 81ms
2020-04-02 05:11:51,183 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:11:51,183 [Thread-2554] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-200169212-172.17.0.14-1585804310386 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 82ms
2020-04-02 05:11:51,187 [Thread-2517] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-200169212-172.17.0.14-1585804310386: 86ms
2020-04-02 05:11:51,187 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 32967
2020-04-02 05:11:51,187 [Thread-2575] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:11:51,188 [Thread-2576] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:11:51,187 [Thread-2409] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:11:51,188 [Thread-2576] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-200169212-172.17.0.14-1585804310386/current/replicas doesn't exist 
2020-04-02 05:11:51,188 [Thread-2575] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-200169212-172.17.0.14-1585804310386/current/replicas doesn't exist 
2020-04-02 05:11:51,188 [Thread-2576] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 0ms
2020-04-02 05:11:51,188 [Thread-2575] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 0ms
2020-04-02 05:11:51,188 [Thread-2517] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-200169212-172.17.0.14-1585804310386: 1ms
2020-04-02 05:11:51,189 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:11:51,189 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:11:51,189 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-1697a81d-1e20-43dd-9e69-d931ceeea2ac): finished scanning block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,189 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-6909d84d-d5f8-4237-ba60-22f2133e4ca2): finished scanning block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,189 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1294a899{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:11:51,189 [Thread-2517] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:52 AM with interval of 21600000ms
2020-04-02 05:11:51,189 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-6909d84d-d5f8-4237-ba60-22f2133e4ca2): no suitable block pools found to scan.  Waiting 1814400000 ms.
2020-04-02 05:11:51,189 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-1697a81d-1e20-43dd-9e69-d931ceeea2ac): no suitable block pools found to scan.  Waiting 1814400000 ms.
2020-04-02 05:11:51,190 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@521cc446{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:11:51,194 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 7c675719-1fa9-4768-a92e-74a0d01cd633) service to localhost/127.0.0.1:37479 beginning handshake with NN
2020-04-02 05:11:51,194 [IPC Server handler 0 on 37479] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44321, datanodeUuid=7c675719-1fa9-4768-a92e-74a0d01cd633, infoPort=41301, infoSecurePort=0, ipcPort=43411, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386) storage 7c675719-1fa9-4768-a92e-74a0d01cd633
2020-04-02 05:11:51,194 [IPC Server handler 0 on 37479] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44321
2020-04-02 05:11:51,195 [IPC Server handler 0 on 37479] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7c675719-1fa9-4768-a92e-74a0d01cd633 (127.0.0.1:44321).
2020-04-02 05:11:51,195 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 7c675719-1fa9-4768-a92e-74a0d01cd633) service to localhost/127.0.0.1:37479 successfully registered with NN
2020-04-02 05:11:51,195 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37479 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:11:51,201 [IPC Server handler 1 on 37479] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1697a81d-1e20-43dd-9e69-d931ceeea2ac for DN 127.0.0.1:44321
2020-04-02 05:11:51,201 [IPC Server handler 1 on 37479] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6909d84d-d5f8-4237-ba60-22f2133e4ca2 for DN 127.0.0.1:44321
2020-04-02 05:11:51,201 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1fe8f80f{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:11:51,202 [Thread-2409] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@777a20d5{HTTP/1.1,[http/1.1]}{localhost:32967}
2020-04-02 05:11:51,202 [Thread-2409] INFO  server.Server (Server.java:doStart(419)) - Started @181612ms
2020-04-02 05:11:51,206 [IPC Server handler 2 on 37479] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:44321, datanodeUuid=7c675719-1fa9-4768-a92e-74a0d01cd633, infoPort=41301, infoSecurePort=0, ipcPort=43411, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), reports.length=2
2020-04-02 05:11:51,206 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2516a9bcb84749eb: Processing first storage report for DS-6909d84d-d5f8-4237-ba60-22f2133e4ca2 from datanode 7c675719-1fa9-4768-a92e-74a0d01cd633
2020-04-02 05:11:51,206 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2516a9bcb84749eb: from storage DS-6909d84d-d5f8-4237-ba60-22f2133e4ca2 node DatanodeRegistration(127.0.0.1:44321, datanodeUuid=7c675719-1fa9-4768-a92e-74a0d01cd633, infoPort=41301, infoSecurePort=0, ipcPort=43411, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:51,206 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2516a9bcb84749eb: Processing first storage report for DS-1697a81d-1e20-43dd-9e69-d931ceeea2ac from datanode 7c675719-1fa9-4768-a92e-74a0d01cd633
2020-04-02 05:11:51,206 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2516a9bcb84749eb: from storage DS-1697a81d-1e20-43dd-9e69-d931ceeea2ac node DatanodeRegistration(127.0.0.1:44321, datanodeUuid=7c675719-1fa9-4768-a92e-74a0d01cd633, infoPort=41301, infoSecurePort=0, ipcPort=43411, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:11:51,207 [IPC Server handler 2 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x2516a9bcb84749eb
2020-04-02 05:11:51,207 [Thread-2561] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,207 [Thread-2561] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,207 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x2516a9bcb84749eb,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:11:51,207 [Thread-2561] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-200169212-172.17.0.14-1585804310386 is not formatted. Formatting ...
2020-04-02 05:11:51,207 [Thread-2561] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-200169212-172.17.0.14-1585804310386 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-200169212-172.17.0.14-1585804310386/current
2020-04-02 05:11:51,207 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,222 [Thread-2409] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40801
2020-04-02 05:11:51,222 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:11:51,222 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@19ede4d8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:11:51,222 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:11:51,223 [Thread-2409] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:11:51,223 [Socket Reader #1 for port 33888] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33888
2020-04-02 05:11:51,228 [Thread-2409] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:33888
2020-04-02 05:11:51,230 [Thread-2561] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,230 [Thread-2561] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,230 [Thread-2561] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-200169212-172.17.0.14-1585804310386 is not formatted. Formatting ...
2020-04-02 05:11:51,230 [Thread-2561] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-200169212-172.17.0.14-1585804310386 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-200169212-172.17.0.14-1585804310386/current
2020-04-02 05:11:51,232 [Thread-2561] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1957767157;bpid=BP-200169212-172.17.0.14-1585804310386;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1957767157;c=1585804310386;bpid=BP-200169212-172.17.0.14-1585804310386;dnuuid=null
2020-04-02 05:11:51,233 [Thread-2561] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 5583f91d-0b87-438d-b05a-1617d27fa2d0
2020-04-02 05:11:51,286 [Thread-2561] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-528bafe7-46b7-43d4-a1d4-d3d9b290c9be
2020-04-02 05:11:51,287 [Thread-2561] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:11:51,287 [Thread-2409] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:11:51,291 [Thread-2409] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:11:51,292 [Thread-2590] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37479 starting to offer service
2020-04-02 05:11:51,292 [Thread-2561] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-91f3d47c-595b-497c-b517-03934afd2a8a
2020-04-02 05:11:51,292 [Thread-2561] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:11:51,296 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:11:51,296 [Thread-2561] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:11:51,296 [IPC Server listener on 33888] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33888: starting
2020-04-02 05:11:51,304 [Thread-2561] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:11:51,304 [Thread-2409] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 33888 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:51,304 [Thread-2561] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:11:51,304 [Thread-2561] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:11:51,305 [Thread-2590] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37479
2020-04-02 05:11:51,305 [Thread-2561] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:11:51,310 [Thread-2590] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:11:51,310 [Thread-2561] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,310 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:11:51,310 [Thread-2602] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:11:51,310 [Thread-2603] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:11:51,311 [Thread-2409] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:11:51,311 [Thread-2409] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:11:51,311 [Thread-2590] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:51,311 [Thread-2590] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 1957767157. Formatting...
2020-04-02 05:11:51,312 [Thread-2590] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b87e9e84-c1e4-4d71-b26f-96076c48386b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-04-02 05:11:51,312 [Thread-2409] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:11:51,316 [Thread-2409] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:11:51,316 [Thread-2409] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:51,317 [Thread-2409] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:11:51,317 [Thread-2409] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:11:51,317 [Thread-2409] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:51,317 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:11:51,318 [Thread-2409] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40916
2020-04-02 05:11:51,318 [Thread-2409] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:11:51,318 [Thread-2409] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:11:51,318 [Thread-2590] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:51,319 [Thread-2590] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 1957767157. Formatting...
2020-04-02 05:11:51,319 [Thread-2590] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5ac6ef19-2e4b-4bf5-bf8b-cba58c81490b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-04-02 05:11:51,319 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:51,321 [Thread-2409] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:11:51,322 [Thread-2409] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:11:51,322 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:51,323 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:11:51,323 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:11:51,323 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:11:51,324 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:11:51,324 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40823
2020-04-02 05:11:51,324 [Thread-2409] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:11:51,325 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@291054d4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:11:51,326 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@750cda7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:11:51,326 [Thread-2590] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,326 [Thread-2590] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,326 [Thread-2590] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-200169212-172.17.0.14-1585804310386 is not formatted. Formatting ...
2020-04-02 05:11:51,326 [Thread-2590] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-200169212-172.17.0.14-1585804310386 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-200169212-172.17.0.14-1585804310386/current
2020-04-02 05:11:51,329 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@760ab751{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:11:51,329 [Thread-2409] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@25c1007e{HTTP/1.1,[http/1.1]}{localhost:40823}
2020-04-02 05:11:51,329 [Thread-2409] INFO  server.Server (Server.java:doStart(419)) - Started @181740ms
2020-04-02 05:11:51,351 [Thread-2409] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42223
2020-04-02 05:11:51,351 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:11:51,351 [Thread-2590] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,351 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@46ab3b30] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:11:51,351 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:11:51,351 [Thread-2590] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,351 [Thread-2409] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:11:51,351 [Thread-2590] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-200169212-172.17.0.14-1585804310386 is not formatted. Formatting ...
2020-04-02 05:11:51,351 [Thread-2590] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-200169212-172.17.0.14-1585804310386 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-200169212-172.17.0.14-1585804310386/current
2020-04-02 05:11:51,352 [Socket Reader #1 for port 35317] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35317
2020-04-02 05:11:51,358 [Thread-2590] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1957767157;bpid=BP-200169212-172.17.0.14-1585804310386;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1957767157;c=1585804310386;bpid=BP-200169212-172.17.0.14-1585804310386;dnuuid=null
2020-04-02 05:11:51,359 [Thread-2409] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:35317
2020-04-02 05:11:51,359 [Thread-2590] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID dd3c628c-6b8d-4a72-834f-2e2e8bf4506f
2020-04-02 05:11:51,366 [Thread-2603] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-200169212-172.17.0.14-1585804310386 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 55ms
2020-04-02 05:11:51,419 [Thread-2409] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:11:51,419 [Thread-2409] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:11:51,419 [Thread-2618] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37479 starting to offer service
2020-04-02 05:11:51,423 [Thread-2590] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-b87e9e84-c1e4-4d71-b26f-96076c48386b
2020-04-02 05:11:51,423 [Thread-2590] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-04-02 05:11:51,427 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:11:51,431 [Thread-2618] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37479
2020-04-02 05:11:51,431 [IPC Server listener on 35317] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35317: starting
2020-04-02 05:11:51,435 [Thread-2618] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:11:51,435 [Thread-2590] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5ac6ef19-2e4b-4bf5-bf8b-cba58c81490b
2020-04-02 05:11:51,435 [Thread-2590] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-04-02 05:11:51,439 [Thread-2590] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:11:51,439 [Thread-2409] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 35317 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:51,439 [Thread-2618] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:51,439 [Thread-2618] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 1957767157. Formatting...
2020-04-02 05:11:51,440 [Thread-2618] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-35186f53-3acb-4231-82e6-0a30a9fd054a for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-04-02 05:11:51,440 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:11:51,441 [Thread-2590] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:11:51,441 [Thread-2409] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:11:51,441 [Thread-2409] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:11:51,441 [Thread-2590] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:11:51,442 [Thread-2590] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:11:51,442 [Thread-2590] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:11:51,442 [Thread-2590] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,442 [Thread-2409] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:11:51,447 [Thread-2618] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:51,447 [Thread-2632] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:11:51,447 [Thread-2631] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:11:51,447 [Thread-2618] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 1957767157. Formatting...
2020-04-02 05:11:51,447 [Thread-2409] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:11:51,447 [Thread-2618] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-86bfa768-ae2f-4725-b926-a715c6b58adb for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-04-02 05:11:51,448 [Thread-2409] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:51,448 [Thread-2409] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:11:51,449 [Thread-2409] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:11:51,449 [Thread-2409] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:51,449 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:11:51,450 [Thread-2409] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:36146
2020-04-02 05:11:51,450 [Thread-2409] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:11:51,450 [Thread-2409] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:11:51,450 [Thread-2602] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-200169212-172.17.0.14-1585804310386 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 139ms
2020-04-02 05:11:51,450 [Thread-2561] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-200169212-172.17.0.14-1585804310386: 140ms
2020-04-02 05:11:51,451 [Thread-2636] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:11:51,451 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:51,451 [Thread-2636] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-200169212-172.17.0.14-1585804310386/current/replicas doesn't exist 
2020-04-02 05:11:51,451 [Thread-2637] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:11:51,451 [Thread-2637] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-200169212-172.17.0.14-1585804310386/current/replicas doesn't exist 
2020-04-02 05:11:51,451 [Thread-2636] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 1ms
2020-04-02 05:11:51,452 [Thread-2637] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 1ms
2020-04-02 05:11:51,452 [Thread-2561] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-200169212-172.17.0.14-1585804310386: 1ms
2020-04-02 05:11:51,452 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:11:51,452 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:11:51,452 [Thread-2561] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:35 AM with interval of 21600000ms
2020-04-02 05:11:51,452 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-528bafe7-46b7-43d4-a1d4-d3d9b290c9be): finished scanning block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,452 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-91f3d47c-595b-497c-b517-03934afd2a8a): finished scanning block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,457 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 5583f91d-0b87-438d-b05a-1617d27fa2d0) service to localhost/127.0.0.1:37479 beginning handshake with NN
2020-04-02 05:11:51,457 [Thread-2409] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:11:51,457 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-91f3d47c-595b-497c-b517-03934afd2a8a): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:11:51,457 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-528bafe7-46b7-43d4-a1d4-d3d9b290c9be): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:11:51,458 [Thread-2409] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:11:51,458 [IPC Server handler 5 on 37479] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39924, datanodeUuid=5583f91d-0b87-438d-b05a-1617d27fa2d0, infoPort=38766, infoSecurePort=0, ipcPort=43691, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386) storage 5583f91d-0b87-438d-b05a-1617d27fa2d0
2020-04-02 05:11:51,458 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:51,458 [IPC Server handler 5 on 37479] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39924
2020-04-02 05:11:51,458 [IPC Server handler 5 on 37479] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5583f91d-0b87-438d-b05a-1617d27fa2d0 (127.0.0.1:39924).
2020-04-02 05:11:51,459 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:11:51,459 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 5583f91d-0b87-438d-b05a-1617d27fa2d0) service to localhost/127.0.0.1:37479 successfully registered with NN
2020-04-02 05:11:51,459 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37479 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:11:51,459 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:11:51,463 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:11:51,463 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:11:51,466 [IPC Server handler 6 on 37479] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-528bafe7-46b7-43d4-a1d4-d3d9b290c9be for DN 127.0.0.1:39924
2020-04-02 05:11:51,467 [IPC Server handler 6 on 37479] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-91f3d47c-595b-497c-b517-03934afd2a8a for DN 127.0.0.1:39924
2020-04-02 05:11:51,467 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35959
2020-04-02 05:11:51,467 [Thread-2409] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:11:51,468 [IPC Server handler 7 on 37479] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:39924, datanodeUuid=5583f91d-0b87-438d-b05a-1617d27fa2d0, infoPort=38766, infoSecurePort=0, ipcPort=43691, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), reports.length=2
2020-04-02 05:11:51,468 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xcd3f04ac3986659b: Processing first storage report for DS-528bafe7-46b7-43d4-a1d4-d3d9b290c9be from datanode 5583f91d-0b87-438d-b05a-1617d27fa2d0
2020-04-02 05:11:51,468 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xcd3f04ac3986659b: from storage DS-528bafe7-46b7-43d4-a1d4-d3d9b290c9be node DatanodeRegistration(127.0.0.1:39924, datanodeUuid=5583f91d-0b87-438d-b05a-1617d27fa2d0, infoPort=38766, infoSecurePort=0, ipcPort=43691, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:51,468 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xcd3f04ac3986659b: Processing first storage report for DS-91f3d47c-595b-497c-b517-03934afd2a8a from datanode 5583f91d-0b87-438d-b05a-1617d27fa2d0
2020-04-02 05:11:51,468 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xcd3f04ac3986659b: from storage DS-91f3d47c-595b-497c-b517-03934afd2a8a node DatanodeRegistration(127.0.0.1:39924, datanodeUuid=5583f91d-0b87-438d-b05a-1617d27fa2d0, infoPort=38766, infoSecurePort=0, ipcPort=43691, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:51,468 [IPC Server handler 7 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xcd3f04ac3986659b
2020-04-02 05:11:51,469 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@25bdcf22{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:11:51,469 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xcd3f04ac3986659b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:11:51,469 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,469 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2ebabee0{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:11:51,472 [Thread-2618] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,472 [Thread-2618] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,472 [Thread-2618] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-200169212-172.17.0.14-1585804310386 is not formatted. Formatting ...
2020-04-02 05:11:51,472 [Thread-2618] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-200169212-172.17.0.14-1585804310386 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-200169212-172.17.0.14-1585804310386/current
2020-04-02 05:11:51,473 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@43c7ea43{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:11:51,473 [Thread-2409] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@463be193{HTTP/1.1,[http/1.1]}{localhost:35959}
2020-04-02 05:11:51,496 [Thread-2409] INFO  server.Server (Server.java:doStart(419)) - Started @181907ms
2020-04-02 05:11:51,505 [Thread-2618] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,505 [Thread-2618] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,506 [Thread-2618] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-200169212-172.17.0.14-1585804310386 is not formatted. Formatting ...
2020-04-02 05:11:51,506 [Thread-2618] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-200169212-172.17.0.14-1585804310386 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-200169212-172.17.0.14-1585804310386/current
2020-04-02 05:11:51,516 [Thread-2409] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34278
2020-04-02 05:11:51,517 [Thread-2631] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-200169212-172.17.0.14-1585804310386 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 70ms
2020-04-02 05:11:51,517 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:11:51,517 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2b628a79] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:11:51,517 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:11:51,517 [Thread-2618] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1957767157;bpid=BP-200169212-172.17.0.14-1585804310386;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1957767157;c=1585804310386;bpid=BP-200169212-172.17.0.14-1585804310386;dnuuid=null
2020-04-02 05:11:51,517 [Thread-2409] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:11:51,518 [Socket Reader #1 for port 44091] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44091
2020-04-02 05:11:51,520 [Thread-2618] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 1bdaec69-9042-40a1-8df0-d17b5545118f
2020-04-02 05:11:51,521 [Thread-2618] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-35186f53-3acb-4231-82e6-0a30a9fd054a
2020-04-02 05:11:51,521 [Thread-2618] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-04-02 05:11:51,524 [Thread-2409] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:44091
2020-04-02 05:11:51,524 [Thread-2618] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-86bfa768-ae2f-4725-b926-a715c6b58adb
2020-04-02 05:11:51,524 [Thread-2618] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-04-02 05:11:51,527 [Thread-2618] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:11:51,532 [Thread-2632] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-200169212-172.17.0.14-1585804310386 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 85ms
2020-04-02 05:11:51,532 [Thread-2590] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-200169212-172.17.0.14-1585804310386: 85ms
2020-04-02 05:11:51,588 [Thread-2652] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:11:51,588 [Thread-2652] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-200169212-172.17.0.14-1585804310386/current/replicas doesn't exist 
2020-04-02 05:11:51,589 [Thread-2653] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:11:51,589 [Thread-2652] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 1ms
2020-04-02 05:11:51,589 [Thread-2653] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-200169212-172.17.0.14-1585804310386/current/replicas doesn't exist 
2020-04-02 05:11:51,589 [Thread-2653] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 0ms
2020-04-02 05:11:51,589 [Thread-2590] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-200169212-172.17.0.14-1585804310386: 57ms
2020-04-02 05:11:51,589 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:11:51,589 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:11:51,590 [Thread-2590] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:46 AM with interval of 21600000ms
2020-04-02 05:11:51,590 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-5ac6ef19-2e4b-4bf5-bf8b-cba58c81490b): finished scanning block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,590 [Thread-2618] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:11:51,590 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-b87e9e84-c1e4-4d71-b26f-96076c48386b): finished scanning block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,594 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid dd3c628c-6b8d-4a72-834f-2e2e8bf4506f) service to localhost/127.0.0.1:37479 beginning handshake with NN
2020-04-02 05:11:51,594 [Thread-2409] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:11:51,594 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-5ac6ef19-2e4b-4bf5-bf8b-cba58c81490b): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:11:51,594 [Thread-2618] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:11:51,594 [Thread-2409] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:11:51,594 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-b87e9e84-c1e4-4d71-b26f-96076c48386b): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:11:51,594 [Thread-2618] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:11:51,595 [IPC Server handler 8 on 37479] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39788, datanodeUuid=dd3c628c-6b8d-4a72-834f-2e2e8bf4506f, infoPort=40801, infoSecurePort=0, ipcPort=33888, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386) storage dd3c628c-6b8d-4a72-834f-2e2e8bf4506f
2020-04-02 05:11:51,595 [Thread-2618] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:11:51,595 [IPC Server handler 8 on 37479] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39788
2020-04-02 05:11:51,595 [Thread-2659] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37479 starting to offer service
2020-04-02 05:11:51,595 [Thread-2618] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,595 [IPC Server handler 8 on 37479] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN dd3c628c-6b8d-4a72-834f-2e2e8bf4506f (127.0.0.1:39788).
2020-04-02 05:11:51,599 [Thread-2660] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:11:51,599 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid dd3c628c-6b8d-4a72-834f-2e2e8bf4506f) service to localhost/127.0.0.1:37479 successfully registered with NN
2020-04-02 05:11:51,599 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37479 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:11:51,605 [Thread-2659] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37479
2020-04-02 05:11:51,605 [Thread-2661] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:11:51,609 [Thread-2659] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:11:51,609 [IPC Server listener on 44091] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44091: starting
2020-04-02 05:11:51,612 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:51,612 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:11:51,612 [IPC Server handler 0 on 37479] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b87e9e84-c1e4-4d71-b26f-96076c48386b for DN 127.0.0.1:39788
2020-04-02 05:11:51,621 [IPC Server handler 0 on 37479] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5ac6ef19-2e4b-4bf5-bf8b-cba58c81490b for DN 127.0.0.1:39788
2020-04-02 05:11:51,616 [Thread-2409] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 44091 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:51,616 [Thread-2659] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:51,622 [Thread-2659] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 1957767157. Formatting...
2020-04-02 05:11:51,622 [Thread-2659] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ffcbda99-74d6-4d0d-946e-22997f222bfd for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-04-02 05:11:51,622 [IPC Server handler 1 on 37479] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:39788, datanodeUuid=dd3c628c-6b8d-4a72-834f-2e2e8bf4506f, infoPort=40801, infoSecurePort=0, ipcPort=33888, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), reports.length=2
2020-04-02 05:11:51,622 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x463b94aa1359d20d: Processing first storage report for DS-5ac6ef19-2e4b-4bf5-bf8b-cba58c81490b from datanode dd3c628c-6b8d-4a72-834f-2e2e8bf4506f
2020-04-02 05:11:51,622 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x463b94aa1359d20d: from storage DS-5ac6ef19-2e4b-4bf5-bf8b-cba58c81490b node DatanodeRegistration(127.0.0.1:39788, datanodeUuid=dd3c628c-6b8d-4a72-834f-2e2e8bf4506f, infoPort=40801, infoSecurePort=0, ipcPort=33888, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:51,623 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x463b94aa1359d20d: Processing first storage report for DS-b87e9e84-c1e4-4d71-b26f-96076c48386b from datanode dd3c628c-6b8d-4a72-834f-2e2e8bf4506f
2020-04-02 05:11:51,623 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:11:51,623 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x463b94aa1359d20d: from storage DS-b87e9e84-c1e4-4d71-b26f-96076c48386b node DatanodeRegistration(127.0.0.1:39788, datanodeUuid=dd3c628c-6b8d-4a72-834f-2e2e8bf4506f, infoPort=40801, infoSecurePort=0, ipcPort=33888, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:51,623 [IPC Server handler 1 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x463b94aa1359d20d
2020-04-02 05:11:51,623 [Thread-2409] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:11:51,624 [Thread-2409] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:11:51,625 [Thread-2409] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:11:51,629 [Thread-2659] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:51,630 [Thread-2659] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 1957767157. Formatting...
2020-04-02 05:11:51,630 [Thread-2659] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-73c80090-94c4-499d-ba29-7fed7cd3d134 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-04-02 05:11:51,630 [Thread-2409] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:11:51,631 [Thread-2409] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:51,631 [Thread-2409] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:11:51,631 [Thread-2409] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:11:51,631 [Thread-2409] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:51,631 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:11:51,632 [Thread-2409] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:46280
2020-04-02 05:11:51,632 [Thread-2409] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:11:51,632 [Thread-2409] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:11:51,633 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:51,634 [Thread-2409] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:11:51,634 [Thread-2409] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:11:51,634 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:51,635 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:11:51,635 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:11:51,635 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:11:51,635 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:11:51,638 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38964
2020-04-02 05:11:51,638 [Thread-2409] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:11:51,638 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x463b94aa1359d20d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 17 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:11:51,638 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,639 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@677f75fd{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:11:51,639 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2d70e67a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:11:51,642 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3b84026f{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:11:51,642 [Thread-2409] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@27587c9{HTTP/1.1,[http/1.1]}{localhost:38964}
2020-04-02 05:11:51,646 [Thread-2409] INFO  server.Server (Server.java:doStart(419)) - Started @182056ms
2020-04-02 05:11:51,650 [Thread-2659] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,650 [Thread-2659] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,650 [Thread-2659] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-200169212-172.17.0.14-1585804310386 is not formatted. Formatting ...
2020-04-02 05:11:51,650 [Thread-2659] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-200169212-172.17.0.14-1585804310386 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-200169212-172.17.0.14-1585804310386/current
2020-04-02 05:11:51,659 [Thread-2409] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45556
2020-04-02 05:11:51,660 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:11:51,660 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6042db47] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:11:51,660 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:11:51,660 [Thread-2409] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:11:51,661 [Socket Reader #1 for port 36565] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36565
2020-04-02 05:11:51,666 [Thread-2409] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:36565
2020-04-02 05:11:51,671 [Thread-2659] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,672 [Thread-2659] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,672 [Thread-2659] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-200169212-172.17.0.14-1585804310386 is not formatted. Formatting ...
2020-04-02 05:11:51,672 [Thread-2659] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-200169212-172.17.0.14-1585804310386 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-200169212-172.17.0.14-1585804310386/current
2020-04-02 05:11:51,674 [Thread-2659] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1957767157;bpid=BP-200169212-172.17.0.14-1585804310386;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1957767157;c=1585804310386;bpid=BP-200169212-172.17.0.14-1585804310386;dnuuid=null
2020-04-02 05:11:51,675 [Thread-2659] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 40d91f97-1611-4923-922d-b0499f6d8bff
2020-04-02 05:11:51,729 [Thread-2409] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:11:51,729 [Thread-2409] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:11:51,730 [Thread-2686] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37479 starting to offer service
2020-04-02 05:11:51,730 [Thread-2659] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-ffcbda99-74d6-4d0d-946e-22997f222bfd
2020-04-02 05:11:51,730 [Thread-2659] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-04-02 05:11:51,734 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:11:51,734 [IPC Server listener on 36565] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36565: starting
2020-04-02 05:11:51,743 [Thread-2659] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-73c80090-94c4-499d-ba29-7fed7cd3d134
2020-04-02 05:11:51,743 [Thread-2686] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37479
2020-04-02 05:11:51,743 [Thread-2659] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-04-02 05:11:51,748 [Thread-2686] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:11:51,748 [Thread-2409] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 36565 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:51,748 [Thread-2659] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:11:51,749 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:11:51,749 [Thread-2686] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:51,749 [Thread-2659] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:11:51,749 [Thread-2686] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 1957767157. Formatting...
2020-04-02 05:11:51,749 [Thread-2686] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c05da3bc-c55f-451f-8797-43bba1fc00cb for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-04-02 05:11:51,750 [Thread-2409] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:11:51,750 [Thread-2659] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:11:51,750 [Thread-2659] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:11:51,750 [Thread-2409] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:11:51,750 [Thread-2659] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:11:51,754 [Thread-2659] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,755 [Thread-2699] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:11:51,755 [Thread-2700] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:11:51,755 [Thread-2409] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:11:51,760 [Thread-2409] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:11:51,761 [Thread-2409] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:51,761 [Thread-2409] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:11:51,762 [Thread-2409] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:11:51,762 [Thread-2409] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:11:51,762 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:11:51,762 [Thread-2409] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:43356
2020-04-02 05:11:51,762 [Thread-2409] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:11:51,762 [Thread-2409] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:11:51,763 [Thread-2660] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-200169212-172.17.0.14-1585804310386 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 163ms
2020-04-02 05:11:51,763 [Thread-2661] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-200169212-172.17.0.14-1585804310386 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 154ms
2020-04-02 05:11:51,763 [Thread-2686] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:51,763 [Thread-2618] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-200169212-172.17.0.14-1585804310386: 168ms
2020-04-02 05:11:51,763 [Thread-2686] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 1957767157. Formatting...
2020-04-02 05:11:51,763 [Thread-2686] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1a1c0fcc-5603-4301-bf17-468d1ba8eac9 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-04-02 05:11:51,763 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:51,783 [Thread-2704] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:11:51,783 [Thread-2704] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-200169212-172.17.0.14-1585804310386/current/replicas doesn't exist 
2020-04-02 05:11:51,783 [Thread-2705] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:11:51,783 [Thread-2705] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-200169212-172.17.0.14-1585804310386/current/replicas doesn't exist 
2020-04-02 05:11:51,783 [Thread-2704] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 0ms
2020-04-02 05:11:51,783 [Thread-2705] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 0ms
2020-04-02 05:11:51,783 [Thread-2618] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-200169212-172.17.0.14-1585804310386: 21ms
2020-04-02 05:11:51,784 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:11:51,784 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:11:51,784 [Thread-2618] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:20 AM with interval of 21600000ms
2020-04-02 05:11:51,784 [Thread-2409] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:11:51,784 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-86bfa768-ae2f-4725-b926-a715c6b58adb): finished scanning block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,784 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-35186f53-3acb-4231-82e6-0a30a9fd054a): finished scanning block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,788 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 1bdaec69-9042-40a1-8df0-d17b5545118f) service to localhost/127.0.0.1:37479 beginning handshake with NN
2020-04-02 05:11:51,789 [Thread-2409] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:11:51,789 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:11:51,789 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-86bfa768-ae2f-4725-b926-a715c6b58adb): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:11:51,789 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-35186f53-3acb-4231-82e6-0a30a9fd054a): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:11:51,789 [IPC Server handler 3 on 37479] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40916, datanodeUuid=1bdaec69-9042-40a1-8df0-d17b5545118f, infoPort=42223, infoSecurePort=0, ipcPort=35317, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386) storage 1bdaec69-9042-40a1-8df0-d17b5545118f
2020-04-02 05:11:51,789 [IPC Server handler 3 on 37479] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40916
2020-04-02 05:11:51,789 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:11:51,790 [IPC Server handler 3 on 37479] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1bdaec69-9042-40a1-8df0-d17b5545118f (127.0.0.1:40916).
2020-04-02 05:11:51,790 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:11:51,790 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 1bdaec69-9042-40a1-8df0-d17b5545118f) service to localhost/127.0.0.1:37479 successfully registered with NN
2020-04-02 05:11:51,790 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:11:51,790 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37479 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:11:51,790 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:11:51,799 [IPC Server handler 4 on 37479] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-35186f53-3acb-4231-82e6-0a30a9fd054a for DN 127.0.0.1:40916
2020-04-02 05:11:51,799 [IPC Server handler 4 on 37479] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-86bfa768-ae2f-4725-b926-a715c6b58adb for DN 127.0.0.1:40916
2020-04-02 05:11:51,799 [Thread-2409] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35460
2020-04-02 05:11:51,799 [Thread-2409] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:11:51,800 [IPC Server handler 5 on 37479] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:40916, datanodeUuid=1bdaec69-9042-40a1-8df0-d17b5545118f, infoPort=42223, infoSecurePort=0, ipcPort=35317, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), reports.length=2
2020-04-02 05:11:51,800 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xff17f6ac6658dd45: Processing first storage report for DS-86bfa768-ae2f-4725-b926-a715c6b58adb from datanode 1bdaec69-9042-40a1-8df0-d17b5545118f
2020-04-02 05:11:51,800 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xff17f6ac6658dd45: from storage DS-86bfa768-ae2f-4725-b926-a715c6b58adb node DatanodeRegistration(127.0.0.1:40916, datanodeUuid=1bdaec69-9042-40a1-8df0-d17b5545118f, infoPort=42223, infoSecurePort=0, ipcPort=35317, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:51,800 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xff17f6ac6658dd45: Processing first storage report for DS-35186f53-3acb-4231-82e6-0a30a9fd054a from datanode 1bdaec69-9042-40a1-8df0-d17b5545118f
2020-04-02 05:11:51,800 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@68e53ab4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:11:51,800 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xff17f6ac6658dd45: from storage DS-35186f53-3acb-4231-82e6-0a30a9fd054a node DatanodeRegistration(127.0.0.1:40916, datanodeUuid=1bdaec69-9042-40a1-8df0-d17b5545118f, infoPort=42223, infoSecurePort=0, ipcPort=35317, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:51,801 [IPC Server handler 5 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xff17f6ac6658dd45
2020-04-02 05:11:51,801 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3cd7638b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:11:51,801 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xff17f6ac6658dd45,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:11:51,801 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,805 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@40d3fdd9{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:11:51,805 [Thread-2686] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,805 [Thread-2686] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,805 [Thread-2409] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@f2bd001{HTTP/1.1,[http/1.1]}{localhost:35460}
2020-04-02 05:11:51,809 [Thread-2686] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-200169212-172.17.0.14-1585804310386 is not formatted. Formatting ...
2020-04-02 05:11:51,809 [Thread-2686] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-200169212-172.17.0.14-1585804310386 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-200169212-172.17.0.14-1585804310386/current
2020-04-02 05:11:51,809 [Thread-2409] INFO  server.Server (Server.java:doStart(419)) - Started @182219ms
2020-04-02 05:11:51,826 [Thread-2409] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42221
2020-04-02 05:11:51,826 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:11:51,826 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@78f985d5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:11:51,826 [Thread-2409] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:11:51,827 [Thread-2409] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:11:51,827 [Socket Reader #1 for port 33543] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33543
2020-04-02 05:11:51,832 [Thread-2409] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:33543
2020-04-02 05:11:51,832 [Thread-2686] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,833 [Thread-2686] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,833 [Thread-2686] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-200169212-172.17.0.14-1585804310386 is not formatted. Formatting ...
2020-04-02 05:11:51,833 [Thread-2686] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-200169212-172.17.0.14-1585804310386 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-200169212-172.17.0.14-1585804310386/current
2020-04-02 05:11:51,835 [Thread-2686] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1957767157;bpid=BP-200169212-172.17.0.14-1585804310386;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1957767157;c=1585804310386;bpid=BP-200169212-172.17.0.14-1585804310386;dnuuid=null
2020-04-02 05:11:51,836 [Thread-2686] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID a0180d68-4703-4668-9faf-b16cb7f708f5
2020-04-02 05:11:51,838 [Thread-2700] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-200169212-172.17.0.14-1585804310386 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 83ms
2020-04-02 05:11:51,838 [Thread-2699] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-200169212-172.17.0.14-1585804310386 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 84ms
2020-04-02 05:11:51,903 [Thread-2659] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-200169212-172.17.0.14-1585804310386: 148ms
2020-04-02 05:11:51,904 [Thread-2718] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:11:51,904 [Thread-2719] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:11:51,904 [Thread-2718] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-200169212-172.17.0.14-1585804310386/current/replicas doesn't exist 
2020-04-02 05:11:51,904 [Thread-2719] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-200169212-172.17.0.14-1585804310386/current/replicas doesn't exist 
2020-04-02 05:11:51,904 [Thread-2718] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 0ms
2020-04-02 05:11:51,904 [Thread-2719] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 0ms
2020-04-02 05:11:51,904 [Thread-2659] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-200169212-172.17.0.14-1585804310386: 1ms
2020-04-02 05:11:51,905 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:11:51,905 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:11:51,907 [Thread-2409] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:11:51,907 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-ffcbda99-74d6-4d0d-946e-22997f222bfd): finished scanning block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,907 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-ffcbda99-74d6-4d0d-946e-22997f222bfd): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:11:51,905 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-73c80090-94c4-499d-ba29-7fed7cd3d134): finished scanning block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,905 [Thread-2659] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:16 AM with interval of 21600000ms
2020-04-02 05:11:51,909 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-73c80090-94c4-499d-ba29-7fed7cd3d134): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:11:51,907 [Thread-2409] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:11:51,909 [Thread-2686] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c05da3bc-c55f-451f-8797-43bba1fc00cb
2020-04-02 05:11:51,910 [Thread-2686] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-04-02 05:11:51,910 [Thread-2726] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37479 starting to offer service
2020-04-02 05:11:51,911 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:11:51,911 [IPC Server listener on 33543] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33543: starting
2020-04-02 05:11:51,912 [Thread-2686] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-1a1c0fcc-5603-4301-bf17-468d1ba8eac9
2020-04-02 05:11:51,912 [Thread-2686] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-04-02 05:11:51,930 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 40d91f97-1611-4923-922d-b0499f6d8bff) service to localhost/127.0.0.1:37479 beginning handshake with NN
2020-04-02 05:11:51,935 [Thread-2409] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 33543 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:51,935 [Thread-2686] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:11:51,935 [IPC Server handler 6 on 37479] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36146, datanodeUuid=40d91f97-1611-4923-922d-b0499f6d8bff, infoPort=34278, infoSecurePort=0, ipcPort=44091, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386) storage 40d91f97-1611-4923-922d-b0499f6d8bff
2020-04-02 05:11:51,935 [IPC Server handler 6 on 37479] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36146
2020-04-02 05:11:51,935 [IPC Server handler 6 on 37479] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 40d91f97-1611-4923-922d-b0499f6d8bff (127.0.0.1:36146).
2020-04-02 05:11:51,935 [Thread-2686] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:11:51,936 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 40d91f97-1611-4923-922d-b0499f6d8bff) service to localhost/127.0.0.1:37479 successfully registered with NN
2020-04-02 05:11:51,936 [Thread-2726] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37479
2020-04-02 05:11:51,936 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37479 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:11:51,940 [Thread-2686] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:11:51,940 [Thread-2726] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:11:51,940 [Thread-2686] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:11:51,944 [Thread-2686] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:11:51,965 [Thread-2686] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,970 [IPC Server handler 9 on 37479] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ffcbda99-74d6-4d0d-946e-22997f222bfd for DN 127.0.0.1:36146
2020-04-02 05:11:51,970 [Thread-2739] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:11:51,970 [IPC Server handler 9 on 37479] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-73c80090-94c4-499d-ba29-7fed7cd3d134 for DN 127.0.0.1:36146
2020-04-02 05:11:51,970 [Thread-2726] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:51,970 [Thread-2726] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 1957767157. Formatting...
2020-04-02 05:11:51,971 [Thread-2726] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6a2edc6d-0b28-413d-b53f-df5870a73857 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-04-02 05:11:51,971 [IPC Server handler 0 on 37479] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:36146, datanodeUuid=40d91f97-1611-4923-922d-b0499f6d8bff, infoPort=34278, infoSecurePort=0, ipcPort=44091, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), reports.length=2
2020-04-02 05:11:51,971 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x6ae1ad306f961aa0: Processing first storage report for DS-73c80090-94c4-499d-ba29-7fed7cd3d134 from datanode 40d91f97-1611-4923-922d-b0499f6d8bff
2020-04-02 05:11:51,971 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x6ae1ad306f961aa0: from storage DS-73c80090-94c4-499d-ba29-7fed7cd3d134 node DatanodeRegistration(127.0.0.1:36146, datanodeUuid=40d91f97-1611-4923-922d-b0499f6d8bff, infoPort=34278, infoSecurePort=0, ipcPort=44091, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:11:51,972 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x6ae1ad306f961aa0: Processing first storage report for DS-ffcbda99-74d6-4d0d-946e-22997f222bfd from datanode 40d91f97-1611-4923-922d-b0499f6d8bff
2020-04-02 05:11:51,976 [IPC Server handler 8 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:11:51,976 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x6ae1ad306f961aa0: from storage DS-ffcbda99-74d6-4d0d-946e-22997f222bfd node DatanodeRegistration(127.0.0.1:36146, datanodeUuid=40d91f97-1611-4923-922d-b0499f6d8bff, infoPort=34278, infoSecurePort=0, ipcPort=44091, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), blocks: 0, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2020-04-02 05:11:51,976 [Thread-2740] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:11:51,976 [IPC Server handler 0 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x6ae1ad306f961aa0
2020-04-02 05:11:51,977 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x6ae1ad306f961aa0,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:11:51,977 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:11:51,977 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:11:51,977 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,979 [Thread-2726] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 17283@8480ff0b2e43
2020-04-02 05:11:51,979 [Thread-2726] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 1957767157. Formatting...
2020-04-02 05:11:51,979 [Thread-2726] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c0cbaf25-703e-48df-a8a6-9afc8c057e31 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-04-02 05:11:51,991 [Thread-2726] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,991 [Thread-2726] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:51,991 [Thread-2726] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-200169212-172.17.0.14-1585804310386 is not formatted. Formatting ...
2020-04-02 05:11:51,991 [Thread-2726] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-200169212-172.17.0.14-1585804310386 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-200169212-172.17.0.14-1585804310386/current
2020-04-02 05:11:52,001 [Thread-2726] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:52,001 [Thread-2726] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:52,001 [Thread-2726] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-200169212-172.17.0.14-1585804310386 is not formatted. Formatting ...
2020-04-02 05:11:52,001 [Thread-2726] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-200169212-172.17.0.14-1585804310386 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-200169212-172.17.0.14-1585804310386/current
2020-04-02 05:11:52,003 [Thread-2726] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1957767157;bpid=BP-200169212-172.17.0.14-1585804310386;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1957767157;c=1585804310386;bpid=BP-200169212-172.17.0.14-1585804310386;dnuuid=null
2020-04-02 05:11:52,004 [Thread-2726] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID c16ac744-1b0b-44f6-9b8a-7492c6c9222c
2020-04-02 05:11:52,005 [Thread-2726] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-6a2edc6d-0b28-413d-b53f-df5870a73857
2020-04-02 05:11:52,005 [Thread-2726] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-04-02 05:11:52,016 [Thread-2726] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c0cbaf25-703e-48df-a8a6-9afc8c057e31
2020-04-02 05:11:52,016 [Thread-2726] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-04-02 05:11:52,021 [Thread-2726] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:11:52,022 [Thread-2726] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:11:52,022 [Thread-2726] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:11:52,022 [Thread-2726] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:11:52,026 [Thread-2726] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:11:52,026 [Thread-2726] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:52,027 [Thread-2745] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:11:52,027 [Thread-2746] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:11:52,046 [Thread-2740] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-200169212-172.17.0.14-1585804310386 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 71ms
2020-04-02 05:11:52,047 [Thread-2739] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-200169212-172.17.0.14-1585804310386 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 77ms
2020-04-02 05:11:52,050 [Thread-2686] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-200169212-172.17.0.14-1585804310386: 86ms
2020-04-02 05:11:52,051 [Thread-2747] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:11:52,051 [Thread-2747] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-200169212-172.17.0.14-1585804310386/current/replicas doesn't exist 
2020-04-02 05:11:52,051 [Thread-2747] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 0ms
2020-04-02 05:11:52,051 [Thread-2748] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:11:52,051 [Thread-2748] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-200169212-172.17.0.14-1585804310386/current/replicas doesn't exist 
2020-04-02 05:11:52,052 [Thread-2748] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 0ms
2020-04-02 05:11:52,052 [Thread-2686] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-200169212-172.17.0.14-1585804310386: 1ms
2020-04-02 05:11:52,052 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:11:52,052 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:11:52,052 [Thread-2686] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:58 AM with interval of 21600000ms
2020-04-02 05:11:52,052 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-1a1c0fcc-5603-4301-bf17-468d1ba8eac9): finished scanning block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:52,052 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-c05da3bc-c55f-451f-8797-43bba1fc00cb): finished scanning block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:52,052 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid a0180d68-4703-4668-9faf-b16cb7f708f5) service to localhost/127.0.0.1:37479 beginning handshake with NN
2020-04-02 05:11:52,053 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-1a1c0fcc-5603-4301-bf17-468d1ba8eac9): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:11:52,053 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-c05da3bc-c55f-451f-8797-43bba1fc00cb): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:11:52,053 [IPC Server handler 1 on 37479] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46280, datanodeUuid=a0180d68-4703-4668-9faf-b16cb7f708f5, infoPort=45556, infoSecurePort=0, ipcPort=36565, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386) storage a0180d68-4703-4668-9faf-b16cb7f708f5
2020-04-02 05:11:52,053 [IPC Server handler 1 on 37479] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46280
2020-04-02 05:11:52,053 [IPC Server handler 1 on 37479] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a0180d68-4703-4668-9faf-b16cb7f708f5 (127.0.0.1:46280).
2020-04-02 05:11:52,054 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid a0180d68-4703-4668-9faf-b16cb7f708f5) service to localhost/127.0.0.1:37479 successfully registered with NN
2020-04-02 05:11:52,054 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37479 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:11:52,061 [IPC Server handler 2 on 37479] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c05da3bc-c55f-451f-8797-43bba1fc00cb for DN 127.0.0.1:46280
2020-04-02 05:11:52,062 [IPC Server handler 2 on 37479] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1a1c0fcc-5603-4301-bf17-468d1ba8eac9 for DN 127.0.0.1:46280
2020-04-02 05:11:52,063 [IPC Server handler 3 on 37479] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:46280, datanodeUuid=a0180d68-4703-4668-9faf-b16cb7f708f5, infoPort=45556, infoSecurePort=0, ipcPort=36565, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), reports.length=2
2020-04-02 05:11:52,063 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb03015c22682012b: Processing first storage report for DS-c05da3bc-c55f-451f-8797-43bba1fc00cb from datanode a0180d68-4703-4668-9faf-b16cb7f708f5
2020-04-02 05:11:52,063 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb03015c22682012b: from storage DS-c05da3bc-c55f-451f-8797-43bba1fc00cb node DatanodeRegistration(127.0.0.1:46280, datanodeUuid=a0180d68-4703-4668-9faf-b16cb7f708f5, infoPort=45556, infoSecurePort=0, ipcPort=36565, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:52,063 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb03015c22682012b: Processing first storage report for DS-1a1c0fcc-5603-4301-bf17-468d1ba8eac9 from datanode a0180d68-4703-4668-9faf-b16cb7f708f5
2020-04-02 05:11:52,063 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb03015c22682012b: from storage DS-1a1c0fcc-5603-4301-bf17-468d1ba8eac9 node DatanodeRegistration(127.0.0.1:46280, datanodeUuid=a0180d68-4703-4668-9faf-b16cb7f708f5, infoPort=45556, infoSecurePort=0, ipcPort=36565, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:52,063 [IPC Server handler 3 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xb03015c22682012b
2020-04-02 05:11:52,063 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xb03015c22682012b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:11:52,064 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:52,086 [IPC Server handler 4 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:11:52,087 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:11:52,087 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:11:52,094 [Thread-2745] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-200169212-172.17.0.14-1585804310386 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 67ms
2020-04-02 05:11:52,097 [Thread-2746] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-200169212-172.17.0.14-1585804310386 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 70ms
2020-04-02 05:11:52,097 [Thread-2726] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-200169212-172.17.0.14-1585804310386: 70ms
2020-04-02 05:11:52,097 [Thread-2754] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:11:52,097 [Thread-2754] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-200169212-172.17.0.14-1585804310386/current/replicas doesn't exist 
2020-04-02 05:11:52,098 [Thread-2754] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 1ms
2020-04-02 05:11:52,099 [Thread-2755] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:11:52,099 [Thread-2755] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-200169212-172.17.0.14-1585804310386/current/replicas doesn't exist 
2020-04-02 05:11:52,099 [Thread-2755] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 0ms
2020-04-02 05:11:52,099 [Thread-2726] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-200169212-172.17.0.14-1585804310386: 2ms
2020-04-02 05:11:52,100 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:11:52,100 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-200169212-172.17.0.14-1585804310386 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:11:52,100 [Thread-2726] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:59 AM with interval of 21600000ms
2020-04-02 05:11:52,100 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-c0cbaf25-703e-48df-a8a6-9afc8c057e31): finished scanning block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:52,100 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-6a2edc6d-0b28-413d-b53f-df5870a73857): finished scanning block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:52,104 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid c16ac744-1b0b-44f6-9b8a-7492c6c9222c) service to localhost/127.0.0.1:37479 beginning handshake with NN
2020-04-02 05:11:52,104 [IPC Server handler 5 on 37479] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43356, datanodeUuid=c16ac744-1b0b-44f6-9b8a-7492c6c9222c, infoPort=42221, infoSecurePort=0, ipcPort=33543, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386) storage c16ac744-1b0b-44f6-9b8a-7492c6c9222c
2020-04-02 05:11:52,104 [IPC Server handler 5 on 37479] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43356
2020-04-02 05:11:52,105 [IPC Server handler 5 on 37479] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c16ac744-1b0b-44f6-9b8a-7492c6c9222c (127.0.0.1:43356).
2020-04-02 05:11:52,105 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-6a2edc6d-0b28-413d-b53f-df5870a73857): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-04-02 05:11:52,105 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-c0cbaf25-703e-48df-a8a6-9afc8c057e31): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:11:52,105 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid c16ac744-1b0b-44f6-9b8a-7492c6c9222c) service to localhost/127.0.0.1:37479 successfully registered with NN
2020-04-02 05:11:52,105 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37479 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:11:52,113 [IPC Server handler 6 on 37479] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6a2edc6d-0b28-413d-b53f-df5870a73857 for DN 127.0.0.1:43356
2020-04-02 05:11:52,113 [IPC Server handler 6 on 37479] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c0cbaf25-703e-48df-a8a6-9afc8c057e31 for DN 127.0.0.1:43356
2020-04-02 05:11:52,114 [IPC Server handler 7 on 37479] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:43356, datanodeUuid=c16ac744-1b0b-44f6-9b8a-7492c6c9222c, infoPort=42221, infoSecurePort=0, ipcPort=33543, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), reports.length=2
2020-04-02 05:11:52,115 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xcf9472117537b5f0: Processing first storage report for DS-c0cbaf25-703e-48df-a8a6-9afc8c057e31 from datanode c16ac744-1b0b-44f6-9b8a-7492c6c9222c
2020-04-02 05:11:52,115 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xcf9472117537b5f0: from storage DS-c0cbaf25-703e-48df-a8a6-9afc8c057e31 node DatanodeRegistration(127.0.0.1:43356, datanodeUuid=c16ac744-1b0b-44f6-9b8a-7492c6c9222c, infoPort=42221, infoSecurePort=0, ipcPort=33543, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:52,115 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xcf9472117537b5f0: Processing first storage report for DS-6a2edc6d-0b28-413d-b53f-df5870a73857 from datanode c16ac744-1b0b-44f6-9b8a-7492c6c9222c
2020-04-02 05:11:52,115 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xcf9472117537b5f0: from storage DS-6a2edc6d-0b28-413d-b53f-df5870a73857 node DatanodeRegistration(127.0.0.1:43356, datanodeUuid=c16ac744-1b0b-44f6-9b8a-7492c6c9222c, infoPort=42221, infoSecurePort=0, ipcPort=33543, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:11:52,115 [IPC Server handler 7 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xcf9472117537b5f0
2020-04-02 05:11:52,115 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xcf9472117537b5f0,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:11:52,115 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:52,188 [IPC Server handler 9 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:11:52,189 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:11:52,191 [IPC Server handler 8 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-04-02 05:11:52,199 [IPC Server handler 0 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:11:52,199 [Thread-2409] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithDNFailure(160)) - testReadWithDNFailure: file = /dnFailure_3_largeFile, fileSize = 25165947, dnFailureNum = 3
2020-04-02 05:11:52,254 [IPC Server handler 1 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dnFailure_3_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:52,255 [IPC Server handler 2 on 37479] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /dnFailure_3_largeFile for DFSClient_NONMAPREDUCE_1077065378_11903 at 127.0.0.1
2020-04-02 05:11:52,255 [IPC Server handler 2 on 37479] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/dnFailure_3_largeFile, holder=DFSClient_NONMAPREDUCE_1077065378_11903, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:11:52,256 [IPC Server handler 2 on 37479] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: dnFailure_3_largeFile is added
2020-04-02 05:11:52,256 [IPC Server handler 2 on 37479] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /dnFailure_3_largeFile inode 16386 DFSClient_NONMAPREDUCE_1077065378_11903
2020-04-02 05:11:52,256 [IPC Server handler 2 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/dnFailure_3_largeFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:11:52,285 [IPC Server handler 3 on 37479] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /dnFailure_3_largeFile  inodeId 16386 for DFSClient_NONMAPREDUCE_1077065378_11903
2020-04-02 05:11:52,286 [IPC Server handler 3 on 37479] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:11:52,288 [IPC Server handler 3 on 37479] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /dnFailure_3_largeFile with blk_-9223372036854775792_1001 block is added to the in-memory file system
2020-04-02 05:11:52,288 [IPC Server handler 3 on 37479] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:39788, 127.0.0.1:44321, 127.0.0.1:39924, 127.0.0.1:43356, 127.0.0.1:41739, 127.0.0.1:46280, 127.0.0.1:36146, 127.0.0.1:34202, 127.0.0.1:40916 for /dnFailure_3_largeFile
2020-04-02 05:11:52,288 [IPC Server handler 3 on 37479] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /dnFailure_3_largeFile with new block blk_-9223372036854775792_1001, current total block count is 1
2020-04-02 05:11:52,313 [DataXceiver for client DFSClient_NONMAPREDUCE_1077065378_11903 at /127.0.0.1:38652 [Receiving block BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775792_1001 src: /127.0.0.1:38652 dest: /127.0.0.1:39788
2020-04-02 05:11:52,313 [DataXceiver for client DFSClient_NONMAPREDUCE_1077065378_11903 at /127.0.0.1:42726 [Receiving block BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775791_1001 src: /127.0.0.1:42726 dest: /127.0.0.1:44321
2020-04-02 05:11:52,339 [DataXceiver for client DFSClient_NONMAPREDUCE_1077065378_11903 at /127.0.0.1:42776 [Receiving block BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775790_1001 src: /127.0.0.1:42776 dest: /127.0.0.1:39924
2020-04-02 05:11:52,348 [DataXceiver for client DFSClient_NONMAPREDUCE_1077065378_11903 at /127.0.0.1:59986 [Receiving block BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775789_1001 src: /127.0.0.1:59986 dest: /127.0.0.1:43356
2020-04-02 05:11:52,367 [DataXceiver for client DFSClient_NONMAPREDUCE_1077065378_11903 at /127.0.0.1:36798 [Receiving block BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775788_1001 src: /127.0.0.1:36798 dest: /127.0.0.1:41739
2020-04-02 05:11:52,378 [DataXceiver for client DFSClient_NONMAPREDUCE_1077065378_11903 at /127.0.0.1:35506 [Receiving block BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775787_1001 src: /127.0.0.1:35506 dest: /127.0.0.1:46280
2020-04-02 05:11:52,430 [DataXceiver for client DFSClient_NONMAPREDUCE_1077065378_11903 at /127.0.0.1:48350 [Receiving block BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775786_1001 src: /127.0.0.1:48350 dest: /127.0.0.1:36146
2020-04-02 05:11:52,446 [DataXceiver for client DFSClient_NONMAPREDUCE_1077065378_11903 at /127.0.0.1:36398 [Receiving block BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775785_1001 src: /127.0.0.1:36398 dest: /127.0.0.1:34202
2020-04-02 05:11:52,465 [DataXceiver for client DFSClient_NONMAPREDUCE_1077065378_11903 at /127.0.0.1:59650 [Receiving block BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775784_1001 src: /127.0.0.1:59650 dest: /127.0.0.1:40916
2020-04-02 05:11:52,638 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35506, dest: /127.0.0.1:46280, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1077065378_11903, offset: 0, srvID: a0180d68-4703-4668-9faf-b16cb7f708f5, blockid: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775787_1001, duration(ns): 255388361
2020-04-02 05:11:52,640 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38652, dest: /127.0.0.1:39788, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1077065378_11903, offset: 0, srvID: dd3c628c-6b8d-4a72-834f-2e2e8bf4506f, blockid: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775792_1001, duration(ns): 320173258
2020-04-02 05:11:52,640 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42776, dest: /127.0.0.1:39924, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1077065378_11903, offset: 0, srvID: 5583f91d-0b87-438d-b05a-1617d27fa2d0, blockid: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775790_1001, duration(ns): 293912626
2020-04-02 05:11:52,642 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:52,642 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:52,640 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36398, dest: /127.0.0.1:34202, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1077065378_11903, offset: 0, srvID: 60cdc7b1-1e99-459f-b5d3-e894178bb3bb, blockid: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775785_1001, duration(ns): 187051521
2020-04-02 05:11:52,640 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42726, dest: /127.0.0.1:44321, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1077065378_11903, offset: 0, srvID: 7c675719-1fa9-4768-a92e-74a0d01cd633, blockid: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775791_1001, duration(ns): 313739261
2020-04-02 05:11:52,643 [IPC Server handler 9 on 37479] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40916, datanodeUuid=1bdaec69-9042-40a1-8df0-d17b5545118f, infoPort=42223, infoSecurePort=0, ipcPort=35317, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386) 1 blocks.
2020-04-02 05:11:52,640 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59650, dest: /127.0.0.1:40916, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1077065378_11903, offset: 0, srvID: 1bdaec69-9042-40a1-8df0-d17b5545118f, blockid: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775784_1001, duration(ns): 164085087
2020-04-02 05:11:52,640 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48350, dest: /127.0.0.1:36146, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1077065378_11903, offset: 0, srvID: 40d91f97-1611-4923-922d-b0499f6d8bff, blockid: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775786_1001, duration(ns): 199855195
2020-04-02 05:11:52,638 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59986, dest: /127.0.0.1:43356, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1077065378_11903, offset: 0, srvID: c16ac744-1b0b-44f6-9b8a-7492c6c9222c, blockid: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775789_1001, duration(ns): 284979903
2020-04-02 05:11:52,645 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:52,645 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:52,645 [IPC Server handler 3 on 37479] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41739, datanodeUuid=6011b007-0ddb-49cc-8c21-7b2c265a459d, infoPort=46542, infoSecurePort=0, ipcPort=42643, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386) 1 blocks.
2020-04-02 05:11:52,645 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:52,645 [IPC Server handler 2 on 37479] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34202, datanodeUuid=60cdc7b1-1e99-459f-b5d3-e894178bb3bb, infoPort=35559, infoSecurePort=0, ipcPort=46001, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386) 1 blocks.
2020-04-02 05:11:52,645 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775784_1001 on 127.0.0.1:40916 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:52,643 [IPC Server handler 1 on 37479] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:36146, datanodeUuid=40d91f97-1611-4923-922d-b0499f6d8bff, infoPort=34278, infoSecurePort=0, ipcPort=44091, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386) 1 blocks.
2020-04-02 05:11:52,643 [IPC Server handler 0 on 37479] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39788, datanodeUuid=dd3c628c-6b8d-4a72-834f-2e2e8bf4506f, infoPort=40801, infoSecurePort=0, ipcPort=33888, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386) 1 blocks.
2020-04-02 05:11:52,643 [IPC Server handler 8 on 37479] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:44321, datanodeUuid=7c675719-1fa9-4768-a92e-74a0d01cd633, infoPort=41301, infoSecurePort=0, ipcPort=43411, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386) 1 blocks.
2020-04-02 05:11:52,643 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:52,643 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:52,642 [IPC Server handler 6 on 37479] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39924, datanodeUuid=5583f91d-0b87-438d-b05a-1617d27fa2d0, infoPort=38766, infoSecurePort=0, ipcPort=43691, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386) 1 blocks.
2020-04-02 05:11:52,642 [IPC Server handler 5 on 37479] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:43356, datanodeUuid=c16ac744-1b0b-44f6-9b8a-7492c6c9222c, infoPort=42221, infoSecurePort=0, ipcPort=33543, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386) 1 blocks.
2020-04-02 05:11:52,642 [IPC Server handler 7 on 37479] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:46280, datanodeUuid=a0180d68-4703-4668-9faf-b16cb7f708f5, infoPort=45556, infoSecurePort=0, ipcPort=36565, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386) 1 blocks.
2020-04-02 05:11:52,642 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:52,642 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36798, dest: /127.0.0.1:41739, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1077065378_11903, offset: 0, srvID: 6011b007-0ddb-49cc-8c21-7b2c265a459d, blockid: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775788_1001, duration(ns): 266411144
2020-04-02 05:11:52,646 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:52,647 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:52,647 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:40916 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:11:52,647 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775784_1001 is received from 127.0.0.1:40916
2020-04-02 05:11:52,647 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40916 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:52,648 [IPC Server handler 4 on 37479] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /dnFailure_3_largeFile  inodeId 16386 for DFSClient_NONMAPREDUCE_1077065378_11903
2020-04-02 05:11:52,648 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:41739 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:52,648 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:52,648 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:41739 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:11:52,648 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775788_1001 is received from 127.0.0.1:41739
2020-04-02 05:11:52,648 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41739 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:52,648 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775785_1001 on 127.0.0.1:34202 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:52,648 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:52,648 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34202 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:11:52,648 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775785_1001 is received from 127.0.0.1:34202
2020-04-02 05:11:52,648 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34202 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:52,648 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775786_1001 on 127.0.0.1:36146 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:52,648 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:52,649 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:36146 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:11:52,649 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775786_1001 is received from 127.0.0.1:36146
2020-04-02 05:11:52,649 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:36146 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:52,649 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775792_1001 on 127.0.0.1:39788 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:52,649 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:52,649 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39788 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:11:52,649 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775792_1001 is received from 127.0.0.1:39788
2020-04-02 05:11:52,649 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39788 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:52,649 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775791_1001 on 127.0.0.1:44321 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:52,649 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:52,649 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:44321 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:11:52,649 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775791_1001 is received from 127.0.0.1:44321
2020-04-02 05:11:52,649 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:44321 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:52,649 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775790_1001 on 127.0.0.1:39924 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:52,650 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:52,650 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39924 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:11:52,650 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775790_1001 is received from 127.0.0.1:39924
2020-04-02 05:11:52,650 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39924 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:52,650 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775789_1001 on 127.0.0.1:43356 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:52,650 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:52,650 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:43356 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:11:52,650 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775789_1001 is received from 127.0.0.1:43356
2020-04-02 05:11:52,650 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:43356 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:52,650 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775787_1001 on 127.0.0.1:46280 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:52,650 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:52,650 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:46280 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:11:52,650 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775787_1001 is received from 127.0.0.1:46280
2020-04-02 05:11:52,650 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:46280 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:52,651 [IPC Server handler 4 on 37479] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:11:52,656 [IPC Server handler 4 on 37479] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /dnFailure_3_largeFile with blk_-9223372036854775776_1002 block is added to the in-memory file system
2020-04-02 05:11:52,656 [IPC Server handler 4 on 37479] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775776_1002, replicas=127.0.0.1:34202, 127.0.0.1:44321, 127.0.0.1:46280, 127.0.0.1:43356, 127.0.0.1:39788, 127.0.0.1:36146, 127.0.0.1:40916, 127.0.0.1:39924, 127.0.0.1:41739 for /dnFailure_3_largeFile
2020-04-02 05:11:52,656 [IPC Server handler 4 on 37479] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /dnFailure_3_largeFile with new block blk_-9223372036854775776_1002, current total block count is 2
2020-04-02 05:11:52,658 [DataXceiver for client DFSClient_NONMAPREDUCE_1077065378_11903 at /127.0.0.1:59652 [Receiving block BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775770_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775770_1002 src: /127.0.0.1:59652 dest: /127.0.0.1:40916
2020-04-02 05:11:52,659 [DataXceiver for client DFSClient_NONMAPREDUCE_1077065378_11903 at /127.0.0.1:36402 [Receiving block BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775776_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775776_1002 src: /127.0.0.1:36402 dest: /127.0.0.1:34202
2020-04-02 05:11:52,659 [DataXceiver for client DFSClient_NONMAPREDUCE_1077065378_11903 at /127.0.0.1:42790 [Receiving block BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775769_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775769_1002 src: /127.0.0.1:42790 dest: /127.0.0.1:39924
2020-04-02 05:11:52,659 [DataXceiver for client DFSClient_NONMAPREDUCE_1077065378_11903 at /127.0.0.1:36808 [Receiving block BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775768_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775768_1002 src: /127.0.0.1:36808 dest: /127.0.0.1:41739
2020-04-02 05:11:52,677 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36402, dest: /127.0.0.1:34202, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1077065378_11903, offset: 0, srvID: 60cdc7b1-1e99-459f-b5d3-e894178bb3bb, blockid: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775776_1002, duration(ns): 11911896
2020-04-02 05:11:52,677 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:52,678 [IPC Server handler 9 on 37479] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34202, datanodeUuid=60cdc7b1-1e99-459f-b5d3-e894178bb3bb, infoPort=35559, infoSecurePort=0, ipcPort=46001, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386) 1 blocks.
2020-04-02 05:11:52,678 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775776_1002 on 127.0.0.1:34202 size 123 replicaState = FINALIZED
2020-04-02 05:11:52,678 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:52,678 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34202 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:11:52,679 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775776_1002 is received from 127.0.0.1:34202
2020-04-02 05:11:52,679 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34202 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:52,679 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59652, dest: /127.0.0.1:40916, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1077065378_11903, offset: 0, srvID: 1bdaec69-9042-40a1-8df0-d17b5545118f, blockid: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775770_1002, duration(ns): 11169579
2020-04-02 05:11:52,680 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:52,680 [IPC Server handler 3 on 37479] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40916, datanodeUuid=1bdaec69-9042-40a1-8df0-d17b5545118f, infoPort=42223, infoSecurePort=0, ipcPort=35317, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386) 1 blocks.
2020-04-02 05:11:52,681 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775770_1002 on 127.0.0.1:40916 size 123 replicaState = FINALIZED
2020-04-02 05:11:52,681 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:52,681 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:40916 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:11:52,681 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775770_1002 is received from 127.0.0.1:40916
2020-04-02 05:11:52,681 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40916 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:52,682 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42790, dest: /127.0.0.1:39924, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1077065378_11903, offset: 0, srvID: 5583f91d-0b87-438d-b05a-1617d27fa2d0, blockid: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775769_1002, duration(ns): 20974016
2020-04-02 05:11:52,682 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:52,684 [IPC Server handler 2 on 37479] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39924, datanodeUuid=5583f91d-0b87-438d-b05a-1617d27fa2d0, infoPort=38766, infoSecurePort=0, ipcPort=43691, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386) 1 blocks.
2020-04-02 05:11:52,684 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775769_1002 on 127.0.0.1:39924 size 123 replicaState = FINALIZED
2020-04-02 05:11:52,684 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:52,684 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39924 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:11:52,684 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775769_1002 is received from 127.0.0.1:39924
2020-04-02 05:11:52,684 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39924 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:52,685 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36808, dest: /127.0.0.1:41739, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1077065378_11903, offset: 0, srvID: 6011b007-0ddb-49cc-8c21-7b2c265a459d, blockid: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775768_1002, duration(ns): 23890282
2020-04-02 05:11:52,686 [PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:52,688 [IPC Server handler 1 on 37479] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41739, datanodeUuid=6011b007-0ddb-49cc-8c21-7b2c265a459d, infoPort=46542, infoSecurePort=0, ipcPort=42643, storageInfo=lv=-57;cid=testClusterID;nsid=1957767157;c=1585804310386) 1 blocks.
2020-04-02 05:11:52,693 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775768_1002 on 127.0.0.1:41739 size 123 replicaState = FINALIZED
2020-04-02 05:11:52,694 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:52,696 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:41739 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:11:52,696 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775768_1002 is received from 127.0.0.1:41739
2020-04-02 05:11:52,696 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41739 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:52,696 [IPC Server handler 0 on 37479] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /dnFailure_3_largeFile for DFSClient_NONMAPREDUCE_1077065378_11903
2020-04-02 05:11:52,697 [IPC Server handler 0 on 37479] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /dnFailure_3_largeFile with 2 blocks is persisted to the file system
2020-04-02 05:11:52,697 [IPC Server handler 0 on 37479] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /dnFailure_3_largeFile is closed by DFSClient_NONMAPREDUCE_1077065378_11903
2020-04-02 05:11:52,698 [IPC Server handler 8 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:11:52,699 [IPC Server handler 6 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:52,700 [IPC Server handler 6 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:52,701 [Thread-2409] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:waitBlockGroupsReported(290)) - All blockGroups of file /dnFailure_3_largeFile verified to have all internalBlocks.
2020-04-02 05:11:52,702 [IPC Server handler 5 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:52,702 [IPC Server handler 5 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:52,703 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33888 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:52,703 [Thread-2409] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:11:52,703 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@f70ad19] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:11:52,705 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-5ac6ef19-2e4b-4bf5-bf8b-cba58c81490b) exiting.
2020-04-02 05:11:52,705 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-b87e9e84-c1e4-4d71-b26f-96076c48386b) exiting.
2020-04-02 05:11:52,719 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1fe8f80f{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:11:52,720 [Thread-2409] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@777a20d5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:11:52,720 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@521cc446{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:11:52,720 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1294a899{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:11:52,721 [Thread-2409] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33888
2020-04-02 05:11:52,721 [IPC Server listener on 33888] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33888
2020-04-02 05:11:52,721 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:11:52,721 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:11:52,723 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid dd3c628c-6b8d-4a72-834f-2e2e8bf4506f) service to localhost/127.0.0.1:37479
2020-04-02 05:11:52,724 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid dd3c628c-6b8d-4a72-834f-2e2e8bf4506f)
2020-04-02 05:11:52,724 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:52,734 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-200169212-172.17.0.14-1585804310386] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:52,740 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-200169212-172.17.0.14-1585804310386] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:52,745 [Thread-2409] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:11:52,746 [Thread-2409] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:11:52,747 [Thread-2409] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:11:52,747 [Thread-2409] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:11:52,754 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:52,754 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43411 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:52,754 [Thread-2409] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:11:52,755 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@455266c7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:11:52,756 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-1697a81d-1e20-43dd-9e69-d931ceeea2ac) exiting.
2020-04-02 05:11:52,756 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-6909d84d-d5f8-4237-ba60-22f2133e4ca2) exiting.
2020-04-02 05:11:52,768 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@18c61b9f{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:11:52,769 [Thread-2409] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2c91a188{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:11:52,769 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@27882b9f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:11:52,769 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5fa4b125{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:11:52,770 [Thread-2409] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43411
2020-04-02 05:11:52,770 [IPC Server listener on 43411] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43411
2020-04-02 05:11:52,771 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:11:52,771 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:11:52,772 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 7c675719-1fa9-4768-a92e-74a0d01cd633) service to localhost/127.0.0.1:37479
2020-04-02 05:11:52,772 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 7c675719-1fa9-4768-a92e-74a0d01cd633)
2020-04-02 05:11:52,772 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:52,782 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-200169212-172.17.0.14-1585804310386] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:52,789 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-200169212-172.17.0.14-1585804310386] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:52,805 [Thread-2409] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:11:52,805 [Thread-2409] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:11:52,811 [Thread-2409] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:11:52,813 [Thread-2409] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:11:52,820 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:52,820 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43691 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:11:52,824 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7f2d61f6] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:11:52,825 [Thread-2409] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:11:52,828 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-528bafe7-46b7-43d4-a1d4-d3d9b290c9be) exiting.
2020-04-02 05:11:52,828 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-91f3d47c-595b-497c-b517-03934afd2a8a) exiting.
2020-04-02 05:11:52,842 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@70ad58a4{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:11:52,843 [Thread-2409] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@f176214{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:11:52,843 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@a0fb737{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:11:52,843 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6c2af4c4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:11:52,844 [Thread-2409] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43691
2020-04-02 05:11:52,844 [IPC Server listener on 43691] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43691
2020-04-02 05:11:52,844 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:11:52,844 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:11:52,847 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 5583f91d-0b87-438d-b05a-1617d27fa2d0) service to localhost/127.0.0.1:37479
2020-04-02 05:11:52,847 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 5583f91d-0b87-438d-b05a-1617d27fa2d0)
2020-04-02 05:11:52,848 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:11:52,858 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-200169212-172.17.0.14-1585804310386] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:52,865 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-200169212-172.17.0.14-1585804310386] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:11:52,865 [Thread-2409] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:11:52,865 [Thread-2409] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:11:52,865 [Thread-2409] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:11:52,865 [Thread-2409] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:11:52,865 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:11:52,866 [Thread-2409] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /dnFailure_3_largeFile
2020-04-02 05:11:52,873 [Thread-2409] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /dnFailure_3_largeFile
2020-04-02 05:11:52,874 [IPC Server handler 7 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dnFailure_3_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:52,875 [Thread-2409] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /dnFailure_3_largeFile
2020-04-02 05:11:52,875 [IPC Server handler 4 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:11:52,876 [IPC Server handler 9 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:52,877 [IPC Server handler 9 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:52,883 [Thread-2409] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:52,884 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:39788 for blockBP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:52,885 [IPC Server handler 3 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:52,885 [IPC Server handler 3 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:52,886 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:39788,DS-b87e9e84-c1e4-4d71-b26f-96076c48386b,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:11:52,887 [Thread-2409] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:52,887 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:44321 for blockBP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775791_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:52,888 [IPC Server handler 2 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:52,888 [IPC Server handler 2 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:52,889 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:44321,DS-1697a81d-1e20-43dd-9e69-d931ceeea2ac,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:11:52,889 [Thread-2409] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:52,890 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:39924 for blockBP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775790_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:52,890 [IPC Server handler 1 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:11:52,891 [IPC Server handler 1 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:11:52,892 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:39924,DS-528bafe7-46b7-43d4-a1d4-d3d9b290c9be,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:11:53,606 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:54,617 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:56,610 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:57,617 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:11:59,611 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:12:00,618 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:12:02,611 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:12:03,618 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:12:05,612 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:12:06,619 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:12:07,555 [Thread-2409] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /dnFailure_3_largeFile
2020-04-02 05:12:07,575 [IPC Server handler 3 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:12:07,576 [IPC Server handler 3 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:12:07,582 [Thread-2409] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:07,582 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:39788 for blockBP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:07,584 [IPC Server handler 2 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:12:07,585 [IPC Server handler 2 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:12:07,586 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:39788,DS-b87e9e84-c1e4-4d71-b26f-96076c48386b,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:12:07,586 [Thread-2409] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:07,587 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:44321 for blockBP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775791_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:07,587 [IPC Server handler 1 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:12:07,587 [IPC Server handler 1 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:12:07,588 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:44321,DS-1697a81d-1e20-43dd-9e69-d931ceeea2ac,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:12:07,588 [Thread-2409] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:07,588 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:39924 for blockBP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775790_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:144)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:07,589 [IPC Server handler 6 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:12:07,589 [IPC Server handler 6 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:12:07,589 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:39924,DS-528bafe7-46b7-43d4-a1d4-d3d9b290c9be,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:12:08,613 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:12:09,619 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:12:11,052 [Thread-2409] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /dnFailure_3_largeFile
2020-04-02 05:12:11,068 [IPC Server handler 7 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:12:11,069 [IPC Server handler 7 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:12:11,086 [Thread-2409] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:11,086 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:39788 for blockBP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:11,087 [IPC Server handler 4 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:12:11,087 [IPC Server handler 4 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:12:11,088 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:39788,DS-b87e9e84-c1e4-4d71-b26f-96076c48386b,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:12:11,088 [Thread-2409] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:11,089 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:44321 for blockBP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775791_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:11,089 [IPC Server handler 9 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:12:11,090 [IPC Server handler 9 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:12:11,091 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:44321,DS-1697a81d-1e20-43dd-9e69-d931ceeea2ac,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:12:11,091 [Thread-2409] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:11,097 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:39924 for blockBP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775790_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:832)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:147)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:147)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:11,098 [IPC Server handler 3 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:12:11,098 [IPC Server handler 3 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:12:11,099 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:39924,DS-528bafe7-46b7-43d4-a1d4-d3d9b290c9be,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:12:11,614 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:12:12,620 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:12:14,614 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:12:14,655 [Thread-2409] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /dnFailure_3_largeFile
2020-04-02 05:12:14,657 [IPC Server handler 8 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:12:14,658 [IPC Server handler 8 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:12:14,662 [Thread-2409] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:14,663 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:44321 for blockBP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775791_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:14,663 [IPC Server handler 5 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:12:14,664 [IPC Server handler 5 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:12:14,664 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:44321,DS-1697a81d-1e20-43dd-9e69-d931ceeea2ac,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:12:14,664 [Thread-2409] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:14,665 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:39924 for blockBP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775790_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:14,665 [IPC Server handler 0 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:12:14,666 [IPC Server handler 0 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:12:14,667 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:39924,DS-528bafe7-46b7-43d4-a1d4-d3d9b290c9be,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:12:14,671 [Thread-2409] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readDataForDecoding(StripeReader.java:191)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:338)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:14,671 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:39788 for blockBP-200169212-172.17.0.14-1585804310386:blk_-9223372036854775792_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2934)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readDataForDecoding(StripeReader.java:191)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:338)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:324)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:415)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:150)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithDNFailure(ReadStripedFileWithDecodingHelper.java:183)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:14,672 [IPC Server handler 7 on 37479] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001, blk_-9223372036854775776_1002]
2020-04-02 05:12:14,673 [IPC Server handler 7 on 37479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/dnFailure_3_largeFile	dst=null	perm=null	proto=rpc
2020-04-02 05:12:14,673 [Thread-2409] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:39788,DS-b87e9e84-c1e4-4d71-b26f-96076c48386b,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:12:15,620 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:12:17,615 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:12:18,621 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:12:20,095 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:12:20,095 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 8
2020-04-02 05:12:20,095 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33543 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:12:20,095 [Thread-2409] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:12:20,095 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4df89112] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:12:20,097 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-6a2edc6d-0b28-413d-b53f-df5870a73857) exiting.
2020-04-02 05:12:20,097 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-c0cbaf25-703e-48df-a8a6-9afc8c057e31) exiting.
2020-04-02 05:12:20,112 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@40d3fdd9{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:12:20,112 [Thread-2409] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@f2bd001{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:12:20,113 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3cd7638b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:12:20,113 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@68e53ab4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:12:20,114 [Thread-2409] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33543
2020-04-02 05:12:20,118 [IPC Server listener on 33543] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33543
2020-04-02 05:12:20,118 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:12:20,118 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:12:20,119 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid c16ac744-1b0b-44f6-9b8a-7492c6c9222c) service to localhost/127.0.0.1:37479
2020-04-02 05:12:20,120 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid c16ac744-1b0b-44f6-9b8a-7492c6c9222c)
2020-04-02 05:12:20,120 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:12:20,132 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-200169212-172.17.0.14-1585804310386] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:12:20,138 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-200169212-172.17.0.14-1585804310386] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:12:20,138 [Thread-2409] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:12:20,138 [Thread-2409] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:12:20,138 [Thread-2409] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:12:20,138 [Thread-2409] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:12:20,139 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:12:20,139 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 7
2020-04-02 05:12:20,139 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 36565 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:12:20,139 [Thread-2409] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:12:20,139 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@364234b9] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:12:20,141 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-1a1c0fcc-5603-4301-bf17-468d1ba8eac9) exiting.
2020-04-02 05:12:20,141 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-c05da3bc-c55f-451f-8797-43bba1fc00cb) exiting.
2020-04-02 05:12:20,157 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3b84026f{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:12:20,158 [Thread-2409] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@27587c9{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:12:20,158 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2d70e67a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:12:20,158 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@677f75fd{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:12:20,161 [Thread-2409] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36565
2020-04-02 05:12:20,164 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:12:20,164 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:12:20,164 [IPC Server listener on 36565] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36565
2020-04-02 05:12:20,164 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid a0180d68-4703-4668-9faf-b16cb7f708f5) service to localhost/127.0.0.1:37479
2020-04-02 05:12:20,164 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid a0180d68-4703-4668-9faf-b16cb7f708f5)
2020-04-02 05:12:20,164 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:12:20,175 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-200169212-172.17.0.14-1585804310386] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:12:20,182 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-200169212-172.17.0.14-1585804310386] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:12:20,182 [Thread-2409] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:12:20,183 [Thread-2409] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:12:20,183 [Thread-2409] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:12:20,183 [Thread-2409] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:12:20,183 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:12:20,183 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 6
2020-04-02 05:12:20,183 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 44091 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:12:20,183 [Thread-2409] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:12:20,184 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@318067c0] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:12:20,185 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-73c80090-94c4-499d-ba29-7fed7cd3d134) exiting.
2020-04-02 05:12:20,185 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-ffcbda99-74d6-4d0d-946e-22997f222bfd) exiting.
2020-04-02 05:12:20,202 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@43c7ea43{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:12:20,204 [Thread-2409] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@463be193{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:12:20,205 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2ebabee0{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:12:20,205 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@25bdcf22{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:12:20,208 [Thread-2409] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44091
2020-04-02 05:12:20,212 [IPC Server listener on 44091] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44091
2020-04-02 05:12:20,213 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:12:20,213 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:12:20,215 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 40d91f97-1611-4923-922d-b0499f6d8bff) service to localhost/127.0.0.1:37479
2020-04-02 05:12:20,215 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 40d91f97-1611-4923-922d-b0499f6d8bff)
2020-04-02 05:12:20,215 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:12:20,226 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-200169212-172.17.0.14-1585804310386] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:12:20,235 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-200169212-172.17.0.14-1585804310386] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:12:20,236 [Thread-2409] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:12:20,236 [Thread-2409] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:12:20,236 [Thread-2409] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:12:20,236 [Thread-2409] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:12:20,236 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:12:20,237 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 5
2020-04-02 05:12:20,237 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 35317 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:12:20,237 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@35939adf] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:12:20,238 [Thread-2409] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:12:20,239 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-35186f53-3acb-4231-82e6-0a30a9fd054a) exiting.
2020-04-02 05:12:20,239 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-86bfa768-ae2f-4725-b926-a715c6b58adb) exiting.
2020-04-02 05:12:20,250 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@760ab751{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:12:20,250 [Thread-2409] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@25c1007e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:12:20,251 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@750cda7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:12:20,251 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@291054d4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:12:20,252 [Thread-2409] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35317
2020-04-02 05:12:20,256 [IPC Server listener on 35317] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35317
2020-04-02 05:12:20,256 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:12:20,256 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:12:20,258 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 1bdaec69-9042-40a1-8df0-d17b5545118f) service to localhost/127.0.0.1:37479
2020-04-02 05:12:20,258 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 1bdaec69-9042-40a1-8df0-d17b5545118f)
2020-04-02 05:12:20,258 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:12:20,268 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-200169212-172.17.0.14-1585804310386] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:12:20,276 [Thread-2409] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:12:20,276 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-200169212-172.17.0.14-1585804310386] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:12:20,276 [Thread-2409] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:12:20,276 [Thread-2409] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:12:20,276 [Thread-2409] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:12:20,277 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:12:20,277 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 4
2020-04-02 05:12:20,277 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33888 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:12:20,277 [Thread-2409] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(340)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-04-02 05:12:20,277 [Thread-2409] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33888
2020-04-02 05:12:20,278 [Thread-2409] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-dd3c628c-6b8d-4a72-834f-2e2e8bf4506f
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-dd3c628c-6b8d-4a72-834f-2e2e8bf4506f
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2146)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2048)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2038)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2017)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1991)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1984)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.tearDownCluster(ReadStripedFileWithDecodingHelper.java:97)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.tearDown(TestReadStripedFileWithDNFailure.java:64)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:105)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:20,278 [Thread-2409] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(190)) - AsyncDiskService has already shut down.
2020-04-02 05:12:20,278 [Thread-2409] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(174)) - AsyncLazyPersistService has already shut down.
2020-04-02 05:12:20,278 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:12:20,278 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 3
2020-04-02 05:12:20,279 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43691 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:12:20,279 [Thread-2409] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(340)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-04-02 05:12:20,279 [Thread-2409] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43691
2020-04-02 05:12:20,279 [Thread-2409] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-5583f91d-0b87-438d-b05a-1617d27fa2d0
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-5583f91d-0b87-438d-b05a-1617d27fa2d0
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2146)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2048)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2038)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2017)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1991)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1984)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.tearDownCluster(ReadStripedFileWithDecodingHelper.java:97)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.tearDown(TestReadStripedFileWithDNFailure.java:64)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:105)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:20,279 [Thread-2409] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(190)) - AsyncDiskService has already shut down.
2020-04-02 05:12:20,280 [Thread-2409] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(174)) - AsyncLazyPersistService has already shut down.
2020-04-02 05:12:20,280 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:12:20,280 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:12:20,280 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43411 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:12:20,280 [Thread-2409] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(340)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-04-02 05:12:20,280 [Thread-2409] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43411
2020-04-02 05:12:20,280 [Thread-2409] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-7c675719-1fa9-4768-a92e-74a0d01cd633
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-7c675719-1fa9-4768-a92e-74a0d01cd633
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2146)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2048)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2038)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2017)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1991)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1984)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.tearDownCluster(ReadStripedFileWithDecodingHelper.java:97)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.tearDown(TestReadStripedFileWithDNFailure.java:64)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure.testReadWithDNFailure(TestReadStripedFileWithDNFailure.java:105)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:20,281 [Thread-2409] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(190)) - AsyncDiskService has already shut down.
2020-04-02 05:12:20,281 [Thread-2409] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(174)) - AsyncLazyPersistService has already shut down.
2020-04-02 05:12:20,281 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:12:20,281 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:12:20,281 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 42643 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:12:20,281 [Thread-2409] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:12:20,281 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@792942a3] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:12:20,284 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-dd2fc9e6-10fe-4937-8f52-a079f3b5b192) exiting.
2020-04-02 05:12:20,284 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-e1a645e3-f3a4-413a-b489-5a2a07f0d88a) exiting.
2020-04-02 05:12:20,300 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@437289e7{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:12:20,300 [Thread-2409] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@119c720c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:12:20,300 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@12b8a869{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:12:20,301 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7189dfed{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:12:20,302 [Thread-2409] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42643
2020-04-02 05:12:20,308 [IPC Server listener on 42643] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42643
2020-04-02 05:12:20,308 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:12:20,308 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:12:20,308 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 6011b007-0ddb-49cc-8c21-7b2c265a459d) service to localhost/127.0.0.1:37479
2020-04-02 05:12:20,311 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 6011b007-0ddb-49cc-8c21-7b2c265a459d)
2020-04-02 05:12:20,311 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:12:20,321 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-200169212-172.17.0.14-1585804310386] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:12:20,328 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-200169212-172.17.0.14-1585804310386] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:12:20,328 [Thread-2409] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:12:20,328 [Thread-2409] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:12:20,328 [Thread-2409] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:12:20,328 [Thread-2409] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:12:20,331 [Thread-2409] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:12:20,338 [Thread-2409] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:12:20,339 [Thread-2409] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:12:20,340 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:12:20,340 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:12:20,340 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 46001 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:12:20,340 [Thread-2409] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:12:20,340 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2ede427f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:12:20,342 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-3da0dd79-074b-4b01-ae85-8b3621c7ea94) exiting.
2020-04-02 05:12:20,342 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-83832e4f-631c-49e5-9c88-fe887fa0b6c4) exiting.
2020-04-02 05:12:20,358 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6a6f5eac{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:12:20,359 [Thread-2409] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5503a9a2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:12:20,359 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@37b6073f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:12:20,359 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@863cfd{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:12:20,361 [Thread-2409] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46001
2020-04-02 05:12:20,367 [IPC Server listener on 46001] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46001
2020-04-02 05:12:20,367 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:12:20,367 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:12:20,367 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 60cdc7b1-1e99-459f-b5d3-e894178bb3bb) service to localhost/127.0.0.1:37479
2020-04-02 05:12:20,367 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-200169212-172.17.0.14-1585804310386 (Datanode Uuid 60cdc7b1-1e99-459f-b5d3-e894178bb3bb)
2020-04-02 05:12:20,368 [BP-200169212-172.17.0.14-1585804310386 heartbeating to localhost/127.0.0.1:37479] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-200169212-172.17.0.14-1585804310386
2020-04-02 05:12:20,381 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-200169212-172.17.0.14-1585804310386] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:12:20,388 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-200169212-172.17.0.14-1585804310386] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:12:20,388 [Thread-2409] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:12:20,388 [Thread-2409] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:12:20,388 [Thread-2409] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:12:20,388 [Thread-2409] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:12:20,389 [Thread-2409] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:12:20,389 [Thread-2409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:12:20,389 [Thread-2409] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 37479 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:12:20,389 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:12:20,390 [Thread-2409] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 11
2020-04-02 05:12:20,390 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@2b42085c] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:12:20,390 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@220e26e7] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:12:20,390 [Thread-2409] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 12 Total time for transactions(ms): 16 Number of transactions batched in Syncs: 2 Number of syncs: 11 SyncTimes(ms): 5 4 
2020-04-02 05:12:20,391 [Thread-2409] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000012
2020-04-02 05:12:20,391 [Thread-2409] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000012
2020-04-02 05:12:20,392 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:12:20,392 [CacheReplicationMonitor(1243575866)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:12:20,400 [Thread-2409] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37479
2020-04-02 05:12:20,401 [IPC Server listener on 37479] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37479
2020-04-02 05:12:20,401 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:12:20,402 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:12:20,402 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:12:20,405 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@4b0bf0f] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:12:20,418 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:12:20,418 [Thread-2409] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:12:20,419 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@68176271{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:12:20,420 [Thread-2409] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@41d7d149{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:12:20,421 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@76348f8e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:12:20,421 [Thread-2409] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3e32540c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure#testReadWithDNFailure[5]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure#testReadWithDNFailure[5]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:12:20,443 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:12:20,443 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:12:20,444 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 37479 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
[msx] all testRunFinished

[msx] before_class
2020-04-02 05:08:39,026 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=3
Formatting using clusterid: testClusterID
2020-04-02 05:08:39,821 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:08:39,835 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:08:39,837 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:08:39,838 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:08:39,846 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:08:39,847 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:08:39,847 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:08:39,848 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:08:39,896 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:39,901 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:08:39,902 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:08:39,902 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:08:39,907 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:08:39,907 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:08:39
2020-04-02 05:08:39,909 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:08:39,911 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:39,913 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:08:39,913 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:08:39,931 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:08:39,937 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:08:39,938 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:08:39,938 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:08:39,939 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:08:39,939 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:08:39,939 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:08:39,940 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:08:39,940 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:08:39,940 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:08:39,940 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:08:39,941 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:08:39,966 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:08:39,983 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:08:39,984 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:39,984 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:08:39,984 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:08:39,991 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:08:39,991 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:08:39,992 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:08:39,992 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:08:39,998 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:08:40,002 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:08:40,008 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:08:40,008 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:40,009 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:08:40,009 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:08:40,021 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:08:40,021 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:08:40,021 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:08:40,024 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:08:40,025 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:08:40,027 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:08:40,028 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:40,028 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:08:40,029 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:08:40,069 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:40,085 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/name-0-1 has been successfully formatted.
2020-04-02 05:08:40,088 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/name-0-2 has been successfully formatted.
2020-04-02 05:08:40,098 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:08:40,099 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:08:40,238 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:08:40,238 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:08:40,270 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:08:40,275 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:08:40,456 [main] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:08:40,532 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:08:41,024 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:08:41,024 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:08:41,031 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:08:41,072 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:08:41,122 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2d710f1a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:41,145 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:08:41,152 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:41,172 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3695ms
2020-04-02 05:08:41,328 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:41,337 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:08:41,337 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:41,346 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:41,349 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:08:41,351 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:41,352 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:41,388 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:08:41,388 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:08:41,398 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43001
2020-04-02 05:08:41,401 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:41,479 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@565f390{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:41,481 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f67a4d3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:41,581 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7fc4780b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:08:41,603 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6b58b9e9{HTTP/1.1,[http/1.1]}{localhost:43001}
2020-04-02 05:08:41,604 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4127ms
2020-04-02 05:08:41,629 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:08:41,630 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:08:41,630 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:08:41,631 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:08:41,631 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:08:41,632 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:08:41,632 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:08:41,632 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:08:41,633 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:41,634 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:08:41,634 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:08:41,635 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:08:41,636 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:08:41
2020-04-02 05:08:41,636 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:08:41,636 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:41,637 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:08:41,637 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:08:41,653 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:08:41,658 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:08:41,659 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:08:41,659 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:08:41,659 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:08:41,660 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:08:41,660 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:08:41,660 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:08:41,660 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:08:41,661 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:08:41,661 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:08:41,661 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:08:41,662 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:08:41,662 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:41,663 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:08:41,663 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:08:41,665 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:08:41,673 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:08:41,674 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:08:41,674 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:08:41,674 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:08:41,675 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:08:41,675 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:08:41,675 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:41,675 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:08:41,676 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:08:41,677 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:08:41,677 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:08:41,677 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:08:41,677 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:08:41,677 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:08:41,678 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:08:41,678 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:41,678 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:08:41,678 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:08:41,683 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/name-0-1/in_use.lock acquired by nodename 11151@974f54091279
2020-04-02 05:08:41,690 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/name-0-2/in_use.lock acquired by nodename 11151@974f54091279
2020-04-02 05:08:41,697 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/name-0-1/current
2020-04-02 05:08:41,698 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/name-0-2/current
2020-04-02 05:08:41,699 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:08:41,699 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:08:41,731 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:08:41,737 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:08:41,738 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:08:41,744 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:08:41,745 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:08:41,772 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:08:41,772 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 91 msecs
2020-04-02 05:08:41,953 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:08:41,965 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:41,982 [Socket Reader #1 for port 34438] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34438
2020-04-02 05:08:42,277 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:34438 to access this namenode/service.
2020-04-02 05:08:42,281 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:08:42,312 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:08:42,349 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:08:42,358 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:08:42,358 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:08:42,358 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:08:42,367 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:08:42,367 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:08:42,367 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:08:42,367 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:08:42,368 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:08:42,368 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2020-04-02 05:08:42,439 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:34438
2020-04-02 05:08:42,443 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:08:42,434 [IPC Server listener on 34438] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34438: starting
2020-04-02 05:08:42,444 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:08:42,434 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:42,450 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 4 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:08:42,467 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 34438 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:42,476 [CacheReplicationMonitor(1397324785)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:08:42,483 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2
2020-04-02 05:08:42,632 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1
2020-04-02 05:08:42,652 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2
2020-04-02 05:08:42,698 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:42,699 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:42,705 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:42,709 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:42,716 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:42,717 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:42,721 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:42,728 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:43315
2020-04-02 05:08:42,730 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:42,731 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:42,776 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:42,779 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:42,780 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:42,781 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:42,787 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:42,790 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:42,791 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:42,791 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:42,795 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33868
2020-04-02 05:08:42,796 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:42,817 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5e81e5ac{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:42,819 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3fa2213{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:42,830 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6aecbb8d{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:42,831 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1af146{HTTP/1.1,[http/1.1]}{localhost:33868}
2020-04-02 05:08:42,831 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5354ms
2020-04-02 05:08:43,290 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41636
2020-04-02 05:08:43,292 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@625e134e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:43,293 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:43,293 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:43,312 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:43,313 [Socket Reader #1 for port 36431] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36431
2020-04-02 05:08:43,331 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:36431
2020-04-02 05:08:43,351 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:43,354 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:43,870 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34438 starting to offer service
2020-04-02 05:08:43,906 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 36431 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:43,916 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4
2020-04-02 05:08:43,902 [IPC Server listener on 36431] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36431: starting
2020-04-02 05:08:43,902 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:43,936 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3
2020-04-02 05:08:43,941 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4
2020-04-02 05:08:43,969 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:43,970 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:43,970 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:43,970 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:43,971 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:43,971 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:43,972 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:43,973 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:46154
2020-04-02 05:08:43,973 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:43,973 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:43,978 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:43,979 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:43,980 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:43,981 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:43,982 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:43,984 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:43,984 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:43,984 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:43,985 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35528
2020-04-02 05:08:43,986 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:43,987 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@172ca72b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:43,988 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@71e5f61d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:44,026 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1d71006f{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:44,029 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5b6813df{HTTP/1.1,[http/1.1]}{localhost:35528}
2020-04-02 05:08:44,029 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6552ms
2020-04-02 05:08:44,198 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41866
2020-04-02 05:08:44,199 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2b58f754] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:44,200 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:44,200 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:44,201 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:44,202 [Socket Reader #1 for port 40471] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40471
2020-04-02 05:08:44,210 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40471
2020-04-02 05:08:44,218 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:44,219 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:44,220 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34438 starting to offer service
2020-04-02 05:08:44,232 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:44,233 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40471 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:44,232 [IPC Server listener on 40471] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40471: starting
2020-04-02 05:08:44,240 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6
2020-04-02 05:08:44,245 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5
2020-04-02 05:08:44,246 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6
2020-04-02 05:08:44,248 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:44,250 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:44,250 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:44,251 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:44,251 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:44,274 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:44,275 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:44,283 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34028
2020-04-02 05:08:44,284 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:44,284 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:44,325 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:44,327 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:44,329 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:44,329 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:44,342 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:44,343 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:44,343 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:44,343 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:44,346 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34778
2020-04-02 05:08:44,348 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:44,355 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f80fafe{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:44,358 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@f9879ac{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:44,372 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@40dd3977{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:44,377 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3a4e343{HTTP/1.1,[http/1.1]}{localhost:34778}
2020-04-02 05:08:44,378 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6901ms
2020-04-02 05:08:44,423 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37046
2020-04-02 05:08:44,423 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:44,424 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:44,424 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:44,425 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@62dae245] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:44,425 [Socket Reader #1 for port 41374] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41374
2020-04-02 05:08:44,441 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:41374
2020-04-02 05:08:44,464 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:44,464 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:44,466 [Thread-108] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34438 starting to offer service
2020-04-02 05:08:44,466 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:44,494 [IPC Server listener on 41374] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41374: starting
2020-04-02 05:08:44,497 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 41374 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:44,748 [Thread-108] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34438
2020-04-02 05:08:44,749 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34438
2020-04-02 05:08:44,753 [Thread-108] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:44,754 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:44,755 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34438
2020-04-02 05:08:44,755 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:44,757 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/in_use.lock acquired by nodename 11151@974f54091279
2020-04-02 05:08:44,757 [Thread-108] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5/in_use.lock acquired by nodename 11151@974f54091279
2020-04-02 05:08:44,758 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1 is not formatted for namespace 1653655509. Formatting...
2020-04-02 05:08:44,759 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1 
2020-04-02 05:08:44,760 [Thread-83] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3/in_use.lock acquired by nodename 11151@974f54091279
2020-04-02 05:08:44,761 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3 is not formatted for namespace 1653655509. Formatting...
2020-04-02 05:08:44,761 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3 
2020-04-02 05:08:44,762 [Thread-108] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5 is not formatted for namespace 1653655509. Formatting...
2020-04-02 05:08:44,762 [Thread-108] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5 
2020-04-02 05:08:44,766 [Thread-83] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4/in_use.lock acquired by nodename 11151@974f54091279
2020-04-02 05:08:44,766 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4 is not formatted for namespace 1653655509. Formatting...
2020-04-02 05:08:44,766 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d6ec7455-d48a-4372-bfc2-a59c9a107d28 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4 
2020-04-02 05:08:44,769 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2/in_use.lock acquired by nodename 11151@974f54091279
2020-04-02 05:08:44,769 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2 is not formatted for namespace 1653655509. Formatting...
2020-04-02 05:08:44,769 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3c105529-4159-4844-a50f-6dce7b951e83 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2 
2020-04-02 05:08:44,774 [Thread-108] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6/in_use.lock acquired by nodename 11151@974f54091279
2020-04-02 05:08:44,774 [Thread-108] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6 is not formatted for namespace 1653655509. Formatting...
2020-04-02 05:08:44,775 [Thread-108] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0649210e-2159-42b8-92ae-9ed2ad87ee25 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6 
2020-04-02 05:08:44,787 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:44,787 [Thread-83] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3/current/BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:44,788 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3 and block pool id BP-725857609-172.17.0.7-1585804120054 is not formatted. Formatting ...
2020-04-02 05:08:44,788 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-725857609-172.17.0.7-1585804120054 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3/current/BP-725857609-172.17.0.7-1585804120054/current
2020-04-02 05:08:44,790 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:44,791 [Thread-108] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5/current/BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:44,791 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5 and block pool id BP-725857609-172.17.0.7-1585804120054 is not formatted. Formatting ...
2020-04-02 05:08:44,791 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-725857609-172.17.0.7-1585804120054 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5/current/BP-725857609-172.17.0.7-1585804120054/current
2020-04-02 05:08:44,802 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:44,802 [Thread-83] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4/current/BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:44,803 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4 and block pool id BP-725857609-172.17.0.7-1585804120054 is not formatted. Formatting ...
2020-04-02 05:08:44,803 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-725857609-172.17.0.7-1585804120054 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4/current/BP-725857609-172.17.0.7-1585804120054/current
2020-04-02 05:08:44,804 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:44,805 [Thread-108] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6/current/BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:44,805 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6 and block pool id BP-725857609-172.17.0.7-1585804120054 is not formatted. Formatting ...
2020-04-02 05:08:44,805 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-725857609-172.17.0.7-1585804120054 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6/current/BP-725857609-172.17.0.7-1585804120054/current
2020-04-02 05:08:44,805 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1653655509;bpid=BP-725857609-172.17.0.7-1585804120054;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1653655509;c=1585804120054;bpid=BP-725857609-172.17.0.7-1585804120054;dnuuid=null
2020-04-02 05:08:44,805 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:44,806 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/current/BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:44,806 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1 and block pool id BP-725857609-172.17.0.7-1585804120054 is not formatted. Formatting ...
2020-04-02 05:08:44,806 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-725857609-172.17.0.7-1585804120054 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/current/BP-725857609-172.17.0.7-1585804120054/current
2020-04-02 05:08:44,808 [Thread-108] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1653655509;bpid=BP-725857609-172.17.0.7-1585804120054;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1653655509;c=1585804120054;bpid=BP-725857609-172.17.0.7-1585804120054;dnuuid=null
2020-04-02 05:08:44,808 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 1b04f1a7-d40a-4308-a02b-6bf636928be8
2020-04-02 05:08:44,810 [Thread-108] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID b6d7199e-caa6-44fb-a7b0-24811dd44850
2020-04-02 05:08:44,823 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:44,824 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2/current/BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:44,824 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2 and block pool id BP-725857609-172.17.0.7-1585804120054 is not formatted. Formatting ...
2020-04-02 05:08:44,824 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-725857609-172.17.0.7-1585804120054 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2/current/BP-725857609-172.17.0.7-1585804120054/current
2020-04-02 05:08:44,826 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1653655509;bpid=BP-725857609-172.17.0.7-1585804120054;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1653655509;c=1585804120054;bpid=BP-725857609-172.17.0.7-1585804120054;dnuuid=null
2020-04-02 05:08:44,828 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 966f464e-a960-4750-b2ba-e71f57dd888a
2020-04-02 05:08:45,081 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7
2020-04-02 05:08:45,099 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1, StorageType: DISK
2020-04-02 05:08:45,102 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b
2020-04-02 05:08:45,106 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3, StorageType: DISK
2020-04-02 05:08:45,107 [Thread-108] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2
2020-04-02 05:08:45,107 [Thread-108] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5, StorageType: DISK
2020-04-02 05:08:45,137 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-3c105529-4159-4844-a50f-6dce7b951e83
2020-04-02 05:08:45,138 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2, StorageType: DISK
2020-04-02 05:08:45,143 [Thread-108] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-0649210e-2159-42b8-92ae-9ed2ad87ee25
2020-04-02 05:08:45,144 [Thread-108] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6, StorageType: DISK
2020-04-02 05:08:45,145 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-d6ec7455-d48a-4372-bfc2-a59c9a107d28
2020-04-02 05:08:45,145 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4, StorageType: DISK
2020-04-02 05:08:45,163 [Thread-108] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:45,164 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:45,163 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:45,172 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3
2020-04-02 05:08:45,172 [Thread-108] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5
2020-04-02 05:08:45,196 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3
2020-04-02 05:08:45,198 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4
2020-04-02 05:08:45,199 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4
2020-04-02 05:08:45,218 [Thread-108] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5
2020-04-02 05:08:45,226 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1
2020-04-02 05:08:45,227 [Thread-108] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6
2020-04-02 05:08:45,230 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:45,244 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1
2020-04-02 05:08:45,245 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2
2020-04-02 05:08:45,245 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2
2020-04-02 05:08:45,245 [Thread-108] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6
2020-04-02 05:08:45,255 [Thread-108] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:45,256 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6...
2020-04-02 05:08:45,261 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5...
2020-04-02 05:08:45,263 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:45,265 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4...
2020-04-02 05:08:45,274 [Thread-129] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1...
2020-04-02 05:08:45,294 [Thread-125] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3...
2020-04-02 05:08:45,300 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2...
2020-04-02 05:08:45,404 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-725857609-172.17.0.7-1585804120054 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2: 103ms
2020-04-02 05:08:45,404 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-725857609-172.17.0.7-1585804120054 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4: 135ms
2020-04-02 05:08:45,414 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-725857609-172.17.0.7-1585804120054 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6: 158ms
2020-04-02 05:08:45,418 [Thread-125] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-725857609-172.17.0.7-1585804120054 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3: 124ms
2020-04-02 05:08:45,418 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-725857609-172.17.0.7-1585804120054: 187ms
2020-04-02 05:08:45,419 [Thread-129] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-725857609-172.17.0.7-1585804120054 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1: 145ms
2020-04-02 05:08:45,419 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-725857609-172.17.0.7-1585804120054: 154ms
2020-04-02 05:08:45,430 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-725857609-172.17.0.7-1585804120054 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5: 167ms
2020-04-02 05:08:45,431 [Thread-108] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-725857609-172.17.0.7-1585804120054: 176ms
2020-04-02 05:08:45,432 [Thread-140] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3...
2020-04-02 05:08:45,433 [Thread-142] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4...
2020-04-02 05:08:45,433 [Thread-142] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4/current/BP-725857609-172.17.0.7-1585804120054/current/replicas doesn't exist 
2020-04-02 05:08:45,433 [Thread-143] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1...
2020-04-02 05:08:45,432 [Thread-141] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5...
2020-04-02 05:08:45,434 [Thread-143] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/current/BP-725857609-172.17.0.7-1585804120054/current/replicas doesn't exist 
2020-04-02 05:08:45,434 [Thread-141] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5/current/BP-725857609-172.17.0.7-1585804120054/current/replicas doesn't exist 
2020-04-02 05:08:45,437 [Thread-145] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2...
2020-04-02 05:08:45,445 [Thread-144] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6...
2020-04-02 05:08:45,438 [Thread-141] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5: 4ms
2020-04-02 05:08:45,448 [Thread-143] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1: 14ms
2020-04-02 05:08:45,438 [Thread-142] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4: 5ms
2020-04-02 05:08:45,445 [Thread-144] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6/current/BP-725857609-172.17.0.7-1585804120054/current/replicas doesn't exist 
2020-04-02 05:08:45,455 [Thread-144] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6: 10ms
2020-04-02 05:08:45,455 [Thread-108] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-725857609-172.17.0.7-1585804120054: 23ms
2020-04-02 05:08:45,445 [Thread-145] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2/current/BP-725857609-172.17.0.7-1585804120054/current/replicas doesn't exist 
2020-04-02 05:08:45,456 [Thread-145] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2: 11ms
2020-04-02 05:08:45,456 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-725857609-172.17.0.7-1585804120054: 25ms
2020-04-02 05:08:45,459 [Thread-140] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3/current/BP-725857609-172.17.0.7-1585804120054/current/replicas doesn't exist 
2020-04-02 05:08:45,459 [Thread-140] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3: 26ms
2020-04-02 05:08:45,462 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6
2020-04-02 05:08:45,464 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6, DS-0649210e-2159-42b8-92ae-9ed2ad87ee25): finished scanning block pool BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:45,463 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5
2020-04-02 05:08:45,466 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2): finished scanning block pool BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:45,467 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1
2020-04-02 05:08:45,468 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1, DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7): finished scanning block pool BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:45,468 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2
2020-04-02 05:08:45,469 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2, DS-3c105529-4159-4844-a50f-6dce7b951e83): finished scanning block pool BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:45,470 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-725857609-172.17.0.7-1585804120054: 38ms
2020-04-02 05:08:45,473 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3
2020-04-02 05:08:45,474 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3, DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b): finished scanning block pool BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:45,474 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-725857609-172.17.0.7-1585804120054 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4
2020-04-02 05:08:45,475 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4, DS-d6ec7455-d48a-4372-bfc2-a59c9a107d28): finished scanning block pool BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:45,494 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:46 AM with interval of 21600000ms
2020-04-02 05:08:45,495 [Thread-108] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:50 AM with interval of 21600000ms
2020-04-02 05:08:45,506 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:25 AM with interval of 21600000ms
2020-04-02 05:08:45,512 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-725857609-172.17.0.7-1585804120054 (Datanode Uuid 1b04f1a7-d40a-4308-a02b-6bf636928be8) service to localhost/127.0.0.1:34438 beginning handshake with NN
2020-04-02 05:08:45,517 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-725857609-172.17.0.7-1585804120054 (Datanode Uuid b6d7199e-caa6-44fb-a7b0-24811dd44850) service to localhost/127.0.0.1:34438 beginning handshake with NN
2020-04-02 05:08:45,526 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:08:45,535 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:08:45,535 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:08:45,544 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-725857609-172.17.0.7-1585804120054 (Datanode Uuid 966f464e-a960-4750-b2ba-e71f57dd888a) service to localhost/127.0.0.1:34438 beginning handshake with NN
2020-04-02 05:08:45,544 [IPC Server handler 5 on 34438] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34028, datanodeUuid=b6d7199e-caa6-44fb-a7b0-24811dd44850, infoPort=37046, infoSecurePort=0, ipcPort=41374, storageInfo=lv=-57;cid=testClusterID;nsid=1653655509;c=1585804120054) storage b6d7199e-caa6-44fb-a7b0-24811dd44850
2020-04-02 05:08:45,548 [IPC Server handler 5 on 34438] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34028
2020-04-02 05:08:45,550 [IPC Server handler 5 on 34438] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b6d7199e-caa6-44fb-a7b0-24811dd44850 (127.0.0.1:34028).
2020-04-02 05:08:45,551 [IPC Server handler 9 on 34438] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46154, datanodeUuid=1b04f1a7-d40a-4308-a02b-6bf636928be8, infoPort=41866, infoSecurePort=0, ipcPort=40471, storageInfo=lv=-57;cid=testClusterID;nsid=1653655509;c=1585804120054) storage 1b04f1a7-d40a-4308-a02b-6bf636928be8
2020-04-02 05:08:45,552 [IPC Server handler 9 on 34438] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46154
2020-04-02 05:08:45,552 [IPC Server handler 9 on 34438] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1b04f1a7-d40a-4308-a02b-6bf636928be8 (127.0.0.1:46154).
2020-04-02 05:08:45,554 [IPC Server handler 2 on 34438] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43315, datanodeUuid=966f464e-a960-4750-b2ba-e71f57dd888a, infoPort=41636, infoSecurePort=0, ipcPort=36431, storageInfo=lv=-57;cid=testClusterID;nsid=1653655509;c=1585804120054) storage 966f464e-a960-4750-b2ba-e71f57dd888a
2020-04-02 05:08:45,554 [IPC Server handler 2 on 34438] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43315
2020-04-02 05:08:45,554 [IPC Server handler 2 on 34438] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 966f464e-a960-4750-b2ba-e71f57dd888a (127.0.0.1:43315).
2020-04-02 05:08:45,555 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2): no suitable block pools found to scan.  Waiting 1814399907 ms.
2020-04-02 05:08:45,555 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1, DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7): no suitable block pools found to scan.  Waiting 1814399907 ms.
2020-04-02 05:08:45,555 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3, DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b): no suitable block pools found to scan.  Waiting 1814399915 ms.
2020-04-02 05:08:45,555 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2, DS-3c105529-4159-4844-a50f-6dce7b951e83): no suitable block pools found to scan.  Waiting 1814399907 ms.
2020-04-02 05:08:45,555 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6, DS-0649210e-2159-42b8-92ae-9ed2ad87ee25): no suitable block pools found to scan.  Waiting 1814399907 ms.
2020-04-02 05:08:45,555 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4, DS-d6ec7455-d48a-4372-bfc2-a59c9a107d28): no suitable block pools found to scan.  Waiting 1814399915 ms.
2020-04-02 05:08:45,556 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-725857609-172.17.0.7-1585804120054 (Datanode Uuid 1b04f1a7-d40a-4308-a02b-6bf636928be8) service to localhost/127.0.0.1:34438 successfully registered with NN
2020-04-02 05:08:45,556 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:34438 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:45,556 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-725857609-172.17.0.7-1585804120054 (Datanode Uuid b6d7199e-caa6-44fb-a7b0-24811dd44850) service to localhost/127.0.0.1:34438 successfully registered with NN
2020-04-02 05:08:45,556 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:34438 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:45,557 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-725857609-172.17.0.7-1585804120054 (Datanode Uuid 966f464e-a960-4750-b2ba-e71f57dd888a) service to localhost/127.0.0.1:34438 successfully registered with NN
2020-04-02 05:08:45,562 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:34438 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:45,585 [IPC Server handler 0 on 34438] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b for DN 127.0.0.1:46154
2020-04-02 05:08:45,585 [IPC Server handler 0 on 34438] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d6ec7455-d48a-4372-bfc2-a59c9a107d28 for DN 127.0.0.1:46154
2020-04-02 05:08:45,602 [IPC Server handler 6 on 34438] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2 for DN 127.0.0.1:34028
2020-04-02 05:08:45,603 [IPC Server handler 6 on 34438] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0649210e-2159-42b8-92ae-9ed2ad87ee25 for DN 127.0.0.1:34028
2020-04-02 05:08:45,609 [IPC Server handler 8 on 34438] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7 for DN 127.0.0.1:43315
2020-04-02 05:08:45,610 [IPC Server handler 8 on 34438] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3c105529-4159-4844-a50f-6dce7b951e83 for DN 127.0.0.1:43315
2020-04-02 05:08:45,642 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2fab823b98f29faf: Processing first storage report for DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b from datanode 1b04f1a7-d40a-4308-a02b-6bf636928be8
2020-04-02 05:08:45,644 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2fab823b98f29faf: from storage DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b node DatanodeRegistration(127.0.0.1:46154, datanodeUuid=1b04f1a7-d40a-4308-a02b-6bf636928be8, infoPort=41866, infoSecurePort=0, ipcPort=40471, storageInfo=lv=-57;cid=testClusterID;nsid=1653655509;c=1585804120054), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:08:45,644 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xeb70da140bbc14d1: Processing first storage report for DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2 from datanode b6d7199e-caa6-44fb-a7b0-24811dd44850
2020-04-02 05:08:45,645 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xeb70da140bbc14d1: from storage DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2 node DatanodeRegistration(127.0.0.1:34028, datanodeUuid=b6d7199e-caa6-44fb-a7b0-24811dd44850, infoPort=37046, infoSecurePort=0, ipcPort=41374, storageInfo=lv=-57;cid=testClusterID;nsid=1653655509;c=1585804120054), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:08:45,645 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xadb282c875d74fcd: Processing first storage report for DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7 from datanode 966f464e-a960-4750-b2ba-e71f57dd888a
2020-04-02 05:08:45,645 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xadb282c875d74fcd: from storage DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7 node DatanodeRegistration(127.0.0.1:43315, datanodeUuid=966f464e-a960-4750-b2ba-e71f57dd888a, infoPort=41636, infoSecurePort=0, ipcPort=36431, storageInfo=lv=-57;cid=testClusterID;nsid=1653655509;c=1585804120054), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:45,651 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:08:45,654 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xadb282c875d74fcd: Processing first storage report for DS-3c105529-4159-4844-a50f-6dce7b951e83 from datanode 966f464e-a960-4750-b2ba-e71f57dd888a
2020-04-02 05:08:45,654 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xadb282c875d74fcd: from storage DS-3c105529-4159-4844-a50f-6dce7b951e83 node DatanodeRegistration(127.0.0.1:43315, datanodeUuid=966f464e-a960-4750-b2ba-e71f57dd888a, infoPort=41636, infoSecurePort=0, ipcPort=36431, storageInfo=lv=-57;cid=testClusterID;nsid=1653655509;c=1585804120054), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:45,654 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xeb70da140bbc14d1: Processing first storage report for DS-0649210e-2159-42b8-92ae-9ed2ad87ee25 from datanode b6d7199e-caa6-44fb-a7b0-24811dd44850
2020-04-02 05:08:45,654 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xeb70da140bbc14d1: from storage DS-0649210e-2159-42b8-92ae-9ed2ad87ee25 node DatanodeRegistration(127.0.0.1:34028, datanodeUuid=b6d7199e-caa6-44fb-a7b0-24811dd44850, infoPort=37046, infoSecurePort=0, ipcPort=41374, storageInfo=lv=-57;cid=testClusterID;nsid=1653655509;c=1585804120054), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:45,654 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2fab823b98f29faf: Processing first storage report for DS-d6ec7455-d48a-4372-bfc2-a59c9a107d28 from datanode 1b04f1a7-d40a-4308-a02b-6bf636928be8
2020-04-02 05:08:45,654 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2fab823b98f29faf: from storage DS-d6ec7455-d48a-4372-bfc2-a59c9a107d28 node DatanodeRegistration(127.0.0.1:46154, datanodeUuid=1b04f1a7-d40a-4308-a02b-6bf636928be8, infoPort=41866, infoSecurePort=0, ipcPort=40471, storageInfo=lv=-57;cid=testClusterID;nsid=1653655509;c=1585804120054), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:45,660 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:08:45,698 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:08:45,703 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:08:45,711 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x2fab823b98f29faf,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 80 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:45,711 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:45,712 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xeb70da140bbc14d1,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 79 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:45,713 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:45,722 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xadb282c875d74fcd,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 92 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:45,722 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:08:45,774 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:45,821 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:45,950 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:45,977 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:45,998 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,002 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,016 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,020 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,027 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,034 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,056 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,091 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,094 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,099 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data0	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:46,110 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:46,172 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/datafile0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:46,260 [IPC Server handler 2 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:43315, 127.0.0.1:34028, 127.0.0.1:46154 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/datafile0
2020-04-02 05:08:46,348 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:52594 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741825_1001 src: /127.0.0.1:52594 dest: /127.0.0.1:43315
2020-04-02 05:08:46,382 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:35804 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741825_1001 src: /127.0.0.1:35804 dest: /127.0.0.1:34028
2020-04-02 05:08:46,399 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54342 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741825_1001 src: /127.0.0.1:54342 dest: /127.0.0.1:46154
2020-04-02 05:08:46,518 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54342, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741825_1001, duration(ns): 92946835
2020-04-02 05:08:46,519 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:46,530 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35804, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741825_1001, duration(ns): 115442407
2020-04-02 05:08:46,530 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154] terminating
2020-04-02 05:08:46,591 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52594, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741825_1001, duration(ns): 167069868
2020-04-02 05:08:46,591 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154] terminating
2020-04-02 05:08:46,610 [IPC Server handler 5 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:34028, 127.0.0.1:46154, 127.0.0.1:43315 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/datafile0
2020-04-02 05:08:46,625 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:35896 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741826_1002 src: /127.0.0.1:35896 dest: /127.0.0.1:34028
2020-04-02 05:08:46,638 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54432 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741826_1002 src: /127.0.0.1:54432 dest: /127.0.0.1:46154
2020-04-02 05:08:46,650 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:52724 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741826_1002 src: /127.0.0.1:52724 dest: /127.0.0.1:43315
2020-04-02 05:08:46,688 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52724, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741826_1002, duration(ns): 34927751
2020-04-02 05:08:46,688 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:46,696 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54432, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741826_1002, duration(ns): 29738202
2020-04-02 05:08:46,696 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315] terminating
2020-04-02 05:08:46,718 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35896, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741826_1002, duration(ns): 39672622
2020-04-02 05:08:46,719 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:43315] terminating
2020-04-02 05:08:46,733 [IPC Server handler 0 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/datafile0 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:46,749 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,758 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,781 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,787 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,802 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,806 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,813 [IPC Server handler 6 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 6 on 34438, call Call#47 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 127.0.0.1:53136: org.apache.hadoop.hdfs.protocol.NSQuotaExceededException: The NameSpace quota (directories and files) of directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test is exceeded: quota=3 file count=4
2020-04-02 05:08:46,823 [IPC Server handler 8 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 8 on 34438, call Call#48 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 127.0.0.1:53136: org.apache.hadoop.hdfs.protocol.NSQuotaExceededException: The NameSpace quota (directories and files) of directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test is exceeded: quota=3 file count=4
2020-04-02 05:08:46,835 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,841 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=clearQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,849 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,851 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,858 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,861 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=clearQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,863 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,875 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:46,886 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/datafile1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:46,896 [IPC Server handler 8 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:46154, 127.0.0.1:34028, 127.0.0.1:43315 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/datafile1
2020-04-02 05:08:46,902 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54530 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741827_1003 src: /127.0.0.1:54530 dest: /127.0.0.1:46154
2020-04-02 05:08:46,923 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:36000 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741827_1003 src: /127.0.0.1:36000 dest: /127.0.0.1:34028
2020-04-02 05:08:46,932 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:52822 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741827_1003 src: /127.0.0.1:52822 dest: /127.0.0.1:43315
2020-04-02 05:08:46,950 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52822, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741827_1003, duration(ns): 11709197
2020-04-02 05:08:46,951 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:46,954 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36000, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741827_1003, duration(ns): 16007642
2020-04-02 05:08:46,955 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315] terminating
2020-04-02 05:08:46,967 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54530, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741827_1003, duration(ns): 29321560
2020-04-02 05:08:46,968 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315] terminating
2020-04-02 05:08:46,975 [IPC Server handler 2 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 2 on 34438, call Call#62 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 127.0.0.1:53136: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test is exceeded: quota = 9600 B = 9.38 KB but diskspace consumed = 10240 B = 10 KB
2020-04-02 05:08:47,002 [IPC Server handler 4 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/datafile1 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:47,007 [IPC Server handler 1 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:completeFileInternal(711)) - DIR* completeFile: request from DFSClient_NONMAPREDUCE_1826976575_1 to complete inode 16401(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/datafile1) which is already closed. But, it appears to be an RPC retry. Returning success
2020-04-02 05:08:47,007 [IPC Server handler 1 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/datafile1 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:47,025 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/datafile1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,037 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,042 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=clearSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,046 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,049 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,052 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:47,059 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/datafile1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:47,075 [IPC Server handler 2 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:43315, 127.0.0.1:34028, 127.0.0.1:46154 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/datafile1
2020-04-02 05:08:47,087 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:52900 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741829_1005 src: /127.0.0.1:52900 dest: /127.0.0.1:43315
2020-04-02 05:08:47,091 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:36084 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741829_1005 src: /127.0.0.1:36084 dest: /127.0.0.1:34028
2020-04-02 05:08:47,096 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54624 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741829_1005 src: /127.0.0.1:54624 dest: /127.0.0.1:46154
2020-04-02 05:08:47,128 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54624, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741829_1005, duration(ns): 29612510
2020-04-02 05:08:47,128 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:47,132 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36084, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741829_1005, duration(ns): 33693500
2020-04-02 05:08:47,132 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154] terminating
2020-04-02 05:08:47,166 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52900, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741829_1005, duration(ns): 44334805
2020-04-02 05:08:47,166 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154] terminating
2020-04-02 05:08:47,174 [IPC Server handler 5 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:46154, 127.0.0.1:34028, 127.0.0.1:43315 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/datafile1
2020-04-02 05:08:47,182 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54668 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741830_1006 src: /127.0.0.1:54668 dest: /127.0.0.1:46154
2020-04-02 05:08:47,192 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:36138 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741830_1006 src: /127.0.0.1:36138 dest: /127.0.0.1:34028
2020-04-02 05:08:47,217 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:52958 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741830_1006 src: /127.0.0.1:52958 dest: /127.0.0.1:43315
2020-04-02 05:08:47,251 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52958, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741830_1006, duration(ns): 31618947
2020-04-02 05:08:47,251 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:47,254 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36138, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741830_1006, duration(ns): 32653270
2020-04-02 05:08:47,254 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315] terminating
2020-04-02 05:08:47,262 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54668, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741830_1006, duration(ns): 37571367
2020-04-02 05:08:47,262 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315] terminating
2020-04-02 05:08:47,267 [IPC Server handler 7 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/datafile1 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:47,283 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,289 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,293 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,296 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,302 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,314 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,317 [IPC Server handler 8 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 8 on 34438, call Call#87 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 127.0.0.1:53136: org.apache.hadoop.hdfs.protocol.NSQuotaExceededException: The NameSpace quota (directories and files) of directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data0 is exceeded: quota=1 file count=2
2020-04-02 05:08:47,324 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,330 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,342 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,347 [IPC Server handler 3 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 3 on 34438, call Call#91 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getQuotaUsage from 127.0.0.1:53136: java.io.FileNotFoundException: File/Directory does not exist: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test1
2020-04-02 05:08:47,362 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,364 [IPC Server handler 1 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 1 on 34438, call Call#93 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota from 127.0.0.1:53136: java.io.FileNotFoundException: Directory does not exist: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test1
2020-04-02 05:08:47,369 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,374 [IPC Server handler 9 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 9 on 34438, call Call#95 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota from 127.0.0.1:53136: java.io.FileNotFoundException: Directory does not exist: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test1
2020-04-02 05:08:47,378 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/datafile0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,398 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/datafile0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,411 [IPC Server handler 6 on 34438] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 6 on 34438, call Call#98 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota from 127.0.0.1:53136
org.apache.hadoop.fs.PathIsNotDirectoryException: `/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/datafile0': Is not a directory
	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.valueOf(INodeDirectory.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSDirAttrOp.unprotectedSetQuota(FSDirAttrOp.java:334)
	at org.apache.hadoop.hdfs.server.namenode.FSDirAttrOp.setQuota(FSDirAttrOp.java:244)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setQuota(FSNamesystem.java:3249)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setQuota(NameNodeRpcServer.java:1412)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setQuota(ClientNamenodeProtocolServerSideTranslatorPB.java:1029)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:08:47,427 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/datafile0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,434 [IPC Server handler 7 on 34438] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 7 on 34438, call Call#100 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota from 127.0.0.1:53136
org.apache.hadoop.fs.PathIsNotDirectoryException: `/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/datafile0': Is not a directory
	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.valueOf(INodeDirectory.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSDirAttrOp.unprotectedSetQuota(FSDirAttrOp.java:334)
	at org.apache.hadoop.hdfs.server.namenode.FSDirAttrOp.setQuota(FSDirAttrOp.java:244)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setQuota(FSNamesystem.java:3249)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setQuota(NameNodeRpcServer.java:1412)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setQuota(ClientNamenodeProtocolServerSideTranslatorPB.java:1029)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:08:47,442 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,448 [IPC Server handler 2 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 2 on 34438, call Call#102 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota from 127.0.0.1:53136: java.io.FileNotFoundException: Directory does not exist: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test1
2020-04-02 05:08:47,465 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/datafile0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,468 [IPC Server handler 4 on 34438] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 4 on 34438, call Call#104 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota from 127.0.0.1:53136
org.apache.hadoop.fs.PathIsNotDirectoryException: `/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/datafile0': Is not a directory
	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.valueOf(INodeDirectory.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSDirAttrOp.unprotectedSetQuota(FSDirAttrOp.java:334)
	at org.apache.hadoop.hdfs.server.namenode.FSDirAttrOp.setQuota(FSDirAttrOp.java:244)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setQuota(FSNamesystem.java:3249)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setQuota(NameNodeRpcServer.java:1412)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setQuota(ClientNamenodeProtocolServerSideTranslatorPB.java:1029)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:08:47,486 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,497 [IPC Server handler 5 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 5 on 34438, call Call#106 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota from 127.0.0.1:53136: java.io.FileNotFoundException: Directory does not exist: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test1
2020-04-02 05:08:47,502 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,506 [IPC Server handler 6 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 6 on 34438, call Call#108 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota from 127.0.0.1:53136: java.io.FileNotFoundException: Directory does not exist: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test1
2020-04-02 05:08:47,510 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,516 [IPC Server handler 7 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 7 on 34438, call Call#110 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota from 127.0.0.1:53136: java.io.FileNotFoundException: Directory does not exist: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test1
2020-04-02 05:08:47,542 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,554 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,566 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,599 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=userxx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,610 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=userxx (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,611 [IPC Server handler 9 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 9 on 34438, call Call#115 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota from 127.0.0.1:53876: org.apache.hadoop.security.AccessControlException: Access denied for user userxx. Superuser privilege is required
2020-04-02 05:08:47,622 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=userxx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,627 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=userxx (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,628 [IPC Server handler 8 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 8 on 34438, call Call#117 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota from 127.0.0.1:53876: org.apache.hadoop.security.AccessControlException: Access denied for user userxx. Superuser privilege is required
2020-04-02 05:08:47,640 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=userxx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,647 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=userxx (auth:SIMPLE)	ip=/127.0.0.1	cmd=clearQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,647 [IPC Server handler 0 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 0 on 34438, call Call#119 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota from 127.0.0.1:53876: org.apache.hadoop.security.AccessControlException: Access denied for user userxx. Superuser privilege is required
2020-04-02 05:08:47,666 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=userxx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,672 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=userxx (auth:SIMPLE)	ip=/127.0.0.1	cmd=clearSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,672 [IPC Server handler 3 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 3 on 34438, call Call#121 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota from 127.0.0.1:53876: org.apache.hadoop.security.AccessControlException: Access denied for user userxx. Superuser privilege is required
2020-04-02 05:08:47,678 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,685 [IPC Server handler 1 on 34438] WARN  ipc.Server (Server.java:logException(2720)) - IPC Server handler 1 on 34438, call Call#123 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota from 127.0.0.1:53136
java.lang.IllegalArgumentException: Cannot clear namespace quota on root.
	at org.apache.hadoop.hdfs.server.namenode.FSDirAttrOp.unprotectedSetQuota(FSDirAttrOp.java:336)
	at org.apache.hadoop.hdfs.server.namenode.FSDirAttrOp.setQuota(FSDirAttrOp.java:244)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setQuota(FSNamesystem.java:3249)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setQuota(NameNodeRpcServer.java:1412)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setQuota(ClientNamenodeProtocolServerSideTranslatorPB.java:1029)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:08:47,690 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,694 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,710 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,718 [IPC Server handler 8 on 34438] WARN  ipc.Server (Server.java:logException(2720)) - IPC Server handler 8 on 34438, call Call#127 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota from 127.0.0.1:53136
java.lang.IllegalArgumentException: Cannot clear namespace quota on root.
	at org.apache.hadoop.hdfs.server.namenode.FSDirAttrOp.unprotectedSetQuota(FSDirAttrOp.java:336)
	at org.apache.hadoop.hdfs.server.namenode.FSDirAttrOp.setQuota(FSDirAttrOp.java:244)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setQuota(FSNamesystem.java:3249)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setQuota(NameNodeRpcServer.java:1412)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setQuota(ClientNamenodeProtocolServerSideTranslatorPB.java:1029)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:08:47,726 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,728 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=clearSpaceQuota	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,731 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,733 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=clearQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,742 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,745 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=clearSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,762 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:47,768 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data2	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,772 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data2	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,776 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data2	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,781 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=clearSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data2	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,782 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:47,785 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data2/datafile2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:47,797 [IPC Server handler 3 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:46154, 127.0.0.1:43315, 127.0.0.1:34028 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data2/datafile2
2020-04-02 05:08:47,808 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54894 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741831_1007 src: /127.0.0.1:54894 dest: /127.0.0.1:46154
2020-04-02 05:08:47,819 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:53182 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741831_1007 src: /127.0.0.1:53182 dest: /127.0.0.1:43315
2020-04-02 05:08:47,824 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:36368 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741831_1007 src: /127.0.0.1:36368 dest: /127.0.0.1:34028
2020-04-02 05:08:47,874 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36368, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741831_1007, duration(ns): 37367175
2020-04-02 05:08:47,875 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:47,878 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53182, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741831_1007, duration(ns): 46608580
2020-04-02 05:08:47,879 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028] terminating
2020-04-02 05:08:47,903 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54894, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741831_1007, duration(ns): 66970171
2020-04-02 05:08:47,903 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:34028] terminating
2020-04-02 05:08:47,919 [IPC Server handler 4 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data2/datafile2 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:47,928 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data2	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,933 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data2	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,938 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:47,941 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data2/datafile3	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:47,954 [IPC Server handler 7 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 7 on 34438, call Call#150 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 127.0.0.1:53136: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data2 is exceeded: quota = 2560 B = 2.50 KB but diskspace consumed = 5120 B = 5 KB
2020-04-02 05:08:47,977 [IPC Server handler 3 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/test/data2/datafile3 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:47,983 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:08:47,994 [IPC Server handler 1 on 34438] WARN  ipc.Server (Server.java:logException(2720)) - IPC Server handler 1 on 34438, call Call#153 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota from 127.0.0.1:53136
java.lang.IllegalArgumentException: Cannot clear namespace quota on root.
	at org.apache.hadoop.hdfs.server.namenode.FSDirAttrOp.unprotectedSetQuota(FSDirAttrOp.java:336)
	at org.apache.hadoop.hdfs.server.namenode.FSDirAttrOp.setQuota(FSDirAttrOp.java:244)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setQuota(FSNamesystem.java:3249)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setQuota(NameNodeRpcServer.java:1412)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setQuota(ClientNamenodeProtocolServerSideTranslatorPB.java:1029)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:08:48,002 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:08:48,006 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=clearSpaceQuota	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:08:48,008 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:08:48,018 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:08:48,022 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:08:48,024 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=clearSpaceQuota	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:08:48,030 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:48,036 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/datafile2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:48,042 [IPC Server handler 2 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741833_1009, replicas=127.0.0.1:34028, 127.0.0.1:46154, 127.0.0.1:43315 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/datafile2
2020-04-02 05:08:48,062 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:36490 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741833_1009 src: /127.0.0.1:36490 dest: /127.0.0.1:34028
2020-04-02 05:08:48,070 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55032 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741833_1009 src: /127.0.0.1:55032 dest: /127.0.0.1:46154
2020-04-02 05:08:48,073 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:53324 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741833_1009 src: /127.0.0.1:53324 dest: /127.0.0.1:43315
2020-04-02 05:08:48,106 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53324, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741833_1009, duration(ns): 31087630
2020-04-02 05:08:48,108 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55032, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741833_1009, duration(ns): 20522887
2020-04-02 05:08:48,109 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315] terminating
2020-04-02 05:08:48,110 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36490, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741833_1009, duration(ns): 18861983
2020-04-02 05:08:48,110 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:43315] terminating
2020-04-02 05:08:48,110 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:48,123 [IPC Server handler 5 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/datafile2 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:48,134 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:08:48,146 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:08:48,154 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:48,159 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/datafile3	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:48,168 [IPC Server handler 3 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 3 on 34438, call Call#171 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 127.0.0.1:53136: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of / is exceeded: quota = 2560 B = 2.50 KB but diskspace consumed = 17920 B = 17.50 KB
2020-04-02 05:08:48,188 [IPC Server handler 2 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/onGrXiiWgT/TestQuota/testQuotaCommands/datafile3 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:48,199 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:08:48,205 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=clearSpaceQuota	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:08:48,238 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/atkCjQUISW/TestQuota/testSetAndClearSpaceQuotaRegular	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:48,250 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/atkCjQUISW/TestQuota/testSetAndClearSpaceQuotaRegular	dst=null	perm=null	proto=rpc
2020-04-02 05:08:48,262 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/atkCjQUISW/TestQuota/testSetAndClearSpaceQuotaRegular	dst=null	perm=null	proto=rpc
2020-04-02 05:08:48,266 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/atkCjQUISW/TestQuota/testSetAndClearSpaceQuotaRegular	dst=null	perm=null	proto=rpc
2020-04-02 05:08:48,270 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/atkCjQUISW/TestQuota/testSetAndClearSpaceQuotaRegular	dst=null	perm=null	proto=rpc
2020-04-02 05:08:48,274 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=clearSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/atkCjQUISW/TestQuota/testSetAndClearSpaceQuotaRegular	dst=null	perm=null	proto=rpc
2020-04-02 05:08:48,276 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/atkCjQUISW/TestQuota/testSetAndClearSpaceQuotaRegular	dst=null	perm=null	proto=rpc
2020-04-02 05:08:48,283 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:48,289 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:48,294 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:48,308 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20/fileDir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:48,314 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20/fileDir/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:48,320 [IPC Server handler 8 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741835_1011, replicas=127.0.0.1:43315, 127.0.0.1:34028, 127.0.0.1:46154 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20/fileDir/file1
2020-04-02 05:08:48,327 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:53450 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741835_1011 src: /127.0.0.1:53450 dest: /127.0.0.1:43315
2020-04-02 05:08:48,330 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:36636 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741835_1011 src: /127.0.0.1:36636 dest: /127.0.0.1:34028
2020-04-02 05:08:48,334 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55172 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741835_1011 src: /127.0.0.1:55172 dest: /127.0.0.1:46154
2020-04-02 05:08:48,373 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55172, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741835_1011, duration(ns): 34189306
2020-04-02 05:08:48,373 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:48,377 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36636, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741835_1011, duration(ns): 31066154
2020-04-02 05:08:48,377 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154] terminating
2020-04-02 05:08:48,383 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53450, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741835_1011, duration(ns): 33219757
2020-04-02 05:08:48,383 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154] terminating
2020-04-02 05:08:48,388 [IPC Server handler 7 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741836_1012, replicas=127.0.0.1:34028, 127.0.0.1:43315, 127.0.0.1:46154 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20/fileDir/file1
2020-04-02 05:08:48,394 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:36674 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741836_1012 src: /127.0.0.1:36674 dest: /127.0.0.1:34028
2020-04-02 05:08:48,397 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:53494 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741836_1012 src: /127.0.0.1:53494 dest: /127.0.0.1:43315
2020-04-02 05:08:48,403 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55210 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741836_1012 src: /127.0.0.1:55210 dest: /127.0.0.1:46154
2020-04-02 05:08:48,432 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55210, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741836_1012, duration(ns): 24074404
2020-04-02 05:08:48,433 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:48,439 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53494, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741836_1012, duration(ns): 24021995
2020-04-02 05:08:48,439 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154] terminating
2020-04-02 05:08:48,444 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36674, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741836_1012, duration(ns): 29956387
2020-04-02 05:08:48,444 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:46154] terminating
2020-04-02 05:08:48,451 [IPC Server handler 9 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741837_1013, replicas=127.0.0.1:34028, 127.0.0.1:46154, 127.0.0.1:43315 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20/fileDir/file1
2020-04-02 05:08:48,467 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:36704 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741837_1013 src: /127.0.0.1:36704 dest: /127.0.0.1:34028
2020-04-02 05:08:48,470 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55238 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741837_1013 src: /127.0.0.1:55238 dest: /127.0.0.1:46154
2020-04-02 05:08:48,490 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:53526 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741837_1013 src: /127.0.0.1:53526 dest: /127.0.0.1:43315
2020-04-02 05:08:48,527 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53526, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741837_1013, duration(ns): 33746482
2020-04-02 05:08:48,528 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:48,538 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55238, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741837_1013, duration(ns): 39284083
2020-04-02 05:08:48,538 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315] terminating
2020-04-02 05:08:48,542 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36704, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741837_1013, duration(ns): 37393974
2020-04-02 05:08:48,542 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:43315] terminating
2020-04-02 05:08:48,547 [IPC Server handler 0 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741838_1014, replicas=127.0.0.1:43315, 127.0.0.1:46154, 127.0.0.1:34028 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20/fileDir/file1
2020-04-02 05:08:48,581 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:53540 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741838_1014 src: /127.0.0.1:53540 dest: /127.0.0.1:43315
2020-04-02 05:08:48,591 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55256 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741838_1014 src: /127.0.0.1:55256 dest: /127.0.0.1:46154
2020-04-02 05:08:48,606 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:36730 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741838_1014 src: /127.0.0.1:36730 dest: /127.0.0.1:34028
2020-04-02 05:08:48,617 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741827_1003 replica FinalizedReplica, blk_1073741827_1003, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741827 for deletion
2020-04-02 05:08:48,632 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741827_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741827
2020-04-02 05:08:48,677 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36730, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741838_1014, duration(ns): 66521847
2020-04-02 05:08:48,678 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:48,680 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55256, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741838_1014, duration(ns): 60543747
2020-04-02 05:08:48,680 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028] terminating
2020-04-02 05:08:48,693 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53540, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741838_1014, duration(ns): 70575048
2020-04-02 05:08:48,693 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:34028] terminating
2020-04-02 05:08:48,697 [IPC Server handler 0 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741839_1015, replicas=127.0.0.1:43315, 127.0.0.1:34028, 127.0.0.1:46154 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20/fileDir/file1
2020-04-02 05:08:48,711 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:53564 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741839_1015 src: /127.0.0.1:53564 dest: /127.0.0.1:43315
2020-04-02 05:08:48,715 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:36748 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741839_1015 src: /127.0.0.1:36748 dest: /127.0.0.1:34028
2020-04-02 05:08:48,750 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55284 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741839_1015 src: /127.0.0.1:55284 dest: /127.0.0.1:46154
2020-04-02 05:08:48,807 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55284, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741839_1015, duration(ns): 48391863
2020-04-02 05:08:48,807 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:48,822 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36748, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741839_1015, duration(ns): 42900005
2020-04-02 05:08:48,823 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154] terminating
2020-04-02 05:08:48,826 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53564, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741839_1015, duration(ns): 60872847
2020-04-02 05:08:48,826 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154] terminating
2020-04-02 05:08:48,836 [IPC Server handler 1 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741840_1016, replicas=127.0.0.1:43315, 127.0.0.1:46154, 127.0.0.1:34028 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20/fileDir/file1
2020-04-02 05:08:48,851 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:53610 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741840_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741840_1016 src: /127.0.0.1:53610 dest: /127.0.0.1:43315
2020-04-02 05:08:48,858 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55326 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741840_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741840_1016 src: /127.0.0.1:55326 dest: /127.0.0.1:46154
2020-04-02 05:08:48,863 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:36800 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741840_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741840_1016 src: /127.0.0.1:36800 dest: /127.0.0.1:34028
2020-04-02 05:08:48,927 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741840_1016, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36800, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741840_1016, duration(ns): 16060260
2020-04-02 05:08:48,927 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741840_1016, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:48,928 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55326, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741840_1016, duration(ns): 29122702
2020-04-02 05:08:48,929 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028] terminating
2020-04-02 05:08:48,934 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53610, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741840_1016, duration(ns): 26983650
2020-04-02 05:08:48,935 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:34028] terminating
2020-04-02 05:08:48,937 [IPC Server handler 5 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20/fileDir/file1 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:48,957 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20/fileDir/file1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:48,971 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setStoragePolicy	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:48,979 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:48,980 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20/fileDir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:48,983 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20/fileDir/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:48,999 [IPC Server handler 1 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741841_1017, replicas=127.0.0.1:46154, 127.0.0.1:34028, 127.0.0.1:43315 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20/fileDir/file1
2020-04-02 05:08:49,014 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55378 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741841_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741841_1017 src: /127.0.0.1:55378 dest: /127.0.0.1:46154
2020-04-02 05:08:49,022 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:36850 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741841_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741841_1017 src: /127.0.0.1:36850 dest: /127.0.0.1:34028
2020-04-02 05:08:49,025 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:53670 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741841_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741841_1017 src: /127.0.0.1:53670 dest: /127.0.0.1:43315
2020-04-02 05:08:49,071 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741841_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53670, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741841_1017, duration(ns): 12528269
2020-04-02 05:08:49,072 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741841_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:49,075 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741841_1017, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36850, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741841_1017, duration(ns): 14276235
2020-04-02 05:08:49,075 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741841_1017, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741841_1017, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315] terminating
2020-04-02 05:08:49,085 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741841_1017, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55378, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741841_1017, duration(ns): 21177608
2020-04-02 05:08:49,086 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741841_1017, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741841_1017, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315] terminating
2020-04-02 05:08:49,091 [IPC Server handler 5 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741842_1018, replicas=127.0.0.1:43315, 127.0.0.1:34028, 127.0.0.1:46154 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20/fileDir/file1
2020-04-02 05:08:49,106 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:53714 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741842_1018]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741842_1018 src: /127.0.0.1:53714 dest: /127.0.0.1:43315
2020-04-02 05:08:49,110 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:36900 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741842_1018]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741842_1018 src: /127.0.0.1:36900 dest: /127.0.0.1:34028
2020-04-02 05:08:49,112 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55434 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741842_1018]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741842_1018 src: /127.0.0.1:55434 dest: /127.0.0.1:46154
2020-04-02 05:08:49,142 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741842_1018, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55434, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741842_1018, duration(ns): 18941511
2020-04-02 05:08:49,143 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741842_1018, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:49,145 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741842_1018, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36900, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741842_1018, duration(ns): 20661716
2020-04-02 05:08:49,145 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741842_1018, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741842_1018, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154] terminating
2020-04-02 05:08:49,147 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741842_1018, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53714, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741842_1018, duration(ns): 23182757
2020-04-02 05:08:49,150 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741842_1018, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741842_1018, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154] terminating
2020-04-02 05:08:49,151 [IPC Server handler 3 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741843_1019, replicas=127.0.0.1:43315, 127.0.0.1:34028, 127.0.0.1:46154 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20/fileDir/file1
2020-04-02 05:08:49,167 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:53754 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741843_1019]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741843_1019 src: /127.0.0.1:53754 dest: /127.0.0.1:43315
2020-04-02 05:08:49,177 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:36938 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741843_1019]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741843_1019 src: /127.0.0.1:36938 dest: /127.0.0.1:34028
2020-04-02 05:08:49,186 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55476 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741843_1019]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741843_1019 src: /127.0.0.1:55476 dest: /127.0.0.1:46154
2020-04-02 05:08:49,223 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741843_1019, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55476, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741843_1019, duration(ns): 32408637
2020-04-02 05:08:49,223 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741843_1019, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:49,233 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741843_1019, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36938, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741843_1019, duration(ns): 31964008
2020-04-02 05:08:49,234 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741843_1019, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741843_1019, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154] terminating
2020-04-02 05:08:49,239 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741843_1019, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53754, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741843_1019, duration(ns): 43887720
2020-04-02 05:08:49,239 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741843_1019, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741843_1019, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154] terminating
2020-04-02 05:08:49,242 [IPC Server handler 9 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741844_1020, replicas=127.0.0.1:34028, 127.0.0.1:43315, 127.0.0.1:46154 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20/fileDir/file1
2020-04-02 05:08:49,254 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:36966 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741844_1020]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741844_1020 src: /127.0.0.1:36966 dest: /127.0.0.1:34028
2020-04-02 05:08:49,259 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:53786 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741844_1020]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741844_1020 src: /127.0.0.1:53786 dest: /127.0.0.1:43315
2020-04-02 05:08:49,264 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55502 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741844_1020]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741844_1020 src: /127.0.0.1:55502 dest: /127.0.0.1:46154
2020-04-02 05:08:49,303 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741844_1020, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55502, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741844_1020, duration(ns): 8151088
2020-04-02 05:08:49,306 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741844_1020, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53786, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741844_1020, duration(ns): 21806743
2020-04-02 05:08:49,306 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741844_1020, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:49,307 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741844_1020, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741844_1020, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154] terminating
2020-04-02 05:08:49,308 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741844_1020, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36966, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741844_1020, duration(ns): 14911610
2020-04-02 05:08:49,308 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741844_1020, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741844_1020, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:46154] terminating
2020-04-02 05:08:49,316 [IPC Server handler 0 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 0 on 34438, call Call#239 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 127.0.0.1:53136: org.apache.hadoop.hdfs.protocol.QuotaByStorageTypeExceededException: Quota by storage type : DISK on path : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20 is exceeded. quota = 6 KB but space consumed = 7.50 KB
2020-04-02 05:08:49,326 [IPC Server handler 7 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20/fileDir/file1 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:49,329 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20/fileDir/file1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,331 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ial0FgLEyJ/TestQuota/testQuotaByStorageType/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,350 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:49,363 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20/nqdir30	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:49,366 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,371 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,373 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,380 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,386 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,389 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,394 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir21	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:49,397 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,406 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,415 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,420 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir21/nqdir32	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:49,424 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,427 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,434 [IPC Server handler 6 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 6 on 34438, call Call#258 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 127.0.0.1:53136: org.apache.hadoop.hdfs.protocol.NSQuotaExceededException: The NameSpace quota (directories and files) of directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir21 is exceeded: quota=2 file count=3
2020-04-02 05:08:49,443 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,454 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,459 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20/nqdir31	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:49,465 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,467 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,486 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,494 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,497 [IPC Server handler 8 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 8 on 34438, call Call#266 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 127.0.0.1:53136: org.apache.hadoop.hdfs.protocol.NSQuotaExceededException: The NameSpace quota (directories and files) of directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1 is exceeded: quota=6 file count=7
2020-04-02 05:08:49,509 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir21/nqdir32	dst=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20/nqdir30	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:49,515 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,519 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,558 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,567 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,570 [IPC Server handler 2 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 2 on 34438, call Call#272 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename from 127.0.0.1:53136: org.apache.hadoop.hdfs.protocol.NSQuotaExceededException: The NameSpace quota (directories and files) of directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir21 is exceeded: quota=2 file count=3
2020-04-02 05:08:49,575 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20/nqdir30	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,578 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir21/nqdir30	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,585 [IPC Server handler 9 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 9 on 34438, call Call#275 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename from 127.0.0.1:53136: org.apache.hadoop.hdfs.protocol.NSQuotaExceededException: The NameSpace quota (directories and files) of directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir21 is exceeded: quota=2 file count=3
2020-04-02 05:08:49,587 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20/nqdir30	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,594 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir21/nqdir32	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,599 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20/nqdir30	dst=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:49,604 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,608 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,620 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,628 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,635 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/nqdir30/nqdir33	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:49,637 [IPC Server handler 4 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 4 on 34438, call Call#284 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename from 127.0.0.1:53136: org.apache.hadoop.hdfs.protocol.NSQuotaExceededException: The NameSpace quota (directories and files) of directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1 is exceeded: quota=6 file count=7
2020-04-02 05:08:49,647 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir21	dst=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:49,653 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,656 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,660 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,662 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,664 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,666 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,667 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,669 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,671 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,675 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,677 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,680 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/nqdir30	dst=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:49,684 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,686 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,698 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,702 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/372glx12NT/TestQuota/testNamespaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,707 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/LeS2Uy9d4I/TestQuota/testSetAndClearSpaceQuotaByStorageType	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:49,712 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/LeS2Uy9d4I/TestQuota/testSetAndClearSpaceQuotaByStorageType	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,722 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/LeS2Uy9d4I/TestQuota/testSetAndClearSpaceQuotaByStorageType	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,730 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/LeS2Uy9d4I/TestQuota/testSetAndClearSpaceQuotaByStorageType	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,740 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/LeS2Uy9d4I/TestQuota/testSetAndClearSpaceQuotaByStorageType	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,745 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=clearSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/LeS2Uy9d4I/TestQuota/testSetAndClearSpaceQuotaByStorageType	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,750 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/LeS2Uy9d4I/TestQuota/testSetAndClearSpaceQuotaByStorageType	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,759 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/OQuhotSK3x/TestQuota/testMaxSpaceQuotas	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:49,761 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/OQuhotSK3x/TestQuota/testMaxSpaceQuotas/testFolder	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:49,764 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/OQuhotSK3x/TestQuota/testMaxSpaceQuotas/testFolder	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,765 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/OQuhotSK3x/TestQuota/testMaxSpaceQuotas/testFolder	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,766 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/OQuhotSK3x/TestQuota/testMaxSpaceQuotas/testFolder	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,770 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/OQuhotSK3x/TestQuota/testMaxSpaceQuotas/testFolder	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,778 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/OQuhotSK3x/TestQuota/testMaxSpaceQuotas/testFolder	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,786 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/OQuhotSK3x/TestQuota/testMaxSpaceQuotas/testFolder	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,788 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/OQuhotSK3x/TestQuota/testMaxSpaceQuotas/testFolder	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,790 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/OQuhotSK3x/TestQuota/testMaxSpaceQuotas/testFolder	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,791 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/OQuhotSK3x/TestQuota/testMaxSpaceQuotas/testFolder	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,792 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/OQuhotSK3x/TestQuota/testMaxSpaceQuotas/testFolder	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,793 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/OQuhotSK3x/TestQuota/testMaxSpaceQuotas/testFolder	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,798 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/OQuhotSK3x/TestQuota/testMaxSpaceQuotas/testFolder	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,814 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/1o7FL0RCwf/TestQuota/testSetAndClearSpaceQuotaNoAccess	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:49,838 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=whoever (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/1o7FL0RCwf/TestQuota/testSetAndClearSpaceQuotaNoAccess	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,851 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=whoever (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/1o7FL0RCwf/TestQuota/testSetAndClearSpaceQuotaNoAccess	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,851 [IPC Server handler 9 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 9 on 34438, call Call#325 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota from 127.0.0.1:54798: org.apache.hadoop.security.AccessControlException: Access denied for user whoever. Superuser privilege is required
2020-04-02 05:08:49,891 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=whoever (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/1o7FL0RCwf/TestQuota/testSetAndClearSpaceQuotaNoAccess	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,894 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=whoever (auth:SIMPLE)	ip=/127.0.0.1	cmd=clearSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/1o7FL0RCwf/TestQuota/testSetAndClearSpaceQuotaNoAccess	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,895 [IPC Server handler 5 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 5 on 34438, call Call#327 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota from 127.0.0.1:54838: org.apache.hadoop.security.AccessControlException: Access denied for user whoever. Superuser privilege is required
2020-04-02 05:08:49,940 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/TestQuota/testQuotaCommandsWithURI	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:49,946 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/TestQuota/testQuotaCommandsWithURI	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,950 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/TestQuota/testQuotaCommandsWithURI	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,952 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/TestQuota/testQuotaCommandsWithURI	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,962 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/TestQuota/testQuotaCommandsWithURI	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,970 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=clearSpaceQuota	src=/TestQuota/testQuotaCommandsWithURI	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,978 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/TestQuota/testQuotaCommandsWithURI	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,982 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/TestQuota/testQuotaCommandsWithURI	dst=null	perm=null	proto=rpc
2020-04-02 05:08:49,990 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/TestQuota/testQuotaCommandsWithURI	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,006 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/TestQuota/testQuotaCommandsWithURI	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,014 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=clearQuota	src=/TestQuota/testQuotaCommandsWithURI	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,038 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,044 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:50,052 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,055 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,061 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:50,070 [Thread-301] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 8, block==null
2020-04-02 05:08:50,070 [Thread-301] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 8 lastPacketInBlock: true lastByteOffsetInBlock: 8, block==null
2020-04-02 05:08:50,070 [Thread-301] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:08:50,074 [Thread-302] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:50,076 [Thread-302] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:50,089 [IPC Server handler 4 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741846_1022, replicas=127.0.0.1:43315, 127.0.0.1:46154, 127.0.0.1:34028 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file
2020-04-02 05:08:50,091 [Thread-302] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK]], blk_1073741846_1022
2020-04-02 05:08:50,092 [Thread-302] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:43315
2020-04-02 05:08:50,092 [Thread-302] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:50,094 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54088 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022 src: /127.0.0.1:54088 dest: /127.0.0.1:43315
2020-04-02 05:08:50,102 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55804 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022 src: /127.0.0.1:55804 dest: /127.0.0.1:46154
2020-04-02 05:08:50,105 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:37278 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022 src: /127.0.0.1:37278 dest: /127.0.0.1:34028
2020-04-02 05:08:50,114 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7, DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2]
2020-04-02 05:08:50,134 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741846_1022 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 8
2020-04-02 05:08:50,136 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741846_1022
2020-04-02 05:08:50,163 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 7813232 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:50,170 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741846_1022 sending packet seqno: 1 offsetInBlock: 8 lastPacketInBlock: true lastByteOffsetInBlock: 8
2020-04-02 05:08:50,183 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37278, dest: /127.0.0.1:34028, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022, duration(ns): 70014869
2020-04-02 05:08:50,183 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:50,184 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55804, dest: /127.0.0.1:46154, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022, duration(ns): 61914087
2020-04-02 05:08:50,185 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028] terminating
2020-04-02 05:08:50,186 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54088, dest: /127.0.0.1:43315, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022, duration(ns): 67689546
2020-04-02 05:08:50,187 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:34028] terminating
2020-04-02 05:08:50,188 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 11664083 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:50,209 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022
2020-04-02 05:08:50,212 [IPC Server handler 6 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:50,230 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=append	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,249 [Thread-301] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:<clinit>(53)) - seed=-892811676774593021
2020-04-02 05:08:50,250 [Thread-301] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:initialValue(64)) - Thread-301: seed=950860911019773840
2020-04-02 05:08:50,250 [Thread-301] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(79)) - seed=958241888, size=4096
2020-04-02 05:08:50,251 [Thread-301] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 0 offsetInBlock: 8 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file, bytesCurBlock=512, blockSize=512, appendChunk=true, blk_1073741846_1022
2020-04-02 05:08:50,251 [Thread-301] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 8 lastPacketInBlock: false lastByteOffsetInBlock: 512, blk_1073741846_1022
2020-04-02 05:08:50,251 [Thread-301] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, blk_1073741846_1022
2020-04-02 05:08:50,251 [Thread-301] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file, bytesCurBlock=512, blockSize=512, appendChunk=false, blk_1073741846_1022
2020-04-02 05:08:50,251 [Thread-301] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, blk_1073741846_1022
2020-04-02 05:08:50,251 [Thread-301] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 3 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, blk_1073741846_1022
2020-04-02 05:08:50,251 [Thread-301] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 4 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file, bytesCurBlock=512, blockSize=512, appendChunk=false, blk_1073741846_1022
2020-04-02 05:08:50,251 [Thread-301] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 4 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, blk_1073741846_1022
2020-04-02 05:08:50,252 [Thread-301] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 5 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, blk_1073741846_1022
2020-04-02 05:08:50,252 [Thread-301] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 6 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file, bytesCurBlock=512, blockSize=512, appendChunk=false, blk_1073741846_1022
2020-04-02 05:08:50,252 [Thread-301] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 6 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, blk_1073741846_1022
2020-04-02 05:08:50,252 [Thread-301] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 7 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, blk_1073741846_1022
2020-04-02 05:08:50,252 [Thread-301] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 8 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file, bytesCurBlock=512, blockSize=512, appendChunk=false, blk_1073741846_1022
2020-04-02 05:08:50,252 [Thread-301] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 8 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, blk_1073741846_1022
2020-04-02 05:08:50,252 [Thread-301] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 9 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, blk_1073741846_1022
2020-04-02 05:08:50,252 [Thread-301] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 10 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file, bytesCurBlock=512, blockSize=512, appendChunk=false, blk_1073741846_1022
2020-04-02 05:08:50,252 [Thread-301] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 10 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, blk_1073741846_1022
2020-04-02 05:08:50,252 [Thread-301] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 11 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, blk_1073741846_1022
2020-04-02 05:08:50,253 [Thread-301] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 12 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file, bytesCurBlock=512, blockSize=512, appendChunk=false, blk_1073741846_1022
2020-04-02 05:08:50,253 [Thread-301] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 12 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, blk_1073741846_1022
2020-04-02 05:08:50,253 [Thread-301] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 13 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, blk_1073741846_1022
2020-04-02 05:08:50,253 [Thread-301] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 14 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file, bytesCurBlock=512, blockSize=512, appendChunk=false, blk_1073741846_1022
2020-04-02 05:08:50,253 [Thread-301] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 14 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, blk_1073741846_1022
2020-04-02 05:08:50,253 [Thread-301] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 15 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, blk_1073741846_1022
2020-04-02 05:08:50,253 [Thread-301] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 16 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 8, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file, bytesCurBlock=8, blockSize=512, appendChunk=false, blk_1073741846_1022
2020-04-02 05:08:50,253 [Thread-301] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 16 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 8, blk_1073741846_1022
2020-04-02 05:08:50,254 [Thread-301] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 17 offsetInBlock: 8 lastPacketInBlock: true lastByteOffsetInBlock: 8, blk_1073741846_1022
2020-04-02 05:08:50,254 [Thread-301] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - blk_1073741846_1022 waiting for ack for: 17
2020-04-02 05:08:50,254 [Thread-310] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_APPEND, blk_1073741846_1022
2020-04-02 05:08:50,262 [Thread-310] DEBUG hdfs.DataStreamer (DataStreamer.java:run(719)) - Append to block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022
2020-04-02 05:08:50,270 [Thread-310] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:34028,DS-0649210e-2159-42b8-92ae-9ed2ad87ee25,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-3c105529-4159-4844-a50f-6dce7b951e83,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-d6ec7455-d48a-4372-bfc2-a59c9a107d28,DISK]], blk_1073741846_1022
2020-04-02 05:08:50,270 [Thread-310] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:34028
2020-04-02 05:08:50,270 [Thread-310] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:50,274 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:37318 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022 src: /127.0.0.1:37318 dest: /127.0.0.1:34028
2020-04-02 05:08:50,274 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:37318 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:append(1187)) - Appending to FinalizedReplica, blk_1073741846_1022, FINALIZED
  getNumBytes()     = 8
  getBytesOnDisk()  = 8
  getVisibleLength()= 8
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741846
2020-04-02 05:08:50,322 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54190 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022 src: /127.0.0.1:54190 dest: /127.0.0.1:43315
2020-04-02 05:08:50,322 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54190 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:append(1187)) - Appending to FinalizedReplica, blk_1073741846_1022, FINALIZED
  getNumBytes()     = 8
  getBytesOnDisk()  = 8
  getVisibleLength()= 8
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741846
2020-04-02 05:08:50,359 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55924 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022 src: /127.0.0.1:55924 dest: /127.0.0.1:46154
2020-04-02 05:08:50,360 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55924 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1022]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:append(1187)) - Appending to FinalizedReplica, blk_1073741846_1022, FINALIZED
  getNumBytes()     = 8
  getBytesOnDisk()  = 8
  getVisibleLength()= 8
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741846
2020-04-02 05:08:50,414 [IPC Server handler 7 on 34438] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5340)) - updatePipeline(blk_1073741846_1022, newGS=1023, newLength=8, newNodes=[127.0.0.1:34028, 127.0.0.1:43315, 127.0.0.1:46154], client=DFSClient_NONMAPREDUCE_1826976575_1)
2020-04-02 05:08:50,419 [IPC Server handler 7 on 34438] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5358)) - updatePipeline(blk_1073741846_1022 => blk_1073741846_1023) success
2020-04-02 05:08:50,421 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1023] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:34028,DS-0649210e-2159-42b8-92ae-9ed2ad87ee25,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-3c105529-4159-4844-a50f-6dce7b951e83,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-d6ec7455-d48a-4372-bfc2-a59c9a107d28,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-0649210e-2159-42b8-92ae-9ed2ad87ee25, DS-3c105529-4159-4844-a50f-6dce7b951e83, DS-d6ec7455-d48a-4372-bfc2-a59c9a107d28]
2020-04-02 05:08:50,422 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1023] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741846_1023 sending packet seqno: 0 offsetInBlock: 8 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:50,423 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1023] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741846_1023
2020-04-02 05:08:50,430 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1023] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 5784055 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:50,437 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1023] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741846_1023 sending packet seqno: 1 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:50,440 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1023, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55924, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1023, duration(ns): 35756221
2020-04-02 05:08:50,441 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1023, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1023, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:50,448 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1023, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54190, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1023, duration(ns): 43857590
2020-04-02 05:08:50,449 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1023, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1023, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154] terminating
2020-04-02 05:08:50,466 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1023, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37318, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1023, duration(ns): 61487136
2020-04-02 05:08:50,466 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1023, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1023, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:46154] terminating
2020-04-02 05:08:50,470 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1023] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 12068643 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:50,488 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1023] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741846_1023
2020-04-02 05:08:50,488 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741846_1023
2020-04-02 05:08:50,488 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741846_1023
2020-04-02 05:08:50,491 [IPC Server handler 9 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741847_1024, replicas=127.0.0.1:46154, 127.0.0.1:34028, 127.0.0.1:43315 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file
2020-04-02 05:08:50,492 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK]], blk_1073741847_1024
2020-04-02 05:08:50,492 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:46154
2020-04-02 05:08:50,493 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:50,494 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56002 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024 src: /127.0.0.1:56002 dest: /127.0.0.1:46154
2020-04-02 05:08:50,514 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:37482 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024 src: /127.0.0.1:37482 dest: /127.0.0.1:34028
2020-04-02 05:08:50,518 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54306 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024 src: /127.0.0.1:54306 dest: /127.0.0.1:43315
2020-04-02 05:08:50,530 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file block BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2, DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7]
2020-04-02 05:08:50,534 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file block BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741847_1024 sending packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:50,534 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file block BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741847_1024
2020-04-02 05:08:50,539 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2563905 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:50,546 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file block BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741847_1024 sending packet seqno: 3 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:50,551 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54306, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024, duration(ns): 22996601
2020-04-02 05:08:50,552 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:50,555 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37482, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024, duration(ns): 26776008
2020-04-02 05:08:50,555 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315] terminating
2020-04-02 05:08:50,556 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56002, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024, duration(ns): 21909824
2020-04-02 05:08:50,556 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315] terminating
2020-04-02 05:08:50,558 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 3 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 7358166 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:50,563 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file block BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741847_1024
2020-04-02 05:08:50,564 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741847_1024
2020-04-02 05:08:50,564 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741847_1024
2020-04-02 05:08:50,567 [IPC Server handler 0 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 0 on 34438, call Call#359 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 127.0.0.1:53136: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend is exceeded: quota = 4000 B = 3.91 KB but diskspace consumed = 4608 B = 4.50 KB
2020-04-02 05:08:50,572 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file] DEBUG hdfs.DataStreamer (DataStreamer.java:run(824)) - DataStreamer Quota Exception
org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend is exceeded: quota = 4000 B = 3.91 KB but diskspace consumed = 4608 B = 4.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1866)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.DSQuotaExceededException): The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend is exceeded: quota = 4000 B = 3.91 KB but diskspace consumed = 4608 B = 4.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy25.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:510)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy29.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	... 3 more
2020-04-02 05:08:50,580 [Thread-301] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, blk_1073741847_1024
java.lang.Throwable: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend is exceeded: quota = 4000 B = 3.91 KB but diskspace consumed = 4608 B = 4.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.ExceptionLastSeen.throwException4Close(ExceptionLastSeen.java:72)
	at org.apache.hadoop.hdfs.DataStreamer.checkClosed(DataStreamer.java:978)
	at org.apache.hadoop.hdfs.DataStreamer.waitForAckedSeqno(DataStreamer.java:894)
	at org.apache.hadoop.hdfs.DFSOutputStream.flushInternal(DFSOutputStream.java:776)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:886)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.TestQuota.testSpaceQuotaExceptionOnAppend(TestQuota.java:1594)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend is exceeded: quota = 4000 B = 3.91 KB but diskspace consumed = 4608 B = 4.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1866)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.DSQuotaExceededException): The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend is exceeded: quota = 4000 B = 3.91 KB but diskspace consumed = 4608 B = 4.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy25.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:510)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy29.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	... 3 more
2020-04-02 05:08:50,595 [IPC Server handler 3 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ZOMhf44Dvg/TestQuota/testSpaceQuotaExceptionOnAppend/file is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:50,610 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:50,614 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:50,617 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,623 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,626 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,628 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,630 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,634 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,637 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:50,639 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,640 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,641 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,647 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:50,650 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32/fileDir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:50,655 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32/fileDir/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:50,657 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32/fileDir/file1, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:50,657 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:50,658 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:50,658 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32/fileDir/file1, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:50,658 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:50,658 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 3 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:50,658 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 3
2020-04-02 05:08:50,664 [Thread-332] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:50,664 [Thread-332] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:50,666 [IPC Server handler 8 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741849_1026, replicas=127.0.0.1:43315, 127.0.0.1:46154, 127.0.0.1:34028 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32/fileDir/file1
2020-04-02 05:08:50,671 [Thread-332] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK]], blk_1073741849_1026
2020-04-02 05:08:50,671 [Thread-332] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:43315
2020-04-02 05:08:50,671 [Thread-332] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:50,673 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54376 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026 src: /127.0.0.1:54376 dest: /127.0.0.1:43315
2020-04-02 05:08:50,675 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56092 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026 src: /127.0.0.1:56092 dest: /127.0.0.1:46154
2020-04-02 05:08:50,684 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:37562 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026 src: /127.0.0.1:37562 dest: /127.0.0.1:34028
2020-04-02 05:08:50,693 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32/fileDir/file1 block BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7, DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2]
2020-04-02 05:08:50,693 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32/fileDir/file1 block BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741849_1026 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:50,695 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32/fileDir/file1 block BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741849_1026
2020-04-02 05:08:50,696 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1237015 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:50,706 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32/fileDir/file1 block BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741849_1026 sending packet seqno: 1 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:50,710 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37562, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026, duration(ns): 23742320
2020-04-02 05:08:50,711 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:50,712 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56092, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026, duration(ns): 16888755
2020-04-02 05:08:50,712 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028] terminating
2020-04-02 05:08:50,712 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54376, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026, duration(ns): 18726677
2020-04-02 05:08:50,713 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 5261655 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:50,713 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:34028] terminating
2020-04-02 05:08:50,713 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32/fileDir/file1 block BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741849_1026
2020-04-02 05:08:50,722 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32/fileDir/file1] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741849_1026
2020-04-02 05:08:50,722 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32/fileDir/file1] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741849_1026
2020-04-02 05:08:50,725 [IPC Server handler 3 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741850_1027, replicas=127.0.0.1:46154, 127.0.0.1:34028, 127.0.0.1:43315 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32/fileDir/file1
2020-04-02 05:08:50,726 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32/fileDir/file1] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK]], blk_1073741850_1027
2020-04-02 05:08:50,727 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32/fileDir/file1] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:46154
2020-04-02 05:08:50,727 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32/fileDir/file1] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:50,729 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56120 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027 src: /127.0.0.1:56120 dest: /127.0.0.1:46154
2020-04-02 05:08:50,737 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:37590 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027 src: /127.0.0.1:37590 dest: /127.0.0.1:34028
2020-04-02 05:08:50,742 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54412 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027 src: /127.0.0.1:54412 dest: /127.0.0.1:43315
2020-04-02 05:08:50,750 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32/fileDir/file1 block BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2, DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7]
2020-04-02 05:08:50,763 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32/fileDir/file1 block BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741850_1027 sending packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:50,763 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32/fileDir/file1 block BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741850_1027
2020-04-02 05:08:50,766 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1124453 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:50,768 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32/fileDir/file1 block BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741850_1027 sending packet seqno: 3 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:50,769 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54412, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027, duration(ns): 25166420
2020-04-02 05:08:50,769 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:50,770 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37590, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027, duration(ns): 23440249
2020-04-02 05:08:50,770 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315] terminating
2020-04-02 05:08:50,771 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56120, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027, duration(ns): 19234648
2020-04-02 05:08:50,771 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 3 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2347905 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:50,772 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315] terminating
2020-04-02 05:08:50,772 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32/fileDir/file1 block BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741850_1027
2020-04-02 05:08:50,783 [IPC Server handler 1 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32/fileDir/file1 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:50,793 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,799 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,801 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:50,814 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:50,816 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:50,816 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:50,817 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:50,817 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:50,817 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:50,817 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 3 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:50,817 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 4 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:50,817 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 4 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:50,817 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 5 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:50,817 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 6 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:50,817 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 6 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:50,817 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 7 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:50,818 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 7
2020-04-02 05:08:50,824 [Thread-347] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:50,825 [Thread-347] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:50,827 [IPC Server handler 0 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741851_1028, replicas=127.0.0.1:34028, 127.0.0.1:43315, 127.0.0.1:46154 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2
2020-04-02 05:08:50,833 [Thread-347] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK]], blk_1073741851_1028
2020-04-02 05:08:50,833 [Thread-347] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:34028
2020-04-02 05:08:50,833 [Thread-347] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:50,835 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:37622 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028 src: /127.0.0.1:37622 dest: /127.0.0.1:34028
2020-04-02 05:08:50,837 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54444 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028 src: /127.0.0.1:54444 dest: /127.0.0.1:43315
2020-04-02 05:08:50,839 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56160 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028 src: /127.0.0.1:56160 dest: /127.0.0.1:46154
2020-04-02 05:08:50,847 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2, DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7, DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b]
2020-04-02 05:08:50,855 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741851_1028 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:50,858 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741851_1028
2020-04-02 05:08:50,870 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1433297 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:50,871 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741851_1028 sending packet seqno: 1 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:50,874 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56160, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028, duration(ns): 31962311
2020-04-02 05:08:50,875 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:50,875 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54444, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028, duration(ns): 12644538
2020-04-02 05:08:50,876 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154] terminating
2020-04-02 05:08:50,879 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37622, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028, duration(ns): 13168832
2020-04-02 05:08:50,879 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:46154] terminating
2020-04-02 05:08:50,880 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 6221422 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:50,880 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741851_1028
2020-04-02 05:08:50,880 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741851_1028
2020-04-02 05:08:50,880 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741851_1028
2020-04-02 05:08:50,884 [IPC Server handler 4 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741852_1029, replicas=127.0.0.1:43315, 127.0.0.1:34028, 127.0.0.1:46154 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2
2020-04-02 05:08:50,886 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK]], blk_1073741852_1029
2020-04-02 05:08:50,886 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:43315
2020-04-02 05:08:50,887 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:50,888 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54456 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029 src: /127.0.0.1:54456 dest: /127.0.0.1:43315
2020-04-02 05:08:50,890 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:37640 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029 src: /127.0.0.1:37640 dest: /127.0.0.1:34028
2020-04-02 05:08:50,892 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56174 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029 src: /127.0.0.1:56174 dest: /127.0.0.1:46154
2020-04-02 05:08:50,902 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2, DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b]
2020-04-02 05:08:50,905 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741852_1029 sending packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:50,905 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741852_1029
2020-04-02 05:08:50,908 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2101556 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:50,908 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741852_1029 sending packet seqno: 3 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:50,914 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56174, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029, duration(ns): 20745250
2020-04-02 05:08:50,915 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:50,917 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37640, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029, duration(ns): 22024817
2020-04-02 05:08:50,917 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154] terminating
2020-04-02 05:08:50,918 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54456, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029, duration(ns): 13091731
2020-04-02 05:08:50,918 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154] terminating
2020-04-02 05:08:50,918 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 3 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 7658804 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:50,919 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741852_1029
2020-04-02 05:08:50,919 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741852_1029
2020-04-02 05:08:50,919 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741852_1029
2020-04-02 05:08:50,923 [IPC Server handler 9 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 9 on 34438, call Call#396 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 127.0.0.1:53136: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21 is exceeded: quota = 6144 B = 6 KB but diskspace consumed = 7680 B = 7.50 KB
2020-04-02 05:08:50,931 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:run(824)) - DataStreamer Quota Exception
org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21 is exceeded: quota = 6144 B = 6 KB but diskspace consumed = 7680 B = 7.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1866)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.DSQuotaExceededException): The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21 is exceeded: quota = 6144 B = 6 KB but diskspace consumed = 7680 B = 7.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy25.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:510)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy29.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	... 3 more
2020-04-02 05:08:50,947 [Thread-331] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, blk_1073741852_1029
java.lang.Throwable: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21 is exceeded: quota = 6144 B = 6 KB but diskspace consumed = 7680 B = 7.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.ExceptionLastSeen.throwException4Close(ExceptionLastSeen.java:72)
	at org.apache.hadoop.hdfs.DataStreamer.checkClosed(DataStreamer.java:978)
	at org.apache.hadoop.hdfs.DataStreamer.waitForAckedSeqno(DataStreamer.java:894)
	at org.apache.hadoop.hdfs.DFSOutputStream.flushInternal(DFSOutputStream.java:776)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:886)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:460)
	at org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:418)
	at org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:411)
	at org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:404)
	at org.apache.hadoop.hdfs.TestQuota.testSpaceCommands(TestQuota.java:718)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21 is exceeded: quota = 6144 B = 6 KB but diskspace consumed = 7680 B = 7.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1866)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.DSQuotaExceededException): The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21 is exceeded: quota = 6144 B = 6 KB but diskspace consumed = 7680 B = 7.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy25.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:510)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy29.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	... 3 more
2020-04-02 05:08:50,950 [IPC Server handler 5 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33/file2 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:50,954 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir33	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,958 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,960 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,961 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,964 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,969 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32	dst=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:50,979 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,989 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,992 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,993 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:50,998 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,000 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:51,010 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:51,013 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,013 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,014 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,014 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,014 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,014 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 3 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,014 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 4 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,014 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 4 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,014 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 5 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,014 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 6 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,015 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 6 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,015 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 7 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,015 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 7
2020-04-02 05:08:51,016 [Thread-362] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:51,016 [Thread-362] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:51,018 [IPC Server handler 1 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741854_1031, replicas=127.0.0.1:46154, 127.0.0.1:43315, 127.0.0.1:34028 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2
2020-04-02 05:08:51,020 [Thread-362] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK]], blk_1073741854_1031
2020-04-02 05:08:51,020 [Thread-362] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:46154
2020-04-02 05:08:51,021 [Thread-362] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:51,026 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56252 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031 src: /127.0.0.1:56252 dest: /127.0.0.1:46154
2020-04-02 05:08:51,029 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54542 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031 src: /127.0.0.1:54542 dest: /127.0.0.1:43315
2020-04-02 05:08:51,032 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:37726 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031 src: /127.0.0.1:37726 dest: /127.0.0.1:34028
2020-04-02 05:08:51,043 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b, DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2]
2020-04-02 05:08:51,046 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741854_1031 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:51,047 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741854_1031
2020-04-02 05:08:51,056 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 8443794 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,057 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741854_1031 sending packet seqno: 1 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:51,060 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37726, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031, duration(ns): 24958349
2020-04-02 05:08:51,061 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54542, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031, duration(ns): 27401289
2020-04-02 05:08:51,061 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028] terminating
2020-04-02 05:08:51,062 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:51,066 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56252, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031, duration(ns): 22593793
2020-04-02 05:08:51,066 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:34028] terminating
2020-04-02 05:08:51,068 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 6614903 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,078 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031
2020-04-02 05:08:51,078 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741854_1031
2020-04-02 05:08:51,078 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741854_1031
2020-04-02 05:08:51,083 [IPC Server handler 6 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741855_1032, replicas=127.0.0.1:43315, 127.0.0.1:34028, 127.0.0.1:46154 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2
2020-04-02 05:08:51,090 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK]], blk_1073741855_1032
2020-04-02 05:08:51,091 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:43315
2020-04-02 05:08:51,091 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:51,095 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54572 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032 src: /127.0.0.1:54572 dest: /127.0.0.1:43315
2020-04-02 05:08:51,097 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:37756 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032 src: /127.0.0.1:37756 dest: /127.0.0.1:34028
2020-04-02 05:08:51,110 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56294 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032 src: /127.0.0.1:56294 dest: /127.0.0.1:46154
2020-04-02 05:08:51,112 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2, DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b]
2020-04-02 05:08:51,118 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741855_1032 sending packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:51,119 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741855_1032
2020-04-02 05:08:51,130 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 10449499 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,131 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741855_1032 sending packet seqno: 3 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:51,132 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56294, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032, duration(ns): 20307045
2020-04-02 05:08:51,133 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37756, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032, duration(ns): 16165566
2020-04-02 05:08:51,133 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154] terminating
2020-04-02 05:08:51,134 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:51,138 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54572, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032, duration(ns): 18425390
2020-04-02 05:08:51,139 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154] terminating
2020-04-02 05:08:51,139 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 3 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2958394 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,141 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032
2020-04-02 05:08:51,142 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741855_1032
2020-04-02 05:08:51,142 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741855_1032
2020-04-02 05:08:51,144 [IPC Server handler 3 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741856_1033, replicas=127.0.0.1:43315, 127.0.0.1:46154, 127.0.0.1:34028 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2
2020-04-02 05:08:51,150 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK]], blk_1073741856_1033
2020-04-02 05:08:51,151 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:43315
2020-04-02 05:08:51,151 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:51,153 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54600 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033 src: /127.0.0.1:54600 dest: /127.0.0.1:43315
2020-04-02 05:08:51,155 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56316 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033 src: /127.0.0.1:56316 dest: /127.0.0.1:46154
2020-04-02 05:08:51,159 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:37790 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033 src: /127.0.0.1:37790 dest: /127.0.0.1:34028
2020-04-02 05:08:51,166 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7, DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2]
2020-04-02 05:08:51,170 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741856_1033 sending packet seqno: 4 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:51,170 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741856_1033
2020-04-02 05:08:51,178 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 4 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 4009778 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,178 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741856_1033 sending packet seqno: 5 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:51,182 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37790, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033, duration(ns): 14911935
2020-04-02 05:08:51,183 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56316, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033, duration(ns): 16311350
2020-04-02 05:08:51,183 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028] terminating
2020-04-02 05:08:51,183 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:51,186 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54600, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033, duration(ns): 20006570
2020-04-02 05:08:51,186 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:34028] terminating
2020-04-02 05:08:51,187 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 5 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 6761291 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,187 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033
2020-04-02 05:08:51,187 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741856_1033
2020-04-02 05:08:51,187 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741856_1033
2020-04-02 05:08:51,189 [IPC Server handler 4 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741857_1034, replicas=127.0.0.1:34028, 127.0.0.1:46154, 127.0.0.1:43315 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2
2020-04-02 05:08:51,191 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK]], blk_1073741857_1034
2020-04-02 05:08:51,191 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:34028
2020-04-02 05:08:51,192 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:51,194 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:37826 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034 src: /127.0.0.1:37826 dest: /127.0.0.1:34028
2020-04-02 05:08:51,197 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56362 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034 src: /127.0.0.1:56362 dest: /127.0.0.1:46154
2020-04-02 05:08:51,198 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54650 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034 src: /127.0.0.1:54650 dest: /127.0.0.1:43315
2020-04-02 05:08:51,200 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2, DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b, DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7]
2020-04-02 05:08:51,206 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741857_1034 sending packet seqno: 6 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:51,206 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741857_1034
2020-04-02 05:08:51,214 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 6 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2749037 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,214 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741857_1034 sending packet seqno: 7 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:51,219 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54650, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034, duration(ns): 18742977
2020-04-02 05:08:51,219 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:51,220 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56362, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034, duration(ns): 18766085
2020-04-02 05:08:51,220 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315] terminating
2020-04-02 05:08:51,221 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37826, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034, duration(ns): 14628449
2020-04-02 05:08:51,221 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:43315] terminating
2020-04-02 05:08:51,231 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 7 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2684788 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,231 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034
2020-04-02 05:08:51,235 [IPC Server handler 0 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:51,240 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,243 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,253 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,254 [IPC Server handler 1 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 1 on 34438, call Call#432 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename from 127.0.0.1:53136: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21 is exceeded: quota = 6144 B = 6 KB but diskspace consumed = 9216 B = 9 KB
2020-04-02 05:08:51,266 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21/nqdir32	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,274 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,279 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,280 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,282 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir21	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,285 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,287 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,290 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,292 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,294 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=append	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,296 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,296 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,296 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,296 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,302 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,302 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 3 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,302 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 3
2020-04-02 05:08:51,297 [Thread-391] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:51,302 [Thread-391] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:51,304 [IPC Server handler 4 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741858_1035, replicas=127.0.0.1:43315, 127.0.0.1:34028, 127.0.0.1:46154 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2
2020-04-02 05:08:51,305 [Thread-391] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK]], blk_1073741858_1035
2020-04-02 05:08:51,306 [Thread-391] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:43315
2020-04-02 05:08:51,306 [Thread-391] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:51,307 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54712 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035 src: /127.0.0.1:54712 dest: /127.0.0.1:43315
2020-04-02 05:08:51,315 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:37898 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035 src: /127.0.0.1:37898 dest: /127.0.0.1:34028
2020-04-02 05:08:51,316 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56432 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035 src: /127.0.0.1:56432 dest: /127.0.0.1:46154
2020-04-02 05:08:51,331 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2, DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b]
2020-04-02 05:08:51,332 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741858_1035 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:51,333 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741858_1035
2020-04-02 05:08:51,340 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 4346458 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,340 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741858_1035 sending packet seqno: 1 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:51,342 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56432, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035, duration(ns): 22848018
2020-04-02 05:08:51,343 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:51,347 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37898, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035, duration(ns): 26437116
2020-04-02 05:08:51,347 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154] terminating
2020-04-02 05:08:51,348 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54712, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035, duration(ns): 20928542
2020-04-02 05:08:51,349 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154] terminating
2020-04-02 05:08:51,349 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 6778927 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,351 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035
2020-04-02 05:08:51,351 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741858_1035
2020-04-02 05:08:51,351 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741858_1035
2020-04-02 05:08:51,353 [IPC Server handler 5 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741859_1036, replicas=127.0.0.1:34028, 127.0.0.1:46154, 127.0.0.1:43315 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2
2020-04-02 05:08:51,354 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK]], blk_1073741859_1036
2020-04-02 05:08:51,354 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:34028
2020-04-02 05:08:51,355 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:51,357 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:37930 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036 src: /127.0.0.1:37930 dest: /127.0.0.1:34028
2020-04-02 05:08:51,364 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56466 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036 src: /127.0.0.1:56466 dest: /127.0.0.1:46154
2020-04-02 05:08:51,366 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54760 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036 src: /127.0.0.1:54760 dest: /127.0.0.1:43315
2020-04-02 05:08:51,370 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2, DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b, DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7]
2020-04-02 05:08:51,371 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741859_1036 sending packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:51,371 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741859_1036
2020-04-02 05:08:51,378 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 6360563 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,379 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741859_1036 sending packet seqno: 3 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:51,382 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54760, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036, duration(ns): 14417546
2020-04-02 05:08:51,382 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:51,384 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56466, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036, duration(ns): 13486728
2020-04-02 05:08:51,384 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315] terminating
2020-04-02 05:08:51,385 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37930, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036, duration(ns): 13774439
2020-04-02 05:08:51,391 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:43315] terminating
2020-04-02 05:08:51,392 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 3 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 5107911 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,393 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036
2020-04-02 05:08:51,394 [IPC Server handler 7 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:51,397 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,402 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,408 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,409 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=append	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,411 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,412 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,412 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,412 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,412 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,412 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 3 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,412 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 4 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,412 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 4 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,412 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 5 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,412 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 6 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,412 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 6 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,413 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 7 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,413 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 7
2020-04-02 05:08:51,417 [Thread-406] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:51,417 [Thread-406] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:51,435 [IPC Server handler 8 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741860_1037, replicas=127.0.0.1:43315, 127.0.0.1:34028, 127.0.0.1:46154 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2
2020-04-02 05:08:51,438 [Thread-406] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK]], blk_1073741860_1037
2020-04-02 05:08:51,438 [Thread-406] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:43315
2020-04-02 05:08:51,438 [Thread-406] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:51,439 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54798 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037 src: /127.0.0.1:54798 dest: /127.0.0.1:43315
2020-04-02 05:08:51,441 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:37982 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037 src: /127.0.0.1:37982 dest: /127.0.0.1:34028
2020-04-02 05:08:51,445 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56516 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037 src: /127.0.0.1:56516 dest: /127.0.0.1:46154
2020-04-02 05:08:51,452 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2, DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b]
2020-04-02 05:08:51,452 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741860_1037 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:51,453 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741860_1037
2020-04-02 05:08:51,456 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1316578 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,462 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741860_1037 sending packet seqno: 1 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:51,463 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56516, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037, duration(ns): 16356335
2020-04-02 05:08:51,464 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:51,464 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37982, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037, duration(ns): 16796819
2020-04-02 05:08:51,464 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154] terminating
2020-04-02 05:08:51,465 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54798, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037, duration(ns): 16157099
2020-04-02 05:08:51,466 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154] terminating
2020-04-02 05:08:51,466 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2286862 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,469 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037
2020-04-02 05:08:51,470 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741860_1037
2020-04-02 05:08:51,470 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741860_1037
2020-04-02 05:08:51,474 [IPC Server handler 5 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741861_1038, replicas=127.0.0.1:43315, 127.0.0.1:46154, 127.0.0.1:34028 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2
2020-04-02 05:08:51,476 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK]], blk_1073741861_1038
2020-04-02 05:08:51,476 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:43315
2020-04-02 05:08:51,477 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:51,478 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54826 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038 src: /127.0.0.1:54826 dest: /127.0.0.1:43315
2020-04-02 05:08:51,481 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56542 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038 src: /127.0.0.1:56542 dest: /127.0.0.1:46154
2020-04-02 05:08:51,482 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:38016 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038 src: /127.0.0.1:38016 dest: /127.0.0.1:34028
2020-04-02 05:08:51,485 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7, DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2]
2020-04-02 05:08:51,494 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741861_1038 sending packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:51,495 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741861_1038
2020-04-02 05:08:51,501 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 5662721 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,501 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741861_1038 sending packet seqno: 3 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:51,503 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38016, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038, duration(ns): 18654848
2020-04-02 05:08:51,503 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:51,510 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56542, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038, duration(ns): 23922729
2020-04-02 05:08:51,510 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028] terminating
2020-04-02 05:08:51,511 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54826, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038, duration(ns): 17121007
2020-04-02 05:08:51,511 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:34028] terminating
2020-04-02 05:08:51,512 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 3 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 8622447 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,512 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 block BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038
2020-04-02 05:08:51,512 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741861_1038
2020-04-02 05:08:51,512 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741861_1038
2020-04-02 05:08:51,515 [IPC Server handler 2 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 2 on 34438, call Call#464 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 127.0.0.1:53136: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1 is exceeded: quota = 15360 B = 15 KB but diskspace consumed = 16896 B = 16.50 KB
2020-04-02 05:08:51,519 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2] DEBUG hdfs.DataStreamer (DataStreamer.java:run(824)) - DataStreamer Quota Exception
org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1 is exceeded: quota = 15360 B = 15 KB but diskspace consumed = 16896 B = 16.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1866)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.DSQuotaExceededException): The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1 is exceeded: quota = 15360 B = 15 KB but diskspace consumed = 16896 B = 16.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy25.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:510)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy29.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	... 3 more
2020-04-02 05:08:51,524 [Thread-331] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, blk_1073741861_1038
java.lang.Throwable: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1 is exceeded: quota = 15360 B = 15 KB but diskspace consumed = 16896 B = 16.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.ExceptionLastSeen.throwException4Close(ExceptionLastSeen.java:72)
	at org.apache.hadoop.hdfs.DataStreamer.checkClosed(DataStreamer.java:978)
	at org.apache.hadoop.hdfs.DataStreamer.waitForAckedSeqno(DataStreamer.java:894)
	at org.apache.hadoop.hdfs.DFSOutputStream.flushInternal(DFSOutputStream.java:776)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:886)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.TestQuota.testSpaceCommands(TestQuota.java:817)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1 is exceeded: quota = 15360 B = 15 KB but diskspace consumed = 16896 B = 16.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1866)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.DSQuotaExceededException): The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1 is exceeded: quota = 15360 B = 15 KB but diskspace consumed = 16896 B = 16.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy25.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:510)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy29.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	... 3 more
2020-04-02 05:08:51,530 [IPC Server handler 6 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:51,531 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:closeImpl(858)) - Closing an already closed stream. [Stream:true, streamer:true]
2020-04-02 05:08:51,531 [Thread-331] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, blk_1073741861_1038
java.lang.Throwable: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1 is exceeded: quota = 15360 B = 15 KB but diskspace consumed = 16896 B = 16.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:861)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.io.IOUtils.cleanupWithLogger(IOUtils.java:280)
	at org.apache.hadoop.io.IOUtils.closeStream(IOUtils.java:298)
	at org.apache.hadoop.hdfs.TestQuota.testSpaceCommands(TestQuota.java:820)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1 is exceeded: quota = 15360 B = 15 KB but diskspace consumed = 16896 B = 16.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1866)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.DSQuotaExceededException): The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1 is exceeded: quota = 15360 B = 15 KB but diskspace consumed = 16896 B = 16.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy25.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:510)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy29.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	... 3 more
2020-04-02 05:08:51,534 [IPC Server handler 8 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:completeFileInternal(711)) - DIR* completeFile: request from DFSClient_NONMAPREDUCE_1826976575_1 to complete inode 16464(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2) which is already closed. But, it appears to be an RPC retry. Returning success
2020-04-02 05:08:51,534 [IPC Server handler 8 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:51,537 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,540 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,547 [IPC Server handler 3 on 34438] INFO  namenode.FSDirectory (FSDirAttrOp.java:unprotectedSetReplication(405)) - Decreasing replication from 3 to 2 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2
2020-04-02 05:08:51,547 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setReplication	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,563 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,567 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741840_1016 replica FinalizedReplica, blk_1073741840_1016, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741840 for deletion
2020-04-02 05:08:51,567 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,567 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741841_1017 replica FinalizedReplica, blk_1073741841_1017, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741841 for deletion
2020-04-02 05:08:51,568 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741840_1016 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741840
2020-04-02 05:08:51,568 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741842_1018 replica FinalizedReplica, blk_1073741842_1018, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741842 for deletion
2020-04-02 05:08:51,568 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741841_1017 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741841
2020-04-02 05:08:51,568 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741843_1019 replica FinalizedReplica, blk_1073741843_1019, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741843 for deletion
2020-04-02 05:08:51,568 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741844_1020 replica FinalizedReplica, blk_1073741844_1020, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741844 for deletion
2020-04-02 05:08:51,568 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741843_1019 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741843
2020-04-02 05:08:51,568 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741842_1018 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741842
2020-04-02 05:08:51,569 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741835_1011 replica FinalizedReplica, blk_1073741835_1011, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741835 for deletion
2020-04-02 05:08:51,569 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741844_1020 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741844
2020-04-02 05:08:51,569 [IPC Server handler 6 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 6 on 34438, call Call#475 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setReplication from 127.0.0.1:53136: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20 is exceeded: quota = 18432 B = 18 KB but diskspace consumed = 19456 B = 19 KB
2020-04-02 05:08:51,569 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741835_1011 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741835
2020-04-02 05:08:51,569 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741851_1028 replica FinalizedReplica, blk_1073741851_1028, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741851 for deletion
2020-04-02 05:08:51,570 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741836_1012 replica FinalizedReplica, blk_1073741836_1012, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741836 for deletion
2020-04-02 05:08:51,570 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741852_1029 replica FinalizedReplica, blk_1073741852_1029, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741852 for deletion
2020-04-02 05:08:51,570 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741836_1012 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741836
2020-04-02 05:08:51,570 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741837_1013 replica FinalizedReplica, blk_1073741837_1013, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741837 for deletion
2020-04-02 05:08:51,570 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741838_1014 replica FinalizedReplica, blk_1073741838_1014, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741838 for deletion
2020-04-02 05:08:51,570 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741839_1015 replica FinalizedReplica, blk_1073741839_1015, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741839 for deletion
2020-04-02 05:08:51,570 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741851_1028 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741851
2020-04-02 05:08:51,570 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741852_1029 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741852
2020-04-02 05:08:51,571 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741837_1013 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741837
2020-04-02 05:08:51,571 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741838_1014 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741838
2020-04-02 05:08:51,571 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741839_1015 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741839
2020-04-02 05:08:51,586 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,591 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,594 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,600 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,602 [IPC Server handler 1 on 34438] INFO  namenode.FSDirectory (FSDirAttrOp.java:unprotectedSetReplication(408)) - Increasing replication from 2 to 4 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2
2020-04-02 05:08:51,602 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setReplication	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30/fileDir/file2	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,606 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,608 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/nqdir0/qdir1/qdir20/nqdir30	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,614 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:51,617 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:51,621 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:51,623 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:51,624 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,625 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,627 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,630 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:51,632 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A/fileA	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:51,644 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A/fileA, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,645 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,645 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,646 [Thread-422] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:51,646 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A/fileA, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,646 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,646 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 3 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,646 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 3
2020-04-02 05:08:51,646 [Thread-422] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:51,655 [IPC Server handler 5 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741863_1040, replicas=127.0.0.1:46154, 127.0.0.1:43315, 127.0.0.1:34028 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A/fileA
2020-04-02 05:08:51,657 [Thread-422] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK]], blk_1073741863_1040
2020-04-02 05:08:51,657 [Thread-422] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:46154
2020-04-02 05:08:51,657 [Thread-422] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:51,658 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56666 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040 src: /127.0.0.1:56666 dest: /127.0.0.1:46154
2020-04-02 05:08:51,660 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54954 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040 src: /127.0.0.1:54954 dest: /127.0.0.1:43315
2020-04-02 05:08:51,661 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:38138 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040 src: /127.0.0.1:38138 dest: /127.0.0.1:34028
2020-04-02 05:08:51,664 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A/fileA block BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b, DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2]
2020-04-02 05:08:51,664 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A/fileA block BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741863_1040 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:51,665 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A/fileA block BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741863_1040
2020-04-02 05:08:51,666 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 874025 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,668 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A/fileA block BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741863_1040 sending packet seqno: 1 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:51,676 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38138, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040, duration(ns): 12381725
2020-04-02 05:08:51,676 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:51,677 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54954, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040, duration(ns): 14240027
2020-04-02 05:08:51,678 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028] terminating
2020-04-02 05:08:51,678 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56666, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040, duration(ns): 15714619
2020-04-02 05:08:51,679 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:34028] terminating
2020-04-02 05:08:51,679 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 9939713 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,682 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A/fileA block BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741863_1040
2020-04-02 05:08:51,682 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A/fileA] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741863_1040
2020-04-02 05:08:51,682 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A/fileA] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741863_1040
2020-04-02 05:08:51,685 [IPC Server handler 8 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741864_1041, replicas=127.0.0.1:43315, 127.0.0.1:46154, 127.0.0.1:34028 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A/fileA
2020-04-02 05:08:51,687 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A/fileA] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK]], blk_1073741864_1041
2020-04-02 05:08:51,687 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A/fileA] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:43315
2020-04-02 05:08:51,687 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A/fileA] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:51,691 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:54972 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041 src: /127.0.0.1:54972 dest: /127.0.0.1:43315
2020-04-02 05:08:51,693 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56690 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041 src: /127.0.0.1:56690 dest: /127.0.0.1:46154
2020-04-02 05:08:51,695 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:38162 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041 src: /127.0.0.1:38162 dest: /127.0.0.1:34028
2020-04-02 05:08:51,699 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A/fileA block BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7, DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2]
2020-04-02 05:08:51,699 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A/fileA block BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741864_1041 sending packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:51,700 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A/fileA block BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741864_1041
2020-04-02 05:08:51,710 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 7036846 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,712 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A/fileA block BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741864_1041 sending packet seqno: 3 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:51,713 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38162, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041, duration(ns): 15771418
2020-04-02 05:08:51,713 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:51,714 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56690, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041, duration(ns): 16959664
2020-04-02 05:08:51,715 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028] terminating
2020-04-02 05:08:51,715 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54972, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041, duration(ns): 16074622
2020-04-02 05:08:51,716 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:34028] terminating
2020-04-02 05:08:51,722 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 3 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2698278 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,725 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A/fileA block BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741864_1041
2020-04-02 05:08:51,728 [IPC Server handler 1 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A/fileA is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:51,742 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,750 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/A	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,751 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:51,754 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:51,770 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,770 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,771 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,771 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,771 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,771 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 3 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,771 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 4 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,771 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 4 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,771 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 5 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,771 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 6 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,771 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 6 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,772 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 7 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,772 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 7
2020-04-02 05:08:51,777 [Thread-437] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:51,778 [Thread-437] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:51,779 [IPC Server handler 6 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741865_1042, replicas=127.0.0.1:34028, 127.0.0.1:43315, 127.0.0.1:46154 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB
2020-04-02 05:08:51,786 [Thread-437] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK]], blk_1073741865_1042
2020-04-02 05:08:51,786 [Thread-437] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:34028
2020-04-02 05:08:51,787 [Thread-437] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:51,788 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:38198 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042 src: /127.0.0.1:38198 dest: /127.0.0.1:34028
2020-04-02 05:08:51,791 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55018 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042 src: /127.0.0.1:55018 dest: /127.0.0.1:43315
2020-04-02 05:08:51,793 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56740 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042 src: /127.0.0.1:56740 dest: /127.0.0.1:46154
2020-04-02 05:08:51,805 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB block BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2, DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7, DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b]
2020-04-02 05:08:51,806 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB block BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741865_1042 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:51,807 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB block BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741865_1042
2020-04-02 05:08:51,813 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 5563033 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,814 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB block BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741865_1042 sending packet seqno: 1 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:51,815 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56740, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042, duration(ns): 20494325
2020-04-02 05:08:51,815 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:51,818 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55018, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042, duration(ns): 19605490
2020-04-02 05:08:51,818 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154] terminating
2020-04-02 05:08:51,819 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38198, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042, duration(ns): 20351643
2020-04-02 05:08:51,819 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:46154] terminating
2020-04-02 05:08:51,819 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 4126700 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,820 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB block BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741865_1042
2020-04-02 05:08:51,820 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741865_1042
2020-04-02 05:08:51,820 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741865_1042
2020-04-02 05:08:51,822 [IPC Server handler 3 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741866_1043, replicas=127.0.0.1:34028, 127.0.0.1:43315, 127.0.0.1:46154 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB
2020-04-02 05:08:51,823 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK]], blk_1073741866_1043
2020-04-02 05:08:51,823 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:34028
2020-04-02 05:08:51,823 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:51,824 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:38234 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043 src: /127.0.0.1:38234 dest: /127.0.0.1:34028
2020-04-02 05:08:51,830 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55056 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043 src: /127.0.0.1:55056 dest: /127.0.0.1:43315
2020-04-02 05:08:51,832 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56772 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043 src: /127.0.0.1:56772 dest: /127.0.0.1:46154
2020-04-02 05:08:51,838 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB block BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2, DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7, DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b]
2020-04-02 05:08:51,842 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB block BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741866_1043 sending packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:51,842 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB block BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741866_1043
2020-04-02 05:08:51,844 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1660249 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,845 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB block BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741866_1043 sending packet seqno: 3 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:51,851 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56772, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043, duration(ns): 17584401
2020-04-02 05:08:51,851 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:51,852 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55056, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043, duration(ns): 18461692
2020-04-02 05:08:51,852 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154] terminating
2020-04-02 05:08:51,853 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38234, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043, duration(ns): 18217625
2020-04-02 05:08:51,856 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:46154] terminating
2020-04-02 05:08:51,856 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 3 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 4483490 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,857 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB block BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741866_1043
2020-04-02 05:08:51,858 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741866_1043
2020-04-02 05:08:51,858 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741866_1043
2020-04-02 05:08:51,860 [IPC Server handler 4 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741867_1044, replicas=127.0.0.1:46154, 127.0.0.1:43315, 127.0.0.1:34028 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB
2020-04-02 05:08:51,862 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK]], blk_1073741867_1044
2020-04-02 05:08:51,862 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:46154
2020-04-02 05:08:51,862 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:51,865 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56792 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044 src: /127.0.0.1:56792 dest: /127.0.0.1:46154
2020-04-02 05:08:51,878 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55080 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044 src: /127.0.0.1:55080 dest: /127.0.0.1:43315
2020-04-02 05:08:51,880 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:38268 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044 src: /127.0.0.1:38268 dest: /127.0.0.1:34028
2020-04-02 05:08:51,881 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB block BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b, DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2]
2020-04-02 05:08:51,887 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB block BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741867_1044 sending packet seqno: 4 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:51,918 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB block BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741867_1044
2020-04-02 05:08:51,920 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 4 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2043957 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,921 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB block BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741867_1044 sending packet seqno: 5 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:51,922 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38268, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044, duration(ns): 28092043
2020-04-02 05:08:51,922 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:51,923 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55080, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044, duration(ns): 41571630
2020-04-02 05:08:51,923 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028] terminating
2020-04-02 05:08:51,924 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56792, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044, duration(ns): 5814347
2020-04-02 05:08:51,924 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:34028] terminating
2020-04-02 05:08:51,926 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 5 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2448575 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,929 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB block BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741867_1044
2020-04-02 05:08:51,930 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741867_1044
2020-04-02 05:08:51,930 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741867_1044
2020-04-02 05:08:51,932 [IPC Server handler 0 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741868_1045, replicas=127.0.0.1:46154, 127.0.0.1:43315, 127.0.0.1:34028 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB
2020-04-02 05:08:51,935 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK]], blk_1073741868_1045
2020-04-02 05:08:51,935 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:46154
2020-04-02 05:08:51,936 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:51,937 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56846 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045 src: /127.0.0.1:56846 dest: /127.0.0.1:46154
2020-04-02 05:08:51,942 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55136 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045 src: /127.0.0.1:55136 dest: /127.0.0.1:43315
2020-04-02 05:08:51,944 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:38326 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045 src: /127.0.0.1:38326 dest: /127.0.0.1:34028
2020-04-02 05:08:51,946 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB block BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b, DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2]
2020-04-02 05:08:51,947 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB block BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741868_1045 sending packet seqno: 6 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:51,947 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB block BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741868_1045
2020-04-02 05:08:51,954 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 6 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 5729599 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,954 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB block BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741868_1045 sending packet seqno: 7 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:51,956 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38326, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045, duration(ns): 11100688
2020-04-02 05:08:51,957 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:51,957 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55136, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045, duration(ns): 11999295
2020-04-02 05:08:51,958 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028] terminating
2020-04-02 05:08:51,959 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56846, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045, duration(ns): 12998315
2020-04-02 05:08:51,959 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:34028] terminating
2020-04-02 05:08:51,959 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 7 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2737699 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:51,960 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB block BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741868_1045
2020-04-02 05:08:51,965 [IPC Server handler 3 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B/fileB is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:51,971 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,975 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/B	dst=null	perm=null	proto=rpc
2020-04-02 05:08:51,976 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:51,981 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:51,987 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,987 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,987 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,987 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,987 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,988 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 3 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,988 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 4 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,988 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 4 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,988 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 5 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,988 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 6 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,988 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 6 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,988 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 7 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,988 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 8 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,988 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 8 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,988 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 9 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,989 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 10 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,989 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 10 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,989 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 11 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,989 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 12 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,989 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 12 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,989 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 13 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,989 [Thread-331] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 14 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:08:51,989 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 14 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,989 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 15 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:08:51,989 [Thread-331] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 15
2020-04-02 05:08:51,991 [Thread-466] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:51,992 [Thread-466] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:51,994 [IPC Server handler 8 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741869_1046, replicas=127.0.0.1:43315, 127.0.0.1:34028, 127.0.0.1:46154 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC
2020-04-02 05:08:51,995 [Thread-466] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK]], blk_1073741869_1046
2020-04-02 05:08:51,995 [Thread-466] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:43315
2020-04-02 05:08:51,995 [Thread-466] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:51,997 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55170 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046 src: /127.0.0.1:55170 dest: /127.0.0.1:43315
2020-04-02 05:08:52,003 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:38354 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046 src: /127.0.0.1:38354 dest: /127.0.0.1:34028
2020-04-02 05:08:52,004 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56896 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046 src: /127.0.0.1:56896 dest: /127.0.0.1:46154
2020-04-02 05:08:52,006 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2, DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b]
2020-04-02 05:08:52,006 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741869_1046 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:52,010 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741869_1046
2020-04-02 05:08:52,015 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2821347 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:52,017 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741869_1046 sending packet seqno: 1 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:52,022 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56896, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046, duration(ns): 16404804
2020-04-02 05:08:52,023 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:52,024 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38354, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046, duration(ns): 18613848
2020-04-02 05:08:52,025 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154] terminating
2020-04-02 05:08:52,025 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55170, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046, duration(ns): 18945356
2020-04-02 05:08:52,026 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154] terminating
2020-04-02 05:08:52,026 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 7465696 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:52,029 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741869_1046
2020-04-02 05:08:52,031 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741869_1046
2020-04-02 05:08:52,031 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741869_1046
2020-04-02 05:08:52,035 [IPC Server handler 1 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741870_1047, replicas=127.0.0.1:46154, 127.0.0.1:34028, 127.0.0.1:43315 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC
2020-04-02 05:08:52,036 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK]], blk_1073741870_1047
2020-04-02 05:08:52,036 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:46154
2020-04-02 05:08:52,036 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:52,037 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56914 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047 src: /127.0.0.1:56914 dest: /127.0.0.1:46154
2020-04-02 05:08:52,043 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:38386 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047 src: /127.0.0.1:38386 dest: /127.0.0.1:34028
2020-04-02 05:08:52,049 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55210 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047 src: /127.0.0.1:55210 dest: /127.0.0.1:43315
2020-04-02 05:08:52,052 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2, DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7]
2020-04-02 05:08:52,054 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741870_1047 sending packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:52,054 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741870_1047
2020-04-02 05:08:52,057 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1730276 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:52,058 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741870_1047 sending packet seqno: 3 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:52,059 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55210, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047, duration(ns): 8214002
2020-04-02 05:08:52,060 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:52,061 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38386, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047, duration(ns): 9895975
2020-04-02 05:08:52,062 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315] terminating
2020-04-02 05:08:52,062 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56914, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047, duration(ns): 11137260
2020-04-02 05:08:52,063 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315] terminating
2020-04-02 05:08:52,065 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 3 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 3585007 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:52,065 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741870_1047
2020-04-02 05:08:52,066 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741870_1047
2020-04-02 05:08:52,066 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741870_1047
2020-04-02 05:08:52,067 [IPC Server handler 2 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741871_1048, replicas=127.0.0.1:34028, 127.0.0.1:46154, 127.0.0.1:43315 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC
2020-04-02 05:08:52,070 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK]], blk_1073741871_1048
2020-04-02 05:08:52,070 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:34028
2020-04-02 05:08:52,071 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:52,072 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:38418 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048 src: /127.0.0.1:38418 dest: /127.0.0.1:34028
2020-04-02 05:08:52,074 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56954 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048 src: /127.0.0.1:56954 dest: /127.0.0.1:46154
2020-04-02 05:08:52,076 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55244 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048 src: /127.0.0.1:55244 dest: /127.0.0.1:43315
2020-04-02 05:08:52,077 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2, DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b, DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7]
2020-04-02 05:08:52,078 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741871_1048 sending packet seqno: 4 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:52,078 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741871_1048
2020-04-02 05:08:52,087 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 4 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 8432785 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:52,087 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741871_1048 sending packet seqno: 5 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:52,088 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55244, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048, duration(ns): 10446123
2020-04-02 05:08:52,089 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:52,089 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56954, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048, duration(ns): 11758799
2020-04-02 05:08:52,090 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315] terminating
2020-04-02 05:08:52,090 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38418, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048, duration(ns): 12322025
2020-04-02 05:08:52,091 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:43315] terminating
2020-04-02 05:08:52,091 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 5 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2846264 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:52,091 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741871_1048
2020-04-02 05:08:52,091 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741871_1048
2020-04-02 05:08:52,091 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741871_1048
2020-04-02 05:08:52,093 [IPC Server handler 9 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741872_1049, replicas=127.0.0.1:46154, 127.0.0.1:34028, 127.0.0.1:43315 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC
2020-04-02 05:08:52,097 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK]], blk_1073741872_1049
2020-04-02 05:08:52,097 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:46154
2020-04-02 05:08:52,098 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:52,121 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:56976 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049 src: /127.0.0.1:56976 dest: /127.0.0.1:46154
2020-04-02 05:08:52,123 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:38464 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049 src: /127.0.0.1:38464 dest: /127.0.0.1:34028
2020-04-02 05:08:52,133 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55284 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049 src: /127.0.0.1:55284 dest: /127.0.0.1:43315
2020-04-02 05:08:52,139 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2, DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7]
2020-04-02 05:08:52,148 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741872_1049 sending packet seqno: 6 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:52,148 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741872_1049
2020-04-02 05:08:52,152 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 6 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 3638593 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:52,152 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741872_1049 sending packet seqno: 7 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:52,170 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55284, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049, duration(ns): 35446602
2020-04-02 05:08:52,172 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:52,178 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38464, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049, duration(ns): 29678902
2020-04-02 05:08:52,178 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315] terminating
2020-04-02 05:08:52,179 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56976, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049, duration(ns): 39819421
2020-04-02 05:08:52,179 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315] terminating
2020-04-02 05:08:52,182 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 7 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 25772477 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:52,182 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741872_1049
2020-04-02 05:08:52,182 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741872_1049
2020-04-02 05:08:52,182 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741872_1049
2020-04-02 05:08:52,191 [IPC Server handler 5 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741873_1050, replicas=127.0.0.1:46154, 127.0.0.1:34028, 127.0.0.1:43315 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC
2020-04-02 05:08:52,192 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK]], blk_1073741873_1050
2020-04-02 05:08:52,192 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:46154
2020-04-02 05:08:52,192 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:52,195 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:57028 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050 src: /127.0.0.1:57028 dest: /127.0.0.1:46154
2020-04-02 05:08:52,202 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:38498 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050 src: /127.0.0.1:38498 dest: /127.0.0.1:34028
2020-04-02 05:08:52,209 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55320 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050 src: /127.0.0.1:55320 dest: /127.0.0.1:43315
2020-04-02 05:08:52,212 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2, DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7]
2020-04-02 05:08:52,217 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741873_1050 sending packet seqno: 8 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:52,217 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741873_1050
2020-04-02 05:08:52,234 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 8 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 16280176 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:52,235 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741873_1050 sending packet seqno: 9 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:52,239 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55320, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050, duration(ns): 28276778
2020-04-02 05:08:52,239 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:52,241 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38498, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050, duration(ns): 22767508
2020-04-02 05:08:52,242 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315] terminating
2020-04-02 05:08:52,244 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57028, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050, duration(ns): 8219235
2020-04-02 05:08:52,245 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:43315] terminating
2020-04-02 05:08:52,246 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 9 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 6781403 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:52,259 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741873_1050
2020-04-02 05:08:52,259 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741873_1050
2020-04-02 05:08:52,259 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741873_1050
2020-04-02 05:08:52,281 [IPC Server handler 8 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741874_1051, replicas=127.0.0.1:43315, 127.0.0.1:34028, 127.0.0.1:46154 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC
2020-04-02 05:08:52,282 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK]], blk_1073741874_1051
2020-04-02 05:08:52,282 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:43315
2020-04-02 05:08:52,282 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:52,283 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55378 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051 src: /127.0.0.1:55378 dest: /127.0.0.1:43315
2020-04-02 05:08:52,285 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:38564 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051 src: /127.0.0.1:38564 dest: /127.0.0.1:34028
2020-04-02 05:08:52,288 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:57098 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051 src: /127.0.0.1:57098 dest: /127.0.0.1:46154
2020-04-02 05:08:52,299 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2, DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b]
2020-04-02 05:08:52,299 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741874_1051 sending packet seqno: 10 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:52,299 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741874_1051
2020-04-02 05:08:52,315 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 10 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 14706447 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:52,315 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741874_1051 sending packet seqno: 11 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:52,317 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57098, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051, duration(ns): 26946700
2020-04-02 05:08:52,317 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:52,318 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38564, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051, duration(ns): 27734275
2020-04-02 05:08:52,318 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154] terminating
2020-04-02 05:08:52,318 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55378, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051, duration(ns): 19601292
2020-04-02 05:08:52,318 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154] terminating
2020-04-02 05:08:52,319 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 11 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2464443 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:52,330 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741874_1051
2020-04-02 05:08:52,330 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741874_1051
2020-04-02 05:08:52,330 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741874_1051
2020-04-02 05:08:52,333 [IPC Server handler 7 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741875_1052, replicas=127.0.0.1:34028, 127.0.0.1:46154, 127.0.0.1:43315 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC
2020-04-02 05:08:52,335 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK]], blk_1073741875_1052
2020-04-02 05:08:52,336 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:34028
2020-04-02 05:08:52,336 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:52,338 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:38606 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052 src: /127.0.0.1:38606 dest: /127.0.0.1:34028
2020-04-02 05:08:52,349 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:57140 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052 src: /127.0.0.1:57140 dest: /127.0.0.1:46154
2020-04-02 05:08:52,357 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55430 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052 src: /127.0.0.1:55430 dest: /127.0.0.1:43315
2020-04-02 05:08:52,360 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2, DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b, DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7]
2020-04-02 05:08:52,384 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741875_1052 sending packet seqno: 12 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:52,385 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741875_1052
2020-04-02 05:08:52,390 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 12 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 3204922 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:52,390 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741875_1052 sending packet seqno: 13 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:52,396 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55430, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052, duration(ns): 36160166
2020-04-02 05:08:52,396 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:52,398 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57140, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052, duration(ns): 31278356
2020-04-02 05:08:52,398 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43315] terminating
2020-04-02 05:08:52,400 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:43315]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38606, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052, duration(ns): 13841941
2020-04-02 05:08:52,406 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 13 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 5451945 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:52,407 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052
2020-04-02 05:08:52,407 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:43315]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741875_1052, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46154, 127.0.0.1:43315] terminating
2020-04-02 05:08:52,407 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741875_1052
2020-04-02 05:08:52,407 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741875_1052
2020-04-02 05:08:52,409 [IPC Server handler 2 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741876_1053, replicas=127.0.0.1:46154, 127.0.0.1:43315, 127.0.0.1:34028 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC
2020-04-02 05:08:52,411 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK]], blk_1073741876_1053
2020-04-02 05:08:52,411 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:46154
2020-04-02 05:08:52,411 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:52,422 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:57170 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053 src: /127.0.0.1:57170 dest: /127.0.0.1:46154
2020-04-02 05:08:52,430 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55458 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053 src: /127.0.0.1:55458 dest: /127.0.0.1:43315
2020-04-02 05:08:52,438 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:38646 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053 src: /127.0.0.1:38646 dest: /127.0.0.1:34028
2020-04-02 05:08:52,450 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b, DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2]
2020-04-02 05:08:52,450 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741876_1053 sending packet seqno: 14 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:08:52,450 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741876_1053
2020-04-02 05:08:52,458 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 14 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 6991166 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:52,458 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741876_1053 sending packet seqno: 15 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:08:52,467 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38646, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053, duration(ns): 26180481
2020-04-02 05:08:52,467 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:52,468 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55458, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053, duration(ns): 27683924
2020-04-02 05:08:52,468 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34028] terminating
2020-04-02 05:08:52,469 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:34028]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57170, dest: /127.0.0.1:46154, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053, duration(ns): 26924728
2020-04-02 05:08:52,469 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:34028]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43315, 127.0.0.1:34028] terminating
2020-04-02 05:08:52,469 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 15 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 9887146 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:52,469 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC block BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741876_1053
2020-04-02 05:08:52,470 [IPC Server handler 8 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C/fileC is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:52,473 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C	dst=null	perm=null	proto=rpc
2020-04-02 05:08:52,475 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053/C	dst=null	perm=null	proto=rpc
2020-04-02 05:08:52,486 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053	dst=null	perm=null	proto=rpc
2020-04-02 05:08:52,500 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/VtZ6FBnZhM/TestQuota/testSpaceCommands/hdfs-2053	dst=null	perm=null	proto=rpc
2020-04-02 05:08:52,514 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:52,519 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:52,522 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:52,525 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:52,526 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:52,528 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test/test1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:52,529 [Thread-523] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 256, block==null
2020-04-02 05:08:52,529 [Thread-523] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 256 lastPacketInBlock: true lastByteOffsetInBlock: 256, block==null
2020-04-02 05:08:52,529 [Thread-523] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:08:52,531 [Thread-524] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:52,531 [Thread-524] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:52,533 [IPC Server handler 3 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741877_1054, replicas=127.0.0.1:43315, 127.0.0.1:34028, 127.0.0.1:46154 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test/test1
2020-04-02 05:08:52,534 [Thread-524] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK]], blk_1073741877_1054
2020-04-02 05:08:52,534 [Thread-524] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:43315
2020-04-02 05:08:52,534 [Thread-524] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:52,535 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:55544 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054 src: /127.0.0.1:55544 dest: /127.0.0.1:43315
2020-04-02 05:08:52,537 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:38728 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054 src: /127.0.0.1:38728 dest: /127.0.0.1:34028
2020-04-02 05:08:52,540 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:57264 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054 src: /127.0.0.1:57264 dest: /127.0.0.1:46154
2020-04-02 05:08:52,554 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test/test1 block BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2, DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b]
2020-04-02 05:08:52,560 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test/test1 block BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741877_1054 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 256
2020-04-02 05:08:52,563 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test/test1 block BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741877_1054
2020-04-02 05:08:52,566 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 3026753 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:52,568 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test/test1 block BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741877_1054 sending packet seqno: 1 offsetInBlock: 256 lastPacketInBlock: true lastByteOffsetInBlock: 256
2020-04-02 05:08:52,577 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57264, dest: /127.0.0.1:46154, bytes: 256, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 1b04f1a7-d40a-4308-a02b-6bf636928be8, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054, duration(ns): 36383619
2020-04-02 05:08:52,578 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:52,579 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38728, dest: /127.0.0.1:34028, bytes: 256, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054, duration(ns): 37372297
2020-04-02 05:08:52,579 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46154] terminating
2020-04-02 05:08:52,580 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55544, dest: /127.0.0.1:43315, bytes: 256, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054, duration(ns): 25420553
2020-04-02 05:08:52,580 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34028, 127.0.0.1:46154] terminating
2020-04-02 05:08:52,580 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 9616446 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:52,580 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test/test1 block BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741877_1054
2020-04-02 05:08:52,582 [IPC Server handler 1 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test/test1 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:52,589 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test/test1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:52,594 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test/test1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:52,614 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:52,621 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:54,579 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741858_1035 replica FinalizedReplica, blk_1073741858_1035, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741858 for deletion
2020-04-02 05:08:54,585 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741827_1003 replica FinalizedReplica, blk_1073741827_1003, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741827 for deletion
2020-04-02 05:08:54,585 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741860_1037 replica FinalizedReplica, blk_1073741860_1037, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741860 for deletion
2020-04-02 05:08:54,590 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741827_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741827
2020-04-02 05:08:54,590 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741835_1011 replica FinalizedReplica, blk_1073741835_1011, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741835 for deletion
2020-04-02 05:08:54,590 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741858_1035 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741858
2020-04-02 05:08:54,602 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741860_1037 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741860
2020-04-02 05:08:54,605 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741835_1011 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741835
2020-04-02 05:08:54,606 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741836_1012 replica FinalizedReplica, blk_1073741836_1012, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741836 for deletion
2020-04-02 05:08:54,606 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741837_1013 replica FinalizedReplica, blk_1073741837_1013, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741837 for deletion
2020-04-02 05:08:54,614 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741837_1013 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741837
2020-04-02 05:08:54,626 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741838_1014 replica FinalizedReplica, blk_1073741838_1014, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741838 for deletion
2020-04-02 05:08:54,626 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741839_1015 replica FinalizedReplica, blk_1073741839_1015, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741839 for deletion
2020-04-02 05:08:54,627 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741840_1016 replica FinalizedReplica, blk_1073741840_1016, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741840 for deletion
2020-04-02 05:08:54,627 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741841_1017 replica FinalizedReplica, blk_1073741841_1017, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741841 for deletion
2020-04-02 05:08:54,627 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741842_1018 replica FinalizedReplica, blk_1073741842_1018, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741842 for deletion
2020-04-02 05:08:54,628 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741843_1019 replica FinalizedReplica, blk_1073741843_1019, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741843 for deletion
2020-04-02 05:08:54,628 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741844_1020 replica FinalizedReplica, blk_1073741844_1020, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741844 for deletion
2020-04-02 05:08:54,628 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741851_1028 replica FinalizedReplica, blk_1073741851_1028, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741851 for deletion
2020-04-02 05:08:54,628 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741852_1029 replica FinalizedReplica, blk_1073741852_1029, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741852 for deletion
2020-04-02 05:08:54,629 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741855_1032 replica FinalizedReplica, blk_1073741855_1032, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741855 for deletion
2020-04-02 05:08:54,630 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741836_1012 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741836
2020-04-02 05:08:54,630 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741838_1014 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741838
2020-04-02 05:08:54,631 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741840_1016 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741840
2020-04-02 05:08:54,631 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741842_1018 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741842
2020-04-02 05:08:54,631 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741844_1020 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741844
2020-04-02 05:08:54,631 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741839_1015 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741839
2020-04-02 05:08:54,632 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741852_1029 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741852
2020-04-02 05:08:54,632 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741841_1017 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741841
2020-04-02 05:08:54,632 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741855_1032 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741855
2020-04-02 05:08:54,632 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741843_1019 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741843
2020-04-02 05:08:54,633 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741851_1028 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741851
2020-04-02 05:08:54,663 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test	dst=null	perm=null	proto=webhdfs
2020-04-02 05:08:54,743 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:54,746 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test/test2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:54,747 [Thread-523] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 256, block==null
2020-04-02 05:08:54,747 [Thread-523] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 256 lastPacketInBlock: true lastByteOffsetInBlock: 256, block==null
2020-04-02 05:08:54,748 [Thread-523] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:08:54,748 [Thread-535] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:54,748 [Thread-535] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:54,750 [IPC Server handler 3 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 3 on 34438, call Call#584 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 127.0.0.1:53136: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test is exceeded: quota = 1536 B = 1.50 KB but diskspace consumed = 2304 B = 2.25 KB
2020-04-02 05:08:54,753 [Thread-535] DEBUG hdfs.DataStreamer (DataStreamer.java:run(824)) - DataStreamer Quota Exception
org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test is exceeded: quota = 1536 B = 1.50 KB but diskspace consumed = 2304 B = 2.25 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1866)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.DSQuotaExceededException): The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test is exceeded: quota = 1536 B = 1.50 KB but diskspace consumed = 2304 B = 2.25 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy25.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:510)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy29.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	... 3 more
2020-04-02 05:08:54,767 [Thread-523] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, block==null
java.lang.Throwable: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test is exceeded: quota = 1536 B = 1.50 KB but diskspace consumed = 2304 B = 2.25 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.ExceptionLastSeen.throwException4Close(ExceptionLastSeen.java:72)
	at org.apache.hadoop.hdfs.DataStreamer.checkClosed(DataStreamer.java:978)
	at org.apache.hadoop.hdfs.DataStreamer.waitForAckedSeqno(DataStreamer.java:894)
	at org.apache.hadoop.hdfs.DFSOutputStream.flushInternal(DFSOutputStream.java:776)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:886)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:460)
	at org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:418)
	at org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:411)
	at org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:404)
	at org.apache.hadoop.hdfs.TestQuota.testBlockAllocationAdjustsUsageConservatively(TestQuota.java:1071)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test is exceeded: quota = 1536 B = 1.50 KB but diskspace consumed = 2304 B = 2.25 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1866)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.DSQuotaExceededException): The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test is exceeded: quota = 1536 B = 1.50 KB but diskspace consumed = 2304 B = 2.25 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy25.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:510)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy29.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	... 3 more
2020-04-02 05:08:54,774 [IPC Server handler 7 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/qdRFBfrmcW/TestQuota/testBlockAllocationAdjustsUsageConservatively/test/test2 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:08:54,778 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:54,788 [Thread-536] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=3
2020-04-02 05:08:54,791 [Thread-536] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:08:54,792 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:08:54,792 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:08:54,792 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:08:54,792 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:08:54,792 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:08:54,792 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:08:54,793 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:08:54,793 [Thread-536] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:54,793 [Thread-536] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:08:54,793 [Thread-536] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:08:54,794 [Thread-536] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:08:54,794 [Thread-536] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:08:54
2020-04-02 05:08:54,794 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:08:54,794 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:54,795 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:08:54,795 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:08:54,832 [Thread-536] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:08:54,832 [Thread-536] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:08:54,832 [Thread-536] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:08:54,832 [Thread-536] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:08:54,833 [Thread-536] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:08:54,833 [Thread-536] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:08:54,833 [Thread-536] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:08:54,833 [Thread-536] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:08:54,833 [Thread-536] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:08:54,833 [Thread-536] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:08:54,833 [Thread-536] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:08:54,833 [Thread-536] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:08:54,845 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:08:54,845 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:54,845 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:08:54,845 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:08:54,847 [Thread-536] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:08:54,847 [Thread-536] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:08:54,847 [Thread-536] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:08:54,847 [Thread-536] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:08:54,847 [Thread-536] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:08:54,847 [Thread-536] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:08:54,847 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:08:54,848 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:54,848 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:08:54,848 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:08:54,849 [Thread-536] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:08:54,849 [Thread-536] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:08:54,849 [Thread-536] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:08:54,849 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:08:54,849 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:08:54,849 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:08:54,849 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:54,859 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:08:54,859 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:08:54,865 [Thread-536] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:54,874 [Thread-536] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:08:54,876 [Thread-536] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:08:54,885 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:08:54,885 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:08:54,892 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 428 bytes saved in 0 seconds .
2020-04-02 05:08:54,898 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 428 bytes saved in 0 seconds .
2020-04-02 05:08:54,907 [Thread-536] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:08:54,909 [Thread-536] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:08:54,909 [Thread-536] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:08:54,909 [Thread-536] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:08:54,910 [Thread-536] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:08:54,915 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@317489db] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:54,916 [Thread-536] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:08:54,916 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:54,918 [Thread-536] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:54,918 [Thread-536] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:08:54,919 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:54,920 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:54,921 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:08:54,921 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:54,921 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:54,923 [Thread-536] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:08:54,923 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:08:54,923 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41739
2020-04-02 05:08:54,924 [Thread-536] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:54,940 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7d73bb7{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:54,941 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6915af1d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:54,947 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@56a7b332{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:08:54,949 [Thread-536] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@460fca55{HTTP/1.1,[http/1.1]}{localhost:41739}
2020-04-02 05:08:54,949 [Thread-536] INFO  server.Server (Server.java:doStart(419)) - Started @17472ms
2020-04-02 05:08:54,952 [Thread-536] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:08:54,952 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:08:54,952 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:08:54,952 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:08:54,952 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:08:54,952 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:08:54,952 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:08:54,953 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:08:54,953 [Thread-536] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:54,954 [Thread-536] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:08:54,954 [Thread-536] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:08:54,954 [Thread-536] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:08:54,955 [Thread-536] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:08:54
2020-04-02 05:08:54,955 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:08:54,955 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:54,955 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:08:54,955 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:08:54,963 [Thread-536] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:08:54,963 [Thread-536] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:08:54,963 [Thread-536] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:08:54,963 [Thread-536] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:08:54,963 [Thread-536] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:08:54,963 [Thread-536] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:08:54,963 [Thread-536] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:08:54,963 [Thread-536] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:08:54,963 [Thread-536] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:08:54,963 [Thread-536] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:08:54,963 [Thread-536] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:08:54,964 [Thread-536] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:08:54,964 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:08:54,964 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:54,964 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:08:54,964 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:08:54,968 [Thread-536] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:08:54,968 [Thread-536] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:08:54,968 [Thread-536] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:08:54,968 [Thread-536] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:08:54,968 [Thread-536] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:08:54,968 [Thread-536] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:08:54,969 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:08:54,969 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:54,969 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:08:54,969 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:08:54,974 [Thread-536] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:08:54,974 [Thread-536] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:08:54,974 [Thread-536] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:08:54,974 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:08:54,975 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:08:54,975 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:08:54,975 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:54,975 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:08:54,975 [Thread-536] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:08:54,981 [Thread-536] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 11151@974f54091279
2020-04-02 05:08:54,982 [Thread-536] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 11151@974f54091279
2020-04-02 05:08:54,984 [Thread-536] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:08:54,984 [Thread-536] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:08:54,984 [Thread-536] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:08:54,984 [Thread-536] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:08:54,986 [Thread-536] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:08:54,988 [Thread-536] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:08:54,988 [Thread-536] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:08:54,988 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:08:54,989 [Thread-536] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:08:55,002 [Thread-536] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:08:55,003 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 26 msecs
2020-04-02 05:08:55,003 [Thread-536] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:08:55,003 [Thread-536] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:55,005 [Socket Reader #1 for port 38969] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38969
2020-04-02 05:08:55,023 [Thread-536] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:38969 to access this namenode/service.
2020-04-02 05:08:55,024 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:08:55,055 [Thread-536] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:08:55,056 [Thread-536] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:08:55,057 [Thread-536] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:08:55,057 [Thread-536] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:08:55,057 [Thread-536] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:08:55,066 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:08:55,066 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:08:55,066 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:08:55,066 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:08:55,066 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:08:55,066 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2020-04-02 05:08:55,066 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:55,068 [IPC Server listener on 38969] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38969: starting
2020-04-02 05:08:55,071 [Thread-536] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:38969
2020-04-02 05:08:55,072 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:08:55,072 [Thread-536] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:08:55,072 [Thread-536] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:08:55,082 [Thread-536] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 38969 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:55,083 [Thread-536] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:08:55,085 [Thread-536] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:08:55,085 [Thread-536] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:08:55,091 [Thread-536] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:55,091 [Thread-536] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:55,090 [CacheReplicationMonitor(1916793197)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:08:55,092 [Thread-536] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:55,094 [Thread-536] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:55,095 [Thread-536] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:55,095 [Thread-536] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:55,095 [Thread-536] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:55,096 [Thread-536] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42233
2020-04-02 05:08:55,096 [Thread-536] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:55,096 [Thread-536] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:55,097 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:55,099 [Thread-536] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:55,107 [Thread-536] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:55,107 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:55,108 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:55,109 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:55,109 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:55,109 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:55,113 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45702
2020-04-02 05:08:55,114 [Thread-536] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:55,115 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@34b1971b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:55,116 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7d17c74{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:55,125 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@45f77a0b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:55,125 [Thread-536] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6b5110b4{HTTP/1.1,[http/1.1]}{localhost:45702}
2020-04-02 05:08:55,125 [Thread-536] INFO  server.Server (Server.java:doStart(419)) - Started @17648ms
2020-04-02 05:08:55,214 [Thread-536] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40850
2020-04-02 05:08:55,215 [Thread-536] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:55,215 [Thread-536] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:55,215 [Thread-536] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:55,216 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4d8fa2e4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:55,216 [Socket Reader #1 for port 41016] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41016
2020-04-02 05:08:55,231 [Thread-536] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:41016
2020-04-02 05:08:55,250 [Thread-536] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:55,251 [Thread-536] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:55,251 [Thread-590] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38969 starting to offer service
2020-04-02 05:08:55,261 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:55,268 [IPC Server listener on 41016] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41016: starting
2020-04-02 05:08:55,271 [Thread-536] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 41016 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:55,272 [Thread-536] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:08:55,274 [Thread-536] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:08:55,274 [Thread-536] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:08:55,275 [Thread-536] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:55,276 [Thread-536] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:55,276 [Thread-536] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:55,276 [Thread-536] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:55,277 [Thread-536] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:55,277 [Thread-536] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:55,277 [Thread-536] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:55,278 [Thread-536] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40636
2020-04-02 05:08:55,278 [Thread-536] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:55,278 [Thread-536] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:55,279 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:55,292 [Thread-536] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:55,293 [Thread-536] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:55,293 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:55,295 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:55,297 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:55,297 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:55,297 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:55,298 [Thread-590] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38969
2020-04-02 05:08:55,299 [Thread-590] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:55,299 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44488
2020-04-02 05:08:55,299 [Thread-536] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:55,300 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@42efb3b8{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:55,301 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@35a405d5{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:55,301 [Thread-590] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 11151@974f54091279
2020-04-02 05:08:55,301 [Thread-590] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 705482036. Formatting...
2020-04-02 05:08:55,301 [Thread-590] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f1d9e669-fa01-461a-a669-696781dcb0c2 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:08:55,305 [Thread-590] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 11151@974f54091279
2020-04-02 05:08:55,305 [Thread-590] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 705482036. Formatting...
2020-04-02 05:08:55,305 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@237f3e25{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:55,305 [Thread-590] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b71b49a9-1814-47a0-997c-c432076ff5a6 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:08:55,307 [Thread-536] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@615243b4{HTTP/1.1,[http/1.1]}{localhost:44488}
2020-04-02 05:08:55,307 [Thread-536] INFO  server.Server (Server.java:doStart(419)) - Started @17830ms
2020-04-02 05:08:55,318 [Thread-590] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,319 [Thread-590] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,319 [Thread-590] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-131831597-172.17.0.7-1585804134865 is not formatted. Formatting ...
2020-04-02 05:08:55,319 [Thread-590] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-131831597-172.17.0.7-1585804134865 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-131831597-172.17.0.7-1585804134865/current
2020-04-02 05:08:55,326 [Thread-536] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41441
2020-04-02 05:08:55,326 [Thread-536] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:55,326 [Thread-536] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:55,327 [Thread-536] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:55,327 [Socket Reader #1 for port 42882] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42882
2020-04-02 05:08:55,328 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@e7771c4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:55,331 [Thread-536] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:42882
2020-04-02 05:08:55,333 [Thread-590] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,334 [Thread-590] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,334 [Thread-590] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-131831597-172.17.0.7-1585804134865 is not formatted. Formatting ...
2020-04-02 05:08:55,334 [Thread-590] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-131831597-172.17.0.7-1585804134865 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-131831597-172.17.0.7-1585804134865/current
2020-04-02 05:08:55,335 [Thread-536] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:55,335 [Thread-536] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:55,336 [Thread-614] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38969 starting to offer service
2020-04-02 05:08:55,336 [Thread-590] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=705482036;bpid=BP-131831597-172.17.0.7-1585804134865;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=705482036;c=1585804134865;bpid=BP-131831597-172.17.0.7-1585804134865;dnuuid=null
2020-04-02 05:08:55,345 [Thread-614] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38969
2020-04-02 05:08:55,346 [Thread-614] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:55,348 [Thread-614] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 11151@974f54091279
2020-04-02 05:08:55,348 [Thread-614] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 705482036. Formatting...
2020-04-02 05:08:55,348 [Thread-614] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2d5ecdcd-9b28-4ff6-b3be-901be89f4ef9 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:08:55,350 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:55,350 [IPC Server listener on 42882] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42882: starting
2020-04-02 05:08:55,350 [Thread-590] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 4b28df83-49bb-44c8-86db-acf4a44833c4
2020-04-02 05:08:55,354 [Thread-536] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 42882 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:55,354 [Thread-590] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-f1d9e669-fa01-461a-a669-696781dcb0c2
2020-04-02 05:08:55,354 [Thread-590] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:08:55,355 [Thread-536] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:08:55,355 [Thread-614] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 11151@974f54091279
2020-04-02 05:08:55,355 [Thread-614] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 705482036. Formatting...
2020-04-02 05:08:55,356 [Thread-614] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:08:55,356 [Thread-536] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:08:55,357 [Thread-590] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-b71b49a9-1814-47a0-997c-c432076ff5a6
2020-04-02 05:08:55,359 [Thread-590] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:08:55,359 [Thread-536] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:08:55,359 [Thread-590] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:55,361 [Thread-536] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:55,361 [Thread-590] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:08:55,362 [Thread-590] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:08:55,361 [Thread-536] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:55,362 [Thread-590] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:08:55,362 [Thread-536] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:55,362 [Thread-590] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:08:55,362 [Thread-536] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:55,364 [Thread-536] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:55,364 [Thread-536] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:55,364 [Thread-536] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:55,365 [Thread-536] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37644
2020-04-02 05:08:55,366 [Thread-590] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,366 [Thread-536] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:55,366 [Thread-536] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:55,368 [Thread-628] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:08:55,368 [Thread-630] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:08:55,369 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:55,371 [Thread-536] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:55,371 [Thread-614] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,372 [Thread-614] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,372 [Thread-536] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:55,372 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:55,372 [Thread-614] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-131831597-172.17.0.7-1585804134865 is not formatted. Formatting ...
2020-04-02 05:08:55,373 [Thread-614] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-131831597-172.17.0.7-1585804134865 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-131831597-172.17.0.7-1585804134865/current
2020-04-02 05:08:55,373 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:55,374 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:55,374 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:55,375 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:55,375 [Thread-536] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38769
2020-04-02 05:08:55,375 [Thread-536] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:55,376 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3a140d5{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:55,377 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@398ab419{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:55,381 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1e0ddb8b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:55,397 [Thread-614] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,397 [Thread-614] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,397 [Thread-614] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-131831597-172.17.0.7-1585804134865 is not formatted. Formatting ...
2020-04-02 05:08:55,397 [Thread-614] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-131831597-172.17.0.7-1585804134865 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-131831597-172.17.0.7-1585804134865/current
2020-04-02 05:08:55,403 [Thread-614] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=705482036;bpid=BP-131831597-172.17.0.7-1585804134865;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=705482036;c=1585804134865;bpid=BP-131831597-172.17.0.7-1585804134865;dnuuid=null
2020-04-02 05:08:55,403 [Thread-628] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-131831597-172.17.0.7-1585804134865 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 35ms
2020-04-02 05:08:55,406 [Thread-614] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID cd6341d9-0481-43d1-9937-ea25dde874e7
2020-04-02 05:08:55,412 [Thread-614] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-2d5ecdcd-9b28-4ff6-b3be-901be89f4ef9
2020-04-02 05:08:55,413 [Thread-614] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:08:55,417 [Thread-536] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7fd126c5{HTTP/1.1,[http/1.1]}{localhost:38769}
2020-04-02 05:08:55,418 [Thread-536] INFO  server.Server (Server.java:doStart(419)) - Started @17941ms
2020-04-02 05:08:55,421 [Thread-630] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-131831597-172.17.0.7-1585804134865 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 53ms
2020-04-02 05:08:55,421 [Thread-590] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-131831597-172.17.0.7-1585804134865: 55ms
2020-04-02 05:08:55,423 [Thread-614] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1
2020-04-02 05:08:55,423 [Thread-614] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:08:55,424 [Thread-614] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:55,426 [Thread-639] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:08:55,426 [Thread-640] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:08:55,427 [Thread-614] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:08:55,426 [Thread-639] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-131831597-172.17.0.7-1585804134865/current/replicas doesn't exist 
2020-04-02 05:08:55,428 [Thread-639] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 3ms
2020-04-02 05:08:55,429 [Thread-640] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-131831597-172.17.0.7-1585804134865/current/replicas doesn't exist 
2020-04-02 05:08:55,431 [Thread-640] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 2ms
2020-04-02 05:08:55,431 [Thread-590] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-131831597-172.17.0.7-1585804134865: 10ms
2020-04-02 05:08:55,431 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:08:55,431 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-f1d9e669-fa01-461a-a669-696781dcb0c2): finished scanning block pool BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,432 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-f1d9e669-fa01-461a-a669-696781dcb0c2): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:08:55,432 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:08:55,432 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-b71b49a9-1814-47a0-997c-c432076ff5a6): finished scanning block pool BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,433 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-b71b49a9-1814-47a0-997c-c432076ff5a6): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:08:55,438 [Thread-614] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:08:55,438 [Thread-614] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:08:55,438 [Thread-614] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:08:55,444 [Thread-590] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:08 AM with interval of 21600000ms
2020-04-02 05:08:55,467 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-131831597-172.17.0.7-1585804134865 (Datanode Uuid 4b28df83-49bb-44c8-86db-acf4a44833c4) service to localhost/127.0.0.1:38969 beginning handshake with NN
2020-04-02 05:08:55,468 [Thread-614] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,475 [Thread-536] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39326
2020-04-02 05:08:55,476 [Thread-536] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:55,476 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6abbedc6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:55,476 [Thread-536] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:55,477 [Thread-536] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:55,477 [IPC Server handler 0 on 38969] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42233, datanodeUuid=4b28df83-49bb-44c8-86db-acf4a44833c4, infoPort=40850, infoSecurePort=0, ipcPort=41016, storageInfo=lv=-57;cid=testClusterID;nsid=705482036;c=1585804134865) storage 4b28df83-49bb-44c8-86db-acf4a44833c4
2020-04-02 05:08:55,478 [Socket Reader #1 for port 33932] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33932
2020-04-02 05:08:55,478 [IPC Server handler 0 on 38969] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42233
2020-04-02 05:08:55,483 [IPC Server handler 0 on 38969] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 4b28df83-49bb-44c8-86db-acf4a44833c4 (127.0.0.1:42233).
2020-04-02 05:08:55,483 [Thread-645] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:08:55,482 [Thread-644] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:08:55,486 [Thread-536] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:33932
2020-04-02 05:08:55,503 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-131831597-172.17.0.7-1585804134865 (Datanode Uuid 4b28df83-49bb-44c8-86db-acf4a44833c4) service to localhost/127.0.0.1:38969 successfully registered with NN
2020-04-02 05:08:55,503 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38969 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:55,507 [IPC Server handler 4 on 38969] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f1d9e669-fa01-461a-a669-696781dcb0c2 for DN 127.0.0.1:42233
2020-04-02 05:08:55,507 [IPC Server handler 4 on 38969] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b71b49a9-1814-47a0-997c-c432076ff5a6 for DN 127.0.0.1:42233
2020-04-02 05:08:55,519 [Thread-645] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-131831597-172.17.0.7-1585804134865 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 35ms
2020-04-02 05:08:55,539 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5143a3cb9405ce4e: Processing first storage report for DS-b71b49a9-1814-47a0-997c-c432076ff5a6 from datanode 4b28df83-49bb-44c8-86db-acf4a44833c4
2020-04-02 05:08:55,546 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5143a3cb9405ce4e: from storage DS-b71b49a9-1814-47a0-997c-c432076ff5a6 node DatanodeRegistration(127.0.0.1:42233, datanodeUuid=4b28df83-49bb-44c8-86db-acf4a44833c4, infoPort=40850, infoSecurePort=0, ipcPort=41016, storageInfo=lv=-57;cid=testClusterID;nsid=705482036;c=1585804134865), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:55,569 [Thread-536] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:55,570 [Thread-536] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:55,570 [Thread-654] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38969 starting to offer service
2020-04-02 05:08:55,571 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:55,571 [IPC Server listener on 33932] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33932: starting
2020-04-02 05:08:55,573 [Thread-536] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 33932 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:55,576 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5143a3cb9405ce4e: Processing first storage report for DS-f1d9e669-fa01-461a-a669-696781dcb0c2 from datanode 4b28df83-49bb-44c8-86db-acf4a44833c4
2020-04-02 05:08:55,576 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5143a3cb9405ce4e: from storage DS-f1d9e669-fa01-461a-a669-696781dcb0c2 node DatanodeRegistration(127.0.0.1:42233, datanodeUuid=4b28df83-49bb-44c8-86db-acf4a44833c4, infoPort=40850, infoSecurePort=0, ipcPort=41016, storageInfo=lv=-57;cid=testClusterID;nsid=705482036;c=1585804134865), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:55,584 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:08:55,587 [Thread-536] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:08:55,587 [Thread-536] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:08:55,589 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x5143a3cb9405ce4e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 74 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:55,590 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,604 [Thread-654] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38969
2020-04-02 05:08:55,605 [Thread-654] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:55,606 [Thread-654] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 11151@974f54091279
2020-04-02 05:08:55,606 [Thread-654] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 705482036. Formatting...
2020-04-02 05:08:55,612 [Thread-654] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-98249807-b056-4053-82a6-38153deb4e9c for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:08:55,616 [Thread-654] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 11151@974f54091279
2020-04-02 05:08:55,616 [Thread-654] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 705482036. Formatting...
2020-04-02 05:08:55,616 [Thread-654] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:08:55,616 [Thread-644] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-131831597-172.17.0.7-1585804134865 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 133ms
2020-04-02 05:08:55,617 [Thread-614] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-131831597-172.17.0.7-1585804134865: 148ms
2020-04-02 05:08:55,617 [Thread-666] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:08:55,617 [Thread-667] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:08:55,617 [Thread-666] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-131831597-172.17.0.7-1585804134865/current/replicas doesn't exist 
2020-04-02 05:08:55,617 [Thread-667] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-131831597-172.17.0.7-1585804134865/current/replicas doesn't exist 
2020-04-02 05:08:55,618 [Thread-667] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-04-02 05:08:55,618 [Thread-666] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-04-02 05:08:55,619 [Thread-614] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-131831597-172.17.0.7-1585804134865: 2ms
2020-04-02 05:08:55,620 [Thread-614] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:12 AM with interval of 21600000ms
2020-04-02 05:08:55,629 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-131831597-172.17.0.7-1585804134865 (Datanode Uuid cd6341d9-0481-43d1-9937-ea25dde874e7) service to localhost/127.0.0.1:38969 beginning handshake with NN
2020-04-02 05:08:55,630 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:08:55,630 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1): finished scanning block pool BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,631 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1): no suitable block pools found to scan.  Waiting 1814399988 ms.
2020-04-02 05:08:55,631 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:08:55,631 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-2d5ecdcd-9b28-4ff6-b3be-901be89f4ef9): finished scanning block pool BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,632 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-2d5ecdcd-9b28-4ff6-b3be-901be89f4ef9): no suitable block pools found to scan.  Waiting 1814399987 ms.
2020-04-02 05:08:55,638 [IPC Server handler 7 on 38969] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40636, datanodeUuid=cd6341d9-0481-43d1-9937-ea25dde874e7, infoPort=41441, infoSecurePort=0, ipcPort=42882, storageInfo=lv=-57;cid=testClusterID;nsid=705482036;c=1585804134865) storage cd6341d9-0481-43d1-9937-ea25dde874e7
2020-04-02 05:08:55,638 [IPC Server handler 7 on 38969] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40636
2020-04-02 05:08:55,639 [IPC Server handler 7 on 38969] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN cd6341d9-0481-43d1-9937-ea25dde874e7 (127.0.0.1:40636).
2020-04-02 05:08:55,641 [Thread-654] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,641 [Thread-654] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,642 [Thread-654] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-131831597-172.17.0.7-1585804134865 is not formatted. Formatting ...
2020-04-02 05:08:55,642 [Thread-654] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-131831597-172.17.0.7-1585804134865 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-131831597-172.17.0.7-1585804134865/current
2020-04-02 05:08:55,642 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-131831597-172.17.0.7-1585804134865 (Datanode Uuid cd6341d9-0481-43d1-9937-ea25dde874e7) service to localhost/127.0.0.1:38969 successfully registered with NN
2020-04-02 05:08:55,642 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38969 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:55,652 [IPC Server handler 9 on 38969] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2d5ecdcd-9b28-4ff6-b3be-901be89f4ef9 for DN 127.0.0.1:40636
2020-04-02 05:08:55,654 [IPC Server handler 9 on 38969] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1 for DN 127.0.0.1:40636
2020-04-02 05:08:55,666 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x99f645846e0b86e9: Processing first storage report for DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1 from datanode cd6341d9-0481-43d1-9937-ea25dde874e7
2020-04-02 05:08:55,666 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x99f645846e0b86e9: from storage DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1 node DatanodeRegistration(127.0.0.1:40636, datanodeUuid=cd6341d9-0481-43d1-9937-ea25dde874e7, infoPort=41441, infoSecurePort=0, ipcPort=42882, storageInfo=lv=-57;cid=testClusterID;nsid=705482036;c=1585804134865), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:55,666 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x99f645846e0b86e9: Processing first storage report for DS-2d5ecdcd-9b28-4ff6-b3be-901be89f4ef9 from datanode cd6341d9-0481-43d1-9937-ea25dde874e7
2020-04-02 05:08:55,666 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x99f645846e0b86e9: from storage DS-2d5ecdcd-9b28-4ff6-b3be-901be89f4ef9 node DatanodeRegistration(127.0.0.1:40636, datanodeUuid=cd6341d9-0481-43d1-9937-ea25dde874e7, infoPort=41441, infoSecurePort=0, ipcPort=42882, storageInfo=lv=-57;cid=testClusterID;nsid=705482036;c=1585804134865), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:55,667 [Thread-654] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,668 [Thread-654] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,668 [Thread-654] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-131831597-172.17.0.7-1585804134865 is not formatted. Formatting ...
2020-04-02 05:08:55,668 [Thread-654] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-131831597-172.17.0.7-1585804134865 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-131831597-172.17.0.7-1585804134865/current
2020-04-02 05:08:55,669 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x99f645846e0b86e9,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 11 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:55,669 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,671 [Thread-654] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=705482036;bpid=BP-131831597-172.17.0.7-1585804134865;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=705482036;c=1585804134865;bpid=BP-131831597-172.17.0.7-1585804134865;dnuuid=null
2020-04-02 05:08:55,673 [Thread-654] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID e0539b34-cc77-4897-b986-112fd2aabddb
2020-04-02 05:08:55,676 [Thread-654] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-98249807-b056-4053-82a6-38153deb4e9c
2020-04-02 05:08:55,676 [Thread-654] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:08:55,678 [Thread-654] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a
2020-04-02 05:08:55,678 [Thread-654] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:08:55,678 [Thread-654] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:55,680 [Thread-654] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:08:55,680 [Thread-654] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:08:55,680 [Thread-654] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:08:55,681 [Thread-654] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:08:55,681 [Thread-654] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,681 [Thread-673] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:08:55,682 [Thread-674] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:08:55,697 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:08:55,703 [Thread-536] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:08:55,703 [Thread-536] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:08:55,722 [Thread-674] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-131831597-172.17.0.7-1585804134865 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 40ms
2020-04-02 05:08:55,736 [Thread-673] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-131831597-172.17.0.7-1585804134865 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 55ms
2020-04-02 05:08:55,736 [Thread-654] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-131831597-172.17.0.7-1585804134865: 55ms
2020-04-02 05:08:55,737 [Thread-677] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:08:55,738 [Thread-678] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:08:55,739 [Thread-678] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-131831597-172.17.0.7-1585804134865/current/replicas doesn't exist 
2020-04-02 05:08:55,738 [Thread-677] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-131831597-172.17.0.7-1585804134865/current/replicas doesn't exist 
2020-04-02 05:08:55,739 [Thread-677] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 2ms
2020-04-02 05:08:55,739 [Thread-678] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 0ms
2020-04-02 05:08:55,740 [Thread-654] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-131831597-172.17.0.7-1585804134865: 4ms
2020-04-02 05:08:55,740 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:08:55,740 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-131831597-172.17.0.7-1585804134865 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:08:55,740 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-98249807-b056-4053-82a6-38153deb4e9c): finished scanning block pool BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,740 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a): finished scanning block pool BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,740 [Thread-654] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:05 AM with interval of 21600000ms
2020-04-02 05:08:55,746 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-131831597-172.17.0.7-1585804134865 (Datanode Uuid e0539b34-cc77-4897-b986-112fd2aabddb) service to localhost/127.0.0.1:38969 beginning handshake with NN
2020-04-02 05:08:55,749 [IPC Server handler 1 on 38969] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37644, datanodeUuid=e0539b34-cc77-4897-b986-112fd2aabddb, infoPort=39326, infoSecurePort=0, ipcPort=33932, storageInfo=lv=-57;cid=testClusterID;nsid=705482036;c=1585804134865) storage e0539b34-cc77-4897-b986-112fd2aabddb
2020-04-02 05:08:55,749 [IPC Server handler 1 on 38969] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37644
2020-04-02 05:08:55,750 [IPC Server handler 1 on 38969] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e0539b34-cc77-4897-b986-112fd2aabddb (127.0.0.1:37644).
2020-04-02 05:08:55,750 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a): no suitable block pools found to scan.  Waiting 1814399990 ms.
2020-04-02 05:08:55,750 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-98249807-b056-4053-82a6-38153deb4e9c): no suitable block pools found to scan.  Waiting 1814399990 ms.
2020-04-02 05:08:55,751 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-131831597-172.17.0.7-1585804134865 (Datanode Uuid e0539b34-cc77-4897-b986-112fd2aabddb) service to localhost/127.0.0.1:38969 successfully registered with NN
2020-04-02 05:08:55,751 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38969 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:55,762 [IPC Server handler 0 on 38969] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-98249807-b056-4053-82a6-38153deb4e9c for DN 127.0.0.1:37644
2020-04-02 05:08:55,762 [IPC Server handler 0 on 38969] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a for DN 127.0.0.1:37644
2020-04-02 05:08:55,773 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x15e01c5f7fc3e13d: Processing first storage report for DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a from datanode e0539b34-cc77-4897-b986-112fd2aabddb
2020-04-02 05:08:55,774 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x15e01c5f7fc3e13d: from storage DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a node DatanodeRegistration(127.0.0.1:37644, datanodeUuid=e0539b34-cc77-4897-b986-112fd2aabddb, infoPort=39326, infoSecurePort=0, ipcPort=33932, storageInfo=lv=-57;cid=testClusterID;nsid=705482036;c=1585804134865), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:08:55,774 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x15e01c5f7fc3e13d: Processing first storage report for DS-98249807-b056-4053-82a6-38153deb4e9c from datanode e0539b34-cc77-4897-b986-112fd2aabddb
2020-04-02 05:08:55,774 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x15e01c5f7fc3e13d: from storage DS-98249807-b056-4053-82a6-38153deb4e9c node DatanodeRegistration(127.0.0.1:37644, datanodeUuid=e0539b34-cc77-4897-b986-112fd2aabddb, infoPort=39326, infoSecurePort=0, ipcPort=33932, storageInfo=lv=-57;cid=testClusterID;nsid=705482036;c=1585804134865), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:55,776 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x15e01c5f7fc3e13d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:55,776 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:08:55,806 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:08:55,814 [Thread-536] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:08:55,817 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:08:55,818 [Thread-536] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:08:55,846 [IPC Server handler 6 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:55,848 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:55,854 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=null	proto=rpc
2020-04-02 05:08:55,855 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:55,857 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:55,863 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:55,863 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:55,863 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:08:55,869 [Thread-682] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:55,869 [Thread-682] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:55,872 [IPC Server handler 1 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:37644, 127.0.0.1:40636, 127.0.0.1:42233 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test0
2020-04-02 05:08:55,874 [Thread-682] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]], blk_1073741825_1001
2020-04-02 05:08:55,874 [Thread-682] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:37644
2020-04-02 05:08:55,875 [Thread-682] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:55,890 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:37964 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001 src: /127.0.0.1:37964 dest: /127.0.0.1:37644
2020-04-02 05:08:55,892 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58012 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001 src: /127.0.0.1:58012 dest: /127.0.0.1:40636
2020-04-02 05:08:55,894 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:54422 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001 src: /127.0.0.1:54422 dest: /127.0.0.1:42233
2020-04-02 05:08:55,902 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test0 block BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6]
2020-04-02 05:08:55,902 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test0 block BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741825_1001 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:08:55,903 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test0 block BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741825_1001
2020-04-02 05:08:55,921 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 15989932 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:55,929 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test0 block BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741825_1001 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:08:55,935 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54422, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001, duration(ns): 38633928
2020-04-02 05:08:55,935 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:55,936 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58012, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001, duration(ns): 40013721
2020-04-02 05:08:55,936 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233] terminating
2020-04-02 05:08:55,939 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37964, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001, duration(ns): 37025995
2020-04-02 05:08:55,940 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 7662676 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:55,940 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233] terminating
2020-04-02 05:08:55,941 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test0 block BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741825_1001
2020-04-02 05:08:55,954 [IPC Server handler 3 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test0 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:08:55,966 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:55,971 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:55,978 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:55,986 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:55,989 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:55,989 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:55,989 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:08:55,991 [Thread-691] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:55,991 [Thread-691] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:55,992 [IPC Server handler 1 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:40636, 127.0.0.1:42233, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test1
2020-04-02 05:08:55,997 [Thread-691] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741826_1002
2020-04-02 05:08:55,997 [Thread-691] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:08:55,997 [Thread-691] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:56,000 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58062 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002 src: /127.0.0.1:58062 dest: /127.0.0.1:40636
2020-04-02 05:08:56,002 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:54472 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002 src: /127.0.0.1:54472 dest: /127.0.0.1:42233
2020-04-02 05:08:56,007 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:38022 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002 src: /127.0.0.1:38022 dest: /127.0.0.1:37644
2020-04-02 05:08:56,014 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test1 block BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:08:56,016 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test1 block BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741826_1002 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:08:56,017 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test1 block BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741826_1002
2020-04-02 05:08:56,023 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 6483580 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:56,029 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test1 block BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741826_1002 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:08:56,030 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38022, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002, duration(ns): 14898621
2020-04-02 05:08:56,031 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:56,032 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54472, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002, duration(ns): 13133270
2020-04-02 05:08:56,032 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:08:56,033 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58062, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002, duration(ns): 24027586
2020-04-02 05:08:56,033 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644] terminating
2020-04-02 05:08:56,035 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2812060 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:56,037 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test1 block BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741826_1002
2020-04-02 05:08:56,038 [IPC Server handler 4 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test1 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:08:56,041 [IPC Server handler 6 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:56,042 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test1	dst=null	perm=null	proto=rpc
2020-04-02 05:08:56,045 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:56,046 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:56,049 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:56,049 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:56,049 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:08:56,057 [Thread-699] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:56,058 [Thread-699] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:56,063 [IPC Server handler 2 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:42233, 127.0.0.1:37644, 127.0.0.1:40636 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test2
2020-04-02 05:08:56,066 [Thread-699] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]], blk_1073741827_1003
2020-04-02 05:08:56,066 [Thread-699] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:42233
2020-04-02 05:08:56,066 [Thread-699] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:56,070 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:54536 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003 src: /127.0.0.1:54536 dest: /127.0.0.1:42233
2020-04-02 05:08:56,072 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:38092 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003 src: /127.0.0.1:38092 dest: /127.0.0.1:37644
2020-04-02 05:08:56,074 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58140 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003 src: /127.0.0.1:58140 dest: /127.0.0.1:40636
2020-04-02 05:08:56,087 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test2 block BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1]
2020-04-02 05:08:56,088 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test2 block BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741827_1003 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:08:56,088 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test2 block BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741827_1003
2020-04-02 05:08:56,102 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 13472344 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:56,105 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test2 block BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741827_1003 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:08:56,111 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58140, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003, duration(ns): 35515291
2020-04-02 05:08:56,111 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:56,112 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38092, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003, duration(ns): 33697775
2020-04-02 05:08:56,112 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636] terminating
2020-04-02 05:08:56,113 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54536, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003, duration(ns): 26063513
2020-04-02 05:08:56,113 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636] terminating
2020-04-02 05:08:56,114 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 5004517 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:56,118 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test2 block BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741827_1003
2020-04-02 05:08:56,122 [IPC Server handler 5 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test2 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:08:56,131 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test2	dst=null	perm=null	proto=rpc
2020-04-02 05:08:56,135 [IPC Server handler 6 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test2	dst=null	perm=null	proto=rpc
2020-04-02 05:08:56,137 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:56,139 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test3	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:56,181 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:56,181 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:56,181 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:08:56,187 [Thread-707] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:56,187 [Thread-707] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:56,189 [IPC Server handler 8 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:37644, 127.0.0.1:40636, 127.0.0.1:42233 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test3
2020-04-02 05:08:56,194 [Thread-707] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]], blk_1073741828_1004
2020-04-02 05:08:56,194 [Thread-707] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:37644
2020-04-02 05:08:56,195 [Thread-707] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:56,198 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:38136 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004 src: /127.0.0.1:38136 dest: /127.0.0.1:37644
2020-04-02 05:08:56,200 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58184 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004 src: /127.0.0.1:58184 dest: /127.0.0.1:40636
2020-04-02 05:08:56,208 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:54594 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004 src: /127.0.0.1:54594 dest: /127.0.0.1:42233
2020-04-02 05:08:56,223 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test3 block BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6]
2020-04-02 05:08:56,228 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test3 block BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741828_1004 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:08:56,242 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test3 block BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741828_1004
2020-04-02 05:08:56,267 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 23322508 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:56,269 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test3 block BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741828_1004 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:08:56,270 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54594, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004, duration(ns): 59996879
2020-04-02 05:08:56,270 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:56,275 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58184, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004, duration(ns): 33010941
2020-04-02 05:08:56,275 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233] terminating
2020-04-02 05:08:56,277 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38136, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004, duration(ns): 41735028
2020-04-02 05:08:56,277 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233] terminating
2020-04-02 05:08:56,279 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 6255346 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:56,281 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test3 block BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741828_1004
2020-04-02 05:08:56,282 [IPC Server handler 4 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test3 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:08:56,304 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test3	dst=null	perm=null	proto=rpc
2020-04-02 05:08:56,306 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test3	dst=null	perm=null	proto=rpc
2020-04-02 05:08:56,309 [IPC Server handler 6 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:56,312 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test4	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:56,313 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:56,314 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:56,314 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:08:56,321 [Thread-715] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:56,322 [Thread-715] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:56,331 [IPC Server handler 9 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:40636, 127.0.0.1:42233, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test4
2020-04-02 05:08:56,332 [Thread-715] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741829_1005
2020-04-02 05:08:56,332 [Thread-715] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:08:56,332 [Thread-715] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:56,338 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58262 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005 src: /127.0.0.1:58262 dest: /127.0.0.1:40636
2020-04-02 05:08:56,342 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:54674 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005 src: /127.0.0.1:54674 dest: /127.0.0.1:42233
2020-04-02 05:08:56,347 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:38224 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005 src: /127.0.0.1:38224 dest: /127.0.0.1:37644
2020-04-02 05:08:56,349 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test4 block BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:08:56,350 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test4 block BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741829_1005 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:08:56,350 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test4 block BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741829_1005
2020-04-02 05:08:56,358 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 5194204 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:56,362 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test4 block BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741829_1005 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:08:56,375 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38224, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005, duration(ns): 26007739
2020-04-02 05:08:56,375 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:56,376 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54674, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005, duration(ns): 27424053
2020-04-02 05:08:56,376 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:08:56,377 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58262, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005, duration(ns): 28636604
2020-04-02 05:08:56,377 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644] terminating
2020-04-02 05:08:56,378 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 14517816 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:56,378 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test4 block BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741829_1005
2020-04-02 05:08:56,379 [IPC Server handler 0 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test4 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:08:56,381 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test4	dst=null	perm=null	proto=rpc
2020-04-02 05:08:56,383 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test4	dst=null	perm=null	proto=rpc
2020-04-02 05:08:56,385 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:56,386 [IPC Server handler 6 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test5	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:56,388 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:56,388 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:56,389 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:08:56,392 [Thread-723] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:56,392 [Thread-723] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:56,395 [IPC Server handler 7 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:37644, 127.0.0.1:40636, 127.0.0.1:42233 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test5
2020-04-02 05:08:56,397 [Thread-723] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]], blk_1073741830_1006
2020-04-02 05:08:56,397 [Thread-723] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:37644
2020-04-02 05:08:56,397 [Thread-723] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:56,398 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:38240 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006 src: /127.0.0.1:38240 dest: /127.0.0.1:37644
2020-04-02 05:08:56,401 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58288 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006 src: /127.0.0.1:58288 dest: /127.0.0.1:40636
2020-04-02 05:08:56,407 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:54700 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006 src: /127.0.0.1:54700 dest: /127.0.0.1:42233
2020-04-02 05:08:56,412 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test5 block BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6]
2020-04-02 05:08:56,412 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test5 block BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741830_1006 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:08:56,412 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test5 block BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741830_1006
2020-04-02 05:08:56,438 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 11457049 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:56,441 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test5 block BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741830_1006 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:08:56,454 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54700, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006, duration(ns): 44906571
2020-04-02 05:08:56,455 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:56,456 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58288, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006, duration(ns): 46315396
2020-04-02 05:08:56,456 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233] terminating
2020-04-02 05:08:56,458 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38240, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006, duration(ns): 32046050
2020-04-02 05:08:56,458 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233] terminating
2020-04-02 05:08:56,464 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 12959797 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:56,465 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test5 block BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741830_1006
2020-04-02 05:08:56,469 [IPC Server handler 1 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test5 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:08:56,471 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test5	dst=null	perm=null	proto=rpc
2020-04-02 05:08:56,478 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test5	dst=null	perm=null	proto=rpc
2020-04-02 05:08:56,486 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:56,490 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test6	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:56,493 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:56,494 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:56,494 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:08:56,497 [Thread-731] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:56,497 [Thread-731] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:56,498 [IPC Server handler 6 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:40636, 127.0.0.1:37644, 127.0.0.1:42233 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test6
2020-04-02 05:08:56,500 [Thread-731] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]], blk_1073741831_1007
2020-04-02 05:08:56,500 [Thread-731] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:08:56,500 [Thread-731] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:56,501 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58322 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007 src: /127.0.0.1:58322 dest: /127.0.0.1:40636
2020-04-02 05:08:56,507 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:38280 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007 src: /127.0.0.1:38280 dest: /127.0.0.1:37644
2020-04-02 05:08:56,511 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:54738 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007 src: /127.0.0.1:54738 dest: /127.0.0.1:42233
2020-04-02 05:08:56,518 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test6 block BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-b71b49a9-1814-47a0-997c-c432076ff5a6]
2020-04-02 05:08:56,519 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test6 block BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741831_1007 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:08:56,519 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test6 block BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741831_1007
2020-04-02 05:08:56,543 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 23526362 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:56,545 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test6 block BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741831_1007 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:08:56,550 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54738, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007, duration(ns): 36614393
2020-04-02 05:08:56,551 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:56,554 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38280, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007, duration(ns): 31217221
2020-04-02 05:08:56,555 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233] terminating
2020-04-02 05:08:56,555 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58322, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007, duration(ns): 36272857
2020-04-02 05:08:56,556 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233] terminating
2020-04-02 05:08:56,556 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741831_1007] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 9558702 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:56,557 [IPC Server handler 8 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test6 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:08:56,562 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test6	dst=null	perm=null	proto=rpc
2020-04-02 05:08:56,564 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test6	dst=null	perm=null	proto=rpc
2020-04-02 05:08:57,367 [RedundancyMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2020-04-02 05:08:57,368 [RedundancyMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2020-04-02 05:08:57,368 [RedundancyMonitor] WARN  protocol.BlockStoragePolicy (BlockStoragePolicy.java:chooseStorageTypes(161)) - Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2020-04-02 05:08:57,368 [RedundancyMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2020-04-02 05:08:57,368 [RedundancyMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2020-04-02 05:08:57,369 [RedundancyMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2020-04-02 05:08:57,369 [RedundancyMonitor] WARN  protocol.BlockStoragePolicy (BlockStoragePolicy.java:chooseStorageTypes(161)) - Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2020-04-02 05:08:57,369 [RedundancyMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2020-04-02 05:08:57,369 [RedundancyMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2020-04-02 05:08:57,370 [RedundancyMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2020-04-02 05:08:57,370 [RedundancyMonitor] WARN  protocol.BlockStoragePolicy (BlockStoragePolicy.java:chooseStorageTypes(161)) - Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2020-04-02 05:08:57,370 [RedundancyMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2020-04-02 05:08:57,370 [RedundancyMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2020-04-02 05:08:57,370 [RedundancyMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2020-04-02 05:08:57,371 [RedundancyMonitor] WARN  protocol.BlockStoragePolicy (BlockStoragePolicy.java:chooseStorageTypes(161)) - Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2020-04-02 05:08:57,371 [RedundancyMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2020-04-02 05:08:57,371 [RedundancyMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2020-04-02 05:08:57,371 [RedundancyMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2020-04-02 05:08:57,371 [RedundancyMonitor] WARN  protocol.BlockStoragePolicy (BlockStoragePolicy.java:chooseStorageTypes(161)) - Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2020-04-02 05:08:57,371 [RedundancyMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2020-04-02 05:08:57,571 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741857_1034 replica FinalizedReplica, blk_1073741857_1034, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741857 for deletion
2020-04-02 05:08:57,572 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test6	dst=null	perm=null	proto=rpc
2020-04-02 05:08:57,572 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741859_1036 replica FinalizedReplica, blk_1073741859_1036, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741859 for deletion
2020-04-02 05:08:57,573 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741827_1003 replica FinalizedReplica, blk_1073741827_1003, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741827 for deletion
2020-04-02 05:08:57,573 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741835_1011 replica FinalizedReplica, blk_1073741835_1011, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741835 for deletion
2020-04-02 05:08:57,573 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741857_1034 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741857
2020-04-02 05:08:57,574 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741836_1012 replica FinalizedReplica, blk_1073741836_1012, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741836 for deletion
2020-04-02 05:08:57,574 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741835_1011 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741835
2020-04-02 05:08:57,574 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741837_1013 replica FinalizedReplica, blk_1073741837_1013, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741837 for deletion
2020-04-02 05:08:57,574 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741838_1014 replica FinalizedReplica, blk_1073741838_1014, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741838 for deletion
2020-04-02 05:08:57,575 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741839_1015 replica FinalizedReplica, blk_1073741839_1015, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741839 for deletion
2020-04-02 05:08:57,575 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741840_1016 replica FinalizedReplica, blk_1073741840_1016, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741840 for deletion
2020-04-02 05:08:57,575 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741841_1017 replica FinalizedReplica, blk_1073741841_1017, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741841 for deletion
2020-04-02 05:08:57,575 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741842_1018 replica FinalizedReplica, blk_1073741842_1018, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741842 for deletion
2020-04-02 05:08:57,575 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741843_1019 replica FinalizedReplica, blk_1073741843_1019, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741843 for deletion
2020-04-02 05:08:57,576 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741844_1020 replica FinalizedReplica, blk_1073741844_1020, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741844 for deletion
2020-04-02 05:08:57,576 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741851_1028 replica FinalizedReplica, blk_1073741851_1028, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741851 for deletion
2020-04-02 05:08:57,576 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741852_1029 replica FinalizedReplica, blk_1073741852_1029, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741852 for deletion
2020-04-02 05:08:57,576 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test6	dst=null	perm=null	proto=rpc
2020-04-02 05:08:57,580 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741837_1013 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741837
2020-04-02 05:08:57,580 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741859_1036 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741859
2020-04-02 05:08:57,580 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741839_1015 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741839
2020-04-02 05:08:57,580 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741827_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741827
2020-04-02 05:08:57,580 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741841_1017 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741841
2020-04-02 05:08:57,581 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741836_1012 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741836
2020-04-02 05:08:57,581 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741843_1019 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741843
2020-04-02 05:08:57,581 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741851_1028 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741851
2020-04-02 05:08:57,581 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741838_1014 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741838
2020-04-02 05:08:57,581 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741840_1016 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741840
2020-04-02 05:08:57,582 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741842_1018 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741842
2020-04-02 05:08:57,582 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741844_1020 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741844
2020-04-02 05:08:57,582 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741852_1029 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741852
2020-04-02 05:08:57,598 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:57,603 [IPC Server handler 6 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test7	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:57,646 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:57,649 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:57,650 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:08:57,657 [Thread-741] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:57,658 [Thread-741] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:57,662 [IPC Server handler 7 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741832_1008, replicas=127.0.0.1:42233, 127.0.0.1:37644, 127.0.0.1:40636 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test7
2020-04-02 05:08:57,666 [Thread-741] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]], blk_1073741832_1008
2020-04-02 05:08:57,666 [Thread-741] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:42233
2020-04-02 05:08:57,666 [Thread-741] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:57,669 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:55348 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008 src: /127.0.0.1:55348 dest: /127.0.0.1:42233
2020-04-02 05:08:57,675 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:38904 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008 src: /127.0.0.1:38904 dest: /127.0.0.1:37644
2020-04-02 05:08:57,691 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58956 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008 src: /127.0.0.1:58956 dest: /127.0.0.1:40636
2020-04-02 05:08:57,695 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test7 block BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1]
2020-04-02 05:08:57,696 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test7 block BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741832_1008 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:08:57,696 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test7 block BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741832_1008
2020-04-02 05:08:57,698 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1213521 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:57,700 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test7 block BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741832_1008 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:08:57,701 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58956, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008, duration(ns): 8373848
2020-04-02 05:08:57,702 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:57,703 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38904, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008, duration(ns): 9616918
2020-04-02 05:08:57,703 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636] terminating
2020-04-02 05:08:57,704 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55348, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008, duration(ns): 9061388
2020-04-02 05:08:57,704 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636] terminating
2020-04-02 05:08:57,705 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2775325 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:57,705 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test7 block BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741832_1008
2020-04-02 05:08:57,707 [IPC Server handler 2 on 38969] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741832_1008 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test7
2020-04-02 05:08:58,109 [IPC Server handler 0 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test7 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:08:58,111 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test7	dst=null	perm=null	proto=rpc
2020-04-02 05:08:58,113 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test7	dst=null	perm=null	proto=rpc
2020-04-02 05:08:58,116 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:58,118 [IPC Server handler 6 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test8	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:58,120 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:58,120 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:58,120 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:08:58,122 [Thread-749] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:58,123 [Thread-749] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:58,125 [IPC Server handler 7 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741833_1009, replicas=127.0.0.1:40636, 127.0.0.1:42233, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test8
2020-04-02 05:08:58,126 [Thread-749] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741833_1009
2020-04-02 05:08:58,126 [Thread-749] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:08:58,126 [Thread-749] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:58,134 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:59244 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009 src: /127.0.0.1:59244 dest: /127.0.0.1:40636
2020-04-02 05:08:58,138 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:55654 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009 src: /127.0.0.1:55654 dest: /127.0.0.1:42233
2020-04-02 05:08:58,146 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:39204 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009 src: /127.0.0.1:39204 dest: /127.0.0.1:37644
2020-04-02 05:08:58,166 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test8 block BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:08:58,170 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test8 block BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741833_1009 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:08:58,171 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test8 block BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741833_1009
2020-04-02 05:08:58,186 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 10773249 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:58,190 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test8 block BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741833_1009 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:08:58,194 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39204, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009, duration(ns): 39995824
2020-04-02 05:08:58,194 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:58,195 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55654, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009, duration(ns): 40955791
2020-04-02 05:08:58,195 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:08:58,195 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59244, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009, duration(ns): 36330694
2020-04-02 05:08:58,196 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644] terminating
2020-04-02 05:08:58,196 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 4549587 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:58,196 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test8 block BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741833_1009
2020-04-02 05:08:58,197 [IPC Server handler 2 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test8 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:08:58,203 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test8	dst=null	perm=null	proto=rpc
2020-04-02 05:08:58,204 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test8	dst=null	perm=null	proto=rpc
2020-04-02 05:08:58,207 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:58,211 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test9	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:58,213 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:58,213 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:58,213 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:08:58,215 [Thread-757] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:58,215 [Thread-757] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:58,219 [IPC Server handler 6 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741834_1010, replicas=127.0.0.1:42233, 127.0.0.1:37644, 127.0.0.1:40636 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test9
2020-04-02 05:08:58,223 [Thread-757] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]], blk_1073741834_1010
2020-04-02 05:08:58,223 [Thread-757] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:42233
2020-04-02 05:08:58,224 [Thread-757] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:58,227 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:55662 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010 src: /127.0.0.1:55662 dest: /127.0.0.1:42233
2020-04-02 05:08:58,233 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:39212 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010 src: /127.0.0.1:39212 dest: /127.0.0.1:37644
2020-04-02 05:08:58,238 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:59258 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010 src: /127.0.0.1:59258 dest: /127.0.0.1:40636
2020-04-02 05:08:58,261 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test9 block BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1]
2020-04-02 05:08:58,270 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test9 block BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741834_1010 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:08:58,270 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test9 block BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741834_1010
2020-04-02 05:08:58,291 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 16226428 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:58,298 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test9 block BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741834_1010 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:08:58,301 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59258, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010, duration(ns): 61058765
2020-04-02 05:08:58,302 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:58,302 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39212, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010, duration(ns): 28280361
2020-04-02 05:08:58,302 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636] terminating
2020-04-02 05:08:58,304 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55662, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010, duration(ns): 42430812
2020-04-02 05:08:58,305 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636] terminating
2020-04-02 05:08:58,305 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 5424306 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:58,305 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test9 block BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741834_1010
2020-04-02 05:08:58,306 [IPC Server handler 2 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test9 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:08:58,308 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test9	dst=null	perm=null	proto=rpc
2020-04-02 05:08:58,309 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test9	dst=null	perm=null	proto=rpc
2020-04-02 05:08:58,311 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:58,313 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test10	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:58,314 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:58,315 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:58,316 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:08:58,316 [Thread-765] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:58,316 [Thread-765] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:58,318 [IPC Server handler 3 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741835_1011, replicas=127.0.0.1:40636, 127.0.0.1:42233, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test10
2020-04-02 05:08:58,320 [Thread-765] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741835_1011
2020-04-02 05:08:58,320 [Thread-765] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:08:58,321 [Thread-765] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:58,322 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:59276 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011 src: /127.0.0.1:59276 dest: /127.0.0.1:40636
2020-04-02 05:08:58,336 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:55688 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011 src: /127.0.0.1:55688 dest: /127.0.0.1:42233
2020-04-02 05:08:58,339 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:39248 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011 src: /127.0.0.1:39248 dest: /127.0.0.1:37644
2020-04-02 05:08:58,367 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test10 block BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:08:58,374 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test10 block BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741835_1011 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:08:58,374 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test10 block BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741835_1011
2020-04-02 05:08:58,410 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 11877260 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:58,412 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test10 block BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741835_1011 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:08:58,418 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39248, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011, duration(ns): 77796384
2020-04-02 05:08:58,419 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:58,419 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55688, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011, duration(ns): 25116717
2020-04-02 05:08:58,419 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:08:58,421 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59276, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011, duration(ns): 34163352
2020-04-02 05:08:58,421 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 7648849 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:58,421 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644] terminating
2020-04-02 05:08:58,430 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test10 block BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741835_1011
2020-04-02 05:08:58,431 [IPC Server handler 8 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test10 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:08:58,432 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test10	dst=null	perm=null	proto=rpc
2020-04-02 05:08:58,433 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test10	dst=null	perm=null	proto=rpc
2020-04-02 05:08:58,434 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:58,435 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test11	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:58,447 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:58,447 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:58,447 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:08:58,454 [Thread-773] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:58,454 [Thread-773] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:58,458 [IPC Server handler 5 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741836_1012, replicas=127.0.0.1:42233, 127.0.0.1:37644, 127.0.0.1:40636 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test11
2020-04-02 05:08:58,459 [Thread-773] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]], blk_1073741836_1012
2020-04-02 05:08:58,460 [Thread-773] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:42233
2020-04-02 05:08:58,460 [Thread-773] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:58,463 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:55752 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012 src: /127.0.0.1:55752 dest: /127.0.0.1:42233
2020-04-02 05:08:58,471 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:39304 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012 src: /127.0.0.1:39304 dest: /127.0.0.1:37644
2020-04-02 05:08:58,474 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:59350 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012 src: /127.0.0.1:59350 dest: /127.0.0.1:40636
2020-04-02 05:08:58,492 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test11 block BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1]
2020-04-02 05:08:58,497 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test11 block BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741836_1012 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:08:58,498 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test11 block BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741836_1012
2020-04-02 05:08:58,506 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 3920333 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:58,509 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test11 block BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741836_1012 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:08:58,516 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59350, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012, duration(ns): 38414255
2020-04-02 05:08:58,516 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39304, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012, duration(ns): 24084763
2020-04-02 05:08:58,517 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636] terminating
2020-04-02 05:08:58,518 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55752, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012, duration(ns): 23887213
2020-04-02 05:08:58,518 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:58,519 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636] terminating
2020-04-02 05:08:58,525 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741836_1012] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 7623060 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:58,526 [IPC Server handler 2 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test11 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:08:58,528 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test11	dst=null	perm=null	proto=rpc
2020-04-02 05:08:58,529 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test11	dst=null	perm=null	proto=rpc
2020-04-02 05:08:58,532 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:58,533 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test12	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:58,534 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:58,534 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:58,534 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:08:58,537 [Thread-781] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:58,537 [Thread-781] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:58,546 [IPC Server handler 3 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741837_1013, replicas=127.0.0.1:40636, 127.0.0.1:37644, 127.0.0.1:42233 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test12
2020-04-02 05:08:58,548 [Thread-781] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]], blk_1073741837_1013
2020-04-02 05:08:58,548 [Thread-781] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:08:58,548 [Thread-781] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:58,550 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:59378 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013 src: /127.0.0.1:59378 dest: /127.0.0.1:40636
2020-04-02 05:08:58,553 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:39338 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013 src: /127.0.0.1:39338 dest: /127.0.0.1:37644
2020-04-02 05:08:58,554 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:55794 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013 src: /127.0.0.1:55794 dest: /127.0.0.1:42233
2020-04-02 05:08:58,564 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test12 block BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-b71b49a9-1814-47a0-997c-c432076ff5a6]
2020-04-02 05:08:58,567 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test12 block BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741837_1013 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:08:58,568 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test12 block BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741837_1013
2020-04-02 05:08:58,574 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 4287889 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:58,575 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test12 block BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741837_1013 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:08:58,577 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55794, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013, duration(ns): 20722674
2020-04-02 05:08:58,577 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:58,588 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39338, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013, duration(ns): 25582879
2020-04-02 05:08:58,588 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233] terminating
2020-04-02 05:08:58,589 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59378, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013, duration(ns): 24887400
2020-04-02 05:08:58,589 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233] terminating
2020-04-02 05:08:58,589 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 12272251 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:58,589 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test12 block BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741837_1013
2020-04-02 05:08:58,590 [IPC Server handler 9 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test12 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:08:58,598 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test12	dst=null	perm=null	proto=rpc
2020-04-02 05:08:58,599 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test12	dst=null	perm=null	proto=rpc
2020-04-02 05:08:58,601 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:58,602 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test13	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:58,609 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:58,609 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:58,609 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:08:58,620 [Thread-789] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:58,620 [Thread-789] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:58,621 [IPC Server handler 5 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741838_1014, replicas=127.0.0.1:40636, 127.0.0.1:42233, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test13
2020-04-02 05:08:58,623 [Thread-789] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741838_1014
2020-04-02 05:08:58,623 [Thread-789] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:08:58,624 [Thread-789] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:58,625 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:59418 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014 src: /127.0.0.1:59418 dest: /127.0.0.1:40636
2020-04-02 05:08:58,629 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:55832 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014 src: /127.0.0.1:55832 dest: /127.0.0.1:42233
2020-04-02 05:08:58,641 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:39382 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014 src: /127.0.0.1:39382 dest: /127.0.0.1:37644
2020-04-02 05:08:58,653 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test13 block BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:08:58,654 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test13 block BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741838_1014 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:08:58,654 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test13 block BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741838_1014
2020-04-02 05:08:58,670 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 9678422 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:58,678 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test13 block BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741838_1014 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:08:58,679 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39382, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014, duration(ns): 13187922
2020-04-02 05:08:58,680 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:58,680 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55832, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014, duration(ns): 17231597
2020-04-02 05:08:58,681 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:08:58,682 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59418, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014, duration(ns): 23530484
2020-04-02 05:08:58,682 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644] terminating
2020-04-02 05:08:58,683 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2683306 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:58,683 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test13 block BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741838_1014
2020-04-02 05:08:58,690 [IPC Server handler 2 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test13 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:08:58,692 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test13	dst=null	perm=null	proto=rpc
2020-04-02 05:08:58,695 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test13	dst=null	perm=null	proto=rpc
2020-04-02 05:08:58,697 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:58,698 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test14	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:58,700 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:58,700 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:58,700 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:08:58,707 [Thread-797] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:58,707 [Thread-797] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:58,710 [IPC Server handler 3 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741839_1015, replicas=127.0.0.1:40636, 127.0.0.1:42233, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test14
2020-04-02 05:08:58,712 [Thread-797] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741839_1015
2020-04-02 05:08:58,712 [Thread-797] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:08:58,712 [Thread-797] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:58,715 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:59466 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015 src: /127.0.0.1:59466 dest: /127.0.0.1:40636
2020-04-02 05:08:58,718 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:55880 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015 src: /127.0.0.1:55880 dest: /127.0.0.1:42233
2020-04-02 05:08:58,720 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:39430 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015 src: /127.0.0.1:39430 dest: /127.0.0.1:37644
2020-04-02 05:08:58,723 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test14 block BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:08:58,724 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test14 block BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741839_1015 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:08:58,724 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test14 block BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741839_1015
2020-04-02 05:08:58,738 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 12767328 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:58,740 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test14 block BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741839_1015 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:08:58,744 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39430, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015, duration(ns): 21837935
2020-04-02 05:08:58,744 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:58,748 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55880, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015, duration(ns): 22921411
2020-04-02 05:08:58,748 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:08:58,749 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59466, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015, duration(ns): 26840464
2020-04-02 05:08:58,750 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644] terminating
2020-04-02 05:08:58,750 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741839_1015] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 7878756 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:58,752 [IPC Server handler 9 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test14 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:08:58,771 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test14	dst=null	perm=null	proto=rpc
2020-04-02 05:08:58,773 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test14	dst=null	perm=null	proto=rpc
2020-04-02 05:08:59,775 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test14	dst=null	perm=null	proto=rpc
2020-04-02 05:08:59,777 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test14	dst=null	perm=null	proto=rpc
2020-04-02 05:08:59,782 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:59,787 [IPC Server handler 6 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test15	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:59,791 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:59,791 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:59,791 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:08:59,795 [Thread-805] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:59,795 [Thread-805] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:59,797 [IPC Server handler 7 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741840_1016, replicas=127.0.0.1:42233, 127.0.0.1:40636, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test15
2020-04-02 05:08:59,798 [Thread-805] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741840_1016
2020-04-02 05:08:59,798 [Thread-805] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:42233
2020-04-02 05:08:59,799 [Thread-805] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:59,805 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:56440 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016 src: /127.0.0.1:56440 dest: /127.0.0.1:42233
2020-04-02 05:08:59,811 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:60036 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016 src: /127.0.0.1:60036 dest: /127.0.0.1:40636
2020-04-02 05:08:59,821 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:39996 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016 src: /127.0.0.1:39996 dest: /127.0.0.1:37644
2020-04-02 05:08:59,833 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test15 block BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:08:59,833 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test15 block BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741840_1016 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:08:59,838 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test15 block BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741840_1016
2020-04-02 05:08:59,862 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2582929 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:59,869 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test15 block BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741840_1016 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:08:59,874 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39996, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016, duration(ns): 44537414
2020-04-02 05:08:59,874 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:59,876 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60036, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016, duration(ns): 41553403
2020-04-02 05:08:59,877 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56440, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016, duration(ns): 43917815
2020-04-02 05:08:59,877 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644] terminating
2020-04-02 05:08:59,878 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:08:59,890 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 5313898 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:59,890 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test15 block BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741840_1016
2020-04-02 05:08:59,891 [IPC Server handler 8 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test15 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:08:59,899 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test15	dst=null	perm=null	proto=rpc
2020-04-02 05:08:59,901 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test15	dst=null	perm=null	proto=rpc
2020-04-02 05:08:59,908 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:08:59,911 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test16	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:59,913 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:59,913 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:08:59,913 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:08:59,919 [Thread-813] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:08:59,919 [Thread-813] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:08:59,923 [IPC Server handler 6 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741841_1017, replicas=127.0.0.1:42233, 127.0.0.1:40636, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test16
2020-04-02 05:08:59,924 [Thread-813] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741841_1017
2020-04-02 05:08:59,924 [Thread-813] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:42233
2020-04-02 05:08:59,924 [Thread-813] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:08:59,928 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:56526 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017 src: /127.0.0.1:56526 dest: /127.0.0.1:42233
2020-04-02 05:08:59,930 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:60124 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017 src: /127.0.0.1:60124 dest: /127.0.0.1:40636
2020-04-02 05:08:59,947 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:40084 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017 src: /127.0.0.1:40084 dest: /127.0.0.1:37644
2020-04-02 05:08:59,959 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test16 block BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:08:59,959 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test16 block BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741841_1017 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:08:59,960 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test16 block BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741841_1017
2020-04-02 05:08:59,990 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 23972400 flag: 0 flag: 0 flag: 0
2020-04-02 05:08:59,995 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test16 block BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741841_1017 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:08:59,997 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40084, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017, duration(ns): 48006799
2020-04-02 05:08:59,997 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:59,998 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60124, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017, duration(ns): 36729464
2020-04-02 05:08:59,998 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:08:59,999 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56526, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017, duration(ns): 39821668
2020-04-02 05:08:59,999 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644] terminating
2020-04-02 05:09:00,006 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2497612 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:00,008 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test16 block BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741841_1017
2020-04-02 05:09:00,008 [IPC Server handler 8 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test16 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:00,010 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test16	dst=null	perm=null	proto=rpc
2020-04-02 05:09:00,011 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test16	dst=null	perm=null	proto=rpc
2020-04-02 05:09:00,014 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:00,023 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test17	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:00,034 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:00,034 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:00,034 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:00,046 [Thread-821] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:00,046 [Thread-821] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:00,048 [IPC Server handler 3 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741842_1018, replicas=127.0.0.1:40636, 127.0.0.1:37644, 127.0.0.1:42233 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test17
2020-04-02 05:09:00,050 [Thread-821] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]], blk_1073741842_1018
2020-04-02 05:09:00,051 [Thread-821] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:09:00,051 [Thread-821] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:00,053 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:60196 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018 src: /127.0.0.1:60196 dest: /127.0.0.1:40636
2020-04-02 05:09:00,061 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:40154 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018 src: /127.0.0.1:40154 dest: /127.0.0.1:37644
2020-04-02 05:09:00,070 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:56620 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018 src: /127.0.0.1:56620 dest: /127.0.0.1:42233
2020-04-02 05:09:00,088 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test17 block BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-b71b49a9-1814-47a0-997c-c432076ff5a6]
2020-04-02 05:09:00,098 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test17 block BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741842_1018 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:00,099 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test17 block BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741842_1018
2020-04-02 05:09:00,111 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 12398729 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:00,112 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test17 block BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741842_1018 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:00,114 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56620, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018, duration(ns): 41330712
2020-04-02 05:09:00,115 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:00,116 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40154, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018, duration(ns): 21119317
2020-04-02 05:09:00,116 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233] terminating
2020-04-02 05:09:00,118 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60196, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018, duration(ns): 28988599
2020-04-02 05:09:00,118 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233] terminating
2020-04-02 05:09:00,118 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 5065659 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:00,126 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test17 block BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741842_1018
2020-04-02 05:09:00,135 [IPC Server handler 2 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test17 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:00,137 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test17	dst=null	perm=null	proto=rpc
2020-04-02 05:09:00,138 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test17	dst=null	perm=null	proto=rpc
2020-04-02 05:09:00,140 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:00,141 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test18	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:00,144 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:00,144 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:00,144 [Thread-829] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:00,145 [Thread-829] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:00,145 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:00,149 [IPC Server handler 5 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741843_1019, replicas=127.0.0.1:37644, 127.0.0.1:42233, 127.0.0.1:40636 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test18
2020-04-02 05:09:00,155 [Thread-829] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]], blk_1073741843_1019
2020-04-02 05:09:00,155 [Thread-829] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:37644
2020-04-02 05:09:00,155 [Thread-829] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:00,157 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:40220 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019 src: /127.0.0.1:40220 dest: /127.0.0.1:37644
2020-04-02 05:09:00,166 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:56674 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019 src: /127.0.0.1:56674 dest: /127.0.0.1:42233
2020-04-02 05:09:00,171 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:60270 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019 src: /127.0.0.1:60270 dest: /127.0.0.1:40636
2020-04-02 05:09:00,175 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test18 block BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1]
2020-04-02 05:09:00,177 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test18 block BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741843_1019 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:00,178 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test18 block BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741843_1019
2020-04-02 05:09:00,183 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 4571667 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:00,183 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test18 block BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741843_1019 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:00,185 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60270, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019, duration(ns): 12706902
2020-04-02 05:09:00,185 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:00,189 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56674, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019, duration(ns): 13566942
2020-04-02 05:09:00,190 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636] terminating
2020-04-02 05:09:00,190 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40220, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019, duration(ns): 12243126
2020-04-02 05:09:00,191 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:40636] terminating
2020-04-02 05:09:00,191 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 6640087 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:00,191 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test18 block BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741843_1019
2020-04-02 05:09:00,192 [IPC Server handler 7 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test18 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:00,194 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test18	dst=null	perm=null	proto=rpc
2020-04-02 05:09:00,195 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test18	dst=null	perm=null	proto=rpc
2020-04-02 05:09:00,197 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:00,200 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test19	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:00,202 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:00,202 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:00,202 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:00,202 [Thread-837] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:00,202 [Thread-837] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:00,204 [IPC Server handler 4 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741844_1020, replicas=127.0.0.1:37644, 127.0.0.1:40636, 127.0.0.1:42233 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test19
2020-04-02 05:09:00,205 [Thread-837] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]], blk_1073741844_1020
2020-04-02 05:09:00,206 [Thread-837] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:37644
2020-04-02 05:09:00,206 [Thread-837] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:00,207 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:40254 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020 src: /127.0.0.1:40254 dest: /127.0.0.1:37644
2020-04-02 05:09:00,218 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:60302 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020 src: /127.0.0.1:60302 dest: /127.0.0.1:40636
2020-04-02 05:09:00,220 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:56720 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020 src: /127.0.0.1:56720 dest: /127.0.0.1:42233
2020-04-02 05:09:00,228 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test19 block BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6]
2020-04-02 05:09:00,228 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test19 block BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741844_1020 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:00,229 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test19 block BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741844_1020
2020-04-02 05:09:00,234 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 4960715 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:00,234 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test19 block BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741844_1020 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:00,238 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56720, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020, duration(ns): 16739754
2020-04-02 05:09:00,239 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:00,239 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60302, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020, duration(ns): 9400079
2020-04-02 05:09:00,239 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233] terminating
2020-04-02 05:09:00,242 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40254, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020, duration(ns): 12444908
2020-04-02 05:09:00,243 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233] terminating
2020-04-02 05:09:00,248 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 6324618 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:00,248 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test19 block BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741844_1020
2020-04-02 05:09:00,249 [IPC Server handler 7 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test19 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:00,251 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test19	dst=null	perm=null	proto=rpc
2020-04-02 05:09:00,252 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test19	dst=null	perm=null	proto=rpc
2020-04-02 05:09:00,254 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:00,255 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test20	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:00,256 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:00,256 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:00,256 [Thread-845] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:00,256 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:00,257 [Thread-845] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:00,258 [IPC Server handler 0 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741845_1021, replicas=127.0.0.1:42233, 127.0.0.1:37644, 127.0.0.1:40636 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test20
2020-04-02 05:09:00,259 [Thread-845] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]], blk_1073741845_1021
2020-04-02 05:09:00,260 [Thread-845] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:42233
2020-04-02 05:09:00,260 [Thread-845] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:00,262 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:56760 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021 src: /127.0.0.1:56760 dest: /127.0.0.1:42233
2020-04-02 05:09:00,264 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:40310 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021 src: /127.0.0.1:40310 dest: /127.0.0.1:37644
2020-04-02 05:09:00,266 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:60356 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021 src: /127.0.0.1:60356 dest: /127.0.0.1:40636
2020-04-02 05:09:00,270 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test20 block BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1]
2020-04-02 05:09:00,277 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test20 block BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741845_1021 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:00,277 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test20 block BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741845_1021
2020-04-02 05:09:00,294 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 4005087 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:00,294 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test20 block BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741845_1021 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:00,296 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60356, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021, duration(ns): 27935236
2020-04-02 05:09:00,296 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40310, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021, duration(ns): 28835248
2020-04-02 05:09:00,297 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636] terminating
2020-04-02 05:09:00,297 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:00,298 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56760, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021, duration(ns): 20898492
2020-04-02 05:09:00,298 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636] terminating
2020-04-02 05:09:00,299 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2744910 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:00,302 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test20 block BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741845_1021
2020-04-02 05:09:00,303 [IPC Server handler 5 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test20 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:00,307 [IPC Server handler 6 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test20	dst=null	perm=null	proto=rpc
2020-04-02 05:09:00,308 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test20	dst=null	perm=null	proto=rpc
2020-04-02 05:09:00,577 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (DataNode.java:transferBlock(2353)) - DatanodeRegistration(127.0.0.1:34028, datanodeUuid=b6d7199e-caa6-44fb-a7b0-24811dd44850, infoPort=37046, infoSecurePort=0, ipcPort=41374, storageInfo=lv=-57;cid=testClusterID;nsid=1653655509;c=1585804120054) Starting thread to transfer BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037 to 127.0.0.1:46154 
2020-04-02 05:09:00,577 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (DataNode.java:transferBlock(2353)) - DatanodeRegistration(127.0.0.1:46154, datanodeUuid=1b04f1a7-d40a-4308-a02b-6bf636928be8, infoPort=41866, infoSecurePort=0, ipcPort=40471, storageInfo=lv=-57;cid=testClusterID;nsid=1653655509;c=1585804120054) Starting thread to transfer BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034 to 127.0.0.1:43315 
2020-04-02 05:09:00,580 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (DataNode.java:transferBlock(2353)) - DatanodeRegistration(127.0.0.1:43315, datanodeUuid=966f464e-a960-4750-b2ba-e71f57dd888a, infoPort=41636, infoSecurePort=0, ipcPort=36431, storageInfo=lv=-57;cid=testClusterID;nsid=1653655509;c=1585804120054) Starting thread to transfer BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035 to 127.0.0.1:46154 
2020-04-02 05:09:00,586 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (DataNode.java:transferBlock(2353)) - DatanodeRegistration(127.0.0.1:34028, datanodeUuid=b6d7199e-caa6-44fb-a7b0-24811dd44850, infoPort=37046, infoSecurePort=0, ipcPort=41374, storageInfo=lv=-57;cid=testClusterID;nsid=1653655509;c=1585804120054) Starting thread to transfer BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032 to 127.0.0.1:46154 
2020-04-02 05:09:00,595 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741856_1033 replica FinalizedReplica, blk_1073741856_1033, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741856 for deletion
2020-04-02 05:09:00,595 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741856_1033 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741856
2020-04-02 05:09:00,596 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741861_1038 replica FinalizedReplica, blk_1073741861_1038, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741861 for deletion
2020-04-02 05:09:00,596 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741854_1031 replica FinalizedReplica, blk_1073741854_1031, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741854 for deletion
2020-04-02 05:09:00,596 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741861_1038 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741861
2020-04-02 05:09:00,597 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-725857609-172.17.0.7-1585804120054 blk_1073741854_1031 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6/current/BP-725857609-172.17.0.7-1585804120054/current/finalized/subdir0/subdir0/blk_1073741854
2020-04-02 05:09:00,622 [DataXceiver for client  at /127.0.0.1:59856 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034 src: /127.0.0.1:59856 dest: /127.0.0.1:43315
2020-04-02 05:09:00,638 [DataXceiver for client  at /127.0.0.1:33346 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032 src: /127.0.0.1:33346 dest: /127.0.0.1:46154
2020-04-02 05:09:00,640 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@3496c4d9] INFO  datanode.DataNode (DataNode.java:run(2566)) - DataTransfer, at 127.0.0.1:34028: Transmitted BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032 (numBytes=512) to /127.0.0.1:46154
2020-04-02 05:09:00,640 [DataXceiver for client  at /127.0.0.1:33346 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(914)) - Received BP-725857609-172.17.0.7-1585804120054:blk_1073741855_1032 src: /127.0.0.1:33346 dest: /127.0.0.1:46154 of size 512
2020-04-02 05:09:00,662 [DataXceiver for client  at /127.0.0.1:59856 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(914)) - Received BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034 src: /127.0.0.1:59856 dest: /127.0.0.1:43315 of size 512
2020-04-02 05:09:00,666 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@3c0f74c2] INFO  datanode.DataNode (DataNode.java:run(2566)) - DataTransfer, at 127.0.0.1:46154: Transmitted BP-725857609-172.17.0.7-1585804120054:blk_1073741857_1034 (numBytes=512) to /127.0.0.1:43315
2020-04-02 05:09:00,680 [DataXceiver for client  at /127.0.0.1:33344 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037 src: /127.0.0.1:33344 dest: /127.0.0.1:46154
2020-04-02 05:09:00,682 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@352b93d2] INFO  datanode.DataNode (DataNode.java:run(2566)) - DataTransfer, at 127.0.0.1:34028: Transmitted BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037 (numBytes=512) to /127.0.0.1:46154
2020-04-02 05:09:00,682 [DataXceiver for client  at /127.0.0.1:33342 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035 src: /127.0.0.1:33342 dest: /127.0.0.1:46154
2020-04-02 05:09:00,690 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@1ca4fcc1] INFO  datanode.DataNode (DataNode.java:run(2566)) - DataTransfer, at 127.0.0.1:43315: Transmitted BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035 (numBytes=512) to /127.0.0.1:46154
2020-04-02 05:09:00,695 [DataXceiver for client  at /127.0.0.1:33342 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(914)) - Received BP-725857609-172.17.0.7-1585804120054:blk_1073741858_1035 src: /127.0.0.1:33342 dest: /127.0.0.1:46154 of size 512
2020-04-02 05:09:00,698 [DataXceiver for client  at /127.0.0.1:33344 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(914)) - Received BP-725857609-172.17.0.7-1585804120054:blk_1073741860_1037 src: /127.0.0.1:33344 dest: /127.0.0.1:46154 of size 512
2020-04-02 05:09:01,311 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test20	dst=null	perm=null	proto=rpc
2020-04-02 05:09:01,313 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test20	dst=null	perm=null	proto=rpc
2020-04-02 05:09:01,315 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:01,316 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test21	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:01,317 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:01,318 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:01,318 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:01,318 [Thread-861] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:01,318 [Thread-861] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:01,319 [IPC Server handler 0 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741846_1022, replicas=127.0.0.1:40636, 127.0.0.1:37644, 127.0.0.1:42233 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test21
2020-04-02 05:09:01,320 [Thread-861] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]], blk_1073741846_1022
2020-04-02 05:09:01,320 [Thread-861] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:09:01,321 [Thread-861] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:01,322 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:60820 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022 src: /127.0.0.1:60820 dest: /127.0.0.1:40636
2020-04-02 05:09:01,323 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:40778 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022 src: /127.0.0.1:40778 dest: /127.0.0.1:37644
2020-04-02 05:09:01,324 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:57234 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022 src: /127.0.0.1:57234 dest: /127.0.0.1:42233
2020-04-02 05:09:01,330 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test21 block BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-b71b49a9-1814-47a0-997c-c432076ff5a6]
2020-04-02 05:09:01,331 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test21 block BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741846_1022 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:01,331 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test21 block BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741846_1022
2020-04-02 05:09:01,334 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1864930 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:01,338 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test21 block BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741846_1022 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:01,350 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57234, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022, duration(ns): 24668497
2020-04-02 05:09:01,351 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:01,354 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40778, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022, duration(ns): 23286347
2020-04-02 05:09:01,354 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233] terminating
2020-04-02 05:09:01,355 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60820, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022, duration(ns): 21653582
2020-04-02 05:09:01,355 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233] terminating
2020-04-02 05:09:01,358 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 10546046 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:01,362 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test21 block BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741846_1022
2020-04-02 05:09:01,370 [IPC Server handler 3 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test21 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:01,372 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test21	dst=null	perm=null	proto=rpc
2020-04-02 05:09:01,374 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test21	dst=null	perm=null	proto=rpc
2020-04-02 05:09:01,376 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:01,378 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test22	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:01,380 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:01,380 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:01,380 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:01,386 [Thread-869] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:01,386 [Thread-869] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:01,388 [IPC Server handler 1 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741847_1023, replicas=127.0.0.1:40636, 127.0.0.1:42233, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test22
2020-04-02 05:09:01,390 [Thread-869] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741847_1023
2020-04-02 05:09:01,390 [Thread-869] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:09:01,390 [Thread-869] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:01,398 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:60846 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023 src: /127.0.0.1:60846 dest: /127.0.0.1:40636
2020-04-02 05:09:01,407 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:57258 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023 src: /127.0.0.1:57258 dest: /127.0.0.1:42233
2020-04-02 05:09:01,409 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:40814 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023 src: /127.0.0.1:40814 dest: /127.0.0.1:37644
2020-04-02 05:09:01,413 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test22 block BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:09:01,413 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test22 block BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741847_1023 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:01,413 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test22 block BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741847_1023
2020-04-02 05:09:01,415 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1014322 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:01,415 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test22 block BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741847_1023 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:01,416 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40814, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023, duration(ns): 3250364
2020-04-02 05:09:01,416 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:01,418 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57258, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023, duration(ns): 4473250
2020-04-02 05:09:01,418 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60846, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023, duration(ns): 4118568
2020-04-02 05:09:01,418 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644] terminating
2020-04-02 05:09:01,419 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:09:01,419 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2629915 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:01,426 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test22 block BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741847_1023
2020-04-02 05:09:01,428 [IPC Server handler 0 on 38969] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741847_1023 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test22
2020-04-02 05:09:01,830 [IPC Server handler 2 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test22 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:01,832 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test22	dst=null	perm=null	proto=rpc
2020-04-02 05:09:01,833 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test22	dst=null	perm=null	proto=rpc
2020-04-02 05:09:01,835 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:01,837 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test23	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:01,838 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:01,838 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:01,838 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:01,838 [Thread-877] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:01,838 [Thread-877] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:01,840 [IPC Server handler 6 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741848_1024, replicas=127.0.0.1:40636, 127.0.0.1:42233, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test23
2020-04-02 05:09:01,841 [Thread-877] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741848_1024
2020-04-02 05:09:01,841 [Thread-877] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:09:01,841 [Thread-877] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:01,842 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:32816 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024 src: /127.0.0.1:32816 dest: /127.0.0.1:40636
2020-04-02 05:09:01,845 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:57458 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024 src: /127.0.0.1:57458 dest: /127.0.0.1:42233
2020-04-02 05:09:01,850 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:41008 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024 src: /127.0.0.1:41008 dest: /127.0.0.1:37644
2020-04-02 05:09:01,852 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test23 block BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:09:01,852 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test23 block BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741848_1024 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:01,852 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test23 block BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741848_1024
2020-04-02 05:09:01,854 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1354376 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:01,854 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test23 block BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741848_1024 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:01,855 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41008, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024, duration(ns): 3814062
2020-04-02 05:09:01,856 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:01,856 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57458, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024, duration(ns): 4024859
2020-04-02 05:09:01,856 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:09:01,857 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:32816, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024, duration(ns): 3835832
2020-04-02 05:09:01,857 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1708716 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:01,858 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test23 block BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024
2020-04-02 05:09:01,858 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741848_1024, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644] terminating
2020-04-02 05:09:01,859 [IPC Server handler 9 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test23 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:01,860 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test23	dst=null	perm=null	proto=rpc
2020-04-02 05:09:01,866 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test23	dst=null	perm=null	proto=rpc
2020-04-02 05:09:01,869 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:01,872 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test24	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:01,874 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:01,875 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:01,875 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:01,875 [Thread-885] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:01,875 [Thread-885] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:01,876 [IPC Server handler 5 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741849_1025, replicas=127.0.0.1:37644, 127.0.0.1:40636, 127.0.0.1:42233 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test24
2020-04-02 05:09:01,877 [Thread-885] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]], blk_1073741849_1025
2020-04-02 05:09:01,877 [Thread-885] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:37644
2020-04-02 05:09:01,877 [Thread-885] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:01,878 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:41038 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025 src: /127.0.0.1:41038 dest: /127.0.0.1:37644
2020-04-02 05:09:01,879 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:32856 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025 src: /127.0.0.1:32856 dest: /127.0.0.1:40636
2020-04-02 05:09:01,881 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:57498 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025 src: /127.0.0.1:57498 dest: /127.0.0.1:42233
2020-04-02 05:09:01,886 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test24 block BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6]
2020-04-02 05:09:01,886 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test24 block BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741849_1025 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:01,886 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test24 block BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741849_1025
2020-04-02 05:09:01,890 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1629296 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:01,893 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test24 block BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741849_1025 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:01,895 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57498, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025, duration(ns): 13122178
2020-04-02 05:09:01,896 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:01,896 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:32856, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025, duration(ns): 14435545
2020-04-02 05:09:01,896 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233] terminating
2020-04-02 05:09:01,897 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41038, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025, duration(ns): 15049642
2020-04-02 05:09:01,897 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233] terminating
2020-04-02 05:09:01,897 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2826979 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:01,897 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test24 block BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741849_1025
2020-04-02 05:09:01,903 [IPC Server handler 7 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test24 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:01,904 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test24	dst=null	perm=null	proto=rpc
2020-04-02 05:09:01,905 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test24	dst=null	perm=null	proto=rpc
2020-04-02 05:09:01,907 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:01,909 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test25	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:01,910 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:01,910 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:01,910 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:01,910 [Thread-893] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:01,910 [Thread-893] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:01,925 [IPC Server handler 4 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741850_1026, replicas=127.0.0.1:42233, 127.0.0.1:40636, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test25
2020-04-02 05:09:01,926 [Thread-893] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741850_1026
2020-04-02 05:09:01,926 [Thread-893] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:42233
2020-04-02 05:09:01,927 [Thread-893] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:01,938 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:57532 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026 src: /127.0.0.1:57532 dest: /127.0.0.1:42233
2020-04-02 05:09:01,942 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:32906 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026 src: /127.0.0.1:32906 dest: /127.0.0.1:40636
2020-04-02 05:09:01,944 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:41100 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026 src: /127.0.0.1:41100 dest: /127.0.0.1:37644
2020-04-02 05:09:01,958 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test25 block BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:09:01,962 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test25 block BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741850_1026 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:01,962 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test25 block BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741850_1026
2020-04-02 05:09:01,986 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 20097428 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:01,988 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test25 block BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741850_1026 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:01,994 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41100, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026, duration(ns): 46944841
2020-04-02 05:09:01,994 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:01,995 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:32906, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026, duration(ns): 32190632
2020-04-02 05:09:01,995 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:09:01,996 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57532, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026, duration(ns): 37564619
2020-04-02 05:09:01,997 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644] terminating
2020-04-02 05:09:01,997 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 6612584 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:01,997 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test25 block BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741850_1026
2020-04-02 05:09:01,998 [IPC Server handler 3 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test25 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:02,001 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test25	dst=null	perm=null	proto=rpc
2020-04-02 05:09:02,011 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test25	dst=null	perm=null	proto=rpc
2020-04-02 05:09:02,016 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:02,018 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test26	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:02,020 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:02,021 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:02,021 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:02,021 [Thread-901] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:02,021 [Thread-901] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:02,023 [IPC Server handler 1 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741851_1027, replicas=127.0.0.1:42233, 127.0.0.1:40636, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test26
2020-04-02 05:09:02,025 [Thread-901] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741851_1027
2020-04-02 05:09:02,025 [Thread-901] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:42233
2020-04-02 05:09:02,025 [Thread-901] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:02,039 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:57608 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027 src: /127.0.0.1:57608 dest: /127.0.0.1:42233
2020-04-02 05:09:02,046 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:32980 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027 src: /127.0.0.1:32980 dest: /127.0.0.1:40636
2020-04-02 05:09:02,054 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:41174 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027 src: /127.0.0.1:41174 dest: /127.0.0.1:37644
2020-04-02 05:09:02,082 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test26 block BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:09:02,084 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test26 block BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741851_1027 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:02,085 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test26 block BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741851_1027
2020-04-02 05:09:02,087 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2092113 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:02,090 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test26 block BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741851_1027 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:02,098 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41174, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027, duration(ns): 15680930
2020-04-02 05:09:02,099 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:02,102 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:32980, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027, duration(ns): 32463954
2020-04-02 05:09:02,102 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:09:02,105 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57608, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027, duration(ns): 21487617
2020-04-02 05:09:02,106 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644] terminating
2020-04-02 05:09:02,106 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 11293030 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:02,107 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test26 block BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741851_1027
2020-04-02 05:09:02,112 [IPC Server handler 4 on 38969] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741851_1027 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test26
2020-04-02 05:09:02,514 [IPC Server handler 3 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test26 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:02,515 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test26	dst=null	perm=null	proto=rpc
2020-04-02 05:09:02,517 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test26	dst=null	perm=null	proto=rpc
2020-04-02 05:09:02,554 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:02,558 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test27	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:02,560 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:02,560 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:02,560 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:02,561 [Thread-909] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:02,561 [Thread-909] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:02,562 [IPC Server handler 1 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741852_1028, replicas=127.0.0.1:42233, 127.0.0.1:40636, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test27
2020-04-02 05:09:02,566 [Thread-909] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741852_1028
2020-04-02 05:09:02,566 [Thread-909] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:42233
2020-04-02 05:09:02,567 [Thread-909] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:02,569 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:57868 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028 src: /127.0.0.1:57868 dest: /127.0.0.1:42233
2020-04-02 05:09:02,578 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:33230 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028 src: /127.0.0.1:33230 dest: /127.0.0.1:40636
2020-04-02 05:09:02,580 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:41428 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028 src: /127.0.0.1:41428 dest: /127.0.0.1:37644
2020-04-02 05:09:02,581 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test27 block BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:09:02,583 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test27 block BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741852_1028 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:02,583 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test27 block BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741852_1028
2020-04-02 05:09:02,585 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 821794 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:02,589 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test27 block BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741852_1028 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:02,591 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41428, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028, duration(ns): 7102012
2020-04-02 05:09:02,591 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:02,592 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33230, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028, duration(ns): 8229853
2020-04-02 05:09:02,592 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:09:02,598 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57868, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028, duration(ns): 14841792
2020-04-02 05:09:02,598 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644] terminating
2020-04-02 05:09:02,599 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 8485821 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:02,599 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test27 block BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741852_1028
2020-04-02 05:09:02,600 [IPC Server handler 4 on 38969] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741852_1028 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test27
2020-04-02 05:09:03,002 [IPC Server handler 3 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test27 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:03,007 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test27	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,009 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test27	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,012 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:03,013 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test28	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:03,015 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:03,016 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:03,016 [Thread-917] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:03,016 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:03,016 [Thread-917] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:03,017 [IPC Server handler 1 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741853_1029, replicas=127.0.0.1:40636, 127.0.0.1:42233, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test28
2020-04-02 05:09:03,018 [Thread-917] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741853_1029
2020-04-02 05:09:03,018 [Thread-917] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:09:03,018 [Thread-917] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:03,022 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:33400 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029 src: /127.0.0.1:33400 dest: /127.0.0.1:40636
2020-04-02 05:09:03,024 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58046 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029 src: /127.0.0.1:58046 dest: /127.0.0.1:42233
2020-04-02 05:09:03,025 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:41596 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029 src: /127.0.0.1:41596 dest: /127.0.0.1:37644
2020-04-02 05:09:03,030 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test28 block BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:09:03,034 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test28 block BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741853_1029 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:03,034 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test28 block BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741853_1029
2020-04-02 05:09:03,038 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 666321 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:03,039 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test28 block BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741853_1029 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:03,042 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41596, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029, duration(ns): 15970850
2020-04-02 05:09:03,042 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:03,043 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58046, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029, duration(ns): 16325405
2020-04-02 05:09:03,043 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:09:03,044 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33400, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029, duration(ns): 13099464
2020-04-02 05:09:03,044 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644] terminating
2020-04-02 05:09:03,044 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 4357139 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:03,045 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test28 block BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741853_1029
2020-04-02 05:09:03,050 [IPC Server handler 0 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test28 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:03,052 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test28	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,053 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test28	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,058 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:03,061 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test29	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:03,063 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:03,063 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:03,063 [Thread-925] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:03,063 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:03,064 [Thread-925] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:03,066 [IPC Server handler 8 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741854_1030, replicas=127.0.0.1:37644, 127.0.0.1:40636, 127.0.0.1:42233 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test29
2020-04-02 05:09:03,067 [Thread-925] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]], blk_1073741854_1030
2020-04-02 05:09:03,068 [Thread-925] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:37644
2020-04-02 05:09:03,068 [Thread-925] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:03,069 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:41624 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030 src: /127.0.0.1:41624 dest: /127.0.0.1:37644
2020-04-02 05:09:03,071 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:33438 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030 src: /127.0.0.1:33438 dest: /127.0.0.1:40636
2020-04-02 05:09:03,072 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58080 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030 src: /127.0.0.1:58080 dest: /127.0.0.1:42233
2020-04-02 05:09:03,079 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test29 block BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6]
2020-04-02 05:09:03,085 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test29 block BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741854_1030 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:03,087 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test29 block BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741854_1030
2020-04-02 05:09:03,088 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 885396 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:03,093 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test29 block BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741854_1030 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:03,095 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58080, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030, duration(ns): 21754593
2020-04-02 05:09:03,096 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:03,096 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33438, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030, duration(ns): 17118273
2020-04-02 05:09:03,096 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233] terminating
2020-04-02 05:09:03,097 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41624, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030, duration(ns): 17867475
2020-04-02 05:09:03,097 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233] terminating
2020-04-02 05:09:03,098 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1971968 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:03,098 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test29 block BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741854_1030
2020-04-02 05:09:03,099 [IPC Server handler 5 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test29 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:03,100 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test29	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,101 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test29	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,104 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:03,105 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test30	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:03,106 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:03,106 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:03,106 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:03,107 [Thread-933] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:03,107 [Thread-933] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:03,108 [IPC Server handler 2 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741855_1031, replicas=127.0.0.1:40636, 127.0.0.1:42233, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test30
2020-04-02 05:09:03,108 [Thread-933] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741855_1031
2020-04-02 05:09:03,108 [Thread-933] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:09:03,110 [Thread-933] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:03,114 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:33468 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031 src: /127.0.0.1:33468 dest: /127.0.0.1:40636
2020-04-02 05:09:03,115 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58118 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031 src: /127.0.0.1:58118 dest: /127.0.0.1:42233
2020-04-02 05:09:03,126 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:41668 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031 src: /127.0.0.1:41668 dest: /127.0.0.1:37644
2020-04-02 05:09:03,128 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test30 block BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:09:03,138 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test30 block BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741855_1031 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:03,138 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test30 block BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741855_1031
2020-04-02 05:09:03,154 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 15318968 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:03,155 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test30 block BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741855_1031 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:03,155 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41668, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031, duration(ns): 21103675
2020-04-02 05:09:03,156 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:03,156 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58118, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031, duration(ns): 4738190
2020-04-02 05:09:03,156 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:09:03,157 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33468, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031, duration(ns): 17677740
2020-04-02 05:09:03,157 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644] terminating
2020-04-02 05:09:03,157 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1488631 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:03,158 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test30 block BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741855_1031
2020-04-02 05:09:03,158 [IPC Server handler 6 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test30 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:03,159 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test30	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,160 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test30	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,161 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:03,162 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test31	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:03,163 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:03,164 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:03,164 [Thread-941] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:03,164 [Thread-941] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:03,164 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:03,166 [IPC Server handler 9 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741856_1032, replicas=127.0.0.1:40636, 127.0.0.1:37644, 127.0.0.1:42233 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test31
2020-04-02 05:09:03,170 [Thread-941] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]], blk_1073741856_1032
2020-04-02 05:09:03,170 [Thread-941] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:09:03,170 [Thread-941] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:03,180 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:33506 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032 src: /127.0.0.1:33506 dest: /127.0.0.1:40636
2020-04-02 05:09:03,184 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:41702 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032 src: /127.0.0.1:41702 dest: /127.0.0.1:37644
2020-04-02 05:09:03,189 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58156 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032 src: /127.0.0.1:58156 dest: /127.0.0.1:42233
2020-04-02 05:09:03,194 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test31 block BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-b71b49a9-1814-47a0-997c-c432076ff5a6]
2020-04-02 05:09:03,195 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test31 block BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741856_1032 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:03,196 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test31 block BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741856_1032
2020-04-02 05:09:03,201 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 4716356 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:03,201 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test31 block BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741856_1032 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:03,202 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58156, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032, duration(ns): 11590231
2020-04-02 05:09:03,202 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:03,203 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41702, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032, duration(ns): 10084245
2020-04-02 05:09:03,203 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233] terminating
2020-04-02 05:09:03,205 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33506, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032, duration(ns): 11269142
2020-04-02 05:09:03,205 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233] terminating
2020-04-02 05:09:03,206 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2765328 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:03,206 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test31 block BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741856_1032
2020-04-02 05:09:03,207 [IPC Server handler 4 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test31 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:03,209 [IPC Server handler 6 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test31	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,211 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test31	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,213 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:03,215 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test32	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:03,216 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:03,217 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:03,217 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:03,217 [Thread-949] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:03,217 [Thread-949] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:03,218 [IPC Server handler 7 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741857_1033, replicas=127.0.0.1:37644, 127.0.0.1:42233, 127.0.0.1:40636 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test32
2020-04-02 05:09:03,219 [Thread-949] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]], blk_1073741857_1033
2020-04-02 05:09:03,219 [Thread-949] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:37644
2020-04-02 05:09:03,219 [Thread-949] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:03,222 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:41730 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033 src: /127.0.0.1:41730 dest: /127.0.0.1:37644
2020-04-02 05:09:03,225 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58186 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033 src: /127.0.0.1:58186 dest: /127.0.0.1:42233
2020-04-02 05:09:03,226 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:33550 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033 src: /127.0.0.1:33550 dest: /127.0.0.1:40636
2020-04-02 05:09:03,228 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test32 block BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1]
2020-04-02 05:09:03,229 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test32 block BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741857_1033 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:03,229 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test32 block BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741857_1033
2020-04-02 05:09:03,246 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1158990 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:03,247 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test32 block BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741857_1033 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:03,253 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33550, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033, duration(ns): 20137931
2020-04-02 05:09:03,253 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:03,255 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58186, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033, duration(ns): 26844060
2020-04-02 05:09:03,255 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636] terminating
2020-04-02 05:09:03,258 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41730, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033, duration(ns): 27422493
2020-04-02 05:09:03,268 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 10466804 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:03,268 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:40636] terminating
2020-04-02 05:09:03,269 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test32 block BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741857_1033
2020-04-02 05:09:03,270 [IPC Server handler 1 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test32 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:03,271 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test32	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,273 [IPC Server handler 6 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test32	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,275 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:03,276 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test33	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:03,278 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:03,278 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:03,278 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:03,281 [Thread-957] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:03,282 [Thread-957] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:03,291 [IPC Server handler 3 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741858_1034, replicas=127.0.0.1:37644, 127.0.0.1:42233, 127.0.0.1:40636 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test33
2020-04-02 05:09:03,298 [Thread-957] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]], blk_1073741858_1034
2020-04-02 05:09:03,298 [Thread-957] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:37644
2020-04-02 05:09:03,298 [Thread-957] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:03,300 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:41768 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034 src: /127.0.0.1:41768 dest: /127.0.0.1:37644
2020-04-02 05:09:03,302 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58224 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034 src: /127.0.0.1:58224 dest: /127.0.0.1:42233
2020-04-02 05:09:03,306 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:33588 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034 src: /127.0.0.1:33588 dest: /127.0.0.1:40636
2020-04-02 05:09:03,312 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test33 block BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1]
2020-04-02 05:09:03,321 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test33 block BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741858_1034 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:03,322 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test33 block BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741858_1034
2020-04-02 05:09:03,330 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 6324467 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:03,330 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test33 block BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741858_1034 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:03,332 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33588, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034, duration(ns): 18497823
2020-04-02 05:09:03,333 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:03,333 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58224, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034, duration(ns): 8889731
2020-04-02 05:09:03,334 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636] terminating
2020-04-02 05:09:03,338 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41768, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034, duration(ns): 7995591
2020-04-02 05:09:03,338 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:40636] terminating
2020-04-02 05:09:03,339 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741858_1034] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 6228302 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:03,348 [IPC Server handler 2 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test33 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:03,351 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test33	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,352 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test33	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,354 [IPC Server handler 6 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:03,355 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test34	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:03,357 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:03,357 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:03,358 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:03,358 [Thread-965] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:03,359 [Thread-965] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:03,360 [IPC Server handler 0 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741859_1035, replicas=127.0.0.1:37644, 127.0.0.1:40636, 127.0.0.1:42233 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test34
2020-04-02 05:09:03,362 [Thread-965] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]], blk_1073741859_1035
2020-04-02 05:09:03,362 [Thread-965] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:37644
2020-04-02 05:09:03,363 [Thread-965] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:03,364 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:41794 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035 src: /127.0.0.1:41794 dest: /127.0.0.1:37644
2020-04-02 05:09:03,366 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:33608 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035 src: /127.0.0.1:33608 dest: /127.0.0.1:40636
2020-04-02 05:09:03,369 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58254 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035 src: /127.0.0.1:58254 dest: /127.0.0.1:42233
2020-04-02 05:09:03,371 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test34 block BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6]
2020-04-02 05:09:03,374 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test34 block BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741859_1035 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:03,374 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test34 block BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741859_1035
2020-04-02 05:09:03,380 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 5102639 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:03,385 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test34 block BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741859_1035 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:03,392 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58254, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035, duration(ns): 17883392
2020-04-02 05:09:03,392 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:03,393 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33608, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035, duration(ns): 16432316
2020-04-02 05:09:03,393 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233] terminating
2020-04-02 05:09:03,394 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41794, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035, duration(ns): 19210062
2020-04-02 05:09:03,395 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2570787 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:03,395 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test34 block BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035
2020-04-02 05:09:03,395 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741859_1035, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233] terminating
2020-04-02 05:09:03,396 [IPC Server handler 9 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test34 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:03,399 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test34	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,400 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test34	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,402 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:03,404 [IPC Server handler 6 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test35	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:03,406 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:03,406 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:03,406 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:03,406 [Thread-973] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:03,406 [Thread-973] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:03,408 [IPC Server handler 5 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741860_1036, replicas=127.0.0.1:42233, 127.0.0.1:37644, 127.0.0.1:40636 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test35
2020-04-02 05:09:03,412 [Thread-973] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]], blk_1073741860_1036
2020-04-02 05:09:03,412 [Thread-973] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:42233
2020-04-02 05:09:03,414 [Thread-973] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:03,415 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58284 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036 src: /127.0.0.1:58284 dest: /127.0.0.1:42233
2020-04-02 05:09:03,422 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:41834 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036 src: /127.0.0.1:41834 dest: /127.0.0.1:37644
2020-04-02 05:09:03,434 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:33654 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036 src: /127.0.0.1:33654 dest: /127.0.0.1:40636
2020-04-02 05:09:03,439 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test35 block BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1]
2020-04-02 05:09:03,443 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test35 block BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741860_1036 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:03,443 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test35 block BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741860_1036
2020-04-02 05:09:03,446 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1987480 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:03,447 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test35 block BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741860_1036 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:03,448 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33654, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036, duration(ns): 12933236
2020-04-02 05:09:03,449 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:03,450 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41834, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036, duration(ns): 7957071
2020-04-02 05:09:03,450 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636] terminating
2020-04-02 05:09:03,454 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58284, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036, duration(ns): 9409434
2020-04-02 05:09:03,455 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636] terminating
2020-04-02 05:09:03,455 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 5739900 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:03,455 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test35 block BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741860_1036
2020-04-02 05:09:03,456 [IPC Server handler 8 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test35 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:03,459 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test35	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,460 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test35	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,461 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:03,463 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test36	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:03,467 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:03,468 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:03,468 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:03,468 [Thread-981] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:03,468 [Thread-981] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:03,477 [IPC Server handler 6 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741861_1037, replicas=127.0.0.1:40636, 127.0.0.1:37644, 127.0.0.1:42233 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test36
2020-04-02 05:09:03,482 [Thread-981] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]], blk_1073741861_1037
2020-04-02 05:09:03,482 [Thread-981] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:09:03,482 [Thread-981] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:03,497 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:33682 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037 src: /127.0.0.1:33682 dest: /127.0.0.1:40636
2020-04-02 05:09:03,498 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:41876 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037 src: /127.0.0.1:41876 dest: /127.0.0.1:37644
2020-04-02 05:09:03,500 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58330 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037 src: /127.0.0.1:58330 dest: /127.0.0.1:42233
2020-04-02 05:09:03,501 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test36 block BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-b71b49a9-1814-47a0-997c-c432076ff5a6]
2020-04-02 05:09:03,501 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test36 block BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741861_1037 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:03,501 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test36 block BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741861_1037
2020-04-02 05:09:03,502 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 609060 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:03,502 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test36 block BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741861_1037 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:03,503 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58330, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037, duration(ns): 1956347
2020-04-02 05:09:03,503 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:03,504 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41876, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037, duration(ns): 2937255
2020-04-02 05:09:03,504 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233] terminating
2020-04-02 05:09:03,505 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33682, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037, duration(ns): 3482138
2020-04-02 05:09:03,505 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233] terminating
2020-04-02 05:09:03,505 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1865347 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:03,505 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test36 block BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741861_1037
2020-04-02 05:09:03,507 [IPC Server handler 7 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test36 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:03,510 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test36	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,511 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test36	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,513 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:03,514 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test37	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:03,516 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:03,516 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:03,516 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:03,518 [Thread-989] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:03,518 [Thread-989] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:03,522 [IPC Server handler 4 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741862_1038, replicas=127.0.0.1:40636, 127.0.0.1:42233, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test37
2020-04-02 05:09:03,524 [Thread-989] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741862_1038
2020-04-02 05:09:03,524 [Thread-989] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:09:03,525 [Thread-989] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:03,526 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:33708 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038 src: /127.0.0.1:33708 dest: /127.0.0.1:40636
2020-04-02 05:09:03,527 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58350 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038 src: /127.0.0.1:58350 dest: /127.0.0.1:42233
2020-04-02 05:09:03,530 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:41902 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038 src: /127.0.0.1:41902 dest: /127.0.0.1:37644
2020-04-02 05:09:03,532 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test37 block BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:09:03,533 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test37 block BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741862_1038 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:03,533 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test37 block BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741862_1038
2020-04-02 05:09:03,535 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1742051 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:03,535 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test37 block BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741862_1038 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:03,537 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41902, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038, duration(ns): 5309675
2020-04-02 05:09:03,537 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:03,538 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58350, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038, duration(ns): 6513852
2020-04-02 05:09:03,538 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:09:03,539 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33708, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038, duration(ns): 5747833
2020-04-02 05:09:03,539 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644] terminating
2020-04-02 05:09:03,539 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2586344 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:03,539 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test37 block BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741862_1038
2020-04-02 05:09:03,540 [IPC Server handler 0 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test37 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:03,541 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test37	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,542 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test37	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,543 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:03,545 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test38	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:03,546 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:03,546 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:03,546 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:03,546 [Thread-997] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:03,546 [Thread-997] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:03,547 [IPC Server handler 1 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741863_1039, replicas=127.0.0.1:40636, 127.0.0.1:42233, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test38
2020-04-02 05:09:03,548 [Thread-997] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741863_1039
2020-04-02 05:09:03,548 [Thread-997] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:09:03,549 [Thread-997] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:03,558 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:33724 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039 src: /127.0.0.1:33724 dest: /127.0.0.1:40636
2020-04-02 05:09:03,561 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58372 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039 src: /127.0.0.1:58372 dest: /127.0.0.1:42233
2020-04-02 05:09:03,563 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:41928 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039 src: /127.0.0.1:41928 dest: /127.0.0.1:37644
2020-04-02 05:09:03,575 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test38 block BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:09:03,582 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test38 block BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741863_1039 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:03,582 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test38 block BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741863_1039
2020-04-02 05:09:03,586 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1920931 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:03,586 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test38 block BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741863_1039 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:03,587 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41928, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039, duration(ns): 5165566
2020-04-02 05:09:03,587 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:03,588 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58372, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039, duration(ns): 2666540
2020-04-02 05:09:03,588 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33724, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039, duration(ns): 4769484
2020-04-02 05:09:03,589 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644] terminating
2020-04-02 05:09:03,589 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:09:03,589 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1704976 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:03,589 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test38 block BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741863_1039
2020-04-02 05:09:03,590 [IPC Server handler 4 on 38969] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741863_1039 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test38
2020-04-02 05:09:03,994 [IPC Server handler 3 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test38 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:03,995 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test38	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,996 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test38	dst=null	perm=null	proto=rpc
2020-04-02 05:09:03,998 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:03,999 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test39	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:04,000 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:04,000 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:04,000 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:04,000 [Thread-1005] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:04,001 [Thread-1005] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:04,002 [IPC Server handler 1 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741864_1040, replicas=127.0.0.1:42233, 127.0.0.1:37644, 127.0.0.1:40636 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test39
2020-04-02 05:09:04,003 [Thread-1005] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]], blk_1073741864_1040
2020-04-02 05:09:04,003 [Thread-1005] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:42233
2020-04-02 05:09:04,003 [Thread-1005] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:04,004 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58550 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040 src: /127.0.0.1:58550 dest: /127.0.0.1:42233
2020-04-02 05:09:04,006 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:42100 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040 src: /127.0.0.1:42100 dest: /127.0.0.1:37644
2020-04-02 05:09:04,007 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:33914 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040 src: /127.0.0.1:33914 dest: /127.0.0.1:40636
2020-04-02 05:09:04,009 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test39 block BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1]
2020-04-02 05:09:04,013 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test39 block BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741864_1040 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:04,013 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test39 block BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741864_1040
2020-04-02 05:09:04,018 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 4288515 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:04,018 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test39 block BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741864_1040 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:04,022 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33914, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040, duration(ns): 13367145
2020-04-02 05:09:04,022 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:04,023 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42100, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040, duration(ns): 14603384
2020-04-02 05:09:04,024 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636] terminating
2020-04-02 05:09:04,025 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58550, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040, duration(ns): 11721145
2020-04-02 05:09:04,025 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636] terminating
2020-04-02 05:09:04,033 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 3127311 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:04,034 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test39 block BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741864_1040
2020-04-02 05:09:04,037 [IPC Server handler 5 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test39 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:04,039 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test39	dst=null	perm=null	proto=rpc
2020-04-02 05:09:04,040 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test39	dst=null	perm=null	proto=rpc
2020-04-02 05:09:04,047 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:04,058 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test40	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:04,061 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:04,061 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:04,061 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:04,061 [Thread-1013] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:04,061 [Thread-1013] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:04,063 [IPC Server handler 2 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741865_1041, replicas=127.0.0.1:40636, 127.0.0.1:37644, 127.0.0.1:42233 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test40
2020-04-02 05:09:04,064 [Thread-1013] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]], blk_1073741865_1041
2020-04-02 05:09:04,064 [Thread-1013] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:09:04,064 [Thread-1013] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:04,066 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:33952 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041 src: /127.0.0.1:33952 dest: /127.0.0.1:40636
2020-04-02 05:09:04,074 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:42144 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041 src: /127.0.0.1:42144 dest: /127.0.0.1:37644
2020-04-02 05:09:04,075 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58606 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041 src: /127.0.0.1:58606 dest: /127.0.0.1:42233
2020-04-02 05:09:04,078 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test40 block BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-b71b49a9-1814-47a0-997c-c432076ff5a6]
2020-04-02 05:09:04,080 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test40 block BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741865_1041 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:04,081 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test40 block BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741865_1041
2020-04-02 05:09:04,088 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1272597 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:04,089 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test40 block BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741865_1041 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:04,091 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58606, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041, duration(ns): 13997283
2020-04-02 05:09:04,091 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:04,092 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42144, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041, duration(ns): 10950200
2020-04-02 05:09:04,092 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233] terminating
2020-04-02 05:09:04,093 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33952, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041, duration(ns): 11417601
2020-04-02 05:09:04,093 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233] terminating
2020-04-02 05:09:04,098 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 3625958 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:04,098 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test40 block BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741865_1041
2020-04-02 05:09:04,106 [IPC Server handler 4 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test40 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:04,107 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test40	dst=null	perm=null	proto=rpc
2020-04-02 05:09:04,109 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test40	dst=null	perm=null	proto=rpc
2020-04-02 05:09:04,111 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:04,121 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test41	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:04,123 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:04,124 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:04,124 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:04,124 [Thread-1021] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:04,124 [Thread-1021] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:04,125 [IPC Server handler 9 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741866_1042, replicas=127.0.0.1:40636, 127.0.0.1:42233, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test41
2020-04-02 05:09:04,131 [Thread-1021] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741866_1042
2020-04-02 05:09:04,132 [Thread-1021] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:09:04,132 [Thread-1021] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:04,135 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:34016 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042 src: /127.0.0.1:34016 dest: /127.0.0.1:40636
2020-04-02 05:09:04,138 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58660 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042 src: /127.0.0.1:58660 dest: /127.0.0.1:42233
2020-04-02 05:09:04,140 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:42210 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042 src: /127.0.0.1:42210 dest: /127.0.0.1:37644
2020-04-02 05:09:04,141 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test41 block BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:09:04,144 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test41 block BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741866_1042 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:04,144 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test41 block BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741866_1042
2020-04-02 05:09:04,147 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1367935 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:04,147 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test41 block BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741866_1042 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:04,150 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42210, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042, duration(ns): 8564026
2020-04-02 05:09:04,150 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:04,152 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58660, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042, duration(ns): 9967811
2020-04-02 05:09:04,152 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:09:04,156 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34016, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042, duration(ns): 13031224
2020-04-02 05:09:04,156 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644] terminating
2020-04-02 05:09:04,156 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 5488096 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:04,156 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test41 block BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741866_1042
2020-04-02 05:09:04,157 [IPC Server handler 0 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test41 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:04,158 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test41	dst=null	perm=null	proto=rpc
2020-04-02 05:09:04,159 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test41	dst=null	perm=null	proto=rpc
2020-04-02 05:09:04,161 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:04,162 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test42	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:04,163 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:04,163 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:04,163 [Thread-1029] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:04,163 [Thread-1029] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:04,163 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:04,165 [IPC Server handler 8 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741867_1043, replicas=127.0.0.1:40636, 127.0.0.1:42233, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test42
2020-04-02 05:09:04,165 [Thread-1029] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741867_1043
2020-04-02 05:09:04,165 [Thread-1029] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:09:04,166 [Thread-1029] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:04,166 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:34036 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043 src: /127.0.0.1:34036 dest: /127.0.0.1:40636
2020-04-02 05:09:04,167 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58678 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043 src: /127.0.0.1:58678 dest: /127.0.0.1:42233
2020-04-02 05:09:04,168 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:42228 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043 src: /127.0.0.1:42228 dest: /127.0.0.1:37644
2020-04-02 05:09:04,169 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test42 block BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:09:04,169 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test42 block BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741867_1043 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:04,169 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test42 block BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741867_1043
2020-04-02 05:09:04,170 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 476482 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:04,170 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test42 block BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741867_1043 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:04,171 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42228, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043, duration(ns): 1832983
2020-04-02 05:09:04,171 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:04,172 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58678, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043, duration(ns): 2993921
2020-04-02 05:09:04,173 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:09:04,173 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34036, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043, duration(ns): 3495964
2020-04-02 05:09:04,173 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644] terminating
2020-04-02 05:09:04,173 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2068621 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:04,173 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test42 block BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741867_1043
2020-04-02 05:09:04,176 [IPC Server handler 6 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test42 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:04,177 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test42	dst=null	perm=null	proto=rpc
2020-04-02 05:09:04,186 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test42	dst=null	perm=null	proto=rpc
2020-04-02 05:09:04,194 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:04,199 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test43	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:04,210 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:04,210 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:04,210 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:04,210 [Thread-1037] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:04,210 [Thread-1037] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:04,212 [IPC Server handler 7 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741868_1044, replicas=127.0.0.1:40636, 127.0.0.1:37644, 127.0.0.1:42233 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test43
2020-04-02 05:09:04,212 [Thread-1037] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]], blk_1073741868_1044
2020-04-02 05:09:04,212 [Thread-1037] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:09:04,213 [Thread-1037] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:04,216 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:34048 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044 src: /127.0.0.1:34048 dest: /127.0.0.1:40636
2020-04-02 05:09:04,222 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:42238 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044 src: /127.0.0.1:42238 dest: /127.0.0.1:37644
2020-04-02 05:09:04,230 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58696 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044 src: /127.0.0.1:58696 dest: /127.0.0.1:42233
2020-04-02 05:09:04,250 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test43 block BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-b71b49a9-1814-47a0-997c-c432076ff5a6]
2020-04-02 05:09:04,254 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test43 block BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741868_1044 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:04,254 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test43 block BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741868_1044
2020-04-02 05:09:04,255 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 817610 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:04,258 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test43 block BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741868_1044 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:04,259 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58696, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044, duration(ns): 27985321
2020-04-02 05:09:04,260 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:04,261 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42238, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044, duration(ns): 29773745
2020-04-02 05:09:04,262 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233] terminating
2020-04-02 05:09:04,262 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34048, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044, duration(ns): 10723831
2020-04-02 05:09:04,262 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233] terminating
2020-04-02 05:09:04,263 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 3074035 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:04,266 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test43 block BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741868_1044
2020-04-02 05:09:04,266 [IPC Server handler 1 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test43 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:04,278 [IPC Server handler 6 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test43	dst=null	perm=null	proto=rpc
2020-04-02 05:09:04,282 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test43	dst=null	perm=null	proto=rpc
2020-04-02 05:09:04,284 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:04,285 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test44	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:04,287 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:04,287 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:04,287 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:04,294 [Thread-1045] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:04,294 [Thread-1045] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:04,295 [IPC Server handler 3 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741869_1045, replicas=127.0.0.1:42233, 127.0.0.1:40636, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test44
2020-04-02 05:09:04,310 [Thread-1045] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741869_1045
2020-04-02 05:09:04,310 [Thread-1045] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:42233
2020-04-02 05:09:04,310 [Thread-1045] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:04,311 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:58772 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045 src: /127.0.0.1:58772 dest: /127.0.0.1:42233
2020-04-02 05:09:04,322 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:34134 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045 src: /127.0.0.1:34134 dest: /127.0.0.1:40636
2020-04-02 05:09:04,327 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:42328 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045 src: /127.0.0.1:42328 dest: /127.0.0.1:37644
2020-04-02 05:09:04,333 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test44 block BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:09:04,334 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test44 block BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741869_1045 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:04,334 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test44 block BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741869_1045
2020-04-02 05:09:04,343 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 4688839 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:04,344 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test44 block BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741869_1045 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:04,345 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42328, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045, duration(ns): 16302686
2020-04-02 05:09:04,345 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:04,346 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34134, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045, duration(ns): 3813215
2020-04-02 05:09:04,347 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58772, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045, duration(ns): 16429696
2020-04-02 05:09:04,347 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644] terminating
2020-04-02 05:09:04,347 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:09:04,347 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2187093 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:04,350 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test44 block BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741869_1045
2020-04-02 05:09:04,351 [IPC Server handler 7 on 38969] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741869_1045 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test44
2020-04-02 05:09:04,752 [IPC Server handler 4 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test44 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:04,753 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test44	dst=null	perm=null	proto=rpc
2020-04-02 05:09:04,756 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test44	dst=null	perm=null	proto=rpc
2020-04-02 05:09:04,758 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:04,760 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test45	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:04,761 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:04,761 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:04,761 [Thread-1054] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:04,761 [Thread-1054] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:04,761 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:04,763 [IPC Server handler 2 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741870_1046, replicas=127.0.0.1:42233, 127.0.0.1:37644, 127.0.0.1:40636 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test45
2020-04-02 05:09:04,764 [Thread-1054] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]], blk_1073741870_1046
2020-04-02 05:09:04,764 [Thread-1054] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:42233
2020-04-02 05:09:04,764 [Thread-1054] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:04,765 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:59076 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046 src: /127.0.0.1:59076 dest: /127.0.0.1:42233
2020-04-02 05:09:04,767 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:42626 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046 src: /127.0.0.1:42626 dest: /127.0.0.1:37644
2020-04-02 05:09:04,771 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:34442 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046 src: /127.0.0.1:34442 dest: /127.0.0.1:40636
2020-04-02 05:09:04,774 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test45 block BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1]
2020-04-02 05:09:04,786 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test45 block BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741870_1046 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:04,790 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test45 block BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741870_1046
2020-04-02 05:09:04,798 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 4624054 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:04,800 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test45 block BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741870_1046 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:04,810 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34442, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046, duration(ns): 37933581
2020-04-02 05:09:04,810 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:04,811 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42626, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046, duration(ns): 29021005
2020-04-02 05:09:04,811 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636] terminating
2020-04-02 05:09:04,814 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59076, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046, duration(ns): 24059755
2020-04-02 05:09:04,814 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636] terminating
2020-04-02 05:09:04,814 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 11104389 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:04,815 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test45 block BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741870_1046
2020-04-02 05:09:04,818 [IPC Server handler 1 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test45 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:04,821 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test45	dst=null	perm=null	proto=rpc
2020-04-02 05:09:04,823 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test45	dst=null	perm=null	proto=rpc
2020-04-02 05:09:04,826 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:04,827 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test46	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:04,834 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:04,834 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:04,836 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:04,837 [Thread-1062] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:04,838 [Thread-1062] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:04,839 [IPC Server handler 8 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741871_1047, replicas=127.0.0.1:42233, 127.0.0.1:37644, 127.0.0.1:40636 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test46
2020-04-02 05:09:04,841 [Thread-1062] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]], blk_1073741871_1047
2020-04-02 05:09:04,841 [Thread-1062] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:42233
2020-04-02 05:09:04,841 [Thread-1062] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:04,846 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:59138 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047 src: /127.0.0.1:59138 dest: /127.0.0.1:42233
2020-04-02 05:09:04,850 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:42690 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047 src: /127.0.0.1:42690 dest: /127.0.0.1:37644
2020-04-02 05:09:04,859 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:34504 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047 src: /127.0.0.1:34504 dest: /127.0.0.1:40636
2020-04-02 05:09:04,862 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test46 block BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1]
2020-04-02 05:09:04,866 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test46 block BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741871_1047 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:04,873 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test46 block BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741871_1047
2020-04-02 05:09:04,882 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 4615918 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:04,883 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test46 block BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741871_1047 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:04,884 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34504, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047, duration(ns): 14548146
2020-04-02 05:09:04,885 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:04,886 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42690, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047, duration(ns): 22689266
2020-04-02 05:09:04,886 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636] terminating
2020-04-02 05:09:04,887 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59138, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047, duration(ns): 13557775
2020-04-02 05:09:04,894 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636] terminating
2020-04-02 05:09:04,898 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2729935 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:04,903 [IPC Server handler 6 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test46 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:04,903 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test46 block BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741871_1047
2020-04-02 05:09:04,910 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test46	dst=null	perm=null	proto=rpc
2020-04-02 05:09:04,911 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test46	dst=null	perm=null	proto=rpc
2020-04-02 05:09:04,913 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:04,916 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test47	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:04,922 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:04,922 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:04,922 [Thread-1070] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:04,923 [Thread-1070] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:04,923 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:04,926 [IPC Server handler 7 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741872_1048, replicas=127.0.0.1:42233, 127.0.0.1:40636, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test47
2020-04-02 05:09:04,928 [Thread-1070] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741872_1048
2020-04-02 05:09:04,928 [Thread-1070] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:42233
2020-04-02 05:09:04,931 [Thread-1070] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:04,958 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:59174 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048 src: /127.0.0.1:59174 dest: /127.0.0.1:42233
2020-04-02 05:09:04,966 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:34548 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048 src: /127.0.0.1:34548 dest: /127.0.0.1:40636
2020-04-02 05:09:04,974 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:42740 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048 src: /127.0.0.1:42740 dest: /127.0.0.1:37644
2020-04-02 05:09:04,978 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test47 block BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:09:04,996 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test47 block BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741872_1048 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:04,996 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test47 block BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741872_1048
2020-04-02 05:09:05,002 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 5972491 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:05,007 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test47 block BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741872_1048 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:05,013 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42740, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048, duration(ns): 36898423
2020-04-02 05:09:05,013 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:05,014 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34548, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048, duration(ns): 25470147
2020-04-02 05:09:05,014 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:09:05,017 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59174, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048, duration(ns): 25634411
2020-04-02 05:09:05,017 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 9082043 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:05,017 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644] terminating
2020-04-02 05:09:05,017 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test47 block BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741872_1048
2020-04-02 05:09:05,018 [IPC Server handler 1 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test47 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:05,022 [IPC Server handler 6 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test47	dst=null	perm=null	proto=rpc
2020-04-02 05:09:05,023 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test47	dst=null	perm=null	proto=rpc
2020-04-02 05:09:05,025 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:05,030 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test48	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:05,032 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:05,032 [Thread-1078] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:05,032 [Thread-1078] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:05,032 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:05,032 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:05,033 [IPC Server handler 3 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741873_1049, replicas=127.0.0.1:40636, 127.0.0.1:37644, 127.0.0.1:42233 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test48
2020-04-02 05:09:05,036 [Thread-1078] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]], blk_1073741873_1049
2020-04-02 05:09:05,036 [Thread-1078] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:09:05,037 [Thread-1078] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:05,040 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:34602 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049 src: /127.0.0.1:34602 dest: /127.0.0.1:40636
2020-04-02 05:09:05,046 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:42792 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049 src: /127.0.0.1:42792 dest: /127.0.0.1:37644
2020-04-02 05:09:05,050 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:59252 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049 src: /127.0.0.1:59252 dest: /127.0.0.1:42233
2020-04-02 05:09:05,052 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test48 block BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-b71b49a9-1814-47a0-997c-c432076ff5a6]
2020-04-02 05:09:05,056 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test48 block BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741873_1049 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:05,056 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test48 block BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741873_1049
2020-04-02 05:09:05,070 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 736617 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:05,070 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test48 block BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741873_1049 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:05,075 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59252, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049, duration(ns): 23019951
2020-04-02 05:09:05,075 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:05,080 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42792, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049, duration(ns): 17600879
2020-04-02 05:09:05,080 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233] terminating
2020-04-02 05:09:05,080 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34602, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049, duration(ns): 17305563
2020-04-02 05:09:05,081 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:42233] terminating
2020-04-02 05:09:05,081 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 7334296 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:05,082 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test48 block BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741873_1049
2020-04-02 05:09:05,086 [IPC Server handler 9 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test48 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:05,087 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test48	dst=null	perm=null	proto=rpc
2020-04-02 05:09:05,089 [IPC Server handler 6 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test48	dst=null	perm=null	proto=rpc
2020-04-02 05:09:05,091 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:05,092 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test49	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:05,093 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:05,095 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:05,095 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:05,095 [Thread-1086] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:05,095 [Thread-1086] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:05,096 [IPC Server handler 5 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741874_1050, replicas=127.0.0.1:37644, 127.0.0.1:42233, 127.0.0.1:40636 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test49
2020-04-02 05:09:05,097 [Thread-1086] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]], blk_1073741874_1050
2020-04-02 05:09:05,097 [Thread-1086] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:37644
2020-04-02 05:09:05,097 [Thread-1086] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:05,098 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:42842 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050 src: /127.0.0.1:42842 dest: /127.0.0.1:37644
2020-04-02 05:09:05,100 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:59296 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050 src: /127.0.0.1:59296 dest: /127.0.0.1:42233
2020-04-02 05:09:05,101 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:34658 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050 src: /127.0.0.1:34658 dest: /127.0.0.1:40636
2020-04-02 05:09:05,102 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test49 block BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1]
2020-04-02 05:09:05,102 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test49 block BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741874_1050 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:05,103 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test49 block BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741874_1050
2020-04-02 05:09:05,104 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1298684 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:05,105 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test49 block BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741874_1050 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:05,106 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34658, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050, duration(ns): 3745758
2020-04-02 05:09:05,106 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:05,107 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59296, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050, duration(ns): 4480228
2020-04-02 05:09:05,107 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636] terminating
2020-04-02 05:09:05,107 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42842, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050, duration(ns): 5374546
2020-04-02 05:09:05,108 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:40636] terminating
2020-04-02 05:09:05,108 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2025220 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:05,109 [IPC Server handler 2 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test49 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:05,109 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test49 block BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741874_1050
2020-04-02 05:09:05,110 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test49	dst=null	perm=null	proto=rpc
2020-04-02 05:09:05,111 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test49	dst=null	perm=null	proto=rpc
2020-04-02 05:09:05,112 [IPC Server handler 6 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:05,113 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test50	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:05,114 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:05,114 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:05,114 [Thread-1094] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:05,114 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:05,114 [Thread-1094] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:05,115 [IPC Server handler 0 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741875_1051, replicas=127.0.0.1:42233, 127.0.0.1:40636, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test50
2020-04-02 05:09:05,116 [Thread-1094] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741875_1051
2020-04-02 05:09:05,116 [Thread-1094] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:42233
2020-04-02 05:09:05,116 [Thread-1094] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:05,117 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:59304 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051 src: /127.0.0.1:59304 dest: /127.0.0.1:42233
2020-04-02 05:09:05,118 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:34666 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051 src: /127.0.0.1:34666 dest: /127.0.0.1:40636
2020-04-02 05:09:05,122 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:42856 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051 src: /127.0.0.1:42856 dest: /127.0.0.1:37644
2020-04-02 05:09:05,125 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test50 block BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:09:05,125 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test50 block BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741875_1051 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:05,125 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test50 block BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741875_1051
2020-04-02 05:09:05,127 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1411509 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:05,129 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test50 block BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741875_1051 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:05,132 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42856, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051, duration(ns): 7988185
2020-04-02 05:09:05,132 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:05,133 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34666, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051, duration(ns): 7126200
2020-04-02 05:09:05,133 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59304, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051, duration(ns): 8351004
2020-04-02 05:09:05,134 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:37644] terminating
2020-04-02 05:09:05,134 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 4035600 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:05,134 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:09:05,134 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test50 block BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741875_1051
2020-04-02 05:09:05,135 [IPC Server handler 8 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test50 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:05,138 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test50	dst=null	perm=null	proto=rpc
2020-04-02 05:09:05,141 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test50	dst=null	perm=null	proto=rpc
2020-04-02 05:09:05,143 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:05,150 [IPC Server handler 6 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test51	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:05,151 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:05,151 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:05,151 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:05,151 [Thread-1102] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:05,151 [Thread-1102] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:05,154 [IPC Server handler 4 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741876_1052, replicas=127.0.0.1:40636, 127.0.0.1:42233, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test51
2020-04-02 05:09:05,155 [Thread-1102] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741876_1052
2020-04-02 05:09:05,156 [Thread-1102] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:09:05,156 [Thread-1102] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:05,162 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:34698 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052 src: /127.0.0.1:34698 dest: /127.0.0.1:40636
2020-04-02 05:09:05,164 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:59350 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052 src: /127.0.0.1:59350 dest: /127.0.0.1:42233
2020-04-02 05:09:05,165 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:42904 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052 src: /127.0.0.1:42904 dest: /127.0.0.1:37644
2020-04-02 05:09:05,174 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test51 block BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:09:05,175 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test51 block BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741876_1052 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:05,176 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test51 block BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741876_1052
2020-04-02 05:09:05,178 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 849577 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:05,182 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test51 block BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741876_1052 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:05,190 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42904, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052, duration(ns): 23841370
2020-04-02 05:09:05,190 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:05,192 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59350, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052, duration(ns): 24652004
2020-04-02 05:09:05,192 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:09:05,194 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34698, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052, duration(ns): 17796414
2020-04-02 05:09:05,194 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644] terminating
2020-04-02 05:09:05,195 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741876_1052] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 4432598 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:05,196 [IPC Server handler 5 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test51 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:05,199 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test51	dst=null	perm=null	proto=rpc
2020-04-02 05:09:05,200 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test51	dst=null	perm=null	proto=rpc
2020-04-02 05:09:05,202 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:05,203 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test52	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:05,205 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:05,205 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:05,205 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:05,205 [Thread-1110] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:05,205 [Thread-1110] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:05,207 [IPC Server handler 6 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741877_1053, replicas=127.0.0.1:40636, 127.0.0.1:42233, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test52
2020-04-02 05:09:05,208 [Thread-1110] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741877_1053
2020-04-02 05:09:05,208 [Thread-1110] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:09:05,208 [Thread-1110] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:05,214 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:34742 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053 src: /127.0.0.1:34742 dest: /127.0.0.1:40636
2020-04-02 05:09:05,219 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:59396 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053 src: /127.0.0.1:59396 dest: /127.0.0.1:42233
2020-04-02 05:09:05,220 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:42950 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053 src: /127.0.0.1:42950 dest: /127.0.0.1:37644
2020-04-02 05:09:05,221 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test52 block BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:09:05,222 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test52 block BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741877_1053 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:05,222 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test52 block BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741877_1053
2020-04-02 05:09:05,227 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 3905670 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:05,228 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test52 block BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741877_1053 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:05,230 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42950, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053, duration(ns): 8489283
2020-04-02 05:09:05,230 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:05,231 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59396, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053, duration(ns): 9283452
2020-04-02 05:09:05,231 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:09:05,231 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34742, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053, duration(ns): 9755076
2020-04-02 05:09:05,232 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644] terminating
2020-04-02 05:09:05,232 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 3029583 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:05,233 [IPC Server handler 4 on 38969] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741877_1053 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test52
2020-04-02 05:09:05,233 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test52 block BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741877_1053
2020-04-02 05:09:05,635 [IPC Server handler 5 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test52 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:05,636 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test52	dst=null	perm=null	proto=rpc
2020-04-02 05:09:05,637 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test52	dst=null	perm=null	proto=rpc
2020-04-02 05:09:05,639 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:05,640 [IPC Server handler 1 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test53	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:05,641 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:05,641 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:05,641 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:05,641 [Thread-1118] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:05,642 [Thread-1118] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:05,646 [IPC Server handler 6 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741878_1054, replicas=127.0.0.1:42233, 127.0.0.1:37644, 127.0.0.1:40636 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test53
2020-04-02 05:09:05,648 [Thread-1118] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]], blk_1073741878_1054
2020-04-02 05:09:05,648 [Thread-1118] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:42233
2020-04-02 05:09:05,648 [Thread-1118] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:05,649 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:59682 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054 src: /127.0.0.1:59682 dest: /127.0.0.1:42233
2020-04-02 05:09:05,650 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:43232 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054 src: /127.0.0.1:43232 dest: /127.0.0.1:37644
2020-04-02 05:09:05,658 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:35048 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054 src: /127.0.0.1:35048 dest: /127.0.0.1:40636
2020-04-02 05:09:05,665 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test53 block BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1]
2020-04-02 05:09:05,674 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test53 block BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741878_1054 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:05,674 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test53 block BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741878_1054
2020-04-02 05:09:05,680 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 4814925 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:05,680 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test53 block BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741878_1054 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:05,682 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35048, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054, duration(ns): 22778657
2020-04-02 05:09:05,683 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:05,686 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43232, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054, duration(ns): 18181023
2020-04-02 05:09:05,686 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636] terminating
2020-04-02 05:09:05,687 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59682, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054, duration(ns): 11778770
2020-04-02 05:09:05,687 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37644, 127.0.0.1:40636] terminating
2020-04-02 05:09:05,688 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 6035595 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:05,694 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test53 block BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741878_1054
2020-04-02 05:09:05,694 [IPC Server handler 3 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test53 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:05,698 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test53	dst=null	perm=null	proto=rpc
2020-04-02 05:09:05,699 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test53	dst=null	perm=null	proto=rpc
2020-04-02 05:09:05,701 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:05,702 [IPC Server handler 9 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test54	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:05,703 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:05,703 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:05,703 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:05,703 [Thread-1126] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:05,704 [Thread-1126] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:05,705 [IPC Server handler 1 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741879_1055, replicas=127.0.0.1:37644, 127.0.0.1:40636, 127.0.0.1:42233 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test54
2020-04-02 05:09:05,706 [Thread-1126] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]], blk_1073741879_1055
2020-04-02 05:09:05,707 [Thread-1126] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:37644
2020-04-02 05:09:05,707 [Thread-1126] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:05,711 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:43290 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055 src: /127.0.0.1:43290 dest: /127.0.0.1:37644
2020-04-02 05:09:05,723 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:35106 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055 src: /127.0.0.1:35106 dest: /127.0.0.1:40636
2020-04-02 05:09:05,730 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:59756 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055 src: /127.0.0.1:59756 dest: /127.0.0.1:42233
2020-04-02 05:09:05,738 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test54 block BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6]
2020-04-02 05:09:05,756 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test54 block BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741879_1055 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:05,756 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test54 block BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741879_1055
2020-04-02 05:09:05,778 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 15878372 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:05,780 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test54 block BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741879_1055 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:05,787 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59756, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055, duration(ns): 44827090
2020-04-02 05:09:05,788 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:05,789 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35106, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055, duration(ns): 31038377
2020-04-02 05:09:05,789 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42233] terminating
2020-04-02 05:09:05,790 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43290, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055, duration(ns): 28123985
2020-04-02 05:09:05,790 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40636, 127.0.0.1:42233] terminating
2020-04-02 05:09:05,791 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 9116063 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:05,792 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test54 block BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741879_1055
2020-04-02 05:09:05,794 [IPC Server handler 3 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test54 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:05,795 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test54	dst=null	perm=null	proto=rpc
2020-04-02 05:09:05,796 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test54	dst=null	perm=null	proto=rpc
2020-04-02 05:09:05,798 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:05,799 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test55	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:05,804 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:05,804 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:05,804 [Thread-1134] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:05,804 [Thread-1134] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:05,804 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:05,810 [IPC Server handler 9 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741880_1056, replicas=127.0.0.1:40636, 127.0.0.1:42233, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test55
2020-04-02 05:09:05,811 [Thread-1134] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741880_1056
2020-04-02 05:09:05,812 [Thread-1134] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:09:05,812 [Thread-1134] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:05,822 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:35150 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056 src: /127.0.0.1:35150 dest: /127.0.0.1:40636
2020-04-02 05:09:05,829 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:59792 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056 src: /127.0.0.1:59792 dest: /127.0.0.1:42233
2020-04-02 05:09:05,832 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:43344 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056 src: /127.0.0.1:43344 dest: /127.0.0.1:37644
2020-04-02 05:09:05,838 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test55 block BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:09:05,845 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test55 block BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741880_1056 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:05,846 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test55 block BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741880_1056
2020-04-02 05:09:05,851 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 4239073 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:05,852 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test55 block BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741880_1056 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:05,855 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43344, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056, duration(ns): 14773194
2020-04-02 05:09:05,855 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:05,858 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59792, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056, duration(ns): 22362898
2020-04-02 05:09:05,858 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:09:05,859 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35150, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056, duration(ns): 12704180
2020-04-02 05:09:05,859 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644] terminating
2020-04-02 05:09:05,859 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 6397467 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:05,860 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test55 block BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741880_1056
2020-04-02 05:09:05,861 [IPC Server handler 0 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test55 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:05,868 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test55	dst=null	perm=null	proto=rpc
2020-04-02 05:09:05,870 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test55	dst=null	perm=null	proto=rpc
2020-04-02 05:09:05,871 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:05,873 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test56	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:05,877 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:05,877 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:05,877 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:05,877 [Thread-1142] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:05,877 [Thread-1142] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:05,878 [IPC Server handler 2 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741881_1057, replicas=127.0.0.1:40636, 127.0.0.1:42233, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test56
2020-04-02 05:09:05,879 [Thread-1142] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741881_1057
2020-04-02 05:09:05,880 [Thread-1142] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:09:05,880 [Thread-1142] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:05,889 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:35168 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057 src: /127.0.0.1:35168 dest: /127.0.0.1:40636
2020-04-02 05:09:05,906 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:59812 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057 src: /127.0.0.1:59812 dest: /127.0.0.1:42233
2020-04-02 05:09:05,910 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:43366 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057 src: /127.0.0.1:43366 dest: /127.0.0.1:37644
2020-04-02 05:09:05,912 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test56 block BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:09:05,918 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test56 block BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741881_1057 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:05,918 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test56 block BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741881_1057
2020-04-02 05:09:05,922 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 792543 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:05,922 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test56 block BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741881_1057 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:05,926 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43366, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057, duration(ns): 15106154
2020-04-02 05:09:05,926 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:05,927 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59812, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057, duration(ns): 15305087
2020-04-02 05:09:05,927 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:09:05,928 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35168, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057, duration(ns): 15426792
2020-04-02 05:09:05,928 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644] terminating
2020-04-02 05:09:05,929 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 5593520 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:05,929 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test56 block BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741881_1057
2020-04-02 05:09:05,930 [IPC Server handler 9 on 38969] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741881_1057 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test56
2020-04-02 05:09:06,331 [IPC Server handler 0 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test56 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:06,333 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test56	dst=null	perm=null	proto=rpc
2020-04-02 05:09:06,334 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test56	dst=null	perm=null	proto=rpc
2020-04-02 05:09:06,336 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:06,337 [IPC Server handler 8 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test57	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:06,338 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:06,338 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:06,338 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:06,339 [Thread-1150] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:06,339 [Thread-1150] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:06,344 [IPC Server handler 2 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741882_1058, replicas=127.0.0.1:37644, 127.0.0.1:42233, 127.0.0.1:40636 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test57
2020-04-02 05:09:06,345 [Thread-1150] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]], blk_1073741882_1058
2020-04-02 05:09:06,345 [Thread-1150] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:37644
2020-04-02 05:09:06,345 [Thread-1150] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:06,350 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:43610 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058 src: /127.0.0.1:43610 dest: /127.0.0.1:37644
2020-04-02 05:09:06,354 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:60066 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058 src: /127.0.0.1:60066 dest: /127.0.0.1:42233
2020-04-02 05:09:06,356 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:35430 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058 src: /127.0.0.1:35430 dest: /127.0.0.1:40636
2020-04-02 05:09:06,358 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test57 block BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1]
2020-04-02 05:09:06,362 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test57 block BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741882_1058 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:06,362 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test57 block BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741882_1058
2020-04-02 05:09:06,368 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2207232 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:06,368 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test57 block BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741882_1058 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:06,378 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35430, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058, duration(ns): 21246016
2020-04-02 05:09:06,378 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:06,379 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60066, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058, duration(ns): 21788463
2020-04-02 05:09:06,379 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40636] terminating
2020-04-02 05:09:06,380 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:40636]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43610, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058, duration(ns): 18928183
2020-04-02 05:09:06,380 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:40636]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:40636] terminating
2020-04-02 05:09:06,386 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 10879566 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:06,386 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test57 block BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741882_1058
2020-04-02 05:09:06,402 [IPC Server handler 4 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test57 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:06,404 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test57	dst=null	perm=null	proto=rpc
2020-04-02 05:09:06,405 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test57	dst=null	perm=null	proto=rpc
2020-04-02 05:09:06,406 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:06,408 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test58	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:06,409 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:06,410 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:06,410 [Thread-1158] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:06,410 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:06,410 [Thread-1158] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:06,414 [IPC Server handler 8 on 38969] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741883_1059, replicas=127.0.0.1:40636, 127.0.0.1:42233, 127.0.0.1:37644 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test58
2020-04-02 05:09:06,415 [Thread-1158] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]], blk_1073741883_1059
2020-04-02 05:09:06,415 [Thread-1158] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40636
2020-04-02 05:09:06,416 [Thread-1158] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:06,426 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:35464 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059 src: /127.0.0.1:35464 dest: /127.0.0.1:40636
2020-04-02 05:09:06,429 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:60112 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059 src: /127.0.0.1:60112 dest: /127.0.0.1:42233
2020-04-02 05:09:06,438 [DataXceiver for client DFSClient_NONMAPREDUCE_121400397_1104 at /127.0.0.1:43662 [Receiving block BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059 src: /127.0.0.1:43662 dest: /127.0.0.1:37644
2020-04-02 05:09:06,442 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test58 block BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40636,DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b71b49a9-1814-47a0-997c-c432076ff5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a,DISK]] storageTypes [DISK, DISK, DISK] storageIDs [DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1, DS-b71b49a9-1814-47a0-997c-c432076ff5a6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a]
2020-04-02 05:09:06,457 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test58 block BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741883_1059 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024
2020-04-02 05:09:06,458 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test58 block BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741883_1059
2020-04-02 05:09:06,470 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 11760481 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:06,474 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test58 block BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741883_1059 sending packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024
2020-04-02 05:09:06,482 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43662, dest: /127.0.0.1:37644, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: e0539b34-cc77-4897-b986-112fd2aabddb, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059, duration(ns): 35548055
2020-04-02 05:09:06,482 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:06,483 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60112, dest: /127.0.0.1:42233, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: 4b28df83-49bb-44c8-86db-acf4a44833c4, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059, duration(ns): 13004689
2020-04-02 05:09:06,483 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37644] terminating
2020-04-02 05:09:06,484 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35464, dest: /127.0.0.1:40636, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_121400397_1104, offset: 0, srvID: cd6341d9-0481-43d1-9937-ea25dde874e7, blockid: BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059, duration(ns): 23209636
2020-04-02 05:09:06,484 [PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42233, 127.0.0.1:37644] terminating
2020-04-02 05:09:06,484 [ResponseProcessor for block BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 9269166 flag: 0 flag: 0 flag: 0
2020-04-02 05:09:06,490 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test58 block BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-131831597-172.17.0.7-1585804134865:blk_1073741883_1059
2020-04-02 05:09:06,492 [IPC Server handler 9 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test58 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:06,502 [IPC Server handler 4 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test58	dst=null	perm=null	proto=rpc
2020-04-02 05:09:06,503 [IPC Server handler 0 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test58	dst=null	perm=null	proto=rpc
2020-04-02 05:09:06,513 [IPC Server handler 3 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=null	proto=rpc
2020-04-02 05:09:06,522 [IPC Server handler 7 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=null	proto=rpc
2020-04-02 05:09:06,614 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (DataNode.java:transferBlock(2353)) - DatanodeRegistration(127.0.0.1:46154, datanodeUuid=1b04f1a7-d40a-4308-a02b-6bf636928be8, infoPort=41866, infoSecurePort=0, ipcPort=40471, storageInfo=lv=-57;cid=testClusterID;nsid=1653655509;c=1585804120054) Starting thread to transfer BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036 to 127.0.0.1:43315 
2020-04-02 05:09:06,619 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (DataNode.java:transferBlock(2353)) - DatanodeRegistration(127.0.0.1:46154, datanodeUuid=1b04f1a7-d40a-4308-a02b-6bf636928be8, infoPort=41866, infoSecurePort=0, ipcPort=40471, storageInfo=lv=-57;cid=testClusterID;nsid=1653655509;c=1585804120054) Starting thread to transfer BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033 to 127.0.0.1:34028 
2020-04-02 05:09:06,648 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (DataNode.java:transferBlock(2353)) - DatanodeRegistration(127.0.0.1:43315, datanodeUuid=966f464e-a960-4750-b2ba-e71f57dd888a, infoPort=41636, infoSecurePort=0, ipcPort=36431, storageInfo=lv=-57;cid=testClusterID;nsid=1653655509;c=1585804120054) Starting thread to transfer BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038 to 127.0.0.1:34028 
2020-04-02 05:09:06,648 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (DataNode.java:transferBlock(2353)) - DatanodeRegistration(127.0.0.1:43315, datanodeUuid=966f464e-a960-4750-b2ba-e71f57dd888a, infoPort=41636, infoSecurePort=0, ipcPort=36431, storageInfo=lv=-57;cid=testClusterID;nsid=1653655509;c=1585804120054) Starting thread to transfer BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031 to 127.0.0.1:34028 
2020-04-02 05:09:06,651 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@44a5698] INFO  datanode.DataNode (DataNode.java:run(2566)) - DataTransfer, at 127.0.0.1:46154: Transmitted BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033 (numBytes=512) to /127.0.0.1:34028
2020-04-02 05:09:06,651 [DataXceiver for client  at /127.0.0.1:46374 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033 src: /127.0.0.1:46374 dest: /127.0.0.1:34028
2020-04-02 05:09:06,653 [DataXceiver for client  at /127.0.0.1:46374 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(914)) - Received BP-725857609-172.17.0.7-1585804120054:blk_1073741856_1033 src: /127.0.0.1:46374 dest: /127.0.0.1:34028 of size 512
2020-04-02 05:09:06,654 [DataXceiver for client  at /127.0.0.1:34930 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036 src: /127.0.0.1:34930 dest: /127.0.0.1:43315
2020-04-02 05:09:06,655 [DataXceiver for client  at /127.0.0.1:34930 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(914)) - Received BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036 src: /127.0.0.1:34930 dest: /127.0.0.1:43315 of size 512
2020-04-02 05:09:06,658 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@15f1fce] INFO  datanode.DataNode (DataNode.java:run(2566)) - DataTransfer, at 127.0.0.1:46154: Transmitted BP-725857609-172.17.0.7-1585804120054:blk_1073741859_1036 (numBytes=512) to /127.0.0.1:43315
2020-04-02 05:09:06,660 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@23c8143a] INFO  datanode.DataNode (DataNode.java:run(2566)) - DataTransfer, at 127.0.0.1:43315: Transmitted BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038 (numBytes=512) to /127.0.0.1:34028
2020-04-02 05:09:06,662 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@535985bd] INFO  datanode.DataNode (DataNode.java:run(2566)) - DataTransfer, at 127.0.0.1:43315: Transmitted BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031 (numBytes=512) to /127.0.0.1:34028
2020-04-02 05:09:06,662 [DataXceiver for client  at /127.0.0.1:46380 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031 src: /127.0.0.1:46380 dest: /127.0.0.1:34028
2020-04-02 05:09:06,662 [DataXceiver for client  at /127.0.0.1:46381 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038 src: /127.0.0.1:46381 dest: /127.0.0.1:34028
2020-04-02 05:09:06,663 [DataXceiver for client  at /127.0.0.1:46380 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(914)) - Received BP-725857609-172.17.0.7-1585804120054:blk_1073741854_1031 src: /127.0.0.1:46380 dest: /127.0.0.1:34028 of size 512
2020-04-02 05:09:06,664 [DataXceiver for client  at /127.0.0.1:46381 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(914)) - Received BP-725857609-172.17.0.7-1585804120054:blk_1073741861_1038 src: /127.0.0.1:46381 dest: /127.0.0.1:34028 of size 512
2020-04-02 05:09:07,652 [IPC Server handler 5 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:07,656 [IPC Server handler 2 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:07,669 [IPC Server handler 6 on 38969] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test59	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:07,671 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:07,671 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 1024 lastPacketInBlock: true lastByteOffsetInBlock: 1024, block==null
2020-04-02 05:09:07,671 [Thread-536] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:07,671 [Thread-1175] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:07,672 [Thread-1175] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:07,673 [IPC Server handler 1 on 38969] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 1 on 38969, call Call#1193 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 127.0.0.1:59976: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test is exceeded: quota = 196608 B = 192 KB but diskspace consumed = 199680 B = 195 KB
2020-04-02 05:09:07,678 [Thread-1175] DEBUG hdfs.DataStreamer (DataStreamer.java:run(824)) - DataStreamer Quota Exception
org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test is exceeded: quota = 196608 B = 192 KB but diskspace consumed = 199680 B = 195 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1866)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.DSQuotaExceededException): The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test is exceeded: quota = 196608 B = 192 KB but diskspace consumed = 199680 B = 195 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy25.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:510)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy29.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	... 3 more
2020-04-02 05:09:07,682 [Thread-536] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, block==null
java.lang.Throwable: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test is exceeded: quota = 196608 B = 192 KB but diskspace consumed = 199680 B = 195 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.ExceptionLastSeen.throwException4Close(ExceptionLastSeen.java:72)
	at org.apache.hadoop.hdfs.DataStreamer.checkClosed(DataStreamer.java:978)
	at org.apache.hadoop.hdfs.DataStreamer.waitForAckedSeqno(DataStreamer.java:894)
	at org.apache.hadoop.hdfs.DFSOutputStream.flushInternal(DFSOutputStream.java:776)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:886)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:460)
	at org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:418)
	at org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:411)
	at org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:404)
	at org.apache.hadoop.hdfs.TestQuota.testMultipleFilesSmallerThanOneBlock(TestQuota.java:1157)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test is exceeded: quota = 196608 B = 192 KB but diskspace consumed = 199680 B = 195 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1866)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.DSQuotaExceededException): The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test is exceeded: quota = 196608 B = 192 KB but diskspace consumed = 199680 B = 195 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy25.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:510)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy29.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	... 3 more
2020-04-02 05:09:07,684 [IPC Server handler 9 on 38969] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Yzb1EcoaIh/TestQuota/testMultipleFilesSmallerThanOneBlock/test/test59 is closed by DFSClient_NONMAPREDUCE_121400397_1104
2020-04-02 05:09:07,685 [Thread-536] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:09:07,685 [Thread-536] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:09:07,686 [Thread-536] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33932 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:07,686 [Thread-536] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:07,689 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@305021cc] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:07,690 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-98249807-b056-4053-82a6-38153deb4e9c) exiting.
2020-04-02 05:09:07,691 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-e80aa24e-4c3e-4382-997b-439f3dd55b7a) exiting.
2020-04-02 05:09:07,727 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1e0ddb8b{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:07,732 [Thread-536] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7fd126c5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:07,733 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@398ab419{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:07,733 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3a140d5{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:07,737 [Thread-536] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33932
2020-04-02 05:09:07,756 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-131831597-172.17.0.7-1585804134865 (Datanode Uuid e0539b34-cc77-4897-b986-112fd2aabddb) service to localhost/127.0.0.1:38969
2020-04-02 05:09:07,758 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-131831597-172.17.0.7-1585804134865 (Datanode Uuid e0539b34-cc77-4897-b986-112fd2aabddb)
2020-04-02 05:09:07,758 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:09:07,766 [IPC Server listener on 33932] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33932
2020-04-02 05:09:07,773 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-131831597-172.17.0.7-1585804134865] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:07,778 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:07,781 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-131831597-172.17.0.7-1585804134865] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:07,798 [Thread-536] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:07,799 [Thread-536] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:07,802 [Thread-536] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:07,802 [Thread-536] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:07,809 [Thread-536] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:07,809 [Thread-536] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:09:07,809 [Thread-536] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 42882 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:07,809 [Thread-536] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:07,809 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@606a9bf2] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:07,812 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-058c0f78-6b04-455c-ba8e-dc60cae8f6e1) exiting.
2020-04-02 05:09:07,812 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-2d5ecdcd-9b28-4ff6-b3be-901be89f4ef9) exiting.
2020-04-02 05:09:07,903 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@237f3e25{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:07,905 [Thread-536] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@615243b4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:07,906 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@35a405d5{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:07,906 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@42efb3b8{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:07,907 [Thread-536] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42882
2020-04-02 05:09:07,922 [IPC Server listener on 42882] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42882
2020-04-02 05:09:07,922 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:07,932 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:07,932 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-131831597-172.17.0.7-1585804134865 (Datanode Uuid cd6341d9-0481-43d1-9937-ea25dde874e7) service to localhost/127.0.0.1:38969
2020-04-02 05:09:07,932 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-131831597-172.17.0.7-1585804134865 (Datanode Uuid cd6341d9-0481-43d1-9937-ea25dde874e7)
2020-04-02 05:09:07,932 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:09:07,941 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-131831597-172.17.0.7-1585804134865] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:07,950 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-131831597-172.17.0.7-1585804134865] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:07,957 [Thread-536] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:07,957 [Thread-536] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:07,959 [Thread-536] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:07,959 [Thread-536] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:07,963 [Thread-536] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:07,963 [Thread-536] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:09:07,963 [Thread-536] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 41016 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:07,964 [Thread-536] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:07,964 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1d7d70f1] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:07,966 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-b71b49a9-1814-47a0-997c-c432076ff5a6) exiting.
2020-04-02 05:09:07,969 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-f1d9e669-fa01-461a-a669-696781dcb0c2) exiting.
2020-04-02 05:09:08,013 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@45f77a0b{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:08,016 [Thread-536] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6b5110b4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:08,017 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7d17c74{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:08,018 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@34b1971b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:08,019 [Thread-536] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41016
2020-04-02 05:09:08,023 [IPC Server listener on 41016] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41016
2020-04-02 05:09:08,023 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:08,023 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:08,037 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-131831597-172.17.0.7-1585804134865 (Datanode Uuid 4b28df83-49bb-44c8-86db-acf4a44833c4) service to localhost/127.0.0.1:38969
2020-04-02 05:09:08,037 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-131831597-172.17.0.7-1585804134865 (Datanode Uuid 4b28df83-49bb-44c8-86db-acf4a44833c4)
2020-04-02 05:09:08,037 [BP-131831597-172.17.0.7-1585804134865 heartbeating to localhost/127.0.0.1:38969] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-131831597-172.17.0.7-1585804134865
2020-04-02 05:09:08,047 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-131831597-172.17.0.7-1585804134865] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:08,055 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-131831597-172.17.0.7-1585804134865] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:08,061 [Thread-536] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:08,061 [Thread-536] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:08,065 [Thread-536] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:08,066 [Thread-536] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:08,071 [Thread-536] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:08,071 [Thread-536] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:09:08,071 [Thread-536] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 38969 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:08,072 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:09:08,072 [Thread-536] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 312
2020-04-02 05:09:08,073 [Thread-536] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 313 Total time for transactions(ms): 20 Number of transactions batched in Syncs: 107 Number of syncs: 207 SyncTimes(ms): 12 4 
2020-04-02 05:09:08,073 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@106a945e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:09:08,075 [Thread-536] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000313
2020-04-02 05:09:08,076 [Thread-536] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000313
2020-04-02 05:09:08,076 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:09:08,082 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@110df75c] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:09:08,083 [CacheReplicationMonitor(1916793197)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:09:08,084 [Thread-536] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38969
2020-04-02 05:09:08,090 [IPC Server listener on 38969] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38969
2020-04-02 05:09:08,094 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:08,094 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:09:08,096 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:09:08,141 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:09:08,145 [Thread-536] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:09:08,150 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@56a7b332{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:09:08,160 [Thread-536] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@460fca55{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:08,161 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6915af1d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:08,163 [Thread-536] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7d73bb7{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:08,206 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/bqPsbE68rU/TestQuota/testHugeFileCount	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:08,217 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/bqPsbE68rU/TestQuota/testHugeFileCount/Folder1/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:08,219 [Thread-1177] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: -1
2020-04-02 05:09:08,220 [IPC Server handler 6 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/bqPsbE68rU/TestQuota/testHugeFileCount/Folder1/file1 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:09:08,224 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/bqPsbE68rU/TestQuota/testHugeFileCount/Folder1/file2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:08,226 [Thread-1177] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: -1
2020-04-02 05:09:08,230 [IPC Server handler 3 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/bqPsbE68rU/TestQuota/testHugeFileCount/Folder1/file2 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:09:08,245 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/bqPsbE68rU/TestQuota/testHugeFileCount/Folder1/file3	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:08,247 [Thread-1177] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: -1
2020-04-02 05:09:08,248 [IPC Server handler 9 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/bqPsbE68rU/TestQuota/testHugeFileCount/Folder1/file3 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:09:08,255 [IPC Server handler 5 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/bqPsbE68rU/TestQuota/testHugeFileCount/Folder1/file4	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:08,262 [Thread-1177] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: -1
2020-04-02 05:09:08,266 [IPC Server handler 1 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/bqPsbE68rU/TestQuota/testHugeFileCount/Folder1/file4 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:09:08,273 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/bqPsbE68rU/TestQuota/testHugeFileCount/Folder1/file5	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:08,276 [Thread-1177] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: -1
2020-04-02 05:09:08,277 [IPC Server handler 0 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/bqPsbE68rU/TestQuota/testHugeFileCount/Folder1/file5 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:09:08,287 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/bqPsbE68rU/TestQuota/testHugeFileCount/Folder2/file6	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:08,289 [Thread-1177] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: -1
2020-04-02 05:09:08,291 [IPC Server handler 6 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/bqPsbE68rU/TestQuota/testHugeFileCount/Folder2/file6 is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:09:08,306 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/bqPsbE68rU/TestQuota/testHugeFileCount	dst=null	perm=null	proto=rpc
2020-04-02 05:09:08,311 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/bqPsbE68rU/TestQuota/testHugeFileCount	dst=null	perm=null	proto=rpc
2020-04-02 05:09:08,329 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:08,340 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:08,342 [Thread-1186] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:09:08,342 [Thread-1186] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:09:08,342 [Thread-1186] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:09:08,342 [Thread-1187] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:08,343 [Thread-1186] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:enqueueCurrentPacketFull(488)) - enqueue full packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file, bytesCurBlock=512, blockSize=512, appendChunk=false, block==null
2020-04-02 05:09:08,343 [Thread-1186] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512, block==null
2020-04-02 05:09:08,343 [Thread-1187] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:08,343 [Thread-1186] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 3 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512, block==null
2020-04-02 05:09:08,343 [Thread-1186] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 3
2020-04-02 05:09:08,344 [IPC Server handler 5 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741879_1056, replicas=127.0.0.1:34028 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file
2020-04-02 05:09:08,344 [Thread-1187] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK]], blk_1073741879_1056
2020-04-02 05:09:08,345 [Thread-1187] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:34028
2020-04-02 05:09:08,345 [Thread-1187] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:08,346 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:47450 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741879_1056]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741879_1056 src: /127.0.0.1:47450 dest: /127.0.0.1:34028
2020-04-02 05:09:08,346 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file block BP-725857609-172.17.0.7-1585804120054:blk_1073741879_1056] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:34028,DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2,DISK]] storageTypes [DISK] storageIDs [DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2]
2020-04-02 05:09:08,347 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file block BP-725857609-172.17.0.7-1585804120054:blk_1073741879_1056] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741879_1056 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:09:08,347 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file block BP-725857609-172.17.0.7-1585804120054:blk_1073741879_1056] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741879_1056
2020-04-02 05:09:08,347 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741879_1056] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-04-02 05:09:08,347 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file block BP-725857609-172.17.0.7-1585804120054:blk_1073741879_1056] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741879_1056 sending packet seqno: 1 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:09:08,348 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741879_1056, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47450, dest: /127.0.0.1:34028, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: b6d7199e-caa6-44fb-a7b0-24811dd44850, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741879_1056, duration(ns): 1152867
2020-04-02 05:09:08,348 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741879_1056, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741879_1056, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:08,348 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741879_1056] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-04-02 05:09:08,348 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file block BP-725857609-172.17.0.7-1585804120054:blk_1073741879_1056] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741879_1056
2020-04-02 05:09:08,348 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, blk_1073741879_1056
2020-04-02 05:09:08,348 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: blk_1073741879_1056
2020-04-02 05:09:08,350 [IPC Server handler 1 on 34438] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741880_1057, replicas=127.0.0.1:43315 for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file
2020-04-02 05:09:08,351 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK]], blk_1073741880_1057
2020-04-02 05:09:08,352 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:43315
2020-04-02 05:09:08,352 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-04-02 05:09:08,354 [DataXceiver for client DFSClient_NONMAPREDUCE_1826976575_1 at /127.0.0.1:36044 [Receiving block BP-725857609-172.17.0.7-1585804120054:blk_1073741880_1057]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-725857609-172.17.0.7-1585804120054:blk_1073741880_1057 src: /127.0.0.1:36044 dest: /127.0.0.1:43315
2020-04-02 05:09:08,355 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file block BP-725857609-172.17.0.7-1585804120054:blk_1073741880_1057] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:43315,DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7,DISK]] storageTypes [DISK] storageIDs [DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7]
2020-04-02 05:09:08,356 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file block BP-725857609-172.17.0.7-1585804120054:blk_1073741880_1057] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741880_1057 sending packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 512
2020-04-02 05:09:08,356 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file block BP-725857609-172.17.0.7-1585804120054:blk_1073741880_1057] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, blk_1073741880_1057
2020-04-02 05:09:08,356 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741880_1057] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-04-02 05:09:08,359 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file block BP-725857609-172.17.0.7-1585804120054:blk_1073741880_1057] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - blk_1073741880_1057 sending packet seqno: 3 offsetInBlock: 512 lastPacketInBlock: true lastByteOffsetInBlock: 512
2020-04-02 05:09:08,360 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741880_1057, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36044, dest: /127.0.0.1:43315, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1826976575_1, offset: 0, srvID: 966f464e-a960-4750-b2ba-e71f57dd888a, blockid: BP-725857609-172.17.0.7-1585804120054:blk_1073741880_1057, duration(ns): 3738965
2020-04-02 05:09:08,360 [PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741880_1057, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-725857609-172.17.0.7-1585804120054:blk_1073741880_1057, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:08,360 [ResponseProcessor for block BP-725857609-172.17.0.7-1585804120054:blk_1073741880_1057] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 3 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-04-02 05:09:08,360 [DataStreamer for file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file block BP-725857609-172.17.0.7-1585804120054:blk_1073741880_1057] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-725857609-172.17.0.7-1585804120054:blk_1073741880_1057
2020-04-02 05:09:08,365 [IPC Server handler 0 on 34438] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741880_1057 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file
2020-04-02 05:09:08,774 [IPC Server handler 6 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:09:08,776 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file	dst=null	perm=null	proto=rpc
2020-04-02 05:09:08,779 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file	dst=null	perm=null	proto=rpc
2020-04-02 05:09:08,780 [IPC Server handler 8 on 34438] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 8 on 34438, call Call#1220 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota from 127.0.0.1:36744
org.apache.hadoop.fs.PathIsNotDirectoryException: `/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file': Is not a directory
	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.valueOf(INodeDirectory.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSDirAttrOp.unprotectedSetQuota(FSDirAttrOp.java:334)
	at org.apache.hadoop.hdfs.server.namenode.FSDirAttrOp.setQuota(FSDirAttrOp.java:244)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setQuota(FSNamesystem.java:3249)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setQuota(NameNodeRpcServer.java:1412)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setQuota(ClientNamenodeProtocolServerSideTranslatorPB.java:1029)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:08,789 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file	dst=null	perm=null	proto=rpc
2020-04-02 05:09:08,791 [IPC Server handler 5 on 34438] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 5 on 34438, call Call#1222 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota from 127.0.0.1:36744
org.apache.hadoop.fs.PathIsNotDirectoryException: `/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/6HcGg2OKO7/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file': Is not a directory
	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.valueOf(INodeDirectory.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSDirAttrOp.unprotectedSetQuota(FSDirAttrOp.java:334)
	at org.apache.hadoop.hdfs.server.namenode.FSDirAttrOp.setQuota(FSDirAttrOp.java:244)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setQuota(FSNamesystem.java:3249)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setQuota(NameNodeRpcServer.java:1412)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setQuota(ClientNamenodeProtocolServerSideTranslatorPB.java:1029)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:08,815 [IPC Server handler 7 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/c2gG40P4aT/TestQuota/testSetSpaceQuotaNegativeNumber	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:08,828 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/zQgWKsTK1a/TestQuota/testSetAndClearSpaceQuotaDirectoryNotExist	dst=null	perm=null	proto=rpc
2020-04-02 05:09:08,829 [IPC Server handler 2 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 2 on 34438, call Call#1225 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota from 127.0.0.1:36744: java.io.FileNotFoundException: Directory does not exist: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/zQgWKsTK1a/TestQuota/testSetAndClearSpaceQuotaDirectoryNotExist
2020-04-02 05:09:08,832 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/zQgWKsTK1a/TestQuota/testSetAndClearSpaceQuotaDirectoryNotExist	dst=null	perm=null	proto=rpc
2020-04-02 05:09:08,833 [IPC Server handler 6 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 6 on 34438, call Call#1227 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota from 127.0.0.1:36744: java.io.FileNotFoundException: Directory does not exist: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/zQgWKsTK1a/TestQuota/testSetAndClearSpaceQuotaDirectoryNotExist
2020-04-02 05:09:08,847 [IPC Server handler 4 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/N2GvAiDSok/TestQuota/testSpaceQuotaExceptionOnClose	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:08,853 [IPC Server handler 3 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/N2GvAiDSok/TestQuota/testSpaceQuotaExceptionOnClose	dst=null	perm=null	proto=rpc
2020-04-02 05:09:08,854 [IPC Server handler 8 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/N2GvAiDSok/TestQuota/testSpaceQuotaExceptionOnClose	dst=null	perm=null	proto=rpc
2020-04-02 05:09:08,856 [IPC Server handler 9 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/N2GvAiDSok/TestQuota/testSpaceQuotaExceptionOnClose/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:08,858 [Thread-1199] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 8, block==null
2020-04-02 05:09:08,858 [Thread-1199] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 8 lastPacketInBlock: true lastByteOffsetInBlock: 8, block==null
2020-04-02 05:09:08,858 [Thread-1200] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:08,858 [Thread-1200] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:08,858 [Thread-1199] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 1
2020-04-02 05:09:08,860 [IPC Server handler 5 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 5 on 34438, call Call#1232 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 127.0.0.1:36744: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/N2GvAiDSok/TestQuota/testSpaceQuotaExceptionOnClose is exceeded: quota = 1 B = 1 B but diskspace consumed = 1536 B = 1.50 KB
2020-04-02 05:09:08,860 [Thread-1200] DEBUG hdfs.DataStreamer (DataStreamer.java:run(824)) - DataStreamer Quota Exception
org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/N2GvAiDSok/TestQuota/testSpaceQuotaExceptionOnClose is exceeded: quota = 1 B = 1 B but diskspace consumed = 1536 B = 1.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1866)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.DSQuotaExceededException): The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/N2GvAiDSok/TestQuota/testSpaceQuotaExceptionOnClose is exceeded: quota = 1 B = 1 B but diskspace consumed = 1536 B = 1.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy25.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:510)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy29.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	... 3 more
2020-04-02 05:09:08,863 [Thread-1199] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, block==null
java.lang.Throwable: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/N2GvAiDSok/TestQuota/testSpaceQuotaExceptionOnClose is exceeded: quota = 1 B = 1 B but diskspace consumed = 1536 B = 1.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.ExceptionLastSeen.throwException4Close(ExceptionLastSeen.java:72)
	at org.apache.hadoop.hdfs.DataStreamer.checkClosed(DataStreamer.java:978)
	at org.apache.hadoop.hdfs.DataStreamer.waitForAckedSeqno(DataStreamer.java:894)
	at org.apache.hadoop.hdfs.DFSOutputStream.flushInternal(DFSOutputStream.java:776)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:886)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.TestQuota.testSpaceQuotaExceptionOnClose(TestQuota.java:1519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/N2GvAiDSok/TestQuota/testSpaceQuotaExceptionOnClose is exceeded: quota = 1 B = 1 B but diskspace consumed = 1536 B = 1.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1866)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.DSQuotaExceededException): The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/N2GvAiDSok/TestQuota/testSpaceQuotaExceptionOnClose is exceeded: quota = 1 B = 1 B but diskspace consumed = 1536 B = 1.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy25.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:510)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy29.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	... 3 more
2020-04-02 05:09:08,865 [IPC Server handler 7 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/N2GvAiDSok/TestQuota/testSpaceQuotaExceptionOnClose/file is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:09:08,874 [Thread-1201] DEBUG hdfs.DFSClient (DFSClient.java:primitiveMkdir(2417)) - /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Gz4vOzNEnX/TestQuota/testSpaceQuotaExceptionOnFlush: masked={ masked: rwxr-xr-x, unmasked: rwxrwxrwx }
2020-04-02 05:09:08,875 [IPC Server handler 1 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Gz4vOzNEnX/TestQuota/testSpaceQuotaExceptionOnFlush	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:08,877 [IPC Server handler 2 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Gz4vOzNEnX/TestQuota/testSpaceQuotaExceptionOnFlush	dst=null	perm=null	proto=rpc
2020-04-02 05:09:08,880 [IPC Server handler 0 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Gz4vOzNEnX/TestQuota/testSpaceQuotaExceptionOnFlush	dst=null	perm=null	proto=rpc
2020-04-02 05:09:08,881 [Thread-1201] DEBUG hdfs.DFSClient (DFSClient.java:create(1210)) - /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Gz4vOzNEnX/TestQuota/testSpaceQuotaExceptionOnFlush/file: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-04-02 05:09:08,885 [IPC Server handler 6 on 34438] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Gz4vOzNEnX/TestQuota/testSpaceQuotaExceptionOnFlush/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:08,885 [Thread-1201] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Gz4vOzNEnX/TestQuota/testSpaceQuotaExceptionOnFlush/file, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-04-02 05:09:08,887 [Thread-1201] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Gz4vOzNEnX/TestQuota/testSpaceQuotaExceptionOnFlush/file, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSOutputStream:block==null
2020-04-02 05:09:08,887 [Thread-1201] DEBUG hdfs.DFSClient (DFSOutputStream.java:flushOrSync(635)) - DFSClient flush():  bytesCurBlock=8, lastFlushOffset=0, createNewBlock=false
2020-04-02 05:09:08,887 [Thread-1201] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 8, block==null
2020-04-02 05:09:08,887 [Thread-1201] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - block==null waiting for ack for: 0
2020-04-02 05:09:08,887 [Thread-1202] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, block==null
2020-04-02 05:09:08,887 [Thread-1202] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: block==null
2020-04-02 05:09:08,889 [IPC Server handler 4 on 34438] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 4 on 34438, call Call#1238 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 127.0.0.1:36744: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Gz4vOzNEnX/TestQuota/testSpaceQuotaExceptionOnFlush is exceeded: quota = 1 B = 1 B but diskspace consumed = 1536 B = 1.50 KB
2020-04-02 05:09:08,890 [Thread-1202] DEBUG hdfs.DataStreamer (DataStreamer.java:run(824)) - DataStreamer Quota Exception
org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Gz4vOzNEnX/TestQuota/testSpaceQuotaExceptionOnFlush is exceeded: quota = 1 B = 1 B but diskspace consumed = 1536 B = 1.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1866)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.DSQuotaExceededException): The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Gz4vOzNEnX/TestQuota/testSpaceQuotaExceptionOnFlush is exceeded: quota = 1 B = 1 B but diskspace consumed = 1536 B = 1.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy25.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:510)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy29.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	... 3 more
2020-04-02 05:09:08,893 [Thread-1201] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, block==null
java.lang.Throwable: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Gz4vOzNEnX/TestQuota/testSpaceQuotaExceptionOnFlush is exceeded: quota = 1 B = 1 B but diskspace consumed = 1536 B = 1.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.ExceptionLastSeen.throwException4Close(ExceptionLastSeen.java:72)
	at org.apache.hadoop.hdfs.DataStreamer.checkClosed(DataStreamer.java:978)
	at org.apache.hadoop.hdfs.DataStreamer.waitForAckedSeqno(DataStreamer.java:894)
	at org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync(DFSOutputStream.java:690)
	at org.apache.hadoop.hdfs.DFSOutputStream.hflush(DFSOutputStream.java:578)
	at org.apache.hadoop.fs.FSDataOutputStream.hflush(FSDataOutputStream.java:134)
	at org.apache.hadoop.hdfs.TestQuota.testSpaceQuotaExceptionOnFlush(TestQuota.java:1547)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Gz4vOzNEnX/TestQuota/testSpaceQuotaExceptionOnFlush is exceeded: quota = 1 B = 1 B but diskspace consumed = 1536 B = 1.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1866)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.DSQuotaExceededException): The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Gz4vOzNEnX/TestQuota/testSpaceQuotaExceptionOnFlush is exceeded: quota = 1 B = 1 B but diskspace consumed = 1536 B = 1.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy25.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:510)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy29.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	... 3 more
2020-04-02 05:09:08,894 [Thread-1201] WARN  hdfs.DFSClient (DFSOutputStream.java:flushOrSync(732)) - Error while syncing
org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Gz4vOzNEnX/TestQuota/testSpaceQuotaExceptionOnFlush is exceeded: quota = 1 B = 1 B but diskspace consumed = 1536 B = 1.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1866)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.DSQuotaExceededException): The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Gz4vOzNEnX/TestQuota/testSpaceQuotaExceptionOnFlush is exceeded: quota = 1 B = 1 B but diskspace consumed = 1536 B = 1.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy25.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:510)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy29.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	... 3 more
2020-04-02 05:09:08,894 [Thread-1201] DEBUG hdfs.DFSOutputStream (DFSOutputStream.java:closeImpl(858)) - Closing an already closed stream. [Stream:false, streamer:true]
2020-04-02 05:09:08,894 [Thread-1201] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, block==null
java.lang.Throwable: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Gz4vOzNEnX/TestQuota/testSpaceQuotaExceptionOnFlush is exceeded: quota = 1 B = 1 B but diskspace consumed = 1536 B = 1.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:861)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.TestQuota.testSpaceQuotaExceptionOnFlush(TestQuota.java:1553)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Gz4vOzNEnX/TestQuota/testSpaceQuotaExceptionOnFlush is exceeded: quota = 1 B = 1 B but diskspace consumed = 1536 B = 1.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1084)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1866)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.DSQuotaExceededException): The DiskSpace quota of /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Gz4vOzNEnX/TestQuota/testSpaceQuotaExceptionOnFlush is exceeded: quota = 1 B = 1 B but diskspace consumed = 1536 B = 1.50 KB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1149)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:981)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:940)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2710)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy25.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:510)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy29.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	... 3 more
2020-04-02 05:09:08,896 [IPC Server handler 3 on 34438] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/Gz4vOzNEnX/TestQuota/testSpaceQuotaExceptionOnFlush/file is closed by DFSClient_NONMAPREDUCE_1826976575_1
2020-04-02 05:09:08,897 [Thread-1201] INFO  hdfs.TestQuota (TestQuota.java:get(1562)) - LeaseRenewer: LeaseRenewer:root@localhost:34438, clients=[], created at null
2020-04-02 05:09:08,898 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:09:08,898 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:09:08,898 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 41374 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:08,898 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:08,898 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@841e575] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:08,902 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6, DS-0649210e-2159-42b8-92ae-9ed2ad87ee25) exiting.
2020-04-02 05:09:08,903 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5, DS-11c1620b-ff86-4ced-bd14-a172fbc3e2f2) exiting.
2020-04-02 05:09:08,935 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@40dd3977{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:08,937 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3a4e343{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:08,937 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@f9879ac{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:08,938 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f80fafe{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:08,940 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41374
2020-04-02 05:09:08,941 [IPC Server listener on 41374] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41374
2020-04-02 05:09:08,944 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:08,944 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:08,944 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-725857609-172.17.0.7-1585804120054 (Datanode Uuid b6d7199e-caa6-44fb-a7b0-24811dd44850) service to localhost/127.0.0.1:34438
2020-04-02 05:09:08,944 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-725857609-172.17.0.7-1585804120054 (Datanode Uuid b6d7199e-caa6-44fb-a7b0-24811dd44850)
2020-04-02 05:09:08,944 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:09:08,951 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data5/current/BP-725857609-172.17.0.7-1585804120054] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:08,957 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data6/current/BP-725857609-172.17.0.7-1585804120054] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:08,961 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:08,961 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:08,965 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:08,970 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:08,975 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:08,975 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:09:08,975 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40471 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:08,975 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:08,976 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2c9399a4] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:08,979 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3, DS-b038a70f-9b00-4273-a9d1-3eecaa45ed5b) exiting.
2020-04-02 05:09:08,981 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4, DS-d6ec7455-d48a-4372-bfc2-a59c9a107d28) exiting.
2020-04-02 05:09:09,021 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1d71006f{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:09,022 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5b6813df{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:09,023 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@71e5f61d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:09,023 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@172ca72b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:09,025 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40471
2020-04-02 05:09:09,039 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:09,039 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:09,039 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-725857609-172.17.0.7-1585804120054 (Datanode Uuid 1b04f1a7-d40a-4308-a02b-6bf636928be8) service to localhost/127.0.0.1:34438
2020-04-02 05:09:09,039 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-725857609-172.17.0.7-1585804120054 (Datanode Uuid 1b04f1a7-d40a-4308-a02b-6bf636928be8)
2020-04-02 05:09:09,039 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:09:09,041 [IPC Server listener on 40471] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40471
2020-04-02 05:09:09,111 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data3/current/BP-725857609-172.17.0.7-1585804120054] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:09,116 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data4/current/BP-725857609-172.17.0.7-1585804120054] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:09,137 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:09,138 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:09,141 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:09,141 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:09,152 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:09,156 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:09:09,156 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 36431 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:09,157 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:09,157 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2ccca26f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:09,162 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2, DS-3c105529-4159-4844-a50f-6dce7b951e83) exiting.
2020-04-02 05:09:09,165 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1, DS-d5ed8046-faed-494d-b1dc-6d6658afc1d7) exiting.
2020-04-02 05:09:09,236 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6aecbb8d{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:09,236 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1af146{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:09,237 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3fa2213{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:09,237 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5e81e5ac{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:09,239 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36431
2020-04-02 05:09:09,251 [IPC Server listener on 36431] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36431
2020-04-02 05:09:09,251 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:09,251 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-725857609-172.17.0.7-1585804120054 (Datanode Uuid 966f464e-a960-4750-b2ba-e71f57dd888a) service to localhost/127.0.0.1:34438
2020-04-02 05:09:09,251 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:09,251 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:09,251 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-725857609-172.17.0.7-1585804120054 (Datanode Uuid 966f464e-a960-4750-b2ba-e71f57dd888a)
2020-04-02 05:09:09,252 [BP-725857609-172.17.0.7-1585804120054 heartbeating to localhost/127.0.0.1:34438] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-725857609-172.17.0.7-1585804120054
2020-04-02 05:09:09,252 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:09,257 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:09,257 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:09,319 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data1/current/BP-725857609-172.17.0.7-1585804120054] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:09,327 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/data/data2/current/BP-725857609-172.17.0.7-1585804120054] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:09,339 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:09,340 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:09:09,340 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 34438 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:09,340 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:09:09,340 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 378
2020-04-02 05:09:09,340 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@25e2ab5a] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:09:09,340 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 379 Total time for transactions(ms): 91 Number of transactions batched in Syncs: 118 Number of syncs: 262 SyncTimes(ms): 39 9 
2020-04-02 05:09:09,341 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/name-0-1/current/edits_0000000000000000001-0000000000000000379
2020-04-02 05:09:09,341 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@35e5d0e5] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:09:09,342 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/my-test-quota/name-0-2/current/edits_0000000000000000001-0000000000000000379
2020-04-02 05:09:09,342 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:09:09,342 [CacheReplicationMonitor(1397324785)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:09:09,343 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34438
2020-04-02 05:09:09,352 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:09:09,352 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:09:09,353 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:09,354 [IPC Server listener on 34438] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34438
2020-04-02 05:09:09,364 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:09:09,365 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:09:09,366 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7fc4780b{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:09:09,372 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6b58b9e9{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:09,373 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f67a4d3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:09,373 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@565f390{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:09,378 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:09:09,449 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:09:09,450 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] all testRunFinished

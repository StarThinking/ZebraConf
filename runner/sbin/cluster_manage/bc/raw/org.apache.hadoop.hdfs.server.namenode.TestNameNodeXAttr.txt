[msx] before_class
2020-04-02 05:07:11,033 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2020-04-02 05:07:11,700 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:11,715 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:11,716 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:11,719 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:11,741 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:11,741 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:11,742 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:11,742 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:11,799 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:11,804 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:07:11,804 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:11,804 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:11,809 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:11,810 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:11
2020-04-02 05:07:11,812 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:11,813 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:11,815 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:11,815 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:11,833 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:11,840 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:11,841 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:11,841 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:11,841 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:11,841 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:11,842 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:11,842 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:11,842 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:11,842 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:11,843 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:11,843 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:11,873 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:07:11,892 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:11,892 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:11,892 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:11,893 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:11,899 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:11,900 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:11,900 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:11,900 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:11,906 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:11,909 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:11,914 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:11,915 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:11,915 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:11,916 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:11,927 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:11,927 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:11,927 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:11,932 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:11,933 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:11,935 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:11,936 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:11,936 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:11,937 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:11,967 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:11,979 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:07:11,981 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:07:11,990 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:11,990 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:12,136 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 388 bytes saved in 0 seconds .
2020-04-02 05:07:12,136 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 388 bytes saved in 0 seconds .
2020-04-02 05:07:12,159 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:07:12,164 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:12,328 [main] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:07:12,381 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:12,720 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:12,720 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:12,725 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:12,750 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:12,794 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@59505b48] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:12,818 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:12,824 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:12,837 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3048ms
2020-04-02 05:07:12,943 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:12,946 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:12,947 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:12,953 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:12,955 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:12,955 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:12,956 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:12,979 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:12,979 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:12,986 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34639
2020-04-02 05:07:12,988 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:13,073 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f67a4d3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:13,078 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2fb0623e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:13,126 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@48c76607{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:13,136 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@52e7a6b2{HTTP/1.1,[http/1.1]}{localhost:34639}
2020-04-02 05:07:13,136 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3348ms
2020-04-02 05:07:13,145 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:13,146 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:13,146 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:13,146 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:13,147 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:13,147 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:13,147 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:13,147 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:13,148 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:13,148 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:13,149 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:13,149 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:13,150 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:13
2020-04-02 05:07:13,150 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:13,150 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:13,165 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:07:13,165 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:13,170 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:13,170 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:13,171 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:13,171 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:13,171 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:13,171 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:13,171 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:13,171 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:13,172 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:13,172 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:13,172 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:13,172 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:13,173 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:13,173 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:13,173 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:07:13,173 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:13,176 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:13,176 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:13,177 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:13,177 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:13,177 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:13,179 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:13,179 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:13,180 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:13,180 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:07:13,180 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:13,181 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:13,182 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:13,182 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:13,182 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:13,182 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:13,183 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:13,183 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:13,183 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:07:13,183 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:13,189 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:13,193 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:13,197 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:13,198 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:13,198 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:07:13,199 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:13,237 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:07:13,251 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:13,253 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:07:13,259 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:13,261 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:07:13,288 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:13,288 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 103 msecs
2020-04-02 05:07:13,471 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:13,482 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:13,499 [Socket Reader #1 for port 38960] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38960
2020-04-02 05:07:13,823 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:38960 to access this namenode/service.
2020-04-02 05:07:13,826 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:13,847 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:13,870 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:13,871 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:13,871 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:13,871 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:13,880 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:07:13,881 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:13,881 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:07:13,881 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:13,881 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:13,881 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 10 msec
2020-04-02 05:07:13,919 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:13,919 [IPC Server listener on 38960] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38960: starting
2020-04-02 05:07:13,924 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:38960
2020-04-02 05:07:13,928 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:13,928 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:13,932 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 4 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:13,936 [CacheReplicationMonitor(923321354)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:13,936 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 38960 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:13,945 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:14,061 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:14,076 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:14,089 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:14,089 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:14,094 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:14,096 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:14,102 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:14,103 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:14,106 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:14,112 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:46045
2020-04-02 05:07:14,115 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:14,115 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:14,129 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:14,136 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:14,137 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:14,137 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:14,138 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:14,139 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:14,140 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:14,140 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:14,143 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42517
2020-04-02 05:07:14,143 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:14,145 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3fa2213{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:14,147 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f0b0a5e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:14,152 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4da602fc{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:14,185 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2a8d39c4{HTTP/1.1,[http/1.1]}{localhost:42517}
2020-04-02 05:07:14,186 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4397ms
2020-04-02 05:07:14,600 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39041
2020-04-02 05:07:14,601 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@625e134e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:14,602 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:14,602 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:14,621 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:14,623 [Socket Reader #1 for port 34294] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34294
2020-04-02 05:07:14,631 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:34294
2020-04-02 05:07:14,656 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:14,658 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:15,054 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38960 starting to offer service
2020-04-02 05:07:15,064 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:15,064 [IPC Server listener on 34294] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34294: starting
2020-04-02 05:07:15,066 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 34294 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:15,424 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38960
2020-04-02 05:07:15,427 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:15,430 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:15,432 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 213151118. Formatting...
2020-04-02 05:07:15,433 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5437a82e-ddff-46c6-ad88-3ed31967d093 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:07:15,437 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:15,437 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 213151118. Formatting...
2020-04-02 05:07:15,437 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:07:15,452 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:15,453 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:15,453 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-944730262-172.17.0.6-1585804031959 is not formatted. Formatting ...
2020-04-02 05:07:15,453 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-944730262-172.17.0.6-1585804031959 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959/current
2020-04-02 05:07:15,477 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:15,477 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:15,478 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-944730262-172.17.0.6-1585804031959 is not formatted. Formatting ...
2020-04-02 05:07:15,478 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-944730262-172.17.0.6-1585804031959 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959/current
2020-04-02 05:07:15,480 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=213151118;bpid=BP-944730262-172.17.0.6-1585804031959;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=213151118;c=1585804031959;bpid=BP-944730262-172.17.0.6-1585804031959;dnuuid=null
2020-04-02 05:07:15,481 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:15,623 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5437a82e-ddff-46c6-ad88-3ed31967d093
2020-04-02 05:07:15,623 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:15,627 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae
2020-04-02 05:07:15,627 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:15,639 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:15,649 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:15,658 [IPC Server handler 6 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:15,671 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:15,673 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:15,673 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:15,677 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:15,677 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:15,677 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:15,678 [Thread-77] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:15,678 [Thread-78] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:15,708 [Thread-78] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-944730262-172.17.0.6-1585804031959 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 27ms
2020-04-02 05:07:15,708 [Thread-77] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-944730262-172.17.0.6-1585804031959 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 30ms
2020-04-02 05:07:15,709 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-944730262-172.17.0.6-1585804031959: 32ms
2020-04-02 05:07:15,712 [Thread-81] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:15,712 [Thread-82] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:15,713 [Thread-81] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959/current/replicas doesn't exist 
2020-04-02 05:07:15,713 [Thread-82] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959/current/replicas doesn't exist 
2020-04-02 05:07:15,715 [Thread-82] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 2ms
2020-04-02 05:07:15,715 [Thread-81] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 3ms
2020-04-02 05:07:15,716 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-944730262-172.17.0.6-1585804031959: 4ms
2020-04-02 05:07:15,717 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:15,719 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae): finished scanning block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:15,717 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:15,722 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093): finished scanning block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:15,728 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:21 AM with interval of 21600000ms
2020-04-02 05:07:15,734 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38960] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:38960 beginning handshake with NN
2020-04-02 05:07:15,747 [IPC Server handler 4 on 38960] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46045, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=39041, infoSecurePort=0, ipcPort=34294, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959) storage a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:15,749 [IPC Server handler 4 on 38960] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46045
2020-04-02 05:07:15,750 [IPC Server handler 4 on 38960] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a66a72ee-5beb-418a-8fdf-000c79d6d741 (127.0.0.1:46045).
2020-04-02 05:07:15,756 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38960] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:38960 successfully registered with NN
2020-04-02 05:07:15,756 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38960] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38960 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:15,761 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093): no suitable block pools found to scan.  Waiting 1814399956 ms.
2020-04-02 05:07:15,761 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae): no suitable block pools found to scan.  Waiting 1814399956 ms.
2020-04-02 05:07:15,780 [IPC Server handler 8 on 38960] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5437a82e-ddff-46c6-ad88-3ed31967d093 for DN 127.0.0.1:46045
2020-04-02 05:07:15,781 [IPC Server handler 8 on 38960] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae for DN 127.0.0.1:46045
2020-04-02 05:07:15,783 [IPC Server handler 7 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:15,792 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:15,806 [IPC Server handler 5 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:15,807 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testXAttrSymlinks
[msx] unitTestCounterInClass = 0
2020-04-02 05:07:15,816 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa2ce01c7f5f269ef: Processing first storage report for DS-5437a82e-ddff-46c6-ad88-3ed31967d093 from datanode a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:15,818 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa2ce01c7f5f269ef: from storage DS-5437a82e-ddff-46c6-ad88-3ed31967d093 node DatanodeRegistration(127.0.0.1:46045, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=39041, infoSecurePort=0, ipcPort=34294, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:07:15,819 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa2ce01c7f5f269ef: Processing first storage report for DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae from datanode a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:15,819 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa2ce01c7f5f269ef: from storage DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae node DatanodeRegistration(127.0.0.1:46045, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=39041, infoSecurePort=0, ipcPort=34294, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:15,832 [IPC Server handler 2 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/symdir1	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:15,844 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38960] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xa2ce01c7f5f269ef,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 38 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:15,844 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38960] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:15,852 [IPC Server handler 1 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/symdir2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:15,856 [IPC Server handler 9 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/symdir2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:15,891 [IPC Server handler 0 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/symdir2/target	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:15,933 [IPC Server handler 6 on 38960] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:46045 for /symdir2/target
2020-04-02 05:07:16,039 [DataXceiver for client DFSClient_NONMAPREDUCE_213626612_1 at /127.0.0.1:49150 [Receiving block BP-944730262-172.17.0.6-1585804031959:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-944730262-172.17.0.6-1585804031959:blk_1073741825_1001 src: /127.0.0.1:49150 dest: /127.0.0.1:46045
2020-04-02 05:07:16,111 [PacketResponder: BP-944730262-172.17.0.6-1585804031959:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49150, dest: /127.0.0.1:46045, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_213626612_1, offset: 0, srvID: a66a72ee-5beb-418a-8fdf-000c79d6d741, blockid: BP-944730262-172.17.0.6-1585804031959:blk_1073741825_1001, duration(ns): 41449156
2020-04-02 05:07:16,111 [PacketResponder: BP-944730262-172.17.0.6-1585804031959:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-944730262-172.17.0.6-1585804031959:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:16,120 [IPC Server handler 7 on 38960] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /symdir2/target
2020-04-02 05:07:16,526 [IPC Server handler 5 on 38960] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /symdir2/target is closed by DFSClient_NONMAPREDUCE_213626612_1
2020-04-02 05:07:16,536 [IPC Server handler 2 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=createSymlink	src=/symdir1/link	dst=/symdir2/target	perm=null	proto=rpc
2020-04-02 05:07:16,549 [IPC Server handler 3 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/symdir2/target	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:16,553 [IPC Server handler 1 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/symdir2/target	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:16,578 [IPC Server handler 0 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/symdir1/link	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,585 [IPC Server handler 6 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/symdir2/target	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,600 [IPC Server handler 7 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/symdir1/link	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,603 [IPC Server handler 8 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/symdir2/target	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:16,606 [IPC Server handler 5 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/symdir2/target	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,621 [IPC Server handler 3 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/symdir1/link	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,628 [IPC Server handler 1 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/symdir2/target	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:16,642 [IPC Server handler 9 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/symdir2/target	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,649 [IPC Server handler 0 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/symdir2/target	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:16,682 [IPC Server handler 4 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/symdir1/link	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,687 [IPC Server handler 7 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/symdir2/target	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,701 [IPC Server handler 8 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/symdir1	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,706 [IPC Server handler 5 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/symdir2	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testXAttrSymlinks
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testXAttrSymlinks
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testUnreadableBySuperuserXAttr
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:16,718 [IPC Server handler 2 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:16,728 [IPC Server handler 3 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p2	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
2020-04-02 05:07:16,731 [IPC Server handler 1 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p2	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
2020-04-02 05:07:16,735 [IPC Server handler 9 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/p2/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:16,740 [IPC Server handler 0 on 38960] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:46045 for /p2/file
2020-04-02 05:07:16,744 [DataXceiver for client DFSClient_NONMAPREDUCE_2110637035_1 at /127.0.0.1:49180 [Receiving block BP-944730262-172.17.0.6-1585804031959:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-944730262-172.17.0.6-1585804031959:blk_1073741826_1002 src: /127.0.0.1:49180 dest: /127.0.0.1:46045
2020-04-02 05:07:16,752 [PacketResponder: BP-944730262-172.17.0.6-1585804031959:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49180, dest: /127.0.0.1:46045, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2110637035_1, offset: 0, srvID: a66a72ee-5beb-418a-8fdf-000c79d6d741, blockid: BP-944730262-172.17.0.6-1585804031959:blk_1073741826_1002, duration(ns): 5074724
2020-04-02 05:07:16,752 [PacketResponder: BP-944730262-172.17.0.6-1585804031959:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-944730262-172.17.0.6-1585804031959:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:16,756 [IPC Server handler 7 on 38960] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /p2/file is closed by DFSClient_NONMAPREDUCE_2110637035_1
2020-04-02 05:07:16,759 [IPC Server handler 8 on 38960] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 8 on 38960, call Call#44 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:33458
java.io.IOException: Can only set 'security.hdfs.unreadable.by.superuser' on a file.
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedSetXAttrs(FSDirXAttrOp.java:298)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setXAttr(FSDirXAttrOp.java:85)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setXAttr(FSNamesystem.java:7714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setXAttr(NameNodeRpcServer.java:2170)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setXAttr(ClientNamenodeProtocolServerSideTranslatorPB.java:1615)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:07:16,767 [IPC Server handler 5 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p2/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:16,770 [IPC Server handler 2 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,773 [IPC Server handler 3 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,784 [IPC Server handler 1 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p2/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:16,791 [IPC Server handler 9 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,793 [IPC Server handler 0 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,798 [IPC Server handler 6 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,798 [IPC Server handler 6 on 38960] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 6 on 38960, call Call#51 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.removeXAttr from 127.0.0.1:33458: org.apache.hadoop.security.AccessControlException: The xattr 'security.hdfs.unreadable.by.superuser' can not be deleted.
2020-04-02 05:07:16,802 [IPC Server handler 4 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,804 [IPC Server handler 7 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,805 [IPC Server handler 8 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,805 [IPC Server handler 8 on 38960] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 8 on 38960, call Call#54 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:33458: org.apache.hadoop.security.AccessControlException: Attempt to set a value for 'security.hdfs.unreadable.by.superuser'. Values are not allowed for this xattr.
2020-04-02 05:07:16,813 [IPC Server handler 5 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,826 [IPC Server handler 2 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,826 [IPC Server handler 2 on 38960] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 2 on 38960, call Call#56 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:33458: org.apache.hadoop.security.AccessControlException: Access is denied for root since the superuser is not allowed to perform this operation.
2020-04-02 05:07:16,838 [IPC Server handler 3 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/p2/file	dst=/p2/filex	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:16,844 [IPC Server handler 1 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/p2/filex	dst=/p2/file	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:16,846 [IPC Server handler 9 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,848 [IPC Server handler 0 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/p2	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,855 [IPC Server handler 6 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:16,860 [IPC Server handler 4 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p2	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
2020-04-02 05:07:16,871 [IPC Server handler 7 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p2	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
2020-04-02 05:07:16,874 [IPC Server handler 8 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/p2/file	dst=null	perm=user:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:16,882 [IPC Server handler 5 on 38960] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:46045 for /p2/file
2020-04-02 05:07:16,885 [DataXceiver for client DFSClient_NONMAPREDUCE_-1047569107_306 at /127.0.0.1:49192 [Receiving block BP-944730262-172.17.0.6-1585804031959:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-944730262-172.17.0.6-1585804031959:blk_1073741827_1003 src: /127.0.0.1:49192 dest: /127.0.0.1:46045
2020-04-02 05:07:16,910 [PacketResponder: BP-944730262-172.17.0.6-1585804031959:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49192, dest: /127.0.0.1:46045, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1047569107_306, offset: 0, srvID: a66a72ee-5beb-418a-8fdf-000c79d6d741, blockid: BP-944730262-172.17.0.6-1585804031959:blk_1073741827_1003, duration(ns): 11030861
2020-04-02 05:07:16,910 [PacketResponder: BP-944730262-172.17.0.6-1585804031959:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-944730262-172.17.0.6-1585804031959:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:16,914 [IPC Server handler 3 on 38960] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741827_1003 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /p2/file
2020-04-02 05:07:17,317 [IPC Server handler 9 on 38960] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /p2/file is closed by DFSClient_NONMAPREDUCE_-1047569107_306
2020-04-02 05:07:17,324 [IPC Server handler 0 on 38960] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 0 on 38960, call Call#70 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:33508
java.io.IOException: Can only set 'security.hdfs.unreadable.by.superuser' on a file.
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedSetXAttrs(FSDirXAttrOp.java:298)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setXAttr(FSDirXAttrOp.java:85)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setXAttr(FSNamesystem.java:7714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setXAttr(NameNodeRpcServer.java:2170)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setXAttr(ClientNamenodeProtocolServerSideTranslatorPB.java:1615)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:07:17,328 [IPC Server handler 6 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p2/file	dst=null	perm=user:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:17,330 [IPC Server handler 4 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,332 [IPC Server handler 7 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,336 [IPC Server handler 8 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p2/file	dst=null	perm=user:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:17,338 [IPC Server handler 5 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,340 [IPC Server handler 2 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,343 [IPC Server handler 1 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,343 [IPC Server handler 1 on 38960] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 1 on 38960, call Call#77 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.removeXAttr from 127.0.0.1:33508: org.apache.hadoop.security.AccessControlException: The xattr 'security.hdfs.unreadable.by.superuser' can not be deleted.
2020-04-02 05:07:17,346 [IPC Server handler 3 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,348 [IPC Server handler 9 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,350 [IPC Server handler 0 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,350 [IPC Server handler 0 on 38960] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 0 on 38960, call Call#80 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:33508: org.apache.hadoop.security.AccessControlException: Attempt to set a value for 'security.hdfs.unreadable.by.superuser'. Values are not allowed for this xattr.
2020-04-02 05:07:17,353 [IPC Server handler 6 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,357 [IPC Server handler 4 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,430 [IPC Server handler 7 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/p2/file	dst=/p2/filex	perm=user:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:17,432 [IPC Server handler 8 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/p2/filex	dst=/p2/file	perm=user:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:17,437 [IPC Server handler 5 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,439 [IPC Server handler 2 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/p2	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testUnreadableBySuperuserXAttr
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testUnreadableBySuperuserXAttr
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testCreateXAttr
[msx] perform reset as unitTestCounterInClass 2 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:17,452 [IPC Server handler 1 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p3	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:17,455 [IPC Server handler 3 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/p3/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:17,474 [IPC Server handler 9 on 38960] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:46045 for /p3/file
2020-04-02 05:07:17,492 [DataXceiver for client DFSClient_NONMAPREDUCE_1737566763_1 at /127.0.0.1:49220 [Receiving block BP-944730262-172.17.0.6-1585804031959:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-944730262-172.17.0.6-1585804031959:blk_1073741828_1004 src: /127.0.0.1:49220 dest: /127.0.0.1:46045
2020-04-02 05:07:17,526 [PacketResponder: BP-944730262-172.17.0.6-1585804031959:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49220, dest: /127.0.0.1:46045, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1737566763_1, offset: 0, srvID: a66a72ee-5beb-418a-8fdf-000c79d6d741, blockid: BP-944730262-172.17.0.6-1585804031959:blk_1073741828_1004, duration(ns): 31696159
2020-04-02 05:07:17,530 [PacketResponder: BP-944730262-172.17.0.6-1585804031959:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-944730262-172.17.0.6-1585804031959:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:17,538 [IPC Server handler 4 on 38960] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /p3/file is closed by DFSClient_NONMAPREDUCE_1737566763_1
2020-04-02 05:07:17,546 [IPC Server handler 7 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p3/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:17,550 [IPC Server handler 8 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p3/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,555 [IPC Server handler 5 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p3/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:17,558 [IPC Server handler 2 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p3/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,566 [IPC Server handler 1 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p3/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:17,574 [IPC Server handler 3 on 38960] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 3 on 38960, call Call#98 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:33458
java.io.IOException: XAttr: a1 already exists. The REPLACE flag must be specified.
	at org.apache.hadoop.fs.XAttrSetFlag.validate(XAttrSetFlag.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setINodeXAttrs(FSDirXAttrOp.java:342)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedSetXAttrs(FSDirXAttrOp.java:272)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setXAttr(FSDirXAttrOp.java:85)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setXAttr(FSNamesystem.java:7714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setXAttr(NameNodeRpcServer.java:2170)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setXAttr(ClientNamenodeProtocolServerSideTranslatorPB.java:1615)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:07:17,582 [IPC Server handler 9 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p3/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:17,587 [IPC Server handler 0 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p3/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:17,593 [IPC Server handler 6 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p3/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:17,598 [IPC Server handler 4 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p3/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:17,608 [IPC Server handler 7 on 38960] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p3/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,618 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:17,622 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:17,623 [Thread-104] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 34294 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:17,624 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3543df7d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:17,624 [Thread-104] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:17,630 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae) exiting.
2020-04-02 05:07:17,630 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093) exiting.
2020-04-02 05:07:17,735 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4da602fc{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:17,741 [Thread-104] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2a8d39c4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:17,743 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f0b0a5e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:17,744 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3fa2213{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:17,764 [Thread-104] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34294
2020-04-02 05:07:17,765 [IPC Server listener on 34294] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34294
2020-04-02 05:07:17,783 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:17,786 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38960] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:17,786 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38960] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:38960
2020-04-02 05:07:17,888 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38960] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741)
2020-04-02 05:07:17,888 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38960] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:17,899 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:17,909 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:17,919 [Thread-104] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:17,919 [Thread-104] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:17,920 [Thread-104] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:17,920 [Thread-104] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:17,928 [Thread-104] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:17,929 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:17,929 [Thread-104] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 38960 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:17,929 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:17,930 [Thread-104] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 55
2020-04-02 05:07:17,933 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@55562aa9] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:17,935 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@73173f63] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:17,936 [Thread-104] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 56 Total time for transactions(ms): 23 Number of transactions batched in Syncs: 4 Number of syncs: 53 SyncTimes(ms): 5 1 
2020-04-02 05:07:17,937 [Thread-104] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000056
2020-04-02 05:07:17,938 [Thread-104] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000056
2020-04-02 05:07:17,939 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:17,939 [CacheReplicationMonitor(923321354)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:17,942 [Thread-104] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38960
2020-04-02 05:07:17,949 [IPC Server listener on 38960] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38960
2020-04-02 05:07:17,949 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:17,949 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:17,949 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:17,995 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:17,996 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:17,999 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@48c76607{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:18,001 [Thread-104] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@52e7a6b2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:18,002 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2fb0623e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:18,003 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f67a4d3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:18,016 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:18,020 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:18,020 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:18,027 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:07:18,031 [Thread-104] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:18,036 [Thread-104] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:18,038 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:18,038 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:18,039 [Thread-104] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:18,039 [Thread-104] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:18,045 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2bbd43b1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:18,045 [Thread-104] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:18,046 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:18,047 [Thread-104] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:18,048 [Thread-104] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:18,049 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:18,050 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:18,052 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:18,052 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:18,052 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:18,054 [Thread-104] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:18,055 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:18,055 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43241
2020-04-02 05:07:18,056 [Thread-104] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:18,058 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@ae95aca{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:18,059 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@40b9dde2{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:18,065 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@23607c4f{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:18,067 [Thread-104] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@553b4e24{HTTP/1.1,[http/1.1]}{localhost:43241}
2020-04-02 05:07:18,068 [Thread-104] INFO  server.Server (Server.java:doStart(419)) - Started @8280ms
2020-04-02 05:07:18,072 [Thread-104] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:18,073 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:18,075 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:18,075 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:18,076 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:18,076 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:18,076 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:18,076 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:18,077 [Thread-104] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:18,077 [Thread-104] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:18,077 [Thread-104] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:18,078 [Thread-104] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:18,078 [Thread-104] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:18
2020-04-02 05:07:18,079 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:18,079 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:18,079 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:18,079 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:18,092 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:18,093 [Thread-104] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:18,093 [Thread-104] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:18,093 [Thread-104] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:18,094 [Thread-104] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:18,094 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:18,094 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:18,094 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:18,094 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:18,094 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:18,095 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:18,095 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:18,095 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:18,095 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:18,096 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:18,096 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:18,102 [Thread-104] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:18,103 [Thread-104] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:18,103 [Thread-104] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:18,103 [Thread-104] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:18,103 [Thread-104] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:18,103 [Thread-104] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:18,103 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:18,103 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:18,104 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:18,104 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:18,106 [Thread-104] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:18,106 [Thread-104] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:18,106 [Thread-104] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:18,107 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:18,107 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:18,107 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:18,107 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:18,108 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:18,108 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:18,110 [Thread-104] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:18,111 [Thread-104] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:18,113 [Thread-104] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:18,114 [Thread-104] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:18,120 [Thread-104] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:18,122 [Thread-104] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:07:18,123 [Thread-104] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:18,123 [Thread-104] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:07:18,123 [Thread-104] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3182270a expecting start txid #1
2020-04-02 05:07:18,124 [Thread-104] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000056, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000056 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:18,124 [Thread-104] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000056' to transaction ID 1
2020-04-02 05:07:18,145 [Thread-104] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000056, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000056 of size 3759 edits # 56 loaded in 0 seconds
2020-04-02 05:07:18,146 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:18,147 [Thread-104] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 57
2020-04-02 05:07:18,161 [Thread-104] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:18,161 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 52 msecs
2020-04-02 05:07:18,162 [Thread-104] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:18,162 [Thread-104] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:18,163 [Socket Reader #1 for port 33704] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33704
2020-04-02 05:07:18,175 [Thread-104] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:33704 to access this namenode/service.
2020-04-02 05:07:18,176 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:18,200 [Thread-104] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:18,202 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:18,202 [Thread-104] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:18,202 [Thread-104] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:18,202 [Thread-104] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:18,208 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:07:18,208 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:18,208 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:07:18,208 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:18,208 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:18,208 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2020-04-02 05:07:18,211 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:18,211 [IPC Server listener on 33704] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33704: starting
2020-04-02 05:07:18,215 [Thread-104] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:33704
2020-04-02 05:07:18,216 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:18,216 [Thread-104] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:18,217 [Thread-104] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=3
storage space=8192
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:18,222 [Thread-104] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 33704 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:18,223 [CacheReplicationMonitor(1303873652)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:18,225 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:18,226 [Thread-104] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:18,227 [Thread-104] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:18,229 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:18,229 [Thread-104] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:18,230 [Thread-104] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:18,230 [Thread-104] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:18,231 [Thread-104] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:18,231 [Thread-104] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:18,232 [Thread-104] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:18,232 [Thread-104] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:43961
2020-04-02 05:07:18,233 [Thread-104] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:18,233 [Thread-104] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:18,234 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:18,236 [Thread-104] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:18,239 [Thread-104] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:18,239 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:18,259 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:18,260 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:18,260 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:18,260 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:18,262 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38520
2020-04-02 05:07:18,262 [Thread-104] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:18,266 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@71363b7b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:18,267 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@11117b50{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:18,272 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@dc06ed3{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:18,272 [Thread-104] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@331dda06{HTTP/1.1,[http/1.1]}{localhost:38520}
2020-04-02 05:07:18,273 [Thread-104] INFO  server.Server (Server.java:doStart(419)) - Started @8485ms
2020-04-02 05:07:18,426 [Thread-104] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38074
2020-04-02 05:07:18,431 [Thread-104] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:18,431 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@32cba361] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:18,431 [Thread-104] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:18,432 [Thread-104] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:18,432 [Socket Reader #1 for port 37434] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37434
2020-04-02 05:07:18,440 [Thread-104] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:37434
2020-04-02 05:07:18,446 [Thread-104] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:18,446 [Thread-104] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:18,449 [Thread-159] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33704 starting to offer service
2020-04-02 05:07:18,450 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:18,450 [IPC Server listener on 37434] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37434: starting
2020-04-02 05:07:18,462 [Thread-104] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 37434 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:18,489 [IPC Server handler 1 on 33704] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:18,490 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:18,490 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:18,490 [Thread-159] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33704
2020-04-02 05:07:18,491 [Thread-159] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:18,495 [Thread-159] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:18,497 [Thread-159] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:18,512 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:18,513 [Thread-159] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:18,530 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:18,530 [Thread-159] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:18,532 [Thread-159] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=213151118;bpid=BP-944730262-172.17.0.6-1585804031959;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=213151118;c=1585804031959;bpid=BP-944730262-172.17.0.6-1585804031959;dnuuid=a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:18,534 [Thread-159] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5437a82e-ddff-46c6-ad88-3ed31967d093
2020-04-02 05:07:18,536 [Thread-159] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:18,541 [Thread-159] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae
2020-04-02 05:07:18,547 [Thread-159] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:18,547 [Thread-159] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:18,549 [Thread-159] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:18,565 [Thread-159] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:18,566 [Thread-159] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:18,566 [Thread-159] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:18,579 [Thread-159] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:18,580 [Thread-174] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:18,581 [Thread-175] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:18,583 [Thread-174] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959/current: 33878
2020-04-02 05:07:18,584 [Thread-175] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959/current: 41102
2020-04-02 05:07:18,593 [Thread-174] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-944730262-172.17.0.6-1585804031959 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 12ms
2020-04-02 05:07:18,598 [Thread-175] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-944730262-172.17.0.6-1585804031959 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 17ms
2020-04-02 05:07:18,604 [IPC Server handler 2 on 33704] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:18,609 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:18,610 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:18,609 [Thread-159] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-944730262-172.17.0.6-1585804031959: 30ms
2020-04-02 05:07:18,618 [Thread-176] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:18,618 [Thread-177] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:18,621 [Thread-176] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959/current/replicas
2020-04-02 05:07:18,621 [Thread-176] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 3ms
2020-04-02 05:07:18,621 [Thread-177] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959/current/replicas
2020-04-02 05:07:18,622 [Thread-177] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 3ms
2020-04-02 05:07:18,624 [Thread-159] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-944730262-172.17.0.6-1585804031959: 10ms
2020-04-02 05:07:18,652 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae): no suitable block pools found to scan.  Waiting 1814397065 ms.
2020-04-02 05:07:18,653 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093): no suitable block pools found to scan.  Waiting 1814397064 ms.
2020-04-02 05:07:18,655 [Thread-159] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:52 AM with interval of 21600000ms
2020-04-02 05:07:18,657 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:33704] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:33704 beginning handshake with NN
2020-04-02 05:07:18,662 [IPC Server handler 4 on 33704] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43961, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=38074, infoSecurePort=0, ipcPort=37434, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959) storage a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:18,663 [IPC Server handler 4 on 33704] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43961
2020-04-02 05:07:18,663 [IPC Server handler 4 on 33704] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a66a72ee-5beb-418a-8fdf-000c79d6d741 (127.0.0.1:43961).
2020-04-02 05:07:18,671 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:33704] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:33704 successfully registered with NN
2020-04-02 05:07:18,672 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:33704] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33704 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:18,678 [IPC Server handler 0 on 33704] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5437a82e-ddff-46c6-ad88-3ed31967d093 for DN 127.0.0.1:43961
2020-04-02 05:07:18,678 [IPC Server handler 0 on 33704] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae for DN 127.0.0.1:43961
2020-04-02 05:07:18,698 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc8526f5ce47b301: Processing first storage report for DS-5437a82e-ddff-46c6-ad88-3ed31967d093 from datanode a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:18,699 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc8526f5ce47b301: from storage DS-5437a82e-ddff-46c6-ad88-3ed31967d093 node DatanodeRegistration(127.0.0.1:43961, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=38074, infoSecurePort=0, ipcPort=37434, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959), blocks: 2, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:18,700 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc8526f5ce47b301: Processing first storage report for DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae from datanode a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:18,702 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc8526f5ce47b301: from storage DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae node DatanodeRegistration(127.0.0.1:43961, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=38074, infoSecurePort=0, ipcPort=37434, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959), blocks: 2, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:07:18,703 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:33704] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xc8526f5ce47b301,  containing 2 storage report(s), of which we sent 2. The reports had 4 total blocks and used 1 RPC(s). This took 1 msec to generate and 21 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:18,703 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:33704] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:18,726 [IPC Server handler 7 on 33704] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:18,742 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:18,748 [IPC Server handler 8 on 33704] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:18,749 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:18,759 [IPC Server handler 6 on 33704] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p3/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:18,761 [Thread-104] INFO  hdfs.StateChange (FSNamesystem.java:enterSafeMode(4593)) - STATE* Safe mode is ON.
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2020-04-02 05:07:18,761 [Thread-104] INFO  namenode.FSImage (FSImage.java:saveNamespace(1101)) - Save namespace ...
2020-04-02 05:07:18,761 [Thread-104] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 57, 57
2020-04-02 05:07:18,768 [Thread-104] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 56 Number of syncs: 3 SyncTimes(ms): 1 2 
2020-04-02 05:07:18,769 [Thread-104] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000057 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000057-0000000000000000058
2020-04-02 05:07:18,770 [Thread-104] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000057 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000057-0000000000000000058
2020-04-02 05:07:18,782 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000058 using no compression
2020-04-02 05:07:18,790 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000058 using no compression
2020-04-02 05:07:18,801 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000058 of size 629 bytes saved in 0 seconds .
2020-04-02 05:07:18,802 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000058 of size 629 bytes saved in 0 seconds .
2020-04-02 05:07:18,816 [Thread-104] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 0
2020-04-02 05:07:18,833 [Thread-104] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 59
2020-04-02 05:07:18,852 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:saveNamespace(4419)) - New namespace image has been created
2020-04-02 05:07:18,853 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:18,853 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:18,853 [Thread-104] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 37434 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:18,853 [Thread-104] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:18,853 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@421f953b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:18,856 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093) exiting.
2020-04-02 05:07:18,857 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae) exiting.
2020-04-02 05:07:18,961 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@dc06ed3{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:19,216 [Thread-104] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@331dda06{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:19,217 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@11117b50{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:19,217 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@71363b7b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:19,239 [Thread-104] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37434
2020-04-02 05:07:19,244 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:19,246 [IPC Server listener on 37434] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37434
2020-04-02 05:07:19,247 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:33704] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:19,253 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:33704] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:33704
2020-04-02 05:07:19,254 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:33704] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741)
2020-04-02 05:07:19,254 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:33704] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:19,262 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:19,269 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:19,279 [Thread-104] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:19,279 [Thread-104] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:19,280 [Thread-104] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:19,280 [Thread-104] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:19,282 [Thread-104] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:19,282 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:19,282 [Thread-104] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 33704 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:19,283 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:19,283 [Thread-104] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 59, 59
2020-04-02 05:07:19,283 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@1379f70e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:19,283 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@2735ca8e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:19,285 [Thread-104] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 2 1 
2020-04-02 05:07:19,286 [Thread-104] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000059 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000059-0000000000000000060
2020-04-02 05:07:19,287 [Thread-104] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000059 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000059-0000000000000000060
2020-04-02 05:07:19,287 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:19,287 [CacheReplicationMonitor(1303873652)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:19,292 [Thread-104] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33704
2020-04-02 05:07:19,300 [IPC Server listener on 33704] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33704
2020-04-02 05:07:19,302 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:19,302 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:19,300 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:19,328 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:19,329 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:19,335 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@23607c4f{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:19,342 [Thread-104] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@553b4e24{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:19,342 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@40b9dde2{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:19,343 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@ae95aca{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:19,354 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:19,358 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:19,359 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:19,367 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:07:19,368 [Thread-104] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:19,373 [Thread-104] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:19,379 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:19,380 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:19,380 [Thread-104] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:19,381 [Thread-104] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:19,386 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@502c153d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:19,387 [Thread-104] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:19,387 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:19,388 [Thread-104] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:19,389 [Thread-104] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:19,389 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:19,391 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:19,391 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:19,391 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:19,391 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:19,393 [Thread-104] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:19,393 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:19,393 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43344
2020-04-02 05:07:19,393 [Thread-104] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:19,395 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@682c7393{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:19,396 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@73b0094c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:19,400 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2fae72db{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:19,407 [Thread-104] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@60c3c343{HTTP/1.1,[http/1.1]}{localhost:43344}
2020-04-02 05:07:19,408 [Thread-104] INFO  server.Server (Server.java:doStart(419)) - Started @9620ms
2020-04-02 05:07:19,411 [Thread-104] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:19,412 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:19,412 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:19,412 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:19,412 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:19,412 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:19,413 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:19,413 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:19,413 [Thread-104] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:19,414 [Thread-104] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:19,414 [Thread-104] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:19,414 [Thread-104] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:19,414 [Thread-104] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:19
2020-04-02 05:07:19,414 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:19,414 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:19,414 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:19,415 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:19,419 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:19,419 [Thread-104] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:19,419 [Thread-104] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:19,420 [Thread-104] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:19,420 [Thread-104] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:19,420 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:19,420 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:19,420 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:19,420 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:19,420 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:19,420 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:19,420 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:19,420 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:19,420 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:19,421 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:19,421 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:19,423 [Thread-104] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:19,423 [Thread-104] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:19,423 [Thread-104] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:19,423 [Thread-104] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:19,424 [Thread-104] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:19,424 [Thread-104] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:19,424 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:19,424 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:19,424 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:19,425 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:19,426 [Thread-104] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:19,426 [Thread-104] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:19,426 [Thread-104] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:19,427 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:19,427 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:19,427 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:19,427 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:19,427 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:19,427 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:19,429 [Thread-104] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:19,430 [Thread-104] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:19,432 [Thread-104] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:19,432 [Thread-104] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:19,433 [Thread-104] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000058, cpktTxId=0000000000000000058)
2020-04-02 05:07:19,434 [Thread-104] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 3 INodes.
2020-04-02 05:07:19,436 [Thread-104] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:19,437 [Thread-104] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 58 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000058
2020-04-02 05:07:19,437 [Thread-104] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@123b3f98 expecting start txid #59
2020-04-02 05:07:19,437 [Thread-104] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000059-0000000000000000060, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000059-0000000000000000060 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:19,437 [Thread-104] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000059-0000000000000000060' to transaction ID 59
2020-04-02 05:07:19,439 [Thread-104] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000059-0000000000000000060, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000059-0000000000000000060 of size 42 edits # 2 loaded in 0 seconds
2020-04-02 05:07:19,439 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:19,441 [Thread-104] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 61
2020-04-02 05:07:19,459 [Thread-104] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:19,460 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 32 msecs
2020-04-02 05:07:19,460 [Thread-104] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:19,461 [Thread-104] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:19,462 [Socket Reader #1 for port 45728] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45728
2020-04-02 05:07:19,467 [Thread-104] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:45728 to access this namenode/service.
2020-04-02 05:07:19,468 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:19,519 [Thread-104] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:19,521 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:19,521 [Thread-104] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:19,521 [Thread-104] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:19,521 [Thread-104] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:19,528 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:07:19,528 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:19,528 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:07:19,528 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:19,528 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:19,528 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 7 msec
2020-04-02 05:07:19,536 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:19,536 [IPC Server listener on 45728] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45728: starting
2020-04-02 05:07:19,542 [Thread-104] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:45728
2020-04-02 05:07:19,542 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:19,543 [Thread-104] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:19,543 [Thread-104] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=3
storage space=8192
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:19,558 [Thread-104] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 45728 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:19,560 [CacheReplicationMonitor(1079048544)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:19,567 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:19,568 [Thread-104] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:19,569 [Thread-104] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:19,569 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:19,570 [Thread-104] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:19,573 [Thread-104] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:19,573 [Thread-104] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:19,573 [Thread-104] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:19,574 [Thread-104] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:19,574 [Thread-104] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:19,575 [Thread-104] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:46451
2020-04-02 05:07:19,575 [Thread-104] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:19,575 [Thread-104] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:19,576 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:19,577 [Thread-104] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:19,578 [Thread-104] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:19,578 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:19,579 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:19,579 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:19,580 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:19,580 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:19,580 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41024
2020-04-02 05:07:19,581 [Thread-104] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:19,582 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@692961de{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:19,583 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@693780ec{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:19,588 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6fe7cb1e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:19,592 [Thread-104] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3388370f{HTTP/1.1,[http/1.1]}{localhost:41024}
2020-04-02 05:07:19,592 [Thread-104] INFO  server.Server (Server.java:doStart(419)) - Started @9804ms
2020-04-02 05:07:19,614 [Thread-104] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40608
2020-04-02 05:07:19,618 [Thread-104] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:19,618 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@33980106] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:19,618 [Thread-104] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:19,622 [Thread-104] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:19,623 [Socket Reader #1 for port 37339] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37339
2020-04-02 05:07:19,627 [Thread-104] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:37339
2020-04-02 05:07:19,633 [Thread-104] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:19,634 [Thread-104] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:19,635 [IPC Server listener on 37339] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37339: starting
2020-04-02 05:07:19,635 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:19,635 [Thread-232] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45728 starting to offer service
2020-04-02 05:07:19,636 [Thread-104] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 37339 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:19,664 [IPC Server handler 0 on 45728] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:19,674 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:19,674 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:19,677 [Thread-232] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45728
2020-04-02 05:07:19,683 [Thread-232] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:19,684 [Thread-232] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:19,686 [Thread-232] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:19,695 [Thread-232] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:19,695 [Thread-232] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:19,705 [Thread-232] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:19,705 [Thread-232] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:19,706 [Thread-232] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=213151118;bpid=BP-944730262-172.17.0.6-1585804031959;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=213151118;c=1585804031959;bpid=BP-944730262-172.17.0.6-1585804031959;dnuuid=a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:19,708 [Thread-232] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5437a82e-ddff-46c6-ad88-3ed31967d093
2020-04-02 05:07:19,708 [Thread-232] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:19,710 [Thread-232] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae
2020-04-02 05:07:19,710 [Thread-232] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:19,711 [Thread-232] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:19,714 [Thread-232] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:19,715 [Thread-232] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:19,716 [Thread-232] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:19,716 [Thread-232] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:19,718 [Thread-232] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:19,718 [Thread-247] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:19,718 [Thread-248] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:19,722 [Thread-248] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959/current: 41102
2020-04-02 05:07:19,722 [Thread-247] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959/current: 33878
2020-04-02 05:07:19,731 [Thread-247] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-944730262-172.17.0.6-1585804031959 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 13ms
2020-04-02 05:07:19,732 [Thread-248] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-944730262-172.17.0.6-1585804031959 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 13ms
2020-04-02 05:07:19,734 [Thread-232] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-944730262-172.17.0.6-1585804031959: 16ms
2020-04-02 05:07:19,735 [Thread-249] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:19,735 [Thread-250] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:19,737 [Thread-249] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959/current/replicas
2020-04-02 05:07:19,737 [Thread-250] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959/current/replicas
2020-04-02 05:07:19,737 [Thread-249] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 2ms
2020-04-02 05:07:19,737 [Thread-250] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 2ms
2020-04-02 05:07:19,737 [Thread-232] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-944730262-172.17.0.6-1585804031959: 2ms
2020-04-02 05:07:19,738 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae): no suitable block pools found to scan.  Waiting 1814395979 ms.
2020-04-02 05:07:19,738 [Thread-232] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:12 AM with interval of 21600000ms
2020-04-02 05:07:19,740 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:45728] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:45728 beginning handshake with NN
2020-04-02 05:07:19,742 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093): no suitable block pools found to scan.  Waiting 1814395975 ms.
2020-04-02 05:07:19,742 [IPC Server handler 1 on 45728] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46451, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=40608, infoSecurePort=0, ipcPort=37339, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959) storage a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:19,742 [IPC Server handler 1 on 45728] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46451
2020-04-02 05:07:19,744 [IPC Server handler 1 on 45728] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a66a72ee-5beb-418a-8fdf-000c79d6d741 (127.0.0.1:46451).
2020-04-02 05:07:19,770 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:45728] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:45728 successfully registered with NN
2020-04-02 05:07:19,770 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:45728] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:45728 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:19,775 [IPC Server handler 4 on 45728] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5437a82e-ddff-46c6-ad88-3ed31967d093 for DN 127.0.0.1:46451
2020-04-02 05:07:19,775 [IPC Server handler 4 on 45728] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae for DN 127.0.0.1:46451
2020-04-02 05:07:19,784 [IPC Server handler 5 on 45728] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:19,790 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:19,797 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb547121bfc5c7422: Processing first storage report for DS-5437a82e-ddff-46c6-ad88-3ed31967d093 from datanode a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:19,797 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb547121bfc5c7422: from storage DS-5437a82e-ddff-46c6-ad88-3ed31967d093 node DatanodeRegistration(127.0.0.1:46451, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=40608, infoSecurePort=0, ipcPort=37339, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959), blocks: 2, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:19,798 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb547121bfc5c7422: Processing first storage report for DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae from datanode a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:19,801 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb547121bfc5c7422: from storage DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae node DatanodeRegistration(127.0.0.1:46451, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=40608, infoSecurePort=0, ipcPort=37339, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959), blocks: 2, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2020-04-02 05:07:19,801 [IPC Server handler 6 on 45728] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:19,803 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:19,805 [IPC Server handler 7 on 45728] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p3/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:19,810 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:45728] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xb547121bfc5c7422,  containing 2 storage report(s), of which we sent 2. The reports had 4 total blocks and used 1 RPC(s). This took 1 msec to generate and 10 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:19,810 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:45728] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:19,835 [IPC Server handler 9 on 45728] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/p3/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:19,837 [IPC Server handler 3 on 45728] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/.reserved/raw/p3	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:19,843 [IPC Server handler 0 on 45728] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/.reserved/raw/p3/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:19,869 [IPC Server handler 2 on 45728] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:46451 for /p3/file
2020-04-02 05:07:19,986 [DataXceiver for client DFSClient_NONMAPREDUCE_195793994_319 at /127.0.0.1:59332 [Receiving block BP-944730262-172.17.0.6-1585804031959:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-944730262-172.17.0.6-1585804031959:blk_1073741829_1005 src: /127.0.0.1:59332 dest: /127.0.0.1:46451
2020-04-02 05:07:20,025 [PacketResponder: BP-944730262-172.17.0.6-1585804031959:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59332, dest: /127.0.0.1:46451, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_195793994_319, offset: 0, srvID: a66a72ee-5beb-418a-8fdf-000c79d6d741, blockid: BP-944730262-172.17.0.6-1585804031959:blk_1073741829_1005, duration(ns): 16000610
2020-04-02 05:07:20,025 [PacketResponder: BP-944730262-172.17.0.6-1585804031959:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-944730262-172.17.0.6-1585804031959:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:20,035 [IPC Server handler 5 on 45728] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /.reserved/raw/p3/file is closed by DFSClient_NONMAPREDUCE_195793994_319
2020-04-02 05:07:20,037 [IPC Server handler 6 on 45728] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p3/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:20,038 [IPC Server handler 8 on 45728] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/p3/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:20,039 [IPC Server handler 7 on 45728] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/.reserved/raw/p3/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:20,041 [IPC Server handler 9 on 45728] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/p3/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:20,042 [IPC Server handler 3 on 45728] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p3/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:20,047 [IPC Server handler 0 on 45728] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 0 on 45728, call Call#133 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:38870
java.io.IOException: XAttr: a1 already exists. The REPLACE flag must be specified.
	at org.apache.hadoop.fs.XAttrSetFlag.validate(XAttrSetFlag.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setINodeXAttrs(FSDirXAttrOp.java:342)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedSetXAttrs(FSDirXAttrOp.java:272)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setXAttr(FSDirXAttrOp.java:85)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setXAttr(FSNamesystem.java:7714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setXAttr(NameNodeRpcServer.java:2170)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setXAttr(ClientNamenodeProtocolServerSideTranslatorPB.java:1615)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:07:20,054 [IPC Server handler 2 on 45728] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/.reserved/raw/p3/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:20,057 [IPC Server handler 1 on 45728] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p3/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:20,059 [IPC Server handler 4 on 45728] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p3/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:20,062 [IPC Server handler 5 on 45728] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p3/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:20,065 [IPC Server handler 6 on 45728] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p3/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:20,066 [IPC Server handler 8 on 45728] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/p3/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:20,067 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:20,067 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:20,067 [Thread-104] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 37339 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:20,067 [Thread-104] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:20,068 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2a503b4d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:20,071 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093) exiting.
2020-04-02 05:07:20,071 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae) exiting.
2020-04-02 05:07:20,088 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6fe7cb1e{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:20,090 [Thread-104] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3388370f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:20,090 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@693780ec{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:20,091 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@692961de{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:20,093 [Thread-104] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37339
2020-04-02 05:07:20,093 [IPC Server listener on 37339] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37339
2020-04-02 05:07:20,095 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:20,095 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:45728] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:20,095 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:45728] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:45728
2020-04-02 05:07:20,196 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:45728] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741)
2020-04-02 05:07:20,196 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:45728] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:20,213 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:20,245 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:20,262 [Thread-104] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:20,262 [Thread-104] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:20,263 [Thread-104] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:20,263 [Thread-104] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:20,265 [Thread-104] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:20,265 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:20,265 [Thread-104] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 45728 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:20,265 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:20,266 [Thread-104] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 61, 75
2020-04-02 05:07:20,266 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@1e14350e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:20,267 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@6331a942] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:20,268 [Thread-104] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 16 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 60 Number of syncs: 17 SyncTimes(ms): 2 5 
2020-04-02 05:07:20,269 [Thread-104] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000061 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000061-0000000000000000076
2020-04-02 05:07:20,270 [Thread-104] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000061 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000061-0000000000000000076
2020-04-02 05:07:20,271 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:20,271 [CacheReplicationMonitor(1079048544)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:20,278 [Thread-104] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45728
2020-04-02 05:07:20,280 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:20,280 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:20,282 [IPC Server listener on 45728] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45728
2020-04-02 05:07:20,282 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:20,292 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:20,292 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:20,293 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2fae72db{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:20,305 [Thread-104] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@60c3c343{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:20,305 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@73b0094c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:20,306 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@682c7393{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:20,311 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:20,314 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:20,314 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:20,320 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:07:20,322 [Thread-104] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:20,329 [Thread-104] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:20,345 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:20,346 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:20,346 [Thread-104] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:20,347 [Thread-104] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:20,353 [Thread-104] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:20,353 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:20,354 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@54ed90df] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:20,355 [Thread-104] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:20,357 [Thread-104] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:20,358 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:20,359 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:20,360 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:20,360 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:20,360 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:20,362 [Thread-104] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:20,362 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:20,362 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46450
2020-04-02 05:07:20,363 [Thread-104] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:20,374 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@59c6d961{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:20,375 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@798d4a88{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:20,386 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4d6917e1{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:20,391 [Thread-104] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5c2b7b5c{HTTP/1.1,[http/1.1]}{localhost:46450}
2020-04-02 05:07:20,392 [Thread-104] INFO  server.Server (Server.java:doStart(419)) - Started @10604ms
2020-04-02 05:07:20,393 [Thread-104] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:20,394 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:20,394 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:20,394 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:20,394 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:20,394 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:20,395 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:20,395 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:20,395 [Thread-104] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:20,396 [Thread-104] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:20,396 [Thread-104] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:20,396 [Thread-104] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:20,397 [Thread-104] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:20
2020-04-02 05:07:20,397 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:20,397 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:20,411 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:20,412 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:20,435 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:20,435 [Thread-104] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:20,436 [Thread-104] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:20,436 [Thread-104] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:20,436 [Thread-104] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:20,436 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:20,436 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:20,436 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:20,436 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:20,436 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:20,436 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:20,437 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:20,437 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:20,437 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:20,437 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:20,438 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:20,443 [Thread-104] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:20,443 [Thread-104] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:20,444 [Thread-104] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:20,444 [Thread-104] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:20,444 [Thread-104] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:20,444 [Thread-104] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:20,444 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:20,445 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:20,445 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:20,445 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:20,447 [Thread-104] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:20,447 [Thread-104] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:20,447 [Thread-104] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:20,450 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:20,450 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:20,450 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:20,450 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:20,451 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:20,451 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:20,453 [Thread-104] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:20,454 [Thread-104] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:20,456 [Thread-104] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:20,456 [Thread-104] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:20,457 [Thread-104] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000058, cpktTxId=0000000000000000058)
2020-04-02 05:07:20,459 [Thread-104] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 3 INodes.
2020-04-02 05:07:20,460 [Thread-104] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:20,460 [Thread-104] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 58 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000058
2020-04-02 05:07:20,460 [Thread-104] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5f91da22 expecting start txid #59
2020-04-02 05:07:20,460 [Thread-104] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000059-0000000000000000060, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000059-0000000000000000060 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:20,460 [Thread-104] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000059-0000000000000000060' to transaction ID 59
2020-04-02 05:07:20,460 [Thread-104] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000059-0000000000000000060, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000059-0000000000000000060 of size 42 edits # 2 loaded in 0 seconds
2020-04-02 05:07:20,461 [Thread-104] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@45b66ce4 expecting start txid #61
2020-04-02 05:07:20,461 [Thread-104] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000061-0000000000000000076, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000061-0000000000000000076 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:20,461 [Thread-104] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000061-0000000000000000076' to transaction ID 59
2020-04-02 05:07:20,466 [Thread-104] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000061-0000000000000000076, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000061-0000000000000000076 of size 974 edits # 16 loaded in 0 seconds
2020-04-02 05:07:20,467 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:20,468 [Thread-104] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 77
2020-04-02 05:07:20,482 [Thread-104] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:20,482 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 31 msecs
2020-04-02 05:07:20,483 [Thread-104] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:20,483 [Thread-104] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:20,484 [Socket Reader #1 for port 38298] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38298
2020-04-02 05:07:20,489 [Thread-104] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:38298 to access this namenode/service.
2020-04-02 05:07:20,490 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:20,535 [Thread-104] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:20,540 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:20,541 [Thread-104] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:20,541 [Thread-104] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:20,541 [Thread-104] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:20,550 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:20,551 [IPC Server listener on 38298] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38298: starting
2020-04-02 05:07:20,551 [Thread-104] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:38298
2020-04-02 05:07:20,571 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:07:20,571 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:20,571 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:07:20,571 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:20,571 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:20,571 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 25 msec
2020-04-02 05:07:20,571 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:20,571 [Thread-104] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:20,572 [Thread-104] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=3
storage space=8192
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:20,590 [Thread-104] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 38298 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:20,594 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:20,595 [Thread-104] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:20,595 [CacheReplicationMonitor(1302060290)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:20,595 [Thread-104] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:20,603 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:20,603 [Thread-104] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:20,604 [Thread-104] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:20,604 [Thread-104] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:20,604 [Thread-104] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:20,604 [Thread-104] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:20,605 [Thread-104] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:20,606 [Thread-104] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:33037
2020-04-02 05:07:20,630 [Thread-104] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:20,630 [Thread-104] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:20,632 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:20,633 [Thread-104] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:20,640 [Thread-104] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:20,640 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:20,645 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:20,646 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:20,646 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:20,646 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:20,647 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39051
2020-04-02 05:07:20,649 [Thread-104] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:20,651 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7ee8b9bb{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:20,652 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@445bd2b7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:20,657 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@14511ac4{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:20,658 [Thread-104] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@22fe9e6{HTTP/1.1,[http/1.1]}{localhost:39051}
2020-04-02 05:07:20,658 [Thread-104] INFO  server.Server (Server.java:doStart(419)) - Started @10870ms
2020-04-02 05:07:20,680 [Thread-104] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35277
2020-04-02 05:07:20,681 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@629465ff] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:20,681 [Thread-104] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:20,681 [Thread-104] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:20,682 [Thread-104] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:20,683 [Socket Reader #1 for port 40828] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40828
2020-04-02 05:07:20,710 [Thread-104] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40828
2020-04-02 05:07:20,717 [Thread-104] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:20,718 [Thread-104] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:20,719 [Thread-314] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38298 starting to offer service
2020-04-02 05:07:20,730 [IPC Server listener on 40828] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40828: starting
2020-04-02 05:07:20,751 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:20,753 [Thread-104] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40828 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:20,776 [IPC Server handler 1 on 38298] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:20,784 [Thread-314] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38298
2020-04-02 05:07:20,786 [Thread-314] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:20,788 [Thread-314] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:20,794 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:20,794 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:20,802 [Thread-314] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:20,819 [Thread-314] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:20,819 [Thread-314] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:20,840 [Thread-314] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:20,840 [Thread-314] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:20,842 [Thread-314] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=213151118;bpid=BP-944730262-172.17.0.6-1585804031959;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=213151118;c=1585804031959;bpid=BP-944730262-172.17.0.6-1585804031959;dnuuid=a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:20,844 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5437a82e-ddff-46c6-ad88-3ed31967d093
2020-04-02 05:07:20,844 [Thread-314] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:20,865 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae
2020-04-02 05:07:20,872 [Thread-314] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:20,872 [Thread-314] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:20,874 [Thread-314] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:20,876 [Thread-314] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:20,877 [Thread-314] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:20,877 [Thread-314] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:20,890 [Thread-314] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:20,891 [Thread-329] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:20,892 [Thread-329] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959/current: 42141
2020-04-02 05:07:20,893 [Thread-330] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:20,894 [Thread-330] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959/current: 41102
2020-04-02 05:07:20,899 [Thread-329] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-944730262-172.17.0.6-1585804031959 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 8ms
2020-04-02 05:07:20,900 [Thread-330] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-944730262-172.17.0.6-1585804031959 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 7ms
2020-04-02 05:07:20,906 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-944730262-172.17.0.6-1585804031959: 15ms
2020-04-02 05:07:20,914 [IPC Server handler 0 on 38298] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:20,914 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:20,918 [Thread-331] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:20,919 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:20,921 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:20,922 [Thread-332] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959/current/replicas
2020-04-02 05:07:20,922 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 8ms
2020-04-02 05:07:20,924 [Thread-331] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959/current/replicas
2020-04-02 05:07:20,924 [Thread-331] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 7ms
2020-04-02 05:07:20,929 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-944730262-172.17.0.6-1585804031959: 24ms
2020-04-02 05:07:20,931 [Thread-314] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:16 AM with interval of 21600000ms
2020-04-02 05:07:20,931 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093): no suitable block pools found to scan.  Waiting 1814394786 ms.
2020-04-02 05:07:20,933 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae): no suitable block pools found to scan.  Waiting 1814394784 ms.
2020-04-02 05:07:20,933 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38298] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:38298 beginning handshake with NN
2020-04-02 05:07:20,939 [IPC Server handler 5 on 38298] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33037, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=35277, infoSecurePort=0, ipcPort=40828, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959) storage a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:20,939 [IPC Server handler 5 on 38298] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33037
2020-04-02 05:07:20,940 [IPC Server handler 5 on 38298] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a66a72ee-5beb-418a-8fdf-000c79d6d741 (127.0.0.1:33037).
2020-04-02 05:07:20,958 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38298] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:38298 successfully registered with NN
2020-04-02 05:07:20,959 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38298] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38298 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:20,976 [IPC Server handler 6 on 38298] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5437a82e-ddff-46c6-ad88-3ed31967d093 for DN 127.0.0.1:33037
2020-04-02 05:07:20,976 [IPC Server handler 6 on 38298] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae for DN 127.0.0.1:33037
2020-04-02 05:07:20,983 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x63e450560ae1ff7e: Processing first storage report for DS-5437a82e-ddff-46c6-ad88-3ed31967d093 from datanode a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:20,987 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x63e450560ae1ff7e: from storage DS-5437a82e-ddff-46c6-ad88-3ed31967d093 node DatanodeRegistration(127.0.0.1:33037, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=35277, infoSecurePort=0, ipcPort=40828, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959), blocks: 3, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:07:20,987 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x63e450560ae1ff7e: Processing first storage report for DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae from datanode a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:20,987 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x63e450560ae1ff7e: from storage DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae node DatanodeRegistration(127.0.0.1:33037, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=35277, infoSecurePort=0, ipcPort=40828, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:20,990 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38298] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x63e450560ae1ff7e,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 0 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:20,990 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38298] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:21,024 [IPC Server handler 7 on 38298] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:21,025 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:21,030 [IPC Server handler 8 on 38298] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:21,031 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:21,034 [IPC Server handler 3 on 38298] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/p3/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:21,038 [Thread-104] INFO  hdfs.StateChange (FSNamesystem.java:enterSafeMode(4593)) - STATE* Safe mode is ON.
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2020-04-02 05:07:21,038 [Thread-104] INFO  namenode.FSImage (FSImage.java:saveNamespace(1101)) - Save namespace ...
2020-04-02 05:07:21,038 [Thread-104] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 77, 77
2020-04-02 05:07:21,045 [Thread-104] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 76 Number of syncs: 3 SyncTimes(ms): 2 3 
2020-04-02 05:07:21,046 [Thread-104] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000077 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000077-0000000000000000078
2020-04-02 05:07:21,047 [Thread-104] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000077 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000077-0000000000000000078
2020-04-02 05:07:21,051 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000078 using no compression
2020-04-02 05:07:21,054 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000078 using no compression
2020-04-02 05:07:21,064 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000078 of size 641 bytes saved in 0 seconds .
2020-04-02 05:07:21,064 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000078 of size 641 bytes saved in 0 seconds .
2020-04-02 05:07:21,067 [Thread-104] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 58
2020-04-02 05:07:21,068 [Thread-104] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(225)) - Purging old image FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:21,068 [Thread-104] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(225)) - Purging old image FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:21,072 [Thread-104] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 79
2020-04-02 05:07:21,088 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:saveNamespace(4419)) - New namespace image has been created
2020-04-02 05:07:21,088 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:21,089 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:21,089 [Thread-104] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40828 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:21,089 [Thread-104] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:21,089 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7bd0de62] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:21,100 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093) exiting.
2020-04-02 05:07:21,100 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae) exiting.
2020-04-02 05:07:21,119 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@14511ac4{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:21,121 [Thread-104] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@22fe9e6{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:21,121 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@445bd2b7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:21,122 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7ee8b9bb{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:21,123 [Thread-104] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40828
2020-04-02 05:07:21,127 [IPC Server listener on 40828] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40828
2020-04-02 05:07:21,128 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:21,128 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38298] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:21,128 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38298] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:38298
2020-04-02 05:07:21,234 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38298] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741)
2020-04-02 05:07:21,235 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38298] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:21,245 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:21,255 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:21,262 [Thread-104] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:21,262 [Thread-104] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:21,263 [Thread-104] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:21,263 [Thread-104] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:21,265 [Thread-104] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:21,266 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:21,266 [Thread-104] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 38298 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:21,266 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:21,266 [Thread-104] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 79, 79
2020-04-02 05:07:21,267 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3d4a1c71] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:21,275 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@73d49996] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:21,276 [Thread-104] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 1 3 
2020-04-02 05:07:21,277 [Thread-104] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000079 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000079-0000000000000000080
2020-04-02 05:07:21,277 [Thread-104] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000079 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000079-0000000000000000080
2020-04-02 05:07:21,277 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:21,285 [Thread-104] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38298
2020-04-02 05:07:21,286 [IPC Server listener on 38298] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38298
2020-04-02 05:07:21,288 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:21,301 [CacheReplicationMonitor(1302060290)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:21,306 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:21,306 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:21,331 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:21,331 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:21,364 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4d6917e1{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:21,386 [Thread-104] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5c2b7b5c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:21,387 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@798d4a88{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:21,387 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@59c6d961{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:21,398 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:21,400 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:21,403 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:21,410 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:07:21,412 [Thread-104] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:21,418 [Thread-104] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:21,421 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:21,421 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:21,422 [Thread-104] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:21,422 [Thread-104] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:21,446 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5478e023] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:21,446 [Thread-104] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:21,447 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:21,449 [Thread-104] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:21,450 [Thread-104] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:21,450 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:21,451 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:21,452 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:21,452 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:21,452 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:21,459 [Thread-104] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:21,459 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:21,460 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44321
2020-04-02 05:07:21,460 [Thread-104] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:21,467 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@65dbec4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:21,468 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@41e7bfa6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:21,497 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3cedeef1{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:21,498 [Thread-104] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@78e0bbd0{HTTP/1.1,[http/1.1]}{localhost:44321}
2020-04-02 05:07:21,498 [Thread-104] INFO  server.Server (Server.java:doStart(419)) - Started @11710ms
2020-04-02 05:07:21,501 [Thread-104] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:21,501 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:21,504 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:21,504 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:21,504 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:21,505 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:21,505 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:21,505 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:21,505 [Thread-104] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:21,506 [Thread-104] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:21,506 [Thread-104] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:21,506 [Thread-104] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:21,507 [Thread-104] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:21
2020-04-02 05:07:21,507 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:21,507 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:21,507 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:21,507 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:21,515 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:21,516 [Thread-104] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:21,516 [Thread-104] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:21,516 [Thread-104] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:21,516 [Thread-104] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:21,516 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:21,516 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:21,516 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:21,517 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:21,517 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:21,517 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:21,517 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:21,517 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:21,517 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:21,518 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:21,518 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:21,524 [Thread-104] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:21,524 [Thread-104] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:21,524 [Thread-104] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:21,524 [Thread-104] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:21,524 [Thread-104] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:21,524 [Thread-104] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:21,524 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:21,524 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:21,525 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:21,526 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:21,528 [Thread-104] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:21,528 [Thread-104] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:21,528 [Thread-104] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:21,529 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:21,529 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:21,529 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:21,532 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:21,533 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:21,533 [Thread-104] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:21,537 [Thread-104] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:21,538 [Thread-104] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:21,540 [Thread-104] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:21,540 [Thread-104] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:21,546 [Thread-104] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000078, cpktTxId=0000000000000000078)
2020-04-02 05:07:21,549 [Thread-104] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 3 INodes.
2020-04-02 05:07:21,552 [Thread-104] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:21,552 [Thread-104] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 78 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000078
2020-04-02 05:07:21,552 [Thread-104] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@17e9580f expecting start txid #79
2020-04-02 05:07:21,553 [Thread-104] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000079-0000000000000000080, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000079-0000000000000000080 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:21,553 [Thread-104] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000079-0000000000000000080' to transaction ID 79
2020-04-02 05:07:21,553 [Thread-104] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000079-0000000000000000080, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000079-0000000000000000080 of size 42 edits # 2 loaded in 0 seconds
2020-04-02 05:07:21,554 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:21,555 [Thread-104] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 81
2020-04-02 05:07:21,608 [Thread-104] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:21,608 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 73 msecs
2020-04-02 05:07:21,608 [Thread-104] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:21,611 [Thread-104] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:21,612 [Socket Reader #1 for port 46759] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46759
2020-04-02 05:07:21,621 [Thread-104] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:46759 to access this namenode/service.
2020-04-02 05:07:21,622 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:21,661 [Thread-104] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:21,665 [Thread-104] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:21,665 [Thread-104] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:21,665 [Thread-104] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:21,665 [Thread-104] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:21,674 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:07:21,675 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:21,675 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:07:21,675 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:21,675 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:21,675 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 10 msec
2020-04-02 05:07:21,685 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:21,686 [IPC Server listener on 46759] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46759: starting
2020-04-02 05:07:21,692 [Thread-104] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:46759
2020-04-02 05:07:21,692 [Thread-104] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:21,699 [Thread-104] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:21,704 [Thread-104] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 4 milliseconds
name space=3
storage space=8192
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:21,710 [Thread-104] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 46759 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:21,713 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:21,716 [Thread-104] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:21,717 [Thread-104] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:21,726 [Thread-104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:21,726 [Thread-104] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:21,727 [Thread-104] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:21,727 [Thread-104] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:21,727 [Thread-104] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:21,727 [Thread-104] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:21,727 [Thread-104] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:21,728 [Thread-104] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:46832
2020-04-02 05:07:21,728 [Thread-104] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:21,728 [Thread-104] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:21,730 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:21,731 [Thread-104] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:21,732 [CacheReplicationMonitor(1942099072)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:21,742 [Thread-104] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:21,762 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:21,764 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:21,778 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:21,779 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:21,779 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:21,779 [Thread-104] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45764
2020-04-02 05:07:21,786 [Thread-104] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:21,792 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@58dec8f0{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:21,802 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3a7747be{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:21,814 [Thread-104] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@204e9c1{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:21,817 [Thread-104] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@59126c19{HTTP/1.1,[http/1.1]}{localhost:45764}
2020-04-02 05:07:21,818 [Thread-104] INFO  server.Server (Server.java:doStart(419)) - Started @12030ms
2020-04-02 05:07:21,860 [Thread-104] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46154
2020-04-02 05:07:21,860 [Thread-104] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:21,861 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5437c67f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:21,861 [Thread-104] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:21,861 [Thread-104] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:21,876 [Thread-104] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43288
2020-04-02 05:07:21,878 [Socket Reader #1 for port 43288] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43288
2020-04-02 05:07:21,898 [Thread-104] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:21,898 [Thread-104] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:21,901 [Thread-386] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46759 starting to offer service
2020-04-02 05:07:21,942 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:21,946 [IPC Server listener on 43288] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43288: starting
2020-04-02 05:07:21,948 [Thread-104] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43288 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:21,966 [IPC Server handler 0 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:21,971 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:21,971 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:21,971 [Thread-386] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46759
2020-04-02 05:07:21,973 [Thread-386] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:21,975 [Thread-386] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:21,979 [Thread-386] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:21,988 [Thread-386] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:21,989 [Thread-386] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:22,002 [Thread-386] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:22,003 [Thread-386] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:22,004 [Thread-386] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=213151118;bpid=BP-944730262-172.17.0.6-1585804031959;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=213151118;c=1585804031959;bpid=BP-944730262-172.17.0.6-1585804031959;dnuuid=a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:22,006 [Thread-386] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5437a82e-ddff-46c6-ad88-3ed31967d093
2020-04-02 05:07:22,009 [Thread-386] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:22,010 [Thread-386] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae
2020-04-02 05:07:22,015 [Thread-386] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:22,016 [Thread-386] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:22,020 [Thread-386] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:22,026 [Thread-386] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:22,027 [Thread-386] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:22,033 [Thread-386] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:22,033 [Thread-386] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:22,035 [Thread-401] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:22,035 [Thread-402] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:22,037 [Thread-401] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959/current: 42141
2020-04-02 05:07:22,037 [Thread-402] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959/current: 41102
2020-04-02 05:07:22,047 [Thread-402] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-944730262-172.17.0.6-1585804031959 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 12ms
2020-04-02 05:07:22,059 [Thread-401] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-944730262-172.17.0.6-1585804031959 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 24ms
2020-04-02 05:07:22,059 [Thread-386] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-944730262-172.17.0.6-1585804031959: 25ms
2020-04-02 05:07:22,060 [Thread-403] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:22,060 [Thread-404] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:22,062 [Thread-403] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959/current/replicas
2020-04-02 05:07:22,062 [Thread-403] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 3ms
2020-04-02 05:07:22,066 [Thread-404] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959/current/replicas
2020-04-02 05:07:22,066 [Thread-404] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 6ms
2020-04-02 05:07:22,066 [Thread-386] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-944730262-172.17.0.6-1585804031959: 6ms
2020-04-02 05:07:22,067 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093): no suitable block pools found to scan.  Waiting 1814393650 ms.
2020-04-02 05:07:22,067 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae): no suitable block pools found to scan.  Waiting 1814393650 ms.
2020-04-02 05:07:22,067 [Thread-386] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:21 AM with interval of 21600000ms
2020-04-02 05:07:22,071 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:46759] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:46759 beginning handshake with NN
2020-04-02 05:07:22,073 [IPC Server handler 2 on 46759] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46832, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=46154, infoSecurePort=0, ipcPort=43288, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959) storage a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:22,073 [IPC Server handler 2 on 46759] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46832
2020-04-02 05:07:22,073 [IPC Server handler 2 on 46759] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a66a72ee-5beb-418a-8fdf-000c79d6d741 (127.0.0.1:46832).
2020-04-02 05:07:22,087 [IPC Server handler 3 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,088 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2709)) - !dn.datanode.isDatanodeFullyStarted()
2020-04-02 05:07:22,088 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:22,087 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:46759] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:46759 successfully registered with NN
2020-04-02 05:07:22,088 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:46759] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46759 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:22,092 [IPC Server handler 4 on 46759] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5437a82e-ddff-46c6-ad88-3ed31967d093 for DN 127.0.0.1:46832
2020-04-02 05:07:22,092 [IPC Server handler 4 on 46759] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae for DN 127.0.0.1:46832
2020-04-02 05:07:22,106 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x6db2d154b1cafb60: Processing first storage report for DS-5437a82e-ddff-46c6-ad88-3ed31967d093 from datanode a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:22,109 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x6db2d154b1cafb60: from storage DS-5437a82e-ddff-46c6-ad88-3ed31967d093 node DatanodeRegistration(127.0.0.1:46832, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=46154, infoSecurePort=0, ipcPort=43288, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959), blocks: 3, hasStaleStorage: true, processing time: 3 msecs, invalidatedBlocks: 0
2020-04-02 05:07:22,110 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x6db2d154b1cafb60: Processing first storage report for DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae from datanode a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:22,110 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x6db2d154b1cafb60: from storage DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae node DatanodeRegistration(127.0.0.1:46832, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=46154, infoSecurePort=0, ipcPort=43288, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:22,111 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:46759] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x6db2d154b1cafb60,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 0 msec to generate and 13 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:22,111 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:46759] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:22,189 [IPC Server handler 9 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,191 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:22,198 [IPC Server handler 8 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,200 [Thread-104] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:22,206 [IPC Server handler 6 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/p3/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,216 [IPC Server handler 7 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/.reserved/raw/p3/file	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testCreateXAttr
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testCreateXAttr
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testRawXAttrs
[msx] perform reset as unitTestCounterInClass 3 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:22,242 [IPC Server handler 1 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p4	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:22,244 [IPC Server handler 0 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p4	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:22,245 [IPC Server handler 2 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p4	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:22,248 [IPC Server handler 3 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/p4	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,249 [IPC Server handler 4 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/p4	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,251 [IPC Server handler 5 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/.reserved/raw/p4	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:22,253 [IPC Server handler 9 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p4	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:22,256 [IPC Server handler 8 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p4	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:22,258 [IPC Server handler 6 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/p4	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,267 [IPC Server handler 7 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/.reserved/raw/p4	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:22,270 [IPC Server handler 1 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p4	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:22,272 [IPC Server handler 0 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p4	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:22,275 [IPC Server handler 2 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/.reserved/raw/p4	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,278 [IPC Server handler 3 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/.reserved/raw/p4	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:22,281 [IPC Server handler 4 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/.reserved/raw/p4	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:22,284 [IPC Server handler 5 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p4	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:22,328 [IPC Server handler 9 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p4	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:22,330 [IPC Server handler 8 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/p4	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,332 [IPC Server handler 6 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/.reserved/raw/p4	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:22,334 [IPC Server handler 7 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/.reserved/raw/p4	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:22,343 [IPC Server handler 1 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p4	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,343 [IPC Server handler 1 on 46759] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 1 on 46759, call Call#179 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:47154: org.apache.hadoop.security.AccessControlException: User doesn't have permission for xattr: raw.a1
2020-04-02 05:07:22,348 [IPC Server handler 0 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p4	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,348 [IPC Server handler 0 on 46759] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 0 on 46759, call Call#180 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:47154: org.apache.hadoop.security.AccessControlException: Access denied for user user. Superuser privilege is required
2020-04-02 05:07:22,351 [IPC Server handler 2 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/p4	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,351 [IPC Server handler 2 on 46759] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 2 on 46759, call Call#181 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:47154: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=READ, inode="/p4":root:supergroup:drwxr-x---
2020-04-02 05:07:22,358 [IPC Server handler 3 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p4	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,358 [IPC Server handler 3 on 46759] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 3 on 46759, call Call#182 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:47154: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=READ, inode="/p4":root:supergroup:drwxr-x---
2020-04-02 05:07:22,364 [IPC Server handler 4 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/p4	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,365 [IPC Server handler 4 on 46759] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 4 on 46759, call Call#183 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:47154: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=READ, inode="/p4":root:supergroup:drwxr-x---
2020-04-02 05:07:22,368 [IPC Server handler 5 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p4	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,368 [IPC Server handler 5 on 46759] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 5 on 46759, call Call#184 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:47154: org.apache.hadoop.security.AccessControlException: User doesn't have permission for xattr: raw.a1
2020-04-02 05:07:22,371 [IPC Server handler 9 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p4	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:22,373 [IPC Server handler 8 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/p4	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,374 [IPC Server handler 8 on 46759] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 8 on 46759, call Call#186 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:47154: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=READ, inode="/p4":root:supergroup:drwxr-x---
2020-04-02 05:07:22,386 [IPC Server handler 6 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p4	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,386 [IPC Server handler 6 on 46759] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 6 on 46759, call Call#187 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:47154: org.apache.hadoop.security.AccessControlException: User doesn't have permission for xattr: raw.a1
2020-04-02 05:07:22,408 [IPC Server handler 7 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/p4	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,408 [IPC Server handler 7 on 46759] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 7 on 46759, call Call#188 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.listXAttrs from 127.0.0.1:47154: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=READ, inode="/p4":root:supergroup:drwxr-x---
2020-04-02 05:07:22,411 [IPC Server handler 1 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/.reserved/raw/p4	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,412 [IPC Server handler 1 on 46759] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 1 on 46759, call Call#189 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.listXAttrs from 127.0.0.1:47154: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=READ, inode="/p4":root:supergroup:drwxr-x---
2020-04-02 05:07:22,417 [IPC Server handler 0 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p4	dst=null	perm=root:supergroup:rwxr-x--x	proto=rpc
2020-04-02 05:07:22,434 [IPC Server handler 2 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p4/child4	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:22,436 [IPC Server handler 3 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p4/child4	dst=null	perm=root:supergroup:rwx---r--	proto=rpc
2020-04-02 05:07:22,439 [IPC Server handler 4 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p4/child4	dst=null	perm=root:supergroup:rwx---r--	proto=rpc
2020-04-02 05:07:22,441 [IPC Server handler 5 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/.reserved/raw/p4/child4	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,444 [IPC Server handler 9 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/.reserved/raw/p4	dst=null	perm=root:supergroup:rwxr-x--x	proto=rpc
2020-04-02 05:07:22,446 [IPC Server handler 8 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/foo	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:22,451 [IPC Server handler 6 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setOwner	src=/foo	dst=null	perm=user:mygroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:22,453 [IPC Server handler 7 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/foo	dst=null	perm=user:mygroup:rwx-----x	proto=rpc
2020-04-02 05:07:22,458 [IPC Server handler 1 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/foo	dst=null	perm=user:mygroup:rwx-----x	proto=rpc
2020-04-02 05:07:22,461 [IPC Server handler 0 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/foo/bar	dst=null	perm=user:mygroup:rw-r--r--	proto=rpc
2020-04-02 05:07:22,496 [IPC Server handler 2 on 46759] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:46832 for /foo/bar
2020-04-02 05:07:22,504 [DataXceiver for client DFSClient_NONMAPREDUCE_-570880658_1364 at /127.0.0.1:48726 [Receiving block BP-944730262-172.17.0.6-1585804031959:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-944730262-172.17.0.6-1585804031959:blk_1073741830_1006 src: /127.0.0.1:48726 dest: /127.0.0.1:46832
2020-04-02 05:07:22,544 [PacketResponder: BP-944730262-172.17.0.6-1585804031959:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48726, dest: /127.0.0.1:46832, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-570880658_1364, offset: 0, srvID: a66a72ee-5beb-418a-8fdf-000c79d6d741, blockid: BP-944730262-172.17.0.6-1585804031959:blk_1073741830_1006, duration(ns): 25553093
2020-04-02 05:07:22,545 [PacketResponder: BP-944730262-172.17.0.6-1585804031959:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-944730262-172.17.0.6-1585804031959:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:22,548 [IPC Server handler 5 on 46759] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /foo/bar is closed by DFSClient_NONMAPREDUCE_-570880658_1364
2020-04-02 05:07:22,550 [IPC Server handler 9 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/foo/bar	dst=null	perm=user:mygroup:rwxr-----	proto=rpc
2020-04-02 05:07:22,552 [IPC Server handler 8 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/foo/bar	dst=null	perm=user:mygroup:rwxr-----	proto=rpc
2020-04-02 05:07:22,554 [IPC Server handler 6 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/foo/bar	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,563 [IPC Server handler 7 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=fakeUser (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p4	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,563 [IPC Server handler 7 on 46759] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 7 on 46759, call Call#208 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:47166: org.apache.hadoop.security.AccessControlException: User doesn't have permission for xattr: raw.a1
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testRawXAttrs
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testRawXAttrs
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testRemoveXAttr
[msx] perform reset as unitTestCounterInClass 4 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:22,569 [IPC Server handler 1 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p5	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:22,572 [IPC Server handler 0 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p5	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:22,575 [IPC Server handler 2 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p5	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:22,577 [IPC Server handler 3 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p5	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:22,583 [IPC Server handler 4 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p5	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:22,584 [IPC Server handler 5 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p5	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:22,591 [IPC Server handler 9 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p5	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:22,594 [IPC Server handler 8 on 46759] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p5	dst=null	perm=null	proto=rpc
2020-04-02 05:07:22,595 [Thread-416] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:22,598 [Thread-416] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:22,599 [Thread-416] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43288 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:22,599 [Thread-416] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:22,599 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7d4c6aee] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:22,602 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093) exiting.
2020-04-02 05:07:22,603 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae) exiting.
2020-04-02 05:07:22,673 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@204e9c1{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:22,674 [Thread-416] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@59126c19{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:22,675 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3a7747be{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:22,676 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@58dec8f0{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:22,677 [Thread-416] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43288
2020-04-02 05:07:22,684 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:22,684 [IPC Server listener on 43288] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43288
2020-04-02 05:07:22,684 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:46759] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:22,684 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:46759] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:46759
2020-04-02 05:07:22,785 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:46759] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741)
2020-04-02 05:07:22,785 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:46759] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:22,795 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:22,804 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:22,817 [Thread-416] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:22,817 [Thread-416] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:22,818 [Thread-416] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:22,818 [Thread-416] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:22,821 [Thread-416] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:22,821 [Thread-416] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:22,821 [Thread-416] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 46759 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:22,821 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:22,826 [Thread-416] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 81, 120
2020-04-02 05:07:22,826 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@5d292d0a] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:22,826 [Thread-416] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 41 Total time for transactions(ms): 14 Number of transactions batched in Syncs: 81 Number of syncs: 41 SyncTimes(ms): 14 15 
2020-04-02 05:07:22,827 [Thread-416] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000081 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000081-0000000000000000121
2020-04-02 05:07:22,829 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@3a896084] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:22,830 [Thread-416] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000081 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000081-0000000000000000121
2020-04-02 05:07:22,830 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:22,830 [CacheReplicationMonitor(1942099072)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:22,837 [Thread-416] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46759
2020-04-02 05:07:22,840 [IPC Server listener on 46759] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46759
2020-04-02 05:07:22,840 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:22,841 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:22,843 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:22,852 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:22,853 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:22,857 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3cedeef1{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:22,877 [Thread-416] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@78e0bbd0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:22,877 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@41e7bfa6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:22,878 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@65dbec4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:22,903 [Thread-416] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:22,916 [Thread-416] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:22,917 [Thread-416] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:22,925 [Thread-416] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:07:22,929 [Thread-416] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:22,960 [Thread-416] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:22,966 [Thread-416] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:22,967 [Thread-416] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:22,967 [Thread-416] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:22,968 [Thread-416] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:22,976 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@23b9b706] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:22,976 [Thread-416] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:22,976 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:22,978 [Thread-416] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:23,042 [Thread-416] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:23,042 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:23,043 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:23,044 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:23,044 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:23,044 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:23,046 [Thread-416] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:23,046 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:23,046 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37480
2020-04-02 05:07:23,046 [Thread-416] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:23,053 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@634e8204{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:23,057 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@71d1430e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:23,068 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7ae8c61{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:23,069 [Thread-416] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@424572ef{HTTP/1.1,[http/1.1]}{localhost:37480}
2020-04-02 05:07:23,069 [Thread-416] INFO  server.Server (Server.java:doStart(419)) - Started @13281ms
2020-04-02 05:07:23,071 [Thread-416] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:23,072 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:23,072 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:23,078 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:23,080 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:23,080 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:23,080 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:23,080 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:23,081 [Thread-416] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:23,081 [Thread-416] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:23,081 [Thread-416] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:23,082 [Thread-416] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:23,082 [Thread-416] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:23
2020-04-02 05:07:23,082 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:23,082 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:23,083 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:23,083 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:23,095 [Thread-416] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:23,096 [Thread-416] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:23,096 [Thread-416] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:23,096 [Thread-416] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:23,097 [Thread-416] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:23,097 [Thread-416] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:23,097 [Thread-416] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:23,097 [Thread-416] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:23,097 [Thread-416] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:23,097 [Thread-416] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:23,098 [Thread-416] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:23,098 [Thread-416] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:23,098 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:23,098 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:23,099 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:23,099 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:23,101 [Thread-416] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:23,101 [Thread-416] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:23,101 [Thread-416] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:23,102 [Thread-416] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:23,102 [Thread-416] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:23,102 [Thread-416] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:23,102 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:23,102 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:23,102 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:23,102 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:23,103 [Thread-416] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:23,103 [Thread-416] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:23,103 [Thread-416] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:23,104 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:23,104 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:23,104 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:23,104 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:23,104 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:23,105 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:23,108 [Thread-416] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:23,110 [Thread-416] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:23,116 [Thread-416] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:23,117 [Thread-416] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:23,123 [Thread-416] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000078, cpktTxId=0000000000000000078)
2020-04-02 05:07:23,125 [Thread-416] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 3 INodes.
2020-04-02 05:07:23,127 [Thread-416] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:23,128 [Thread-416] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 78 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000078
2020-04-02 05:07:23,128 [Thread-416] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@22ee219a expecting start txid #79
2020-04-02 05:07:23,128 [Thread-416] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000079-0000000000000000080, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000079-0000000000000000080 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:23,128 [Thread-416] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000079-0000000000000000080' to transaction ID 79
2020-04-02 05:07:23,129 [Thread-416] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000079-0000000000000000080, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000079-0000000000000000080 of size 42 edits # 2 loaded in 0 seconds
2020-04-02 05:07:23,129 [Thread-416] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@34916800 expecting start txid #81
2020-04-02 05:07:23,130 [Thread-416] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000081-0000000000000000121, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000081-0000000000000000121 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:23,130 [Thread-416] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000081-0000000000000000121' to transaction ID 79
2020-04-02 05:07:23,135 [Thread-416] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000081-0000000000000000121, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000081-0000000000000000121 of size 2177 edits # 41 loaded in 0 seconds
2020-04-02 05:07:23,136 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:23,136 [Thread-416] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 122
2020-04-02 05:07:23,173 [Thread-416] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:23,173 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 68 msecs
2020-04-02 05:07:23,174 [Thread-416] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:23,174 [Thread-416] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:23,175 [Socket Reader #1 for port 39749] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39749
2020-04-02 05:07:23,191 [Thread-416] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:39749 to access this namenode/service.
2020-04-02 05:07:23,194 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:23,255 [Thread-416] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:23,261 [Thread-416] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:23,262 [Thread-416] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:23,262 [Thread-416] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:23,262 [Thread-416] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:23,279 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:23,279 [IPC Server listener on 39749] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39749: starting
2020-04-02 05:07:23,298 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:07:23,298 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:23,298 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:07:23,298 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:23,298 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:23,298 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 35 msec
2020-04-02 05:07:23,336 [Thread-416] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:39749
2020-04-02 05:07:23,337 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:23,337 [Thread-416] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:23,374 [Thread-416] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 37 milliseconds
name space=7
storage space=1024
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:23,376 [Thread-416] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 39749 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:23,383 [Thread-416] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:23,383 [CacheReplicationMonitor(1777219745)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:23,386 [Thread-416] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:23,387 [Thread-416] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:23,391 [Thread-416] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:23,391 [Thread-416] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:23,392 [Thread-416] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:23,392 [Thread-416] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:23,393 [Thread-416] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:23,393 [Thread-416] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:23,398 [Thread-416] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:23,399 [Thread-416] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:36664
2020-04-02 05:07:23,400 [Thread-416] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:23,400 [Thread-416] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:23,401 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:23,404 [Thread-416] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:23,406 [Thread-416] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:23,406 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:23,408 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:23,409 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:23,409 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:23,409 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:23,410 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42817
2020-04-02 05:07:23,410 [Thread-416] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:23,420 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@42588c2a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:23,432 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@16981836{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:23,448 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@46bd7f2{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:23,449 [Thread-416] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@561d0046{HTTP/1.1,[http/1.1]}{localhost:42817}
2020-04-02 05:07:23,451 [Thread-416] INFO  server.Server (Server.java:doStart(419)) - Started @13663ms
2020-04-02 05:07:23,476 [Thread-416] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45978
2020-04-02 05:07:23,477 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2866d013] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:23,477 [Thread-416] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:23,478 [Thread-416] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:23,478 [Thread-416] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:23,479 [Socket Reader #1 for port 42089] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42089
2020-04-02 05:07:23,487 [Thread-416] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:42089
2020-04-02 05:07:23,490 [Thread-416] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:23,490 [Thread-416] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:23,491 [Thread-471] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39749 starting to offer service
2020-04-02 05:07:23,498 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:23,507 [IPC Server listener on 42089] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42089: starting
2020-04-02 05:07:23,514 [Thread-416] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 42089 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:23,580 [IPC Server handler 0 on 39749] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:23,581 [Thread-416] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:23,581 [Thread-416] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:23,582 [Thread-471] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39749
2020-04-02 05:07:23,586 [Thread-471] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:23,591 [Thread-471] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:23,596 [Thread-471] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:23,605 [Thread-471] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:23,605 [Thread-471] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:23,614 [Thread-471] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:23,615 [Thread-471] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:23,618 [Thread-471] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=213151118;bpid=BP-944730262-172.17.0.6-1585804031959;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=213151118;c=1585804031959;bpid=BP-944730262-172.17.0.6-1585804031959;dnuuid=a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:23,620 [Thread-471] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5437a82e-ddff-46c6-ad88-3ed31967d093
2020-04-02 05:07:23,622 [Thread-471] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:23,627 [Thread-471] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae
2020-04-02 05:07:23,628 [Thread-471] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:23,629 [Thread-471] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:23,630 [Thread-471] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:23,631 [Thread-471] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:23,632 [Thread-471] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:23,633 [Thread-471] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:23,633 [Thread-471] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:23,634 [Thread-486] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:23,634 [Thread-487] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:23,636 [Thread-487] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959/current: 41102
2020-04-02 05:07:23,637 [Thread-486] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959/current: 43180
2020-04-02 05:07:23,646 [Thread-486] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-944730262-172.17.0.6-1585804031959 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 12ms
2020-04-02 05:07:23,646 [Thread-487] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-944730262-172.17.0.6-1585804031959 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 12ms
2020-04-02 05:07:23,653 [Thread-471] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-944730262-172.17.0.6-1585804031959: 20ms
2020-04-02 05:07:23,653 [Thread-488] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:23,656 [Thread-489] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:23,656 [Thread-488] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959/current/replicas
2020-04-02 05:07:23,656 [Thread-489] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959/current/replicas
2020-04-02 05:07:23,656 [Thread-488] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 2ms
2020-04-02 05:07:23,656 [Thread-489] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 0ms
2020-04-02 05:07:23,656 [Thread-471] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-944730262-172.17.0.6-1585804031959: 4ms
2020-04-02 05:07:23,658 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093): no suitable block pools found to scan.  Waiting 1814392059 ms.
2020-04-02 05:07:23,658 [Thread-471] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:23 AM with interval of 21600000ms
2020-04-02 05:07:23,659 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae): no suitable block pools found to scan.  Waiting 1814392058 ms.
2020-04-02 05:07:23,660 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:39749] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:39749 beginning handshake with NN
2020-04-02 05:07:23,664 [IPC Server handler 3 on 39749] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36664, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=45978, infoSecurePort=0, ipcPort=42089, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959) storage a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:23,665 [IPC Server handler 3 on 39749] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36664
2020-04-02 05:07:23,665 [IPC Server handler 3 on 39749] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a66a72ee-5beb-418a-8fdf-000c79d6d741 (127.0.0.1:36664).
2020-04-02 05:07:23,670 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:39749] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:39749 successfully registered with NN
2020-04-02 05:07:23,670 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:39749] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:39749 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:23,674 [IPC Server handler 4 on 39749] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5437a82e-ddff-46c6-ad88-3ed31967d093 for DN 127.0.0.1:36664
2020-04-02 05:07:23,674 [IPC Server handler 4 on 39749] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae for DN 127.0.0.1:36664
2020-04-02 05:07:23,678 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x1411dc655336ce2a: Processing first storage report for DS-5437a82e-ddff-46c6-ad88-3ed31967d093 from datanode a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:23,680 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x1411dc655336ce2a: from storage DS-5437a82e-ddff-46c6-ad88-3ed31967d093 node DatanodeRegistration(127.0.0.1:36664, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=45978, infoSecurePort=0, ipcPort=42089, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959), blocks: 4, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:07:23,680 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x1411dc655336ce2a: Processing first storage report for DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae from datanode a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:23,680 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x1411dc655336ce2a: from storage DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae node DatanodeRegistration(127.0.0.1:36664, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=45978, infoSecurePort=0, ipcPort=42089, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:23,681 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:39749] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x1411dc655336ce2a,  containing 2 storage report(s), of which we sent 2. The reports had 6 total blocks and used 1 RPC(s). This took 1 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:23,682 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:39749] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:23,685 [IPC Server handler 6 on 39749] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:23,686 [Thread-416] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:23,689 [IPC Server handler 7 on 39749] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:23,693 [Thread-416] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:23,695 [IPC Server handler 5 on 39749] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p5	dst=null	perm=null	proto=rpc
2020-04-02 05:07:23,696 [Thread-416] INFO  hdfs.StateChange (FSNamesystem.java:enterSafeMode(4593)) - STATE* Safe mode is ON.
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2020-04-02 05:07:23,697 [Thread-416] INFO  namenode.FSImage (FSImage.java:saveNamespace(1101)) - Save namespace ...
2020-04-02 05:07:23,697 [Thread-416] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 122, 122
2020-04-02 05:07:23,706 [Thread-416] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 18 Number of transactions batched in Syncs: 121 Number of syncs: 3 SyncTimes(ms): 2 2 
2020-04-02 05:07:23,707 [Thread-416] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000122 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000122-0000000000000000123
2020-04-02 05:07:23,708 [Thread-416] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000122 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000122-0000000000000000123
2020-04-02 05:07:23,716 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000123 using no compression
2020-04-02 05:07:23,719 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000123 using no compression
2020-04-02 05:07:23,726 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000123 of size 877 bytes saved in 0 seconds .
2020-04-02 05:07:23,728 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000123 of size 877 bytes saved in 0 seconds .
2020-04-02 05:07:23,731 [Thread-416] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 78
2020-04-02 05:07:23,731 [Thread-416] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(225)) - Purging old image FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000058, cpktTxId=0000000000000000058)
2020-04-02 05:07:23,731 [Thread-416] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(225)) - Purging old image FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage_0000000000000000058, cpktTxId=0000000000000000058)
2020-04-02 05:07:23,735 [Thread-416] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 124
2020-04-02 05:07:23,747 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:saveNamespace(4419)) - New namespace image has been created
2020-04-02 05:07:23,747 [Thread-416] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:23,747 [Thread-416] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:23,747 [Thread-416] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 42089 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:23,747 [Thread-416] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:23,748 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093) exiting.
2020-04-02 05:07:23,750 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@635bc910] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:23,752 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae) exiting.
2020-04-02 05:07:23,788 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@46bd7f2{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:23,789 [Thread-416] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@561d0046{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:23,790 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@16981836{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:23,790 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@42588c2a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:23,792 [Thread-416] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42089
2020-04-02 05:07:23,794 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:39749] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:23,794 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:39749] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:39749
2020-04-02 05:07:23,794 [IPC Server listener on 42089] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42089
2020-04-02 05:07:23,795 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:23,925 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:39749] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741)
2020-04-02 05:07:23,926 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:39749] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:23,933 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:23,942 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:23,960 [Thread-416] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:23,960 [Thread-416] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:23,961 [Thread-416] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:23,962 [Thread-416] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:23,964 [Thread-416] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:23,964 [Thread-416] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:23,964 [Thread-416] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 39749 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:23,964 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:23,965 [Thread-416] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 124, 124
2020-04-02 05:07:23,965 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@7cf5ff1c] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:23,968 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@2f4c85c] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:23,968 [Thread-416] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 3 1 
2020-04-02 05:07:23,968 [Thread-416] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000124 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000124-0000000000000000125
2020-04-02 05:07:23,969 [Thread-416] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000124 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000124-0000000000000000125
2020-04-02 05:07:23,969 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:23,969 [CacheReplicationMonitor(1777219745)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:23,989 [Thread-416] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39749
2020-04-02 05:07:23,990 [IPC Server listener on 39749] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39749
2020-04-02 05:07:23,993 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:23,993 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:23,993 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:24,003 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:24,003 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:24,008 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7ae8c61{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:24,018 [Thread-416] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@424572ef{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:24,019 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@71d1430e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:24,019 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@634e8204{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:24,026 [Thread-416] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:24,033 [Thread-416] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:24,034 [Thread-416] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:24,045 [Thread-416] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:07:24,047 [Thread-416] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:24,052 [Thread-416] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:24,054 [Thread-416] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:24,054 [Thread-416] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:24,055 [Thread-416] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:24,055 [Thread-416] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:24,061 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@71b8b91f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:24,061 [Thread-416] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:24,061 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:24,063 [Thread-416] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:24,063 [Thread-416] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:24,064 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:24,065 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:24,065 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:24,066 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:24,066 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:24,067 [Thread-416] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:24,067 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:24,067 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33662
2020-04-02 05:07:24,067 [Thread-416] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:24,094 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5bd85be5{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:24,106 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4ebe2bc2{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:24,123 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5cfb84fc{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:24,124 [Thread-416] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@45f5d1f{HTTP/1.1,[http/1.1]}{localhost:33662}
2020-04-02 05:07:24,124 [Thread-416] INFO  server.Server (Server.java:doStart(419)) - Started @14336ms
2020-04-02 05:07:24,129 [Thread-416] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:24,130 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:24,130 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:24,130 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:24,131 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:24,131 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:24,131 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:24,131 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:24,131 [Thread-416] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:24,132 [Thread-416] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:24,132 [Thread-416] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:24,132 [Thread-416] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:24,133 [Thread-416] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:24
2020-04-02 05:07:24,133 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:24,133 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:24,133 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:24,133 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:24,147 [Thread-416] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:24,147 [Thread-416] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:24,147 [Thread-416] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:24,147 [Thread-416] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:24,147 [Thread-416] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:24,148 [Thread-416] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:24,148 [Thread-416] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:24,148 [Thread-416] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:24,148 [Thread-416] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:24,148 [Thread-416] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:24,148 [Thread-416] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:24,148 [Thread-416] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:24,148 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:24,148 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:24,149 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:24,149 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:24,154 [Thread-416] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:24,154 [Thread-416] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:24,154 [Thread-416] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:24,155 [Thread-416] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:24,155 [Thread-416] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:24,155 [Thread-416] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:24,155 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:24,155 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:24,155 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:24,155 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:24,157 [Thread-416] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:24,157 [Thread-416] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:24,157 [Thread-416] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:24,158 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:24,158 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:24,158 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:24,158 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:24,159 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:24,159 [Thread-416] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:24,162 [Thread-416] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:24,163 [Thread-416] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:24,166 [Thread-416] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:24,166 [Thread-416] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:24,168 [Thread-416] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000123, cpktTxId=0000000000000000123)
2020-04-02 05:07:24,170 [Thread-416] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 7 INodes.
2020-04-02 05:07:24,171 [Thread-416] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:24,172 [Thread-416] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 123 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000123
2020-04-02 05:07:24,172 [Thread-416] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@66e368b4 expecting start txid #124
2020-04-02 05:07:24,172 [Thread-416] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000124-0000000000000000125, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000124-0000000000000000125 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:24,173 [Thread-416] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000124-0000000000000000125' to transaction ID 124
2020-04-02 05:07:24,174 [Thread-416] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000124-0000000000000000125, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000124-0000000000000000125 of size 42 edits # 2 loaded in 0 seconds
2020-04-02 05:07:24,174 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:24,175 [Thread-416] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 126
2020-04-02 05:07:24,193 [Thread-416] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:24,193 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 34 msecs
2020-04-02 05:07:24,194 [Thread-416] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:24,194 [Thread-416] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:24,195 [Socket Reader #1 for port 43071] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43071
2020-04-02 05:07:24,201 [Thread-416] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:43071 to access this namenode/service.
2020-04-02 05:07:24,202 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:24,250 [Thread-416] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:24,274 [Thread-416] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:24,281 [Thread-416] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:24,282 [Thread-416] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:24,282 [Thread-416] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:24,289 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:24,289 [IPC Server listener on 43071] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43071: starting
2020-04-02 05:07:24,290 [Thread-416] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:43071
2020-04-02 05:07:24,290 [Thread-416] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:24,290 [Thread-416] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:24,294 [Thread-416] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 4 milliseconds
name space=7
storage space=1024
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:24,306 [Thread-416] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 43071 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:24,308 [Thread-416] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:24,310 [CacheReplicationMonitor(1614095238)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:24,316 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:07:24,317 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:24,317 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:07:24,317 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:24,317 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:24,317 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 26 msec
2020-04-02 05:07:24,324 [Thread-416] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:24,325 [Thread-416] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:24,326 [Thread-416] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:24,327 [Thread-416] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:24,327 [Thread-416] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:24,327 [Thread-416] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:24,328 [Thread-416] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:24,328 [Thread-416] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:24,328 [Thread-416] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:24,329 [Thread-416] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:45176
2020-04-02 05:07:24,329 [Thread-416] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:24,329 [Thread-416] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:24,330 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:24,332 [Thread-416] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:24,334 [Thread-416] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:24,337 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:24,340 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:24,341 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:24,341 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:24,342 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:24,343 [Thread-416] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44182
2020-04-02 05:07:24,343 [Thread-416] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:24,345 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@75cb77db{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:24,346 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@f8eaec8{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:24,352 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2ca00314{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:24,352 [Thread-416] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@765a0672{HTTP/1.1,[http/1.1]}{localhost:44182}
2020-04-02 05:07:24,354 [Thread-416] INFO  server.Server (Server.java:doStart(419)) - Started @14566ms
2020-04-02 05:07:24,383 [Thread-416] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42378
2020-04-02 05:07:24,384 [Thread-416] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:24,384 [Thread-416] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:24,384 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@61acdd4e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:24,384 [Thread-416] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:24,385 [Socket Reader #1 for port 35173] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35173
2020-04-02 05:07:24,405 [Thread-416] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:35173
2020-04-02 05:07:24,409 [Thread-416] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:24,410 [Thread-416] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:24,411 [Thread-546] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43071 starting to offer service
2020-04-02 05:07:24,416 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:24,419 [IPC Server listener on 35173] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35173: starting
2020-04-02 05:07:24,419 [Thread-416] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 35173 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:24,439 [Thread-546] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43071
2020-04-02 05:07:24,440 [Thread-546] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:24,444 [Thread-546] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:24,447 [IPC Server handler 0 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:24,448 [Thread-416] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:24,449 [Thread-416] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:24,449 [Thread-546] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:24,463 [Thread-546] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:24,463 [Thread-546] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:24,472 [Thread-546] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:24,473 [Thread-546] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:24,474 [Thread-546] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=213151118;bpid=BP-944730262-172.17.0.6-1585804031959;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=213151118;c=1585804031959;bpid=BP-944730262-172.17.0.6-1585804031959;dnuuid=a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:24,476 [Thread-546] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5437a82e-ddff-46c6-ad88-3ed31967d093
2020-04-02 05:07:24,476 [Thread-546] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:24,477 [Thread-546] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae
2020-04-02 05:07:24,477 [Thread-546] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:24,477 [Thread-546] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:24,481 [Thread-546] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:24,482 [Thread-546] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:24,483 [Thread-546] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:24,483 [Thread-546] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:24,494 [Thread-546] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:24,494 [Thread-561] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:24,494 [Thread-562] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:24,496 [Thread-562] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959/current: 41102
2020-04-02 05:07:24,496 [Thread-561] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959/current: 43180
2020-04-02 05:07:24,504 [Thread-561] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-944730262-172.17.0.6-1585804031959 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 10ms
2020-04-02 05:07:24,505 [Thread-562] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-944730262-172.17.0.6-1585804031959 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 10ms
2020-04-02 05:07:24,505 [Thread-546] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-944730262-172.17.0.6-1585804031959: 11ms
2020-04-02 05:07:24,506 [Thread-563] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:24,506 [Thread-564] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:24,508 [Thread-564] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959/current/replicas
2020-04-02 05:07:24,508 [Thread-563] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959/current/replicas
2020-04-02 05:07:24,508 [Thread-564] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 2ms
2020-04-02 05:07:24,508 [Thread-563] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 2ms
2020-04-02 05:07:24,509 [Thread-546] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-944730262-172.17.0.6-1585804031959: 4ms
2020-04-02 05:07:24,510 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093): no suitable block pools found to scan.  Waiting 1814391207 ms.
2020-04-02 05:07:24,511 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae): no suitable block pools found to scan.  Waiting 1814391206 ms.
2020-04-02 05:07:24,511 [Thread-546] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:39 AM with interval of 21600000ms
2020-04-02 05:07:24,513 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:43071] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:43071 beginning handshake with NN
2020-04-02 05:07:24,518 [IPC Server handler 3 on 43071] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45176, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=42378, infoSecurePort=0, ipcPort=35173, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959) storage a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:24,519 [IPC Server handler 3 on 43071] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45176
2020-04-02 05:07:24,519 [IPC Server handler 3 on 43071] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a66a72ee-5beb-418a-8fdf-000c79d6d741 (127.0.0.1:45176).
2020-04-02 05:07:24,528 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:43071] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:43071 successfully registered with NN
2020-04-02 05:07:24,528 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:43071] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:43071 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:24,534 [IPC Server handler 6 on 43071] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5437a82e-ddff-46c6-ad88-3ed31967d093 for DN 127.0.0.1:45176
2020-04-02 05:07:24,534 [IPC Server handler 6 on 43071] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae for DN 127.0.0.1:45176
2020-04-02 05:07:24,542 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd9a8960eee5b3e0: Processing first storage report for DS-5437a82e-ddff-46c6-ad88-3ed31967d093 from datanode a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:24,547 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd9a8960eee5b3e0: from storage DS-5437a82e-ddff-46c6-ad88-3ed31967d093 node DatanodeRegistration(127.0.0.1:45176, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=42378, infoSecurePort=0, ipcPort=35173, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959), blocks: 4, hasStaleStorage: true, processing time: 5 msecs, invalidatedBlocks: 0
2020-04-02 05:07:24,551 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd9a8960eee5b3e0: Processing first storage report for DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae from datanode a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:24,552 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd9a8960eee5b3e0: from storage DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae node DatanodeRegistration(127.0.0.1:45176, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=42378, infoSecurePort=0, ipcPort=35173, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:24,553 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:43071] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xd9a8960eee5b3e0,  containing 2 storage report(s), of which we sent 2. The reports had 6 total blocks and used 1 RPC(s). This took 0 msec to generate and 16 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:24,553 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:43071] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:24,553 [IPC Server handler 1 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:24,555 [Thread-416] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:24,558 [IPC Server handler 8 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:24,559 [Thread-416] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:24,560 [IPC Server handler 7 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p5	dst=null	perm=null	proto=rpc
2020-04-02 05:07:24,566 [IPC Server handler 4 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p5	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testRemoveXAttr
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testRemoveXAttr
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testListXAttrs
[msx] perform reset as unitTestCounterInClass 5 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:24,577 [IPC Server handler 9 on 43071] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 9 on 43071, call Call#234 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.listXAttrs from 127.0.0.1:41088: java.io.FileNotFoundException: cannot find /p6
2020-04-02 05:07:24,586 [IPC Server handler 2 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p6	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:24,588 [IPC Server handler 0 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p6	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:24,589 [IPC Server handler 3 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/p6	dst=null	perm=null	proto=rpc
2020-04-02 05:07:24,592 [IPC Server handler 6 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p6	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:24,593 [IPC Server handler 5 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p6	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:24,606 [IPC Server handler 1 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/p6	dst=null	perm=null	proto=rpc
2020-04-02 05:07:24,608 [IPC Server handler 8 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p6	dst=null	perm=root:supergroup:rwx---r--	proto=rpc
2020-04-02 05:07:24,610 [IPC Server handler 7 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p6/child6	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:24,613 [IPC Server handler 4 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p6/child6	dst=null	perm=root:supergroup:rwx------	proto=rpc
2020-04-02 05:07:24,615 [IPC Server handler 9 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p6/child6	dst=null	perm=root:supergroup:rwx------	proto=rpc
2020-04-02 05:07:24,626 [IPC Server handler 2 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/p6/child6	dst=null	perm=null	proto=rpc
2020-04-02 05:07:24,627 [IPC Server handler 2 on 43071] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 2 on 43071, call Call#245 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.listXAttrs from 127.0.0.1:41092: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=EXECUTE, inode="/p6":root:supergroup:drwx---r--
2020-04-02 05:07:24,642 [IPC Server handler 0 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p6	dst=null	perm=root:supergroup:rwx----w-	proto=rpc
2020-04-02 05:07:24,649 [IPC Server handler 3 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/p6/child6	dst=null	perm=null	proto=rpc
2020-04-02 05:07:24,649 [IPC Server handler 3 on 43071] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 3 on 43071, call Call#247 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.listXAttrs from 127.0.0.1:41092: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=EXECUTE, inode="/p6":root:supergroup:drwx----w-
2020-04-02 05:07:24,657 [IPC Server handler 6 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p6	dst=null	perm=root:supergroup:rwx-----x	proto=rpc
2020-04-02 05:07:24,662 [IPC Server handler 5 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/p6/child6	dst=null	perm=null	proto=rpc
2020-04-02 05:07:24,662 [IPC Server handler 5 on 43071] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 5 on 43071, call Call#249 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.listXAttrs from 127.0.0.1:41092: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=READ, inode="/p6/child6":root:supergroup:drwx------
2020-04-02 05:07:24,672 [IPC Server handler 1 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p6/child6	dst=null	perm=root:supergroup:rwx---r--	proto=rpc
2020-04-02 05:07:24,676 [IPC Server handler 8 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p6/child6	dst=null	perm=root:supergroup:rwx---r--	proto=rpc
2020-04-02 05:07:24,679 [IPC Server handler 7 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/p6/child6	dst=null	perm=null	proto=rpc
2020-04-02 05:07:24,685 [IPC Server handler 4 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/p6/child6	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testListXAttrs
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testListXAttrs
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testRemoveXAttrPermissions
[msx] perform reset as unitTestCounterInClass 6 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:24,702 [IPC Server handler 9 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p7	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:24,705 [IPC Server handler 2 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p7	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:24,708 [IPC Server handler 0 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p7	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:24,710 [IPC Server handler 3 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p7	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:24,712 [IPC Server handler 6 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p7	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:24,719 [IPC Server handler 5 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p7	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:24,721 [IPC Server handler 1 on 43071] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 1 on 43071, call Call#260 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.removeXAttr from 127.0.0.1:41088
java.io.IOException: No matching attributes found for remove operation
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.removeXAttr(FSDirXAttrOp.java:184)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeXAttr(FSNamesystem.java:7775)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.removeXAttr(NameNodeRpcServer.java:2200)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.removeXAttr(ClientNamenodeProtocolServerSideTranslatorPB.java:1648)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:07:24,729 [IPC Server handler 8 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p7	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:24,741 [IPC Server handler 7 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p7	dst=null	perm=null	proto=rpc
2020-04-02 05:07:24,741 [IPC Server handler 7 on 43071] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 7 on 43071, call Call#262 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.removeXAttr from 127.0.0.1:41104: org.apache.hadoop.security.AccessControlException: User doesn't have permission for xattr: trusted.foo
2020-04-02 05:07:24,752 [IPC Server handler 4 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p7	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:24,755 [IPC Server handler 9 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p7	dst=null	perm=root:supergroup:rwx------	proto=rpc
2020-04-02 05:07:24,769 [IPC Server handler 2 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p7	dst=null	perm=null	proto=rpc
2020-04-02 05:07:24,769 [IPC Server handler 2 on 43071] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 2 on 43071, call Call#265 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.removeXAttr from 127.0.0.1:41104: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=WRITE, inode="/p7":root:supergroup:drwx------
2020-04-02 05:07:24,777 [IPC Server handler 0 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p7/child7	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:24,786 [IPC Server handler 3 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p7/child7	dst=null	perm=root:supergroup:rwx------	proto=rpc
2020-04-02 05:07:24,790 [IPC Server handler 6 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p7/child7	dst=null	perm=root:supergroup:rwx------	proto=rpc
2020-04-02 05:07:24,793 [IPC Server handler 5 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p7/child7	dst=null	perm=null	proto=rpc
2020-04-02 05:07:24,793 [IPC Server handler 5 on 43071] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 5 on 43071, call Call#269 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.removeXAttr from 127.0.0.1:41104: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=EXECUTE, inode="/p7":root:supergroup:drwx------
2020-04-02 05:07:24,796 [IPC Server handler 1 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p7	dst=null	perm=root:supergroup:rwx---r--	proto=rpc
2020-04-02 05:07:24,799 [IPC Server handler 8 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p7/child7	dst=null	perm=null	proto=rpc
2020-04-02 05:07:24,799 [IPC Server handler 8 on 43071] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 8 on 43071, call Call#271 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.removeXAttr from 127.0.0.1:41104: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=EXECUTE, inode="/p7":root:supergroup:drwx---r--
2020-04-02 05:07:24,804 [IPC Server handler 7 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p7	dst=null	perm=root:supergroup:rwx-----x	proto=rpc
2020-04-02 05:07:24,805 [IPC Server handler 4 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p7/child7	dst=null	perm=root:supergroup:rwx-----x	proto=rpc
2020-04-02 05:07:24,808 [IPC Server handler 9 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p7/child7	dst=null	perm=null	proto=rpc
2020-04-02 05:07:24,808 [IPC Server handler 9 on 43071] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 9 on 43071, call Call#274 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.removeXAttr from 127.0.0.1:41104: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=WRITE, inode="/p7/child7":root:supergroup:drwx-----x
2020-04-02 05:07:24,813 [IPC Server handler 2 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p7	dst=null	perm=root:supergroup:rwx-----x	proto=rpc
2020-04-02 05:07:24,814 [IPC Server handler 0 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p7/child7	dst=null	perm=root:supergroup:rwx---rw-	proto=rpc
2020-04-02 05:07:24,819 [IPC Server handler 3 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p7/child7	dst=null	perm=root:supergroup:rwx---rw-	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testRemoveXAttrPermissions
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testRemoveXAttrPermissions
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testXAttrAcl
[msx] perform reset as unitTestCounterInClass 7 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:24,832 [IPC Server handler 6 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p8	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:24,834 [IPC Server handler 5 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p8	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:24,836 [IPC Server handler 1 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setOwner	src=/p8	dst=null	perm=bruce:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:24,854 [IPC Server handler 8 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=bruce (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p8	dst=null	perm=bruce:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:24,877 [IPC Server handler 7 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=diana (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p8	dst=null	perm=null	proto=rpc
2020-04-02 05:07:24,878 [IPC Server handler 7 on 43071] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 7 on 43071, call Call#282 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:41132: org.apache.hadoop.security.AccessControlException: Permission denied: user=diana, access=READ, inode="/p8":bruce:supergroup:drwxr-x---
2020-04-02 05:07:24,911 [IPC Server handler 4 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=bruce (auth:SIMPLE)	ip=/127.0.0.1	cmd=modifyAclEntries	src=/p8	dst=null	perm=bruce:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:24,921 [IPC Server handler 9 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=diana (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p8	dst=null	perm=null	proto=rpc
2020-04-02 05:07:24,927 [IPC Server handler 2 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=diana (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p8	dst=null	perm=null	proto=rpc
2020-04-02 05:07:24,927 [IPC Server handler 2 on 43071] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 2 on 43071, call Call#285 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.removeXAttr from 127.0.0.1:41132: org.apache.hadoop.security.AccessControlException: Permission denied: user=diana, access=WRITE, inode="/p8":bruce:supergroup:drwxr-x---
2020-04-02 05:07:24,930 [IPC Server handler 0 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=diana (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p8	dst=null	perm=null	proto=rpc
2020-04-02 05:07:24,930 [IPC Server handler 0 on 43071] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 0 on 43071, call Call#286 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:41132: org.apache.hadoop.security.AccessControlException: Permission denied: user=diana, access=WRITE, inode="/p8":bruce:supergroup:drwxr-x---
2020-04-02 05:07:24,937 [IPC Server handler 3 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=bruce (auth:SIMPLE)	ip=/127.0.0.1	cmd=modifyAclEntries	src=/p8	dst=null	perm=bruce:supergroup:rwxrwx---	proto=rpc
2020-04-02 05:07:24,939 [IPC Server handler 6 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=diana (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p8	dst=null	perm=bruce:supergroup:rwxrwx---	proto=rpc
2020-04-02 05:07:24,950 [IPC Server handler 5 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=diana (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p8	dst=null	perm=null	proto=rpc
2020-04-02 05:07:24,951 [IPC Server handler 1 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=diana (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p8	dst=null	perm=bruce:supergroup:rwxrwx---	proto=rpc
2020-04-02 05:07:24,952 [IPC Server handler 8 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=diana (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p8	dst=null	perm=bruce:supergroup:rwxrwx---	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testXAttrAcl
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testXAttrAcl
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testCleanupXAttrs
[msx] perform reset as unitTestCounterInClass 8 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:24,957 [IPC Server handler 7 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p9	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:24,959 [IPC Server handler 4 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:24,963 [IPC Server handler 9 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:24,965 [IPC Server handler 2 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:24,967 [IPC Server handler 0 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:24,969 [IPC Server handler 3 on 43071] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:24,973 [Thread-575] INFO  hdfs.StateChange (FSNamesystem.java:enterSafeMode(4593)) - STATE* Safe mode is ON.
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2020-04-02 05:07:24,973 [Thread-575] INFO  namenode.FSImage (FSImage.java:saveNamespace(1101)) - Save namespace ...
2020-04-02 05:07:24,973 [Thread-575] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 126, 172
2020-04-02 05:07:24,975 [Thread-575] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 48 Total time for transactions(ms): 24 Number of transactions batched in Syncs: 125 Number of syncs: 49 SyncTimes(ms): 5 4 
2020-04-02 05:07:24,977 [Thread-575] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000126 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000126-0000000000000000173
2020-04-02 05:07:24,979 [Thread-575] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000126 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000126-0000000000000000173
2020-04-02 05:07:24,979 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000173 using no compression
2020-04-02 05:07:24,979 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000173 using no compression
2020-04-02 05:07:24,994 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000173 of size 1343 bytes saved in 0 seconds .
2020-04-02 05:07:24,997 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000173 of size 1343 bytes saved in 0 seconds .
2020-04-02 05:07:25,000 [Thread-575] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 123
2020-04-02 05:07:25,000 [Thread-575] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(225)) - Purging old image FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000078, cpktTxId=0000000000000000078)
2020-04-02 05:07:25,001 [Thread-575] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(225)) - Purging old image FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage_0000000000000000078, cpktTxId=0000000000000000078)
2020-04-02 05:07:25,007 [Thread-575] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 174
2020-04-02 05:07:25,200 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:saveNamespace(4419)) - New namespace image has been created
2020-04-02 05:07:25,205 [Thread-575] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:25,233 [Thread-575] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:25,233 [Thread-575] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 35173 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:25,233 [Thread-575] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:25,234 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5f49c698] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:25,241 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae) exiting.
2020-04-02 05:07:25,239 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093) exiting.
2020-04-02 05:07:25,331 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2ca00314{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:25,334 [Thread-575] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@765a0672{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:25,340 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@f8eaec8{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:25,341 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@75cb77db{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:25,375 [Thread-575] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35173
2020-04-02 05:07:25,379 [IPC Server listener on 35173] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35173
2020-04-02 05:07:25,381 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:25,381 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:43071] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:25,382 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:43071] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:43071
2020-04-02 05:07:25,382 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:43071] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741)
2020-04-02 05:07:25,382 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:43071] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:25,411 [Thread-575] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:25,412 [Thread-575] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:25,413 [Thread-575] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:25,419 [Thread-575] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:25,421 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:25,430 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:25,432 [Thread-575] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:25,433 [Thread-575] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:25,433 [Thread-575] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 43071 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:25,433 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:25,433 [Thread-575] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 174, 174
2020-04-02 05:07:25,433 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4263fbab] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:25,440 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@652f2815] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:25,445 [Thread-575] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 16 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 10 2 
2020-04-02 05:07:25,446 [Thread-575] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000174 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000174-0000000000000000175
2020-04-02 05:07:25,447 [Thread-575] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000174 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000174-0000000000000000175
2020-04-02 05:07:25,447 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:25,448 [CacheReplicationMonitor(1614095238)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:25,458 [Thread-575] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43071
2020-04-02 05:07:25,463 [IPC Server listener on 43071] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43071
2020-04-02 05:07:25,466 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:25,469 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:25,469 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:25,486 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:25,486 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:25,496 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5cfb84fc{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:25,497 [Thread-575] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@45f5d1f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:25,503 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4ebe2bc2{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:25,504 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5bd85be5{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:25,507 [Thread-575] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:25,523 [Thread-575] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:25,523 [Thread-575] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:25,530 [Thread-575] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:07:25,534 [Thread-575] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:25,552 [Thread-575] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:25,564 [Thread-575] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:25,564 [Thread-575] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:25,565 [Thread-575] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:25,565 [Thread-575] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:25,578 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4141a28b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:25,578 [Thread-575] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:25,579 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:25,580 [Thread-575] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:25,581 [Thread-575] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:25,582 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:25,583 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:25,583 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:25,584 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:25,584 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:25,585 [Thread-575] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:25,585 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:25,594 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40395
2020-04-02 05:07:25,594 [Thread-575] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:25,618 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@34b7c368{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:25,620 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3565f55c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:25,627 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@785b71c4{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:25,628 [Thread-575] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1f67a119{HTTP/1.1,[http/1.1]}{localhost:40395}
2020-04-02 05:07:25,629 [Thread-575] INFO  server.Server (Server.java:doStart(419)) - Started @15841ms
2020-04-02 05:07:25,640 [Thread-575] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:25,641 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:25,644 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:25,645 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:25,645 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:25,645 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:25,645 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:25,645 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:25,646 [Thread-575] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:25,646 [Thread-575] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:25,646 [Thread-575] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:25,646 [Thread-575] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:25,647 [Thread-575] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:25
2020-04-02 05:07:25,647 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:25,647 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:25,647 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:25,647 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:25,651 [Thread-575] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:25,651 [Thread-575] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:25,651 [Thread-575] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:25,652 [Thread-575] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:25,652 [Thread-575] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:25,652 [Thread-575] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:25,652 [Thread-575] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:25,652 [Thread-575] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:25,652 [Thread-575] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:25,652 [Thread-575] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:25,652 [Thread-575] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:25,652 [Thread-575] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:25,654 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:25,654 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:25,655 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:25,655 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:25,657 [Thread-575] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:25,657 [Thread-575] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:25,657 [Thread-575] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:25,657 [Thread-575] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:25,657 [Thread-575] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:25,658 [Thread-575] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:25,658 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:25,658 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:25,658 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:25,658 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:25,659 [Thread-575] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:25,659 [Thread-575] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:25,659 [Thread-575] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:25,660 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:25,660 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:25,660 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:25,660 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:25,661 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:25,661 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:25,669 [Thread-575] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:25,670 [Thread-575] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:25,672 [Thread-575] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:25,672 [Thread-575] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:25,674 [Thread-575] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000173, cpktTxId=0000000000000000173)
2020-04-02 05:07:25,675 [Thread-575] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 13 INodes.
2020-04-02 05:07:25,677 [Thread-575] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:25,677 [Thread-575] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 173 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000173
2020-04-02 05:07:25,678 [Thread-575] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@350af50f expecting start txid #174
2020-04-02 05:07:25,678 [Thread-575] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000174-0000000000000000175, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000174-0000000000000000175 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:25,678 [Thread-575] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000174-0000000000000000175' to transaction ID 174
2020-04-02 05:07:25,681 [Thread-575] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000174-0000000000000000175, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000174-0000000000000000175 of size 42 edits # 2 loaded in 0 seconds
2020-04-02 05:07:25,681 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:25,682 [Thread-575] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 176
2020-04-02 05:07:25,690 [Thread-575] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:25,690 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 24 msecs
2020-04-02 05:07:25,691 [Thread-575] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:25,691 [Thread-575] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:25,692 [Socket Reader #1 for port 34933] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34933
2020-04-02 05:07:25,703 [Thread-575] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:34933 to access this namenode/service.
2020-04-02 05:07:25,704 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:25,734 [Thread-575] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:25,735 [Thread-575] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:25,736 [Thread-575] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:25,736 [Thread-575] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:25,736 [Thread-575] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:25,750 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:25,751 [IPC Server listener on 34933] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34933: starting
2020-04-02 05:07:25,756 [Thread-575] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:34933
2020-04-02 05:07:25,757 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:25,757 [Thread-575] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:25,801 [Thread-575] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 44 milliseconds
name space=13
storage space=1024
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:25,802 [Thread-575] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 34933 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:25,803 [Thread-575] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:25,804 [Thread-575] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:25,804 [Thread-575] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:25,804 [Thread-575] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:25,805 [Thread-575] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:25,805 [Thread-575] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:25,805 [Thread-575] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:25,805 [Thread-575] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:25,805 [Thread-575] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:25,808 [Thread-575] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:25,808 [Thread-575] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:41688
2020-04-02 05:07:25,809 [Thread-575] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:25,809 [Thread-575] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:25,809 [CacheReplicationMonitor(1918778329)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:25,814 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:25,814 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:07:25,814 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:25,814 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:07:25,814 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:25,814 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:25,815 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 52 msec
2020-04-02 05:07:25,824 [Thread-575] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:25,825 [Thread-575] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:25,825 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:25,827 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:25,828 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:25,828 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:25,828 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:25,838 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42512
2020-04-02 05:07:25,838 [Thread-575] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:25,851 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7ae71d5c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:25,852 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1a388f02{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:25,868 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4ad86630{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:25,869 [Thread-575] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@27c520b0{HTTP/1.1,[http/1.1]}{localhost:42512}
2020-04-02 05:07:25,869 [Thread-575] INFO  server.Server (Server.java:doStart(419)) - Started @16081ms
2020-04-02 05:07:25,893 [Thread-575] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37047
2020-04-02 05:07:25,898 [Thread-575] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:25,898 [Thread-575] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:25,899 [Thread-575] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:25,900 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1f55b7b2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:25,902 [Socket Reader #1 for port 40592] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40592
2020-04-02 05:07:25,915 [Thread-575] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40592
2020-04-02 05:07:25,919 [Thread-575] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:25,925 [Thread-575] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:25,928 [Thread-626] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34933 starting to offer service
2020-04-02 05:07:25,934 [IPC Server listener on 40592] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40592: starting
2020-04-02 05:07:25,934 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:25,943 [Thread-575] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40592 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:25,966 [Thread-626] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34933
2020-04-02 05:07:25,978 [Thread-626] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:26,013 [Thread-626] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:26,037 [IPC Server handler 2 on 34933] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:26,040 [Thread-575] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:26,041 [Thread-575] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:26,049 [Thread-626] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:26,073 [Thread-626] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:26,073 [Thread-626] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:26,083 [Thread-626] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:26,083 [Thread-626] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:26,084 [Thread-626] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=213151118;bpid=BP-944730262-172.17.0.6-1585804031959;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=213151118;c=1585804031959;bpid=BP-944730262-172.17.0.6-1585804031959;dnuuid=a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:26,086 [Thread-626] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5437a82e-ddff-46c6-ad88-3ed31967d093
2020-04-02 05:07:26,087 [Thread-626] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:26,090 [Thread-626] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae
2020-04-02 05:07:26,090 [Thread-626] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:26,091 [Thread-626] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:26,092 [Thread-626] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:26,092 [Thread-626] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:26,093 [Thread-626] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:26,093 [Thread-626] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:26,103 [Thread-626] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:26,104 [Thread-641] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:26,105 [Thread-642] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:26,105 [Thread-641] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959/current: 43180
2020-04-02 05:07:26,106 [Thread-642] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959/current: 41102
2020-04-02 05:07:26,118 [Thread-641] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-944730262-172.17.0.6-1585804031959 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 14ms
2020-04-02 05:07:26,124 [Thread-642] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-944730262-172.17.0.6-1585804031959 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 19ms
2020-04-02 05:07:26,125 [Thread-626] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-944730262-172.17.0.6-1585804031959: 21ms
2020-04-02 05:07:26,126 [Thread-643] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:26,143 [Thread-644] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:26,144 [Thread-644] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959/current/replicas
2020-04-02 05:07:26,144 [Thread-644] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 0ms
2020-04-02 05:07:26,150 [Thread-643] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959/current/replicas
2020-04-02 05:07:26,146 [IPC Server handler 3 on 34933] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:26,155 [Thread-643] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 29ms
2020-04-02 05:07:26,156 [Thread-575] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:26,156 [Thread-575] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:26,157 [Thread-626] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-944730262-172.17.0.6-1585804031959: 33ms
2020-04-02 05:07:26,158 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093): no suitable block pools found to scan.  Waiting 1814389559 ms.
2020-04-02 05:07:26,159 [Thread-626] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:45 AM with interval of 21600000ms
2020-04-02 05:07:26,161 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae): no suitable block pools found to scan.  Waiting 1814389556 ms.
2020-04-02 05:07:26,169 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:34933] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:34933 beginning handshake with NN
2020-04-02 05:07:26,178 [IPC Server handler 1 on 34933] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41688, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=37047, infoSecurePort=0, ipcPort=40592, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959) storage a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:26,179 [IPC Server handler 1 on 34933] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41688
2020-04-02 05:07:26,179 [IPC Server handler 1 on 34933] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a66a72ee-5beb-418a-8fdf-000c79d6d741 (127.0.0.1:41688).
2020-04-02 05:07:26,186 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:34933] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:34933 successfully registered with NN
2020-04-02 05:07:26,186 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:34933] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:34933 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:26,199 [IPC Server handler 4 on 34933] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5437a82e-ddff-46c6-ad88-3ed31967d093 for DN 127.0.0.1:41688
2020-04-02 05:07:26,199 [IPC Server handler 4 on 34933] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae for DN 127.0.0.1:41688
2020-04-02 05:07:26,216 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb83fe79628f22bce: Processing first storage report for DS-5437a82e-ddff-46c6-ad88-3ed31967d093 from datanode a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:26,218 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb83fe79628f22bce: from storage DS-5437a82e-ddff-46c6-ad88-3ed31967d093 node DatanodeRegistration(127.0.0.1:41688, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=37047, infoSecurePort=0, ipcPort=40592, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959), blocks: 4, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:07:26,218 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb83fe79628f22bce: Processing first storage report for DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae from datanode a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:26,218 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb83fe79628f22bce: from storage DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae node DatanodeRegistration(127.0.0.1:41688, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=37047, infoSecurePort=0, ipcPort=40592, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:26,219 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:34933] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xb83fe79628f22bce,  containing 2 storage report(s), of which we sent 2. The reports had 6 total blocks and used 1 RPC(s). This took 0 msec to generate and 13 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:26,219 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:34933] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:26,258 [IPC Server handler 6 on 34933] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:26,258 [Thread-575] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:26,261 [IPC Server handler 7 on 34933] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:26,264 [Thread-575] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:26,266 [IPC Server handler 8 on 34933] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:26,269 [IPC Server handler 9 on 34933] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:26,271 [IPC Server handler 0 on 34933] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:26,274 [IPC Server handler 2 on 34933] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:26,275 [Thread-575] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:26,275 [Thread-575] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:26,275 [Thread-575] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40592 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:26,278 [Thread-575] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:26,278 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@572c0120] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:26,279 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae) exiting.
2020-04-02 05:07:26,279 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093) exiting.
2020-04-02 05:07:26,292 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4ad86630{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:26,293 [Thread-575] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@27c520b0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:26,293 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1a388f02{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:26,293 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7ae71d5c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:26,297 [Thread-575] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40592
2020-04-02 05:07:26,308 [IPC Server listener on 40592] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40592
2020-04-02 05:07:26,308 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:26,309 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:34933] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:26,309 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:34933] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:34933
2020-04-02 05:07:26,309 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:34933] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741)
2020-04-02 05:07:26,309 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:34933] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:26,327 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:26,334 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:26,345 [Thread-575] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:26,345 [Thread-575] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:26,351 [Thread-575] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:26,351 [Thread-575] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:26,358 [Thread-575] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:26,358 [Thread-575] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:26,358 [Thread-575] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 34933 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:26,358 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:26,358 [Thread-575] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 176, 180
2020-04-02 05:07:26,359 [Thread-575] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 6 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 175 Number of syncs: 7 SyncTimes(ms): 4 2 
2020-04-02 05:07:26,359 [Thread-575] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000176 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000176-0000000000000000181
2020-04-02 05:07:26,360 [Thread-575] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000176 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000176-0000000000000000181
2020-04-02 05:07:26,362 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@6319adcf] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:26,369 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:26,370 [CacheReplicationMonitor(1918778329)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:26,370 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@52cadd2f] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:26,382 [Thread-575] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34933
2020-04-02 05:07:26,385 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:26,385 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:26,385 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:26,386 [IPC Server listener on 34933] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34933
2020-04-02 05:07:26,394 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:26,394 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:26,395 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@785b71c4{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:26,398 [Thread-575] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1f67a119{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:26,399 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3565f55c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:26,399 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@34b7c368{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:26,400 [Thread-575] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:26,400 [Thread-575] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:26,400 [Thread-575] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:26,405 [Thread-575] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:07:26,406 [Thread-575] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:26,411 [Thread-575] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:26,414 [Thread-575] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:26,414 [Thread-575] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:26,415 [Thread-575] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:26,415 [Thread-575] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:26,420 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@26d3d5b1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:26,421 [Thread-575] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:26,421 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:26,422 [Thread-575] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:26,423 [Thread-575] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:26,423 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:26,425 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:26,425 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:26,436 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:26,436 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:26,444 [Thread-575] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:26,445 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:26,445 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38829
2020-04-02 05:07:26,446 [Thread-575] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:26,447 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@758b4be4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:26,448 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7c5b3165{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:26,453 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4f698b86{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:26,454 [Thread-575] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1af27351{HTTP/1.1,[http/1.1]}{localhost:38829}
2020-04-02 05:07:26,454 [Thread-575] INFO  server.Server (Server.java:doStart(419)) - Started @16666ms
2020-04-02 05:07:26,456 [Thread-575] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:26,456 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:26,456 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:26,456 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:26,457 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:26,457 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:26,457 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:26,457 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:26,459 [Thread-575] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:26,460 [Thread-575] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:26,460 [Thread-575] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:26,460 [Thread-575] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:26,460 [Thread-575] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:26
2020-04-02 05:07:26,461 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:26,461 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:26,461 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:26,461 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:26,469 [Thread-575] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:26,469 [Thread-575] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:26,470 [Thread-575] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:26,470 [Thread-575] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:26,470 [Thread-575] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:26,470 [Thread-575] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:26,470 [Thread-575] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:26,470 [Thread-575] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:26,470 [Thread-575] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:26,470 [Thread-575] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:26,470 [Thread-575] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:26,470 [Thread-575] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:26,471 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:26,471 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:26,471 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:26,471 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:26,476 [Thread-575] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:26,477 [Thread-575] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:26,477 [Thread-575] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:26,477 [Thread-575] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:26,477 [Thread-575] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:26,477 [Thread-575] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:26,477 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:26,477 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:26,477 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:26,477 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:26,478 [Thread-575] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:26,478 [Thread-575] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:26,478 [Thread-575] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:26,479 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:26,479 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:26,479 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:26,479 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:26,479 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:26,480 [Thread-575] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:26,482 [Thread-575] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:26,483 [Thread-575] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:26,485 [Thread-575] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:26,485 [Thread-575] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:26,486 [Thread-575] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000173, cpktTxId=0000000000000000173)
2020-04-02 05:07:26,487 [Thread-575] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 13 INodes.
2020-04-02 05:07:26,488 [Thread-575] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:26,488 [Thread-575] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 173 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000173
2020-04-02 05:07:26,488 [Thread-575] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@75396d08 expecting start txid #174
2020-04-02 05:07:26,488 [Thread-575] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000174-0000000000000000175, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000174-0000000000000000175 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:26,489 [Thread-575] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000174-0000000000000000175' to transaction ID 174
2020-04-02 05:07:26,489 [Thread-575] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000174-0000000000000000175, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000174-0000000000000000175 of size 42 edits # 2 loaded in 0 seconds
2020-04-02 05:07:26,489 [Thread-575] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5a1d1efd expecting start txid #176
2020-04-02 05:07:26,489 [Thread-575] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000176-0000000000000000181, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000176-0000000000000000181 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:26,489 [Thread-575] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000176-0000000000000000181' to transaction ID 174
2020-04-02 05:07:26,490 [Thread-575] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000176-0000000000000000181, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000176-0000000000000000181 of size 264 edits # 6 loaded in 0 seconds
2020-04-02 05:07:26,490 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:26,491 [Thread-575] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 182
2020-04-02 05:07:26,495 [Thread-575] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:26,496 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 16 msecs
2020-04-02 05:07:26,496 [Thread-575] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:26,497 [Thread-575] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:26,497 [Socket Reader #1 for port 46263] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46263
2020-04-02 05:07:26,508 [Thread-575] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:46263 to access this namenode/service.
2020-04-02 05:07:26,509 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:26,545 [Thread-575] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:26,547 [Thread-575] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:26,547 [Thread-575] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:26,547 [Thread-575] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:26,547 [Thread-575] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:26,551 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:26,551 [IPC Server listener on 46263] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46263: starting
2020-04-02 05:07:26,556 [Thread-575] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:46263
2020-04-02 05:07:26,558 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:07:26,562 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:26,562 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:07:26,562 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:26,562 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:26,562 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 15 msec
2020-04-02 05:07:26,581 [Thread-575] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:26,581 [Thread-575] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:26,585 [Thread-575] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 3 milliseconds
name space=13
storage space=1024
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:26,593 [Thread-575] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 46263 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:26,594 [Thread-575] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:26,595 [Thread-575] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:26,595 [Thread-575] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:26,615 [CacheReplicationMonitor(1441042029)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:26,624 [Thread-575] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:26,624 [Thread-575] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:26,625 [Thread-575] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:26,625 [Thread-575] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:26,626 [Thread-575] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:26,626 [Thread-575] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:26,626 [Thread-575] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:26,627 [Thread-575] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:41982
2020-04-02 05:07:26,627 [Thread-575] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:26,627 [Thread-575] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:26,628 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:26,629 [Thread-575] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:26,634 [Thread-575] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:26,634 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:26,635 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:26,635 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:26,635 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:26,636 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:26,636 [Thread-575] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34238
2020-04-02 05:07:26,636 [Thread-575] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:26,645 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4ab46dd{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:26,650 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f7dc1f3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:26,654 [Thread-575] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@fb02a07{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:26,655 [Thread-575] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3697df39{HTTP/1.1,[http/1.1]}{localhost:34238}
2020-04-02 05:07:26,655 [Thread-575] INFO  server.Server (Server.java:doStart(419)) - Started @16867ms
2020-04-02 05:07:26,673 [Thread-575] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42772
2020-04-02 05:07:26,674 [Thread-575] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:26,674 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2576d04a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:26,674 [Thread-575] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:26,674 [Thread-575] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:26,675 [Socket Reader #1 for port 39459] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39459
2020-04-02 05:07:26,679 [Thread-575] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:39459
2020-04-02 05:07:26,683 [Thread-575] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:26,684 [Thread-575] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:26,684 [Thread-698] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46263 starting to offer service
2020-04-02 05:07:26,690 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:26,701 [IPC Server listener on 39459] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39459: starting
2020-04-02 05:07:26,710 [Thread-575] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 39459 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:26,781 [IPC Server handler 0 on 46263] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:26,781 [Thread-698] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46263
2020-04-02 05:07:26,789 [Thread-698] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:26,789 [Thread-575] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:26,790 [Thread-575] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:26,792 [Thread-698] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:26,796 [Thread-698] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:26,810 [Thread-698] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:26,810 [Thread-698] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:26,821 [Thread-698] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:26,821 [Thread-698] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:26,823 [Thread-698] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=213151118;bpid=BP-944730262-172.17.0.6-1585804031959;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=213151118;c=1585804031959;bpid=BP-944730262-172.17.0.6-1585804031959;dnuuid=a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:26,829 [Thread-698] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5437a82e-ddff-46c6-ad88-3ed31967d093
2020-04-02 05:07:26,831 [Thread-698] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:26,837 [Thread-698] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae
2020-04-02 05:07:26,838 [Thread-698] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:26,838 [Thread-698] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:26,840 [Thread-698] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:26,850 [Thread-698] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:26,850 [Thread-698] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:26,850 [Thread-698] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:26,850 [Thread-698] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:26,854 [Thread-713] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:26,855 [Thread-714] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:26,858 [Thread-714] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959/current: 41102
2020-04-02 05:07:26,866 [Thread-713] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959/current: 43180
2020-04-02 05:07:26,873 [Thread-714] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-944730262-172.17.0.6-1585804031959 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 18ms
2020-04-02 05:07:26,878 [Thread-713] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-944730262-172.17.0.6-1585804031959 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 24ms
2020-04-02 05:07:26,879 [Thread-698] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-944730262-172.17.0.6-1585804031959: 29ms
2020-04-02 05:07:26,881 [Thread-715] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:26,883 [Thread-715] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959/current/replicas
2020-04-02 05:07:26,884 [Thread-715] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 3ms
2020-04-02 05:07:26,885 [Thread-716] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:26,886 [Thread-716] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959/current/replicas
2020-04-02 05:07:26,886 [Thread-716] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:07:26,886 [Thread-698] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-944730262-172.17.0.6-1585804031959: 7ms
2020-04-02 05:07:26,887 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093): no suitable block pools found to scan.  Waiting 1814388830 ms.
2020-04-02 05:07:26,888 [Thread-698] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:04 AM with interval of 21600000ms
2020-04-02 05:07:26,888 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae): no suitable block pools found to scan.  Waiting 1814388829 ms.
2020-04-02 05:07:26,889 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:46263] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:46263 beginning handshake with NN
2020-04-02 05:07:26,891 [IPC Server handler 5 on 46263] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41982, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=42772, infoSecurePort=0, ipcPort=39459, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959) storage a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:26,892 [IPC Server handler 5 on 46263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41982
2020-04-02 05:07:26,892 [IPC Server handler 5 on 46263] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a66a72ee-5beb-418a-8fdf-000c79d6d741 (127.0.0.1:41982).
2020-04-02 05:07:26,901 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:46263] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:46263 successfully registered with NN
2020-04-02 05:07:26,908 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:46263] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46263 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:26,915 [IPC Server handler 6 on 46263] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:26,916 [Thread-575] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2718)) - No heartbeat from DataNode: 127.0.0.1:41982
2020-04-02 05:07:26,916 [Thread-575] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:26,919 [IPC Server handler 3 on 46263] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5437a82e-ddff-46c6-ad88-3ed31967d093 for DN 127.0.0.1:41982
2020-04-02 05:07:26,919 [IPC Server handler 3 on 46263] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae for DN 127.0.0.1:41982
2020-04-02 05:07:26,930 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf627db5a7a52eec5: Processing first storage report for DS-5437a82e-ddff-46c6-ad88-3ed31967d093 from datanode a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:26,936 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf627db5a7a52eec5: from storage DS-5437a82e-ddff-46c6-ad88-3ed31967d093 node DatanodeRegistration(127.0.0.1:41982, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=42772, infoSecurePort=0, ipcPort=39459, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959), blocks: 4, hasStaleStorage: true, processing time: 6 msecs, invalidatedBlocks: 0
2020-04-02 05:07:26,936 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf627db5a7a52eec5: Processing first storage report for DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae from datanode a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:26,936 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf627db5a7a52eec5: from storage DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae node DatanodeRegistration(127.0.0.1:41982, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=42772, infoSecurePort=0, ipcPort=39459, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:26,937 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:46263] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xf627db5a7a52eec5,  containing 2 storage report(s), of which we sent 2. The reports had 6 total blocks and used 1 RPC(s). This took 0 msec to generate and 11 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:26,937 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:46263] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:27,017 [IPC Server handler 4 on 46263] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:27,018 [Thread-575] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:27,022 [IPC Server handler 9 on 46263] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:27,023 [Thread-575] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:27,025 [IPC Server handler 2 on 46263] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:27,030 [IPC Server handler 8 on 46263] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:27,032 [IPC Server handler 1 on 46263] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:27,034 [IPC Server handler 0 on 46263] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:27,039 [IPC Server handler 5 on 46263] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:27,041 [IPC Server handler 6 on 46263] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:27,043 [IPC Server handler 3 on 46263] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p9	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testCleanupXAttrs
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testCleanupXAttrs
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testReplaceXAttr
[msx] perform reset as unitTestCounterInClass 9 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:27,055 [IPC Server handler 7 on 46263] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p10	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:27,067 [IPC Server handler 4 on 46263] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p10	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:27,070 [IPC Server handler 9 on 46263] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p10	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:27,074 [IPC Server handler 2 on 46263] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p10	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:27,076 [IPC Server handler 8 on 46263] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p10	dst=null	perm=null	proto=rpc
2020-04-02 05:07:27,078 [IPC Server handler 1 on 46263] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p10	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:27,080 [IPC Server handler 0 on 46263] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 0 on 46263, call Call#331 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:55118
java.io.IOException: XAttr: a1 does not exist. The CREATE flag must be specified.
	at org.apache.hadoop.fs.XAttrSetFlag.validate(XAttrSetFlag.java:66)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setINodeXAttrs(FSDirXAttrOp.java:342)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedSetXAttrs(FSDirXAttrOp.java:272)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setXAttr(FSDirXAttrOp.java:85)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setXAttr(FSNamesystem.java:7714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setXAttr(NameNodeRpcServer.java:2170)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setXAttr(ClientNamenodeProtocolServerSideTranslatorPB.java:1615)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:07:27,092 [IPC Server handler 5 on 46263] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p10	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:27,093 [IPC Server handler 6 on 46263] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p10	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:27,104 [IPC Server handler 3 on 46263] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p10	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:27,105 [IPC Server handler 7 on 46263] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p10	dst=null	perm=null	proto=rpc
2020-04-02 05:07:27,109 [Thread-720] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:27,116 [Thread-720] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:27,116 [Thread-720] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 39459 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:27,116 [Thread-720] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:27,116 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@b5cdb31] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:27,119 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093) exiting.
2020-04-02 05:07:27,119 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae) exiting.
2020-04-02 05:07:27,134 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@fb02a07{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:27,134 [Thread-720] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3697df39{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:27,135 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f7dc1f3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:27,135 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4ab46dd{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:27,142 [Thread-720] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39459
2020-04-02 05:07:27,146 [IPC Server listener on 39459] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39459
2020-04-02 05:07:27,150 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:27,150 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:46263] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:27,150 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:46263] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:46263
2020-04-02 05:07:27,150 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:46263] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741)
2020-04-02 05:07:27,153 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:46263] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:27,165 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:27,172 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:27,177 [Thread-720] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:27,177 [Thread-720] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:27,178 [Thread-720] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:27,178 [Thread-720] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:27,182 [Thread-720] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:27,182 [Thread-720] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:27,182 [Thread-720] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 46263 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:27,182 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:27,183 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@1528a806] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:27,183 [Thread-720] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 182, 196
2020-04-02 05:07:27,188 [Thread-720] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 16 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 181 Number of syncs: 17 SyncTimes(ms): 1 0 
2020-04-02 05:07:27,189 [Thread-720] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000182 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000182-0000000000000000197
2020-04-02 05:07:27,190 [Thread-720] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000182 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000182-0000000000000000197
2020-04-02 05:07:27,190 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:27,190 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@4d6b9965] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:27,190 [CacheReplicationMonitor(1441042029)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:27,210 [Thread-720] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46263
2020-04-02 05:07:27,213 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:27,213 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:27,213 [IPC Server listener on 46263] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46263
2020-04-02 05:07:27,213 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:27,224 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:27,224 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:27,226 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4f698b86{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:27,227 [Thread-720] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1af27351{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:27,228 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7c5b3165{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:27,229 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@758b4be4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:27,232 [Thread-720] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:27,242 [Thread-720] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:27,245 [Thread-720] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:27,251 [Thread-720] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:07:27,252 [Thread-720] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:27,255 [Thread-720] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:27,256 [Thread-720] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:27,256 [Thread-720] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:27,257 [Thread-720] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:27,257 [Thread-720] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:27,263 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@39863982] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:27,263 [Thread-720] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:27,266 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:27,267 [Thread-720] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:27,268 [Thread-720] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:27,268 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:27,269 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:27,269 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:27,269 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:27,269 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:27,271 [Thread-720] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:27,271 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:27,271 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41012
2020-04-02 05:07:27,271 [Thread-720] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:27,273 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1a708d9f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:27,274 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1617bdf{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:27,280 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6ef70efe{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:27,281 [Thread-720] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5230a340{HTTP/1.1,[http/1.1]}{localhost:41012}
2020-04-02 05:07:27,281 [Thread-720] INFO  server.Server (Server.java:doStart(419)) - Started @17493ms
2020-04-02 05:07:27,306 [Thread-720] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:27,307 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:27,308 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:27,308 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:27,309 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:27,309 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:27,309 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:27,309 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:27,310 [Thread-720] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:27,311 [Thread-720] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:27,311 [Thread-720] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:27,311 [Thread-720] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:27,312 [Thread-720] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:27
2020-04-02 05:07:27,312 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:27,312 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:27,312 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:27,313 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:27,324 [Thread-720] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:27,325 [Thread-720] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:27,325 [Thread-720] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:27,326 [Thread-720] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:27,326 [Thread-720] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:27,326 [Thread-720] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:27,326 [Thread-720] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:27,326 [Thread-720] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:27,326 [Thread-720] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:27,327 [Thread-720] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:27,327 [Thread-720] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:27,327 [Thread-720] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:27,328 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:27,329 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:27,329 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:27,330 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:27,332 [Thread-720] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:27,333 [Thread-720] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:27,333 [Thread-720] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:27,333 [Thread-720] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:27,333 [Thread-720] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:27,333 [Thread-720] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:27,333 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:27,334 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:27,334 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:27,334 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:27,335 [Thread-720] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:27,335 [Thread-720] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:27,335 [Thread-720] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:27,338 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:27,338 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:27,338 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:27,338 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:27,338 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:27,338 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:27,345 [Thread-720] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:27,347 [Thread-720] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:27,348 [Thread-720] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:27,349 [Thread-720] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:27,350 [Thread-720] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000173, cpktTxId=0000000000000000173)
2020-04-02 05:07:27,351 [Thread-720] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 13 INodes.
2020-04-02 05:07:27,353 [Thread-720] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:27,353 [Thread-720] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 173 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000173
2020-04-02 05:07:27,353 [Thread-720] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5ad92d07 expecting start txid #174
2020-04-02 05:07:27,354 [Thread-720] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000174-0000000000000000175, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000174-0000000000000000175 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:27,354 [Thread-720] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000174-0000000000000000175' to transaction ID 174
2020-04-02 05:07:27,354 [Thread-720] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000174-0000000000000000175, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000174-0000000000000000175 of size 42 edits # 2 loaded in 0 seconds
2020-04-02 05:07:27,355 [Thread-720] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@363ef5bd expecting start txid #176
2020-04-02 05:07:27,355 [Thread-720] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000176-0000000000000000181, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000176-0000000000000000181 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:27,355 [Thread-720] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000176-0000000000000000181' to transaction ID 174
2020-04-02 05:07:27,356 [Thread-720] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000176-0000000000000000181, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000176-0000000000000000181 of size 264 edits # 6 loaded in 0 seconds
2020-04-02 05:07:27,356 [Thread-720] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1250fc1a expecting start txid #182
2020-04-02 05:07:27,356 [Thread-720] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000182-0000000000000000197, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000182-0000000000000000197 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:27,356 [Thread-720] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000182-0000000000000000197' to transaction ID 174
2020-04-02 05:07:27,363 [Thread-720] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000182-0000000000000000197, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000182-0000000000000000197 of size 819 edits # 16 loaded in 0 seconds
2020-04-02 05:07:27,363 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:27,364 [Thread-720] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 198
2020-04-02 05:07:27,370 [Thread-720] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:27,370 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 31 msecs
2020-04-02 05:07:27,370 [Thread-720] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:27,370 [Thread-720] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:27,371 [Socket Reader #1 for port 38279] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38279
2020-04-02 05:07:27,378 [Thread-720] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:38279 to access this namenode/service.
2020-04-02 05:07:27,379 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:27,420 [Thread-720] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:27,422 [Thread-720] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:27,423 [Thread-720] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:27,423 [Thread-720] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:27,423 [Thread-720] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:27,429 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:27,429 [IPC Server listener on 38279] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38279: starting
2020-04-02 05:07:27,432 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:07:27,432 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:27,432 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:07:27,432 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:27,432 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:27,432 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2020-04-02 05:07:27,433 [Thread-720] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:38279
2020-04-02 05:07:27,433 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:27,433 [Thread-720] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:27,457 [Thread-720] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 24 milliseconds
name space=14
storage space=1024
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:27,458 [Thread-720] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 38279 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:27,459 [Thread-720] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:27,460 [Thread-720] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:27,460 [Thread-720] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:27,461 [Thread-720] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:27,461 [Thread-720] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:27,461 [Thread-720] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:27,464 [Thread-720] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:27,465 [Thread-720] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:27,465 [Thread-720] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:27,465 [Thread-720] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:27,466 [Thread-720] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:38753
2020-04-02 05:07:27,466 [Thread-720] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:27,466 [Thread-720] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:27,467 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:27,468 [Thread-720] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:27,469 [Thread-720] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:27,469 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:27,470 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:27,470 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:27,470 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:27,470 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:27,471 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37667
2020-04-02 05:07:27,471 [Thread-720] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:27,472 [CacheReplicationMonitor(1856328863)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:27,472 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4edd3458{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:27,478 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@19df7929{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:27,482 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3d6a8daa{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:27,485 [Thread-720] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@546eca34{HTTP/1.1,[http/1.1]}{localhost:37667}
2020-04-02 05:07:27,485 [Thread-720] INFO  server.Server (Server.java:doStart(419)) - Started @17697ms
2020-04-02 05:07:27,553 [Thread-720] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40872
2020-04-02 05:07:27,554 [Thread-720] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:27,554 [Thread-720] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:27,554 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7f1bf796] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:27,554 [Thread-720] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:27,557 [Socket Reader #1 for port 37531] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37531
2020-04-02 05:07:27,563 [Thread-720] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:37531
2020-04-02 05:07:27,568 [Thread-720] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:27,568 [Thread-720] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:27,569 [Thread-771] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38279 starting to offer service
2020-04-02 05:07:27,574 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:27,574 [IPC Server listener on 37531] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37531: starting
2020-04-02 05:07:27,581 [Thread-720] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 37531 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:27,602 [Thread-771] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38279
2020-04-02 05:07:27,626 [Thread-771] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:27,633 [Thread-771] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:27,633 [IPC Server handler 1 on 38279] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:27,637 [Thread-771] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:27,638 [Thread-720] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:27,638 [Thread-720] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:27,650 [Thread-771] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:27,650 [Thread-771] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:27,659 [Thread-771] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:27,660 [Thread-771] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:27,661 [Thread-771] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=213151118;bpid=BP-944730262-172.17.0.6-1585804031959;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=213151118;c=1585804031959;bpid=BP-944730262-172.17.0.6-1585804031959;dnuuid=a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:27,663 [Thread-771] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5437a82e-ddff-46c6-ad88-3ed31967d093
2020-04-02 05:07:27,665 [Thread-771] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:27,666 [Thread-771] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae
2020-04-02 05:07:27,674 [Thread-771] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:27,679 [Thread-771] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:27,680 [Thread-771] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:27,681 [Thread-771] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:27,681 [Thread-771] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:27,683 [Thread-771] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:27,683 [Thread-771] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:27,683 [Thread-786] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:27,683 [Thread-787] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:27,684 [Thread-786] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959/current: 43180
2020-04-02 05:07:27,684 [Thread-787] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959/current: 41102
2020-04-02 05:07:27,702 [Thread-787] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-944730262-172.17.0.6-1585804031959 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 18ms
2020-04-02 05:07:27,705 [Thread-786] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-944730262-172.17.0.6-1585804031959 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 22ms
2020-04-02 05:07:27,705 [Thread-771] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-944730262-172.17.0.6-1585804031959: 23ms
2020-04-02 05:07:27,710 [Thread-788] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:27,712 [Thread-788] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959/current/replicas
2020-04-02 05:07:27,712 [Thread-788] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 2ms
2020-04-02 05:07:27,722 [Thread-789] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:27,722 [Thread-789] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959/current/replicas
2020-04-02 05:07:27,722 [Thread-789] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 0ms
2020-04-02 05:07:27,722 [Thread-771] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-944730262-172.17.0.6-1585804031959: 16ms
2020-04-02 05:07:27,723 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093): no suitable block pools found to scan.  Waiting 1814387994 ms.
2020-04-02 05:07:27,723 [Thread-771] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:52 AM with interval of 21600000ms
2020-04-02 05:07:27,725 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38279] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:38279 beginning handshake with NN
2020-04-02 05:07:27,725 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae): no suitable block pools found to scan.  Waiting 1814387992 ms.
2020-04-02 05:07:27,730 [IPC Server handler 2 on 38279] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38753, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=40872, infoSecurePort=0, ipcPort=37531, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959) storage a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:27,730 [IPC Server handler 2 on 38279] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38753
2020-04-02 05:07:27,731 [IPC Server handler 2 on 38279] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a66a72ee-5beb-418a-8fdf-000c79d6d741 (127.0.0.1:38753).
2020-04-02 05:07:27,741 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38279] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:38279 successfully registered with NN
2020-04-02 05:07:27,741 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38279] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38279 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:27,752 [IPC Server handler 4 on 38279] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5437a82e-ddff-46c6-ad88-3ed31967d093 for DN 127.0.0.1:38753
2020-04-02 05:07:27,752 [IPC Server handler 4 on 38279] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae for DN 127.0.0.1:38753
2020-04-02 05:07:27,752 [IPC Server handler 3 on 38279] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:27,758 [Thread-720] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2718)) - No heartbeat from DataNode: 127.0.0.1:38753
2020-04-02 05:07:27,758 [Thread-720] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:27,762 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2166defb59799c3f: Processing first storage report for DS-5437a82e-ddff-46c6-ad88-3ed31967d093 from datanode a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:27,766 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2166defb59799c3f: from storage DS-5437a82e-ddff-46c6-ad88-3ed31967d093 node DatanodeRegistration(127.0.0.1:38753, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=40872, infoSecurePort=0, ipcPort=37531, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959), blocks: 4, hasStaleStorage: true, processing time: 4 msecs, invalidatedBlocks: 0
2020-04-02 05:07:27,775 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2166defb59799c3f: Processing first storage report for DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae from datanode a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:27,775 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2166defb59799c3f: from storage DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae node DatanodeRegistration(127.0.0.1:38753, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=40872, infoSecurePort=0, ipcPort=37531, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:27,778 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38279] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x2166defb59799c3f,  containing 2 storage report(s), of which we sent 2. The reports had 6 total blocks and used 1 RPC(s). This took 0 msec to generate and 24 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:27,778 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38279] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:27,859 [IPC Server handler 6 on 38279] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:27,860 [Thread-720] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:27,863 [IPC Server handler 7 on 38279] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:27,864 [Thread-720] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:27,866 [IPC Server handler 8 on 38279] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p10	dst=null	perm=null	proto=rpc
2020-04-02 05:07:27,868 [Thread-720] INFO  hdfs.StateChange (FSNamesystem.java:enterSafeMode(4593)) - STATE* Safe mode is ON.
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2020-04-02 05:07:27,869 [Thread-720] INFO  namenode.FSImage (FSImage.java:saveNamespace(1101)) - Save namespace ...
2020-04-02 05:07:27,869 [Thread-720] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 198, 198
2020-04-02 05:07:27,869 [Thread-720] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 197 Number of syncs: 3 SyncTimes(ms): 1 0 
2020-04-02 05:07:27,870 [Thread-720] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000198 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000198-0000000000000000199
2020-04-02 05:07:27,871 [Thread-720] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000198 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000198-0000000000000000199
2020-04-02 05:07:27,892 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000199 using no compression
2020-04-02 05:07:27,896 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000199 using no compression
2020-04-02 05:07:27,912 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000199 of size 1445 bytes saved in 0 seconds .
2020-04-02 05:07:27,914 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000199 of size 1445 bytes saved in 0 seconds .
2020-04-02 05:07:27,920 [Thread-720] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 173
2020-04-02 05:07:27,921 [Thread-720] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(225)) - Purging old image FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000123, cpktTxId=0000000000000000123)
2020-04-02 05:07:27,921 [Thread-720] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(225)) - Purging old image FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage_0000000000000000123, cpktTxId=0000000000000000123)
2020-04-02 05:07:27,941 [Thread-720] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 200
2020-04-02 05:07:27,950 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:saveNamespace(4419)) - New namespace image has been created
2020-04-02 05:07:27,951 [Thread-720] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:27,951 [Thread-720] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:27,951 [Thread-720] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 37531 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:27,951 [Thread-720] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:27,951 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4e0d6dfc] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:27,959 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae) exiting.
2020-04-02 05:07:27,965 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093) exiting.
2020-04-02 05:07:28,046 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3d6a8daa{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:28,054 [Thread-720] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@546eca34{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:28,054 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@19df7929{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:28,055 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4edd3458{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:28,086 [Thread-720] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37531
2020-04-02 05:07:28,087 [IPC Server listener on 37531] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37531
2020-04-02 05:07:28,096 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:28,096 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38279] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:28,096 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38279] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:38279
2020-04-02 05:07:28,096 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38279] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741)
2020-04-02 05:07:28,096 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:38279] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:28,109 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:28,128 [Thread-720] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:28,129 [Thread-720] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:28,130 [Thread-720] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:28,131 [Thread-720] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:28,138 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:28,140 [Thread-720] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:28,140 [Thread-720] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:28,140 [Thread-720] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 38279 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:28,140 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:28,140 [Thread-720] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 200, 200
2020-04-02 05:07:28,140 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3059e93e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:28,141 [Thread-720] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 1 1 
2020-04-02 05:07:28,142 [Thread-720] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000200 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000200-0000000000000000201
2020-04-02 05:07:28,142 [Thread-720] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000200 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000200-0000000000000000201
2020-04-02 05:07:28,150 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:28,150 [CacheReplicationMonitor(1856328863)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:28,144 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@1e18bf0b] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:28,160 [Thread-720] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38279
2020-04-02 05:07:28,162 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:28,164 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:28,170 [IPC Server listener on 38279] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38279
2020-04-02 05:07:28,170 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:28,202 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:28,202 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:28,206 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6ef70efe{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:28,214 [Thread-720] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5230a340{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:28,214 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1617bdf{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:28,215 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1a708d9f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:28,238 [Thread-720] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:28,238 [Thread-720] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:28,238 [Thread-720] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:28,247 [Thread-720] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:07:28,248 [Thread-720] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:28,251 [Thread-720] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:28,252 [Thread-720] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:28,252 [Thread-720] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:28,253 [Thread-720] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:28,253 [Thread-720] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:28,278 [Thread-720] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:28,278 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:28,279 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3befe73b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:28,291 [Thread-720] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:28,292 [Thread-720] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:28,292 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:28,294 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:28,294 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:28,294 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:28,294 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:28,296 [Thread-720] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:28,296 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:28,296 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38934
2020-04-02 05:07:28,296 [Thread-720] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:28,302 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5042a7a8{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:28,302 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3a05feb{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:28,307 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2a74f13f{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:28,307 [Thread-720] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5c297288{HTTP/1.1,[http/1.1]}{localhost:38934}
2020-04-02 05:07:28,308 [Thread-720] INFO  server.Server (Server.java:doStart(419)) - Started @18520ms
2020-04-02 05:07:28,326 [Thread-720] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:28,336 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:28,336 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:28,336 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:28,336 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:28,336 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:28,337 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:28,337 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:28,337 [Thread-720] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:28,338 [Thread-720] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:28,338 [Thread-720] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:28,338 [Thread-720] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:28,339 [Thread-720] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:28
2020-04-02 05:07:28,339 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:28,339 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:28,339 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:28,339 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:28,344 [Thread-720] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:28,345 [Thread-720] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:28,345 [Thread-720] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:28,345 [Thread-720] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:28,345 [Thread-720] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:28,345 [Thread-720] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:28,345 [Thread-720] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:28,345 [Thread-720] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:28,346 [Thread-720] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:28,346 [Thread-720] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:28,346 [Thread-720] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:28,346 [Thread-720] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:28,346 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:28,347 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:28,347 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:28,347 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:28,349 [Thread-720] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:28,349 [Thread-720] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:28,350 [Thread-720] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:28,350 [Thread-720] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:28,350 [Thread-720] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:28,350 [Thread-720] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:28,350 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:28,350 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:28,351 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:28,351 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:28,353 [Thread-720] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:28,353 [Thread-720] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:28,353 [Thread-720] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:28,354 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:28,354 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:28,354 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:28,354 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:28,355 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:28,355 [Thread-720] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:28,362 [Thread-720] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:28,364 [Thread-720] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:28,370 [Thread-720] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:28,370 [Thread-720] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:28,371 [Thread-720] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000199, cpktTxId=0000000000000000199)
2020-04-02 05:07:28,372 [Thread-720] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 14 INodes.
2020-04-02 05:07:28,378 [Thread-720] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:28,379 [Thread-720] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 199 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000199
2020-04-02 05:07:28,379 [Thread-720] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@40c67734 expecting start txid #200
2020-04-02 05:07:28,379 [Thread-720] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000200-0000000000000000201, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000200-0000000000000000201 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:28,379 [Thread-720] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000200-0000000000000000201' to transaction ID 200
2020-04-02 05:07:28,380 [Thread-720] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000200-0000000000000000201, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000200-0000000000000000201 of size 42 edits # 2 loaded in 0 seconds
2020-04-02 05:07:28,380 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:28,385 [Thread-720] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 202
2020-04-02 05:07:28,392 [Thread-720] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:28,393 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 37 msecs
2020-04-02 05:07:28,393 [Thread-720] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:28,393 [Thread-720] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:28,394 [Socket Reader #1 for port 45602] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45602
2020-04-02 05:07:28,409 [Thread-720] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:45602 to access this namenode/service.
2020-04-02 05:07:28,409 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:28,471 [Thread-720] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:28,478 [Thread-720] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:28,479 [Thread-720] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:28,479 [Thread-720] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:28,479 [Thread-720] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:28,497 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:07:28,497 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:28,497 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:07:28,497 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:28,497 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:28,497 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 18 msec
2020-04-02 05:07:28,531 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:28,532 [IPC Server listener on 45602] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45602: starting
2020-04-02 05:07:28,581 [Thread-720] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:45602
2020-04-02 05:07:28,582 [Thread-720] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:28,582 [Thread-720] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:28,588 [Thread-720] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 6 milliseconds
name space=14
storage space=1024
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:28,590 [Thread-720] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 45602 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:28,591 [Thread-720] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:28,592 [Thread-720] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:28,593 [Thread-720] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:28,594 [Thread-720] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:28,594 [Thread-720] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:28,594 [Thread-720] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:28,594 [Thread-720] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:28,594 [Thread-720] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:28,595 [Thread-720] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:28,595 [Thread-720] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:28,595 [Thread-720] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:33886
2020-04-02 05:07:28,595 [Thread-720] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:28,595 [Thread-720] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:28,597 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:28,598 [Thread-720] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:28,599 [Thread-720] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:28,606 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:28,607 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:28,618 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:28,618 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:28,619 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:28,619 [Thread-720] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46332
2020-04-02 05:07:28,620 [Thread-720] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:28,630 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@32565191{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:28,631 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@59891a7f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:28,654 [CacheReplicationMonitor(671981132)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:28,658 [Thread-720] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1d9d16c6{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:28,658 [Thread-720] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7e9899e0{HTTP/1.1,[http/1.1]}{localhost:46332}
2020-04-02 05:07:28,658 [Thread-720] INFO  server.Server (Server.java:doStart(419)) - Started @18870ms
2020-04-02 05:07:28,709 [Thread-720] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35520
2020-04-02 05:07:28,712 [Thread-720] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:28,712 [Thread-720] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:28,712 [Thread-720] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:28,713 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@24508efc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:28,713 [Socket Reader #1 for port 37121] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37121
2020-04-02 05:07:28,715 [Thread-720] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:37121
2020-04-02 05:07:28,720 [Thread-720] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:28,721 [Thread-720] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:28,722 [Thread-846] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45602 starting to offer service
2020-04-02 05:07:28,726 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:28,732 [Thread-720] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 37121 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:28,733 [IPC Server listener on 37121] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37121: starting
2020-04-02 05:07:28,785 [Thread-846] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45602
2020-04-02 05:07:28,788 [Thread-846] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:28,793 [Thread-846] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:28,797 [Thread-846] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 13159@0d6e4bc4608e
2020-04-02 05:07:28,807 [Thread-846] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:28,807 [Thread-846] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:28,809 [IPC Server handler 0 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:28,814 [Thread-720] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:28,814 [Thread-720] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:28,816 [Thread-846] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:28,816 [Thread-846] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:28,817 [Thread-846] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=213151118;bpid=BP-944730262-172.17.0.6-1585804031959;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=213151118;c=1585804031959;bpid=BP-944730262-172.17.0.6-1585804031959;dnuuid=a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:28,819 [Thread-846] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5437a82e-ddff-46c6-ad88-3ed31967d093
2020-04-02 05:07:28,819 [Thread-846] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:28,824 [Thread-846] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae
2020-04-02 05:07:28,825 [Thread-846] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:28,827 [Thread-846] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:28,828 [Thread-846] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:28,839 [Thread-846] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:28,839 [Thread-846] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:28,840 [Thread-846] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:28,845 [Thread-846] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:28,850 [Thread-861] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:28,856 [Thread-861] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959/current: 43180
2020-04-02 05:07:28,857 [Thread-862] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:28,859 [Thread-862] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959/current: 41102
2020-04-02 05:07:28,871 [Thread-861] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-944730262-172.17.0.6-1585804031959 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 20ms
2020-04-02 05:07:28,888 [Thread-862] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-944730262-172.17.0.6-1585804031959 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 31ms
2020-04-02 05:07:28,888 [Thread-846] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-944730262-172.17.0.6-1585804031959: 42ms
2020-04-02 05:07:28,889 [Thread-863] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:28,894 [Thread-864] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:28,894 [Thread-863] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959/current/replicas
2020-04-02 05:07:28,895 [Thread-864] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959/current/replicas
2020-04-02 05:07:28,895 [Thread-863] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 6ms
2020-04-02 05:07:28,895 [Thread-864] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-944730262-172.17.0.6-1585804031959 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:07:28,895 [Thread-846] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-944730262-172.17.0.6-1585804031959: 6ms
2020-04-02 05:07:28,896 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093): no suitable block pools found to scan.  Waiting 1814386821 ms.
2020-04-02 05:07:28,896 [Thread-846] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:25 AM with interval of 21600000ms
2020-04-02 05:07:28,896 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae): no suitable block pools found to scan.  Waiting 1814386821 ms.
2020-04-02 05:07:28,902 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:45602] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:45602 beginning handshake with NN
2020-04-02 05:07:28,910 [IPC Server handler 2 on 45602] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33886, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=35520, infoSecurePort=0, ipcPort=37121, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959) storage a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:28,910 [IPC Server handler 2 on 45602] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33886
2020-04-02 05:07:28,910 [IPC Server handler 2 on 45602] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a66a72ee-5beb-418a-8fdf-000c79d6d741 (127.0.0.1:33886).
2020-04-02 05:07:28,915 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:45602] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:45602 successfully registered with NN
2020-04-02 05:07:28,915 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:45602] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:45602 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:28,924 [IPC Server handler 9 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:28,932 [Thread-720] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2718)) - No heartbeat from DataNode: 127.0.0.1:33886
2020-04-02 05:07:28,932 [Thread-720] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:28,935 [IPC Server handler 6 on 45602] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5437a82e-ddff-46c6-ad88-3ed31967d093 for DN 127.0.0.1:33886
2020-04-02 05:07:28,935 [IPC Server handler 6 on 45602] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae for DN 127.0.0.1:33886
2020-04-02 05:07:28,959 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x9197f291d57890d4: Processing first storage report for DS-5437a82e-ddff-46c6-ad88-3ed31967d093 from datanode a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:28,968 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x9197f291d57890d4: from storage DS-5437a82e-ddff-46c6-ad88-3ed31967d093 node DatanodeRegistration(127.0.0.1:33886, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=35520, infoSecurePort=0, ipcPort=37121, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959), blocks: 4, hasStaleStorage: true, processing time: 9 msecs, invalidatedBlocks: 0
2020-04-02 05:07:28,968 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x9197f291d57890d4: Processing first storage report for DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae from datanode a66a72ee-5beb-418a-8fdf-000c79d6d741
2020-04-02 05:07:28,968 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x9197f291d57890d4: from storage DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae node DatanodeRegistration(127.0.0.1:33886, datanodeUuid=a66a72ee-5beb-418a-8fdf-000c79d6d741, infoPort=35520, infoSecurePort=0, ipcPort=37121, storageInfo=lv=-57;cid=testClusterID;nsid=213151118;c=1585804031959), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:28,970 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:45602] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x9197f291d57890d4,  containing 2 storage report(s), of which we sent 2. The reports had 6 total blocks and used 1 RPC(s). This took 0 msec to generate and 26 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:28,970 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:45602] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:29,033 [IPC Server handler 7 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:29,034 [Thread-720] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:29,036 [IPC Server handler 5 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:29,037 [Thread-720] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:29,040 [IPC Server handler 4 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p10	dst=null	perm=null	proto=rpc
2020-04-02 05:07:29,042 [IPC Server handler 3 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p10	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,046 [IPC Server handler 1 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p10	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testReplaceXAttr
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testReplaceXAttr
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testGetXAttrs
[msx] perform reset as unitTestCounterInClass 10 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:29,056 [IPC Server handler 0 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p11	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:29,059 [IPC Server handler 2 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p11	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,062 [IPC Server handler 9 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p11	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,065 [IPC Server handler 6 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p11	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,066 [IPC Server handler 8 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p11	dst=null	perm=null	proto=rpc
2020-04-02 05:07:29,068 [IPC Server handler 7 on 45602] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 7 on 45602, call Call#361 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:39704
java.io.IOException: At least one of the attributes provided was not found.
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.getXAttrs(FSDirXAttrOp.java:129)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getXAttrs(FSNamesystem.java:7735)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getXAttrs(NameNodeRpcServer.java:2181)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getXAttrs(ClientNamenodeProtocolServerSideTranslatorPB.java:1627)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:07:29,079 [IPC Server handler 5 on 45602] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 5 on 45602, call Call#362 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:39704
java.io.IOException: At least one of the attributes provided was not found.
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.getXAttrs(FSDirXAttrOp.java:129)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getXAttrs(FSNamesystem.java:7735)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getXAttrs(NameNodeRpcServer.java:2181)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getXAttrs(ClientNamenodeProtocolServerSideTranslatorPB.java:1627)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:07:29,085 [IPC Server handler 4 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p11	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,087 [IPC Server handler 3 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p11	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,088 [IPC Server handler 1 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p11	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,110 [IPC Server handler 0 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p11	dst=null	perm=null	proto=rpc
2020-04-02 05:07:29,110 [IPC Server handler 0 on 45602] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 0 on 45602, call Call#366 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:39716: org.apache.hadoop.security.AccessControlException: User doesn't have permission for xattr: trusted.foo
2020-04-02 05:07:29,113 [IPC Server handler 2 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p11	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,114 [IPC Server handler 9 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p11	dst=null	perm=root:supergroup:rwx------	proto=rpc
2020-04-02 05:07:29,118 [IPC Server handler 6 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p11	dst=null	perm=null	proto=rpc
2020-04-02 05:07:29,119 [IPC Server handler 6 on 45602] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 6 on 45602, call Call#369 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:39716: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=READ, inode="/p11":root:supergroup:drwx------
2020-04-02 05:07:29,138 [IPC Server handler 8 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p11/child11	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:29,139 [IPC Server handler 7 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p11/child11	dst=null	perm=root:supergroup:rwx------	proto=rpc
2020-04-02 05:07:29,141 [IPC Server handler 5 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p11/child11	dst=null	perm=root:supergroup:rwx------	proto=rpc
2020-04-02 05:07:29,143 [IPC Server handler 4 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p11/child11	dst=null	perm=null	proto=rpc
2020-04-02 05:07:29,143 [IPC Server handler 4 on 45602] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 4 on 45602, call Call#373 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:39716: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=EXECUTE, inode="/p11":root:supergroup:drwx------
2020-04-02 05:07:29,144 [IPC Server handler 3 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p11	dst=null	perm=root:supergroup:rwx---r--	proto=rpc
2020-04-02 05:07:29,159 [IPC Server handler 1 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p11/child11	dst=null	perm=null	proto=rpc
2020-04-02 05:07:29,159 [IPC Server handler 1 on 45602] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 1 on 45602, call Call#375 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:39716: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=EXECUTE, inode="/p11":root:supergroup:drwx---r--
2020-04-02 05:07:29,168 [IPC Server handler 0 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p11	dst=null	perm=root:supergroup:rwx-----x	proto=rpc
2020-04-02 05:07:29,173 [IPC Server handler 2 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p11/child11	dst=null	perm=root:supergroup:rwx-----x	proto=rpc
2020-04-02 05:07:29,177 [IPC Server handler 9 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p11/child11	dst=null	perm=null	proto=rpc
2020-04-02 05:07:29,178 [IPC Server handler 9 on 45602] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 9 on 45602, call Call#378 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:39716: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=READ, inode="/p11/child11":root:supergroup:drwx-----x
2020-04-02 05:07:29,180 [IPC Server handler 6 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p11	dst=null	perm=root:supergroup:rwx-----x	proto=rpc
2020-04-02 05:07:29,181 [IPC Server handler 8 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p11/child11	dst=null	perm=root:supergroup:rwx---r--	proto=rpc
2020-04-02 05:07:29,183 [IPC Server handler 7 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p11/child11	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testGetXAttrs
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testGetXAttrs
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testRenameFileWithXAttr
[msx] perform reset as unitTestCounterInClass 11 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:29,189 [IPC Server handler 5 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p12	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:29,190 [IPC Server handler 4 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p12	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,192 [IPC Server handler 3 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p12	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,193 [IPC Server handler 1 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p12	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,194 [IPC Server handler 0 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/p12	dst=/p12-rename	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,195 [IPC Server handler 2 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p12-rename	dst=null	perm=null	proto=rpc
2020-04-02 05:07:29,196 [IPC Server handler 9 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p12-rename	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,197 [IPC Server handler 6 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p12-rename	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testRenameFileWithXAttr
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testRenameFileWithXAttr
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testSetXAttr
[msx] perform reset as unitTestCounterInClass 12 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:29,208 [IPC Server handler 8 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p13	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:29,218 [IPC Server handler 7 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p13	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,226 [IPC Server handler 5 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p13	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,227 [IPC Server handler 4 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p13	dst=null	perm=null	proto=rpc
2020-04-02 05:07:29,228 [IPC Server handler 3 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p13	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,229 [IPC Server handler 1 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p13	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,234 [IPC Server handler 0 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p13	dst=null	perm=null	proto=rpc
2020-04-02 05:07:29,238 [IPC Server handler 2 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p13	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,240 [IPC Server handler 9 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p13	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,241 [IPC Server handler 6 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p13	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,241 [IPC Server handler 8 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p13	dst=null	perm=null	proto=rpc
2020-04-02 05:07:29,242 [IPC Server handler 7 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p13	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,243 [IPC Server handler 5 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p13	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,244 [IPC Server handler 4 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p13	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,245 [IPC Server handler 3 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p13	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,246 [IPC Server handler 1 on 45602] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 1 on 45602, call Call#405 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:39704
java.io.IOException: Cannot add additional XAttr to inode, would exceed limit of 3
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setINodeXAttrs(FSDirXAttrOp.java:371)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedSetXAttrs(FSDirXAttrOp.java:272)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setXAttr(FSDirXAttrOp.java:85)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setXAttr(FSNamesystem.java:7714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setXAttr(NameNodeRpcServer.java:2170)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setXAttr(ClientNamenodeProtocolServerSideTranslatorPB.java:1615)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:07:29,247 [IPC Server handler 0 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p13	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,248 [IPC Server handler 2 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p13	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,248 [IPC Server handler 9 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p13	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:29,249 [IPC Server handler 6 on 45602] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 6 on 45602, call Call#409 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:39704: org.apache.hadoop.HadoopIllegalArgumentException: The XAttr is too big. The maximum combined size of the name and value is 37, but the total size is 50
2020-04-02 05:07:29,250 [IPC Server handler 8 on 45602] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 8 on 45602, call Call#410 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:39704: org.apache.hadoop.HadoopIllegalArgumentException: The XAttr is too big. The maximum combined size of the name and value is 37, but the total size is 38
2020-04-02 05:07:29,251 [IPC Server handler 7 on 45602] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p13	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testSetXAttr
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr#testSetXAttr
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:29,253 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:29,254 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:29,254 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 37121 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:29,254 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:29,255 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@32c7dc16] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:29,264 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c279d74e-a940-4499-a5d8-5b1f0136e6ae) exiting.
2020-04-02 05:07:29,265 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5437a82e-ddff-46c6-ad88-3ed31967d093) exiting.
2020-04-02 05:07:29,371 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1d9d16c6{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:29,372 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7e9899e0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:29,376 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@59891a7f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:29,382 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@32565191{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:29,421 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37121
2020-04-02 05:07:29,427 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:29,428 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:45602] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:29,428 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:45602] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741) service to localhost/127.0.0.1:45602
2020-04-02 05:07:29,428 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:45602] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-944730262-172.17.0.6-1585804031959 (Datanode Uuid a66a72ee-5beb-418a-8fdf-000c79d6d741)
2020-04-02 05:07:29,428 [BP-944730262-172.17.0.6-1585804031959 heartbeating to localhost/127.0.0.1:45602] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-944730262-172.17.0.6-1585804031959
2020-04-02 05:07:29,433 [IPC Server listener on 37121] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37121
2020-04-02 05:07:29,444 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-944730262-172.17.0.6-1585804031959] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:29,460 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:29,460 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:29,462 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:29,462 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:29,462 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:29,462 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:29,463 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 45602 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:29,463 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:29,465 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-944730262-172.17.0.6-1585804031959] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:29,469 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 202, 244
2020-04-02 05:07:29,471 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 44 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 201 Number of syncs: 45 SyncTimes(ms): 1 1 
2020-04-02 05:07:29,472 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@77ac7273] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:29,473 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000202 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000202-0000000000000000245
2020-04-02 05:07:29,473 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@76ec004b] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:29,476 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000202 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000202-0000000000000000245
2020-04-02 05:07:29,477 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:29,481 [CacheReplicationMonitor(671981132)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:29,493 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45602
2020-04-02 05:07:29,497 [IPC Server listener on 45602] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45602
2020-04-02 05:07:29,513 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:29,527 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:29,527 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:29,544 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:29,544 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:29,573 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2a74f13f{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:29,578 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5c297288{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:29,581 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3a05feb{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:29,584 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5042a7a8{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:29,589 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:29,593 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:29,593 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] all testRunFinished

[msx] before_class
2020-04-02 05:06:11,528 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=2
Formatting using clusterid: testClusterID
2020-04-02 05:06:12,592 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:12,619 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:12,622 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:12,623 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:12,632 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:06:12,633 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:12,633 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:12,634 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns0
2020-04-02 05:06:12,635 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:12,707 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:12,713 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:06:12,714 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:06:12,715 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:12,722 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:12,724 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:12
2020-04-02 05:06:12,728 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:12,729 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:12,732 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:12,732 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:12,758 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:06:12,772 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:12,772 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:12,773 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:06:12,773 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:12,778 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 2
2020-04-02 05:06:12,778 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:12,779 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:12,779 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:12,779 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:06:12,780 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:12,780 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:12,869 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:06:12,902 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:12,903 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:12,904 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:12,905 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:12,924 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:12,925 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:12,926 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:12,927 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:12,936 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:12,940 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:12,948 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:12,948 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:12,949 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:12,949 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:12,969 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:12,969 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:12,969 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:12,977 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:12,977 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:12,979 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:12,980 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:12,980 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:12,980 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:13,033 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-256847006-172.17.0.2-1585803973008
2020-04-02 05:06:13,062 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:06:13,069 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:06:13,085 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:13,090 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:13,286 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:06:13,286 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:06:13,305 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:06:13,310 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:06:13,534 [main] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:06:13,610 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:06:14,167 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:06:14,168 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:06:14,173 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:06:14,208 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-04-02 05:06:14,267 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@76b1e9b8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:14,282 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:06:14,302 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @4499ms
2020-04-02 05:06:14,411 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:14,420 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:06:14,433 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:14,436 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:06:14,437 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:14,437 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:14,498 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:06:14,498 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:06:14,510 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42085
2020-04-02 05:06:14,512 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:14,587 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@13df2a8c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:06:14,589 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@72d6b3ba{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:06:14,702 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6aa61224{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:06:14,711 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@39d9314d{HTTP/1.1,[http/1.1]}{localhost:42085}
2020-04-02 05:06:14,712 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4909ms
2020-04-02 05:06:14,782 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:14,783 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:14,783 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:14,783 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:14,783 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:06:14,784 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:14,784 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:14,784 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns0
2020-04-02 05:06:14,784 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:14,785 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:14,786 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:06:14,790 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:14,791 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:14,791 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:14
2020-04-02 05:06:14,791 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:14,792 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:14,792 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:06:14,792 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:14,802 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:06:14,803 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:14,804 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:14,805 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:06:14,805 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:14,805 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 2
2020-04-02 05:06:14,806 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:14,806 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:14,806 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:14,806 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:06:14,807 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:14,807 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:14,808 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:14,808 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:14,808 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:06:14,809 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:14,811 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:14,811 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:14,811 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:14,812 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:14,812 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:14,812 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:14,812 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:14,813 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:14,818 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:06:14,818 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:14,822 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:14,822 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:14,822 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:14,823 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:14,823 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:14,824 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:14,824 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:14,825 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:06:14,825 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:14,836 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 11154@6f69b628a45f
2020-04-02 05:06:14,841 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 11154@6f69b628a45f
2020-04-02 05:06:14,844 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current
2020-04-02 05:06:14,845 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current
2020-04-02 05:06:14,846 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:06:14,847 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:06:14,903 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:06:14,917 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:06:14,917 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:06:14,932 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:06:14,934 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:06:14,978 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:06:14,978 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 150 msecs
2020-04-02 05:06:15,186 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to 0.0.0.0:0
2020-04-02 05:06:15,196 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:15,218 [Socket Reader #1 for port 35264] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35264
2020-04-02 05:06:15,507 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:35264 to access this namenode/service.
2020-04-02 05:06:15,514 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:06:15,549 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:06:15,571 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:06:15,572 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:06:15,572 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:06:15,573 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:06:15,576 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:06:15,576 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:06:15,576 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:06:15,576 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:06:15,576 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:06:15,576 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-04-02 05:06:15,649 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:15,665 [IPC Server listener on 35264] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35264: starting
2020-04-02 05:06:15,690 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:35264
2020-04-02 05:06:15,693 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:06:15,701 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:06:15,708 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 6 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:06:15,736 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 35264 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:15,757 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:06:15,758 [CacheReplicationMonitor(1794970873)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:06:15,867 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:06:15,879 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:06:15,904 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:15,905 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:15,910 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:15,915 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:15,919 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:06:15,920 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:15,926 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:15,934 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34677
2020-04-02 05:06:15,937 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:15,937 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:16,003 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:16,008 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:16,019 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:16,020 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:16,021 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:16,021 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:16,025 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37438
2020-04-02 05:06:16,026 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:16,066 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@22b53226{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:06:16,072 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@726e5805{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:06:16,097 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@75f5fd58{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:16,099 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@37b70343{HTTP/1.1,[http/1.1]}{localhost:37438}
2020-04-02 05:06:16,100 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6297ms
2020-04-02 05:06:17,228 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37498
2020-04-02 05:06:17,244 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:17,244 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:17,230 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1d9bec4d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:17,273 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:17,284 [Socket Reader #1 for port 35120] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35120
2020-04-02 05:06:17,298 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:35120
2020-04-02 05:06:17,311 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0
2020-04-02 05:06:17,315 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0
2020-04-02 05:06:17,366 [Thread-58] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35264 starting to offer service
2020-04-02 05:06:17,407 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:17,407 [IPC Server listener on 35120] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35120: starting
2020-04-02 05:06:17,418 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 35120 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:17,420 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:06:17,437 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:06:17,442 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:06:17,444 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:17,445 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:17,445 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:17,445 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:17,470 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:06:17,470 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:17,471 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:17,472 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:45163
2020-04-02 05:06:17,472 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:17,472 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:17,518 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:17,520 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:17,523 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:17,525 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:17,526 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:17,526 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:17,527 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40687
2020-04-02 05:06:17,527 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:17,548 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3c9168dc{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:06:17,549 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@549621f3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:06:17,600 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6fefce9e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:17,602 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4f8969b0{HTTP/1.1,[http/1.1]}{localhost:40687}
2020-04-02 05:06:17,602 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7799ms
2020-04-02 05:06:17,813 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40328
2020-04-02 05:06:17,814 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:17,814 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@192f2f27] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:17,815 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:17,826 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:17,827 [Socket Reader #1 for port 38821] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38821
2020-04-02 05:06:17,842 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:38821
2020-04-02 05:06:17,857 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0
2020-04-02 05:06:17,863 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0
2020-04-02 05:06:17,866 [Thread-82] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35264 starting to offer service
2020-04-02 05:06:17,873 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:17,875 [IPC Server listener on 38821] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38821: starting
2020-04-02 05:06:17,876 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 38821 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:18,119 [Thread-58] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35264
2020-04-02 05:06:18,124 [Thread-82] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35264
2020-04-02 05:06:18,129 [Thread-58] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:18,129 [Thread-82] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:18,133 [Thread-58] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 11154@6f69b628a45f
2020-04-02 05:06:18,133 [Thread-82] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 11154@6f69b628a45f
2020-04-02 05:06:18,135 [Thread-58] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 is not formatted for namespace 2036642655. Formatting...
2020-04-02 05:06:18,135 [Thread-82] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 is not formatted for namespace 2036642655. Formatting...
2020-04-02 05:06:18,148 [Thread-58] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7f4a5447-ad06-498b-8f35-878d784733eb for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 
2020-04-02 05:06:18,148 [Thread-82] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-14c2a942-4d33-4f97-ae02-3acc0062bb9f for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 
2020-04-02 05:06:18,152 [Thread-58] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 11154@6f69b628a45f
2020-04-02 05:06:18,153 [Thread-58] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 is not formatted for namespace 2036642655. Formatting...
2020-04-02 05:06:18,154 [Thread-58] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bd17d644-c59f-4e78-90c5-824ff55df128 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 
2020-04-02 05:06:18,153 [Thread-82] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 11154@6f69b628a45f
2020-04-02 05:06:18,155 [Thread-82] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 is not formatted for namespace 2036642655. Formatting...
2020-04-02 05:06:18,155 [Thread-82] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-cf75e51a-4748-4fca-82ac-24ca8830ecc7 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 
2020-04-02 05:06:18,172 [Thread-58] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-256847006-172.17.0.2-1585803973008
2020-04-02 05:06:18,177 [Thread-58] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-256847006-172.17.0.2-1585803973008
2020-04-02 05:06:18,178 [Thread-58] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-256847006-172.17.0.2-1585803973008 is not formatted. Formatting ...
2020-04-02 05:06:18,179 [Thread-58] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-256847006-172.17.0.2-1585803973008 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-256847006-172.17.0.2-1585803973008/current
2020-04-02 05:06:18,180 [Thread-82] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-256847006-172.17.0.2-1585803973008
2020-04-02 05:06:18,180 [Thread-82] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-256847006-172.17.0.2-1585803973008
2020-04-02 05:06:18,206 [Thread-82] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-256847006-172.17.0.2-1585803973008 is not formatted. Formatting ...
2020-04-02 05:06:18,211 [Thread-82] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-256847006-172.17.0.2-1585803973008 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-256847006-172.17.0.2-1585803973008/current
2020-04-02 05:06:18,193 [Thread-58] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-256847006-172.17.0.2-1585803973008
2020-04-02 05:06:18,219 [Thread-58] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-256847006-172.17.0.2-1585803973008
2020-04-02 05:06:18,220 [Thread-58] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-256847006-172.17.0.2-1585803973008 is not formatted. Formatting ...
2020-04-02 05:06:18,220 [Thread-58] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-256847006-172.17.0.2-1585803973008 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-256847006-172.17.0.2-1585803973008/current
2020-04-02 05:06:18,226 [Thread-58] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=2036642655;bpid=BP-256847006-172.17.0.2-1585803973008;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=2036642655;c=1585803973009;bpid=BP-256847006-172.17.0.2-1585803973008;dnuuid=null
2020-04-02 05:06:18,228 [Thread-58] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 53b034eb-8ac1-453e-9e34-45120ef97ed1
2020-04-02 05:06:18,233 [Thread-82] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-256847006-172.17.0.2-1585803973008
2020-04-02 05:06:18,234 [Thread-82] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-256847006-172.17.0.2-1585803973008
2020-04-02 05:06:18,235 [Thread-82] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-256847006-172.17.0.2-1585803973008 is not formatted. Formatting ...
2020-04-02 05:06:18,235 [Thread-82] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-256847006-172.17.0.2-1585803973008 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-256847006-172.17.0.2-1585803973008/current
2020-04-02 05:06:18,237 [Thread-82] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=2036642655;bpid=BP-256847006-172.17.0.2-1585803973008;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=2036642655;c=1585803973009;bpid=BP-256847006-172.17.0.2-1585803973008;dnuuid=null
2020-04-02 05:06:18,239 [Thread-82] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 3e8b6e86-dd93-4ecf-9753-e4f4b083db49
2020-04-02 05:06:18,486 [Thread-58] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-7f4a5447-ad06-498b-8f35-878d784733eb
2020-04-02 05:06:18,486 [Thread-58] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:06:18,487 [Thread-82] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-14c2a942-4d33-4f97-ae02-3acc0062bb9f
2020-04-02 05:06:18,489 [Thread-82] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:06:18,496 [Thread-58] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-bd17d644-c59f-4e78-90c5-824ff55df128
2020-04-02 05:06:18,496 [Thread-58] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:06:18,497 [Thread-82] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-cf75e51a-4748-4fca-82ac-24ca8830ecc7
2020-04-02 05:06:18,498 [Thread-82] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:06:18,530 [Thread-58] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:18,534 [Thread-82] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:18,567 [Thread-58] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:06:18,547 [Thread-82] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:06:18,589 [Thread-82] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:06:18,590 [Thread-82] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:06:18,599 [Thread-82] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:06:18,599 [Thread-82] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-256847006-172.17.0.2-1585803973008
2020-04-02 05:06:18,607 [Thread-58] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:06:18,608 [Thread-58] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:06:18,614 [Thread-99] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-256847006-172.17.0.2-1585803973008 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-04-02 05:06:18,614 [Thread-100] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-256847006-172.17.0.2-1585803973008 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-04-02 05:06:18,614 [Thread-58] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:06:18,618 [Thread-58] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-256847006-172.17.0.2-1585803973008
2020-04-02 05:06:18,623 [Thread-102] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-256847006-172.17.0.2-1585803973008 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-04-02 05:06:18,633 [Thread-101] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-256847006-172.17.0.2-1585803973008 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-04-02 05:06:18,779 [IPC Server handler 6 on 35264] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:18,790 [Thread-99] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-256847006-172.17.0.2-1585803973008 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 175ms
2020-04-02 05:06:18,791 [Thread-102] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-256847006-172.17.0.2-1585803973008 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 167ms
2020-04-02 05:06:18,794 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:18,794 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:18,801 [Thread-101] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-256847006-172.17.0.2-1585803973008 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 168ms
2020-04-02 05:06:18,802 [Thread-58] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-256847006-172.17.0.2-1585803973008: 183ms
2020-04-02 05:06:18,805 [Thread-108] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-256847006-172.17.0.2-1585803973008 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-04-02 05:06:18,805 [Thread-108] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-256847006-172.17.0.2-1585803973008/current/replicas doesn't exist 
2020-04-02 05:06:18,806 [Thread-109] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-256847006-172.17.0.2-1585803973008 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-04-02 05:06:18,806 [Thread-109] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-256847006-172.17.0.2-1585803973008/current/replicas doesn't exist 
2020-04-02 05:06:18,812 [Thread-108] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-256847006-172.17.0.2-1585803973008 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 7ms
2020-04-02 05:06:18,817 [Thread-100] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-256847006-172.17.0.2-1585803973008 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 201ms
2020-04-02 05:06:18,834 [Thread-109] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-256847006-172.17.0.2-1585803973008 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 28ms
2020-04-02 05:06:18,835 [Thread-58] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-256847006-172.17.0.2-1585803973008: 31ms
2020-04-02 05:06:18,836 [Thread-82] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-256847006-172.17.0.2-1585803973008: 237ms
2020-04-02 05:06:18,837 [Thread-111] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-256847006-172.17.0.2-1585803973008 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-04-02 05:06:18,838 [Thread-111] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-256847006-172.17.0.2-1585803973008/current/replicas doesn't exist 
2020-04-02 05:06:18,838 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-256847006-172.17.0.2-1585803973008 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:06:18,838 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-256847006-172.17.0.2-1585803973008 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:06:18,859 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-7f4a5447-ad06-498b-8f35-878d784733eb): finished scanning block pool BP-256847006-172.17.0.2-1585803973008
2020-04-02 05:06:18,859 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-bd17d644-c59f-4e78-90c5-824ff55df128): finished scanning block pool BP-256847006-172.17.0.2-1585803973008
2020-04-02 05:06:18,854 [Thread-111] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-256847006-172.17.0.2-1585803973008 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 16ms
2020-04-02 05:06:18,853 [Thread-110] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-256847006-172.17.0.2-1585803973008 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-04-02 05:06:18,866 [Thread-110] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-256847006-172.17.0.2-1585803973008/current/replicas doesn't exist 
2020-04-02 05:06:18,908 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-bd17d644-c59f-4e78-90c5-824ff55df128): no suitable block pools found to scan.  Waiting 1814399930 ms.
2020-04-02 05:06:18,910 [Thread-110] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-256847006-172.17.0.2-1585803973008 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 44ms
2020-04-02 05:06:18,910 [Thread-82] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-256847006-172.17.0.2-1585803973008: 75ms
2020-04-02 05:06:18,911 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-256847006-172.17.0.2-1585803973008 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:06:18,912 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-14c2a942-4d33-4f97-ae02-3acc0062bb9f): finished scanning block pool BP-256847006-172.17.0.2-1585803973008
2020-04-02 05:06:18,912 [Thread-82] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:39 AM with interval of 21600000ms
2020-04-02 05:06:18,913 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-256847006-172.17.0.2-1585803973008 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:06:18,914 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-cf75e51a-4748-4fca-82ac-24ca8830ecc7): finished scanning block pool BP-256847006-172.17.0.2-1585803973008
2020-04-02 05:06:18,915 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-cf75e51a-4748-4fca-82ac-24ca8830ecc7): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:06:18,908 [IPC Server handler 9 on 35264] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:18,905 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-7f4a5447-ad06-498b-8f35-878d784733eb): no suitable block pools found to scan.  Waiting 1814399933 ms.
2020-04-02 05:06:18,902 [Thread-58] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:53 AM with interval of 21600000ms
2020-04-02 05:06:18,914 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-14c2a942-4d33-4f97-ae02-3acc0062bb9f): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:06:18,946 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:18,963 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:18,965 [BP-256847006-172.17.0.2-1585803973008 heartbeating to localhost/127.0.0.1:35264] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-256847006-172.17.0.2-1585803973008 (Datanode Uuid 3e8b6e86-dd93-4ecf-9753-e4f4b083db49) service to localhost/127.0.0.1:35264 beginning handshake with NN
2020-04-02 05:06:18,965 [BP-256847006-172.17.0.2-1585803973008 heartbeating to localhost/127.0.0.1:35264] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-256847006-172.17.0.2-1585803973008 (Datanode Uuid 53b034eb-8ac1-453e-9e34-45120ef97ed1) service to localhost/127.0.0.1:35264 beginning handshake with NN
2020-04-02 05:06:18,988 [IPC Server handler 5 on 35264] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45163, datanodeUuid=3e8b6e86-dd93-4ecf-9753-e4f4b083db49, infoPort=40328, infoSecurePort=0, ipcPort=38821, storageInfo=lv=-57;cid=testClusterID;nsid=2036642655;c=1585803973009) storage 3e8b6e86-dd93-4ecf-9753-e4f4b083db49
2020-04-02 05:06:18,991 [IPC Server handler 5 on 35264] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45163
2020-04-02 05:06:18,992 [IPC Server handler 5 on 35264] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3e8b6e86-dd93-4ecf-9753-e4f4b083db49 (127.0.0.1:45163).
2020-04-02 05:06:18,995 [IPC Server handler 4 on 35264] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34677, datanodeUuid=53b034eb-8ac1-453e-9e34-45120ef97ed1, infoPort=37498, infoSecurePort=0, ipcPort=35120, storageInfo=lv=-57;cid=testClusterID;nsid=2036642655;c=1585803973009) storage 53b034eb-8ac1-453e-9e34-45120ef97ed1
2020-04-02 05:06:18,995 [IPC Server handler 4 on 35264] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34677
2020-04-02 05:06:18,996 [IPC Server handler 4 on 35264] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 53b034eb-8ac1-453e-9e34-45120ef97ed1 (127.0.0.1:34677).
2020-04-02 05:06:19,005 [BP-256847006-172.17.0.2-1585803973008 heartbeating to localhost/127.0.0.1:35264] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-256847006-172.17.0.2-1585803973008 (Datanode Uuid 53b034eb-8ac1-453e-9e34-45120ef97ed1) service to localhost/127.0.0.1:35264 successfully registered with NN
2020-04-02 05:06:19,005 [BP-256847006-172.17.0.2-1585803973008 heartbeating to localhost/127.0.0.1:35264] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-256847006-172.17.0.2-1585803973008 (Datanode Uuid 3e8b6e86-dd93-4ecf-9753-e4f4b083db49) service to localhost/127.0.0.1:35264 successfully registered with NN
2020-04-02 05:06:19,005 [BP-256847006-172.17.0.2-1585803973008 heartbeating to localhost/127.0.0.1:35264] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35264 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:19,005 [BP-256847006-172.17.0.2-1585803973008 heartbeating to localhost/127.0.0.1:35264] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35264 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:19,042 [IPC Server handler 3 on 35264] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-14c2a942-4d33-4f97-ae02-3acc0062bb9f for DN 127.0.0.1:45163
2020-04-02 05:06:19,043 [IPC Server handler 3 on 35264] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-cf75e51a-4748-4fca-82ac-24ca8830ecc7 for DN 127.0.0.1:45163
2020-04-02 05:06:19,049 [IPC Server handler 2 on 35264] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7f4a5447-ad06-498b-8f35-878d784733eb for DN 127.0.0.1:34677
2020-04-02 05:06:19,050 [IPC Server handler 2 on 35264] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bd17d644-c59f-4e78-90c5-824ff55df128 for DN 127.0.0.1:34677
2020-04-02 05:06:19,068 [IPC Server handler 7 on 35264] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:19,076 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:19,084 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x51a505deb7d29c84: Processing first storage report for DS-bd17d644-c59f-4e78-90c5-824ff55df128 from datanode 53b034eb-8ac1-453e-9e34-45120ef97ed1
2020-04-02 05:06:19,101 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x51a505deb7d29c84: from storage DS-bd17d644-c59f-4e78-90c5-824ff55df128 node DatanodeRegistration(127.0.0.1:34677, datanodeUuid=53b034eb-8ac1-453e-9e34-45120ef97ed1, infoPort=37498, infoSecurePort=0, ipcPort=35120, storageInfo=lv=-57;cid=testClusterID;nsid=2036642655;c=1585803973009), blocks: 0, hasStaleStorage: true, processing time: 3 msecs, invalidatedBlocks: 0
2020-04-02 05:06:19,104 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x51a505deb7d29c84: Processing first storage report for DS-7f4a5447-ad06-498b-8f35-878d784733eb from datanode 53b034eb-8ac1-453e-9e34-45120ef97ed1
2020-04-02 05:06:19,104 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x51a505deb7d29c84: from storage DS-7f4a5447-ad06-498b-8f35-878d784733eb node DatanodeRegistration(127.0.0.1:34677, datanodeUuid=53b034eb-8ac1-453e-9e34-45120ef97ed1, infoPort=37498, infoSecurePort=0, ipcPort=35120, storageInfo=lv=-57;cid=testClusterID;nsid=2036642655;c=1585803973009), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:19,104 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x4c6e261e730e45e: Processing first storage report for DS-cf75e51a-4748-4fca-82ac-24ca8830ecc7 from datanode 3e8b6e86-dd93-4ecf-9753-e4f4b083db49
2020-04-02 05:06:19,105 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x4c6e261e730e45e: from storage DS-cf75e51a-4748-4fca-82ac-24ca8830ecc7 node DatanodeRegistration(127.0.0.1:45163, datanodeUuid=3e8b6e86-dd93-4ecf-9753-e4f4b083db49, infoPort=40328, infoSecurePort=0, ipcPort=38821, storageInfo=lv=-57;cid=testClusterID;nsid=2036642655;c=1585803973009), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:06:19,105 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x4c6e261e730e45e: Processing first storage report for DS-14c2a942-4d33-4f97-ae02-3acc0062bb9f from datanode 3e8b6e86-dd93-4ecf-9753-e4f4b083db49
2020-04-02 05:06:19,105 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x4c6e261e730e45e: from storage DS-14c2a942-4d33-4f97-ae02-3acc0062bb9f node DatanodeRegistration(127.0.0.1:45163, datanodeUuid=3e8b6e86-dd93-4ecf-9753-e4f4b083db49, infoPort=40328, infoSecurePort=0, ipcPort=38821, storageInfo=lv=-57;cid=testClusterID;nsid=2036642655;c=1585803973009), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:19,142 [IPC Server handler 6 on 35264] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:19,151 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:19,194 [BP-256847006-172.17.0.2-1585803973008 heartbeating to localhost/127.0.0.1:35264] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x51a505deb7d29c84,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 124 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:19,195 [BP-256847006-172.17.0.2-1585803973008 heartbeating to localhost/127.0.0.1:35264] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-256847006-172.17.0.2-1585803973008
2020-04-02 05:06:19,213 [main] INFO  resolver.MountTableResolver (MountTableResolver.java:initDefaultNameService(191)) - Default name service: ns0, enabled to read or write
2020-04-02 05:06:19,218 [BP-256847006-172.17.0.2-1585803973008 heartbeating to localhost/127.0.0.1:35264] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x4c6e261e730e45e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 153 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:19,218 [BP-256847006-172.17.0.2-1585803973008 heartbeating to localhost/127.0.0.1:35264] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-256847006-172.17.0.2-1585803973008
2020-04-02 05:06:19,218 [main] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(250)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-04-02 05:06:19,224 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:19,225 [Socket Reader #1 for port 35282] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35282
2020-04-02 05:06:19,240 [main] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-04-02 05:06:19,240 [main] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-04-02 05:06:19,252 [main] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-04-02 05:06:19,275 [main] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-04-02 05:06:19,275 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:19,282 [Socket Reader #1 for port 34155] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34155
2020-04-02 05:06:19,296 [main] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore
2020-04-02 05:06:19,297 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-04-02 05:06:19,300 [main] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC
2020-04-02 05:06:19,302 [main] WARN  impl.StateStoreFileImpl (StateStoreFileImpl.java:getRootDir(93)) - The root directory is not available, using /tmp/1585803979302-0
2020-04-02 05:06:19,303 [main] INFO  impl.StateStoreFileBaseImpl (StateStoreFileBaseImpl.java:initRecordStorage(181)) - /tmp/1585803979302-0/MembershipState data directory doesn't exist, creating it
2020-04-02 05:06:19,303 [main] INFO  impl.StateStoreFileBaseImpl (StateStoreFileBaseImpl.java:initRecordStorage(181)) - /tmp/1585803979302-0/DisabledNameservice data directory doesn't exist, creating it
2020-04-02 05:06:19,303 [main] INFO  impl.StateStoreFileBaseImpl (StateStoreFileBaseImpl.java:initRecordStorage(181)) - /tmp/1585803979302-0/MountTable data directory doesn't exist, creating it
2020-04-02 05:06:19,304 [main] INFO  impl.StateStoreFileBaseImpl (StateStoreFileBaseImpl.java:initRecordStorage(181)) - /tmp/1585803979302-0/RouterState data directory doesn't exist, creating it
2020-04-02 05:06:19,304 [main] INFO  store.StateStoreService (StateStoreService.java:loadDriver(275)) - Connection to the State Store driver StateStoreFileImpl is open and ready
2020-04-02 05:06:19,326 [main] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-04-02 05:06:19,328 [main] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-04-02 05:06:19,328 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:19,339 [IPC Server listener on 35282] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35282: starting
2020-04-02 05:06:19,358 [main] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(321)) - Router RPC up at: /0.0.0.0:35282
2020-04-02 05:06:19,359 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:19,359 [IPC Server listener on 34155] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34155: starting
2020-04-02 05:06:19,396 [main] INFO  impl.MembershipStoreImpl (MembershipStoreImpl.java:namenodeHeartbeat(176)) - Inserting new NN registration: 6f69b628a45f:35282->ns0:null:localhost:35264-ACTIVE
2020-04-02 05:06:19,431 [main] ERROR resolver.MembershipNamenodeResolver (MembershipNamenodeResolver.java:getNamenodesForNameserviceId(192)) - Cannot locate eligible NNs for ns0
2020-04-02 05:06:20,432 [main] ERROR resolver.MembershipNamenodeResolver (MembershipNamenodeResolver.java:getNamenodesForNameserviceId(192)) - Cannot locate eligible NNs for ns0
2020-04-02 05:06:21,433 [main] ERROR resolver.MembershipNamenodeResolver (MembershipNamenodeResolver.java:getNamenodesForNameserviceId(192)) - Cannot locate eligible NNs for ns0
2020-04-02 05:06:22,434 [main] ERROR resolver.MembershipNamenodeResolver (MembershipNamenodeResolver.java:getNamenodesForNameserviceId(192)) - Cannot locate eligible NNs for ns0
2020-04-02 05:06:23,435 [main] ERROR resolver.MembershipNamenodeResolver (MembershipNamenodeResolver.java:getNamenodesForNameserviceId(192)) - Cannot locate eligible NNs for ns0
2020-04-02 05:06:24,436 [main] INFO  federation.MiniRouterDFSCluster (MiniRouterDFSCluster.java:getClient(249)) - Connecting to router at hdfs://0.0.0.0:35282
[msx] test Started org.apache.hadoop.hdfs.server.federation.router.TestRouterMountTable#testListFilesTime
[msx] unitTestCounterInClass = 0
2020-04-02 05:06:24,461 [main] INFO  federation.MiniRouterDFSCluster (MiniRouterDFSCluster.java:getAdminClient(237)) - Connecting to router admin at /0.0.0.0:34155
2020-04-02 05:06:24,499 [main] INFO  resolver.MountTableResolver (MountTableResolver.java:refreshEntries(332)) - Added new mount point /testdir to resolver
2020-04-02 05:06:24,505 [main] INFO  resolver.MountTableResolver (MountTableResolver.java:refreshEntries(332)) - Added new mount point /testdir2 to resolver
2020-04-02 05:06:24,515 [main] INFO  resolver.MountTableResolver (MountTableResolver.java:refreshEntries(332)) - Added new mount point /testdir/subdir to resolver
2020-04-02 05:06:24,520 [main] INFO  resolver.MountTableResolver (MountTableResolver.java:refreshEntries(332)) - Added new mount point /testdir3/subdir1 to resolver
2020-04-02 05:06:24,529 [main] INFO  resolver.MountTableResolver (MountTableResolver.java:refreshEntries(332)) - Added new mount point /testA/testB/testC/testD to resolver
2020-04-02 05:06:24,557 [IPC Server handler 9 on 35264] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/newdir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:06:24,600 [IPC Server handler 4 on 35264] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:06:24,674 [IPC Server handler 5 on 35264] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.federation.router.TestRouterMountTable#testListFilesTime
[msx] writeFile testName = org.apache.hadoop.hdfs.server.federation.router.TestRouterMountTable#testListFilesTime
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.federation.router.TestRouterMountTable#testReadOnly
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:06:24,691 [main] INFO  resolver.MountTableResolver (MountTableResolver.java:refreshEntries(332)) - Added new mount point /readonly to resolver
2020-04-02 05:06:24,698 [main] INFO  resolver.MountTableResolver (MountTableResolver.java:refreshEntries(332)) - Added new mount point /regular to resolver
2020-04-02 05:06:24,714 [IPC Server handler 2 on 35264] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/testdir/newdir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:06:24,728 [IPC Server handler 3 on 35264] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/testdir/newdir	dst=null	perm=null	proto=rpc
2020-04-02 05:06:24,739 [IPC Server handler 7 on 35264] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/testdir/newdir	dst=null	perm=null	proto=rpc
2020-04-02 05:06:24,754 [IPC Server handler 0 on 35264] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/testdir/newdir	dst=null	perm=null	proto=rpc
2020-04-02 05:06:24,758 [IPC Server handler 4 on 35282] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 4 on 35282, call Call#32 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 172.17.0.2:52770: java.io.IOException: /readonly/newdirfail is in a read only mount point
[msx] test Finished org.apache.hadoop.hdfs.server.federation.router.TestRouterMountTable#testReadOnly
[msx] writeFile testName = org.apache.hadoop.hdfs.server.federation.router.TestRouterMountTable#testReadOnly
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:06:24,790 [Thread-138] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34155
2020-04-02 05:06:24,791 [IPC Server listener on 34155] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34155
2020-04-02 05:06:24,802 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:24,810 [Thread-138] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35282
2020-04-02 05:06:24,812 [IPC Server listener on 35282] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35282
2020-04-02 05:06:24,816 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:24,832 [Thread-138] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-04-02 05:06:24,833 [Thread-138] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-04-02 05:06:24,834 [Thread-138] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-04-02 05:06:24,834 [Thread-138] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-04-02 05:06:25,766 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:06:25,766 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:06:25,766 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 38821 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:25,767 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:25,767 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@15a902e7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:25,769 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-14c2a942-4d33-4f97-ae02-3acc0062bb9f) exiting.
2020-04-02 05:06:25,769 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-cf75e51a-4748-4fca-82ac-24ca8830ecc7) exiting.
2020-04-02 05:06:25,857 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6fefce9e{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:25,863 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4f8969b0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:25,864 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@549621f3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:25,870 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3c9168dc{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:06:25,873 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38821
2020-04-02 05:06:25,875 [IPC Server listener on 38821] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38821
2020-04-02 05:06:25,875 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:25,883 [BP-256847006-172.17.0.2-1585803973008 heartbeating to localhost/127.0.0.1:35264] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:25,884 [BP-256847006-172.17.0.2-1585803973008 heartbeating to localhost/127.0.0.1:35264] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-256847006-172.17.0.2-1585803973008 (Datanode Uuid 3e8b6e86-dd93-4ecf-9753-e4f4b083db49) service to localhost/127.0.0.1:35264
2020-04-02 05:06:25,884 [BP-256847006-172.17.0.2-1585803973008 heartbeating to localhost/127.0.0.1:35264] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-256847006-172.17.0.2-1585803973008 (Datanode Uuid 3e8b6e86-dd93-4ecf-9753-e4f4b083db49)
2020-04-02 05:06:25,884 [BP-256847006-172.17.0.2-1585803973008 heartbeating to localhost/127.0.0.1:35264] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-256847006-172.17.0.2-1585803973008
2020-04-02 05:06:25,895 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-256847006-172.17.0.2-1585803973008] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:25,904 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-256847006-172.17.0.2-1585803973008] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:25,907 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:25,907 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:25,908 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:25,908 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:25,915 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:25,916 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:06:25,916 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 35120 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:25,916 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:25,916 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@183e8023] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:25,923 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-bd17d644-c59f-4e78-90c5-824ff55df128) exiting.
2020-04-02 05:06:25,923 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-7f4a5447-ad06-498b-8f35-878d784733eb) exiting.
2020-04-02 05:06:26,009 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@75f5fd58{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:26,010 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@37b70343{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:26,011 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@726e5805{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:26,011 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@22b53226{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:06:26,014 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35120
2020-04-02 05:06:26,020 [IPC Server listener on 35120] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35120
2020-04-02 05:06:26,020 [BP-256847006-172.17.0.2-1585803973008 heartbeating to localhost/127.0.0.1:35264] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:26,020 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:26,022 [BP-256847006-172.17.0.2-1585803973008 heartbeating to localhost/127.0.0.1:35264] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-256847006-172.17.0.2-1585803973008 (Datanode Uuid 53b034eb-8ac1-453e-9e34-45120ef97ed1) service to localhost/127.0.0.1:35264
2020-04-02 05:06:26,023 [BP-256847006-172.17.0.2-1585803973008 heartbeating to localhost/127.0.0.1:35264] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-256847006-172.17.0.2-1585803973008 (Datanode Uuid 53b034eb-8ac1-453e-9e34-45120ef97ed1)
2020-04-02 05:06:26,024 [BP-256847006-172.17.0.2-1585803973008 heartbeating to localhost/127.0.0.1:35264] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-256847006-172.17.0.2-1585803973008
2020-04-02 05:06:26,034 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-256847006-172.17.0.2-1585803973008] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:26,051 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-256847006-172.17.0.2-1585803973008] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:26,111 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:26,111 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:26,112 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:26,112 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:26,114 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:06:26,118 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:06:26,118 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:06:26,119 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:26,119 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:06:26,119 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 35264 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:26,119 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:26,120 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5c8504fd] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:06:26,122 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 4
2020-04-02 05:06:26,122 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4b7e96a] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:06:26,125 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 5 Total time for transactions(ms): 31 Number of transactions batched in Syncs: 1 Number of syncs: 5 SyncTimes(ms): 2 2 
2020-04-02 05:06:26,128 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000005
2020-04-02 05:06:26,129 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000005
2020-04-02 05:06:26,133 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:06:26,136 [CacheReplicationMonitor(1794970873)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:06:26,138 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35264
2020-04-02 05:06:26,138 [IPC Server listener on 35264] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35264
2020-04-02 05:06:26,151 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:26,152 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:06:26,152 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:06:26,195 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:26,195 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:06:26,202 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6aa61224{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:06:26,315 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@39d9314d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:26,316 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@72d6b3ba{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:26,316 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@13df2a8c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
[msx] all testRunFinished

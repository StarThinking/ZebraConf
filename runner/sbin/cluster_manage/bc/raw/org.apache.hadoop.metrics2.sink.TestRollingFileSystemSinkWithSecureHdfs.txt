[msx] before_class
2020-04-02 05:09:53,414 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(225)) - Configuration:
2020-04-02 05:09:53,419 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(226)) - ---------------------------------------------------------------
2020-04-02 05:09:53,421 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   debug: false
2020-04-02 05:09:53,421 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   transport: TCP
2020-04-02 05:09:53,421 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   max.ticket.lifetime: 86400000
2020-04-02 05:09:53,422 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   org.name: EXAMPLE
2020-04-02 05:09:53,422 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   kdc.port: 0
2020-04-02 05:09:53,422 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   org.domain: COM
2020-04-02 05:09:53,423 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   max.renewable.lifetime: 604800000
2020-04-02 05:09:53,423 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   instance: DefaultKrbServer
2020-04-02 05:09:53,423 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   kdc.bind.address: localhost
2020-04-02 05:09:53,423 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(230)) - ---------------------------------------------------------------
2020-04-02 05:09:53,568 [main] INFO  minikdc.MiniKdc (MiniKdc.java:start(285)) - MiniKdc started.
[msx] test Started org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithSecureHdfs#testMissingPropertiesWithSecureHDFS
[msx] unitTestCounterInClass = 0
2020-04-02 05:09:54,416 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=4
Formatting using clusterid: testClusterID
2020-04-02 05:09:54,988 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:09:55,004 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:09:55,009 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:09:55,011 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:09:55,020 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:09:55,020 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:09:55,021 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:09:55,022 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:09:55,089 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:55,097 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:09:55,097 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:09:55,098 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:09:55,102 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:09:55,103 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:09:55
2020-04-02 05:09:55,105 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:09:55,106 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:55,108 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:09:55,108 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:09:55,130 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:09:55,130 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:09:55,151 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:09:55,152 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:09:55,152 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:09:55,152 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:09:55,153 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:09:55,153 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:09:55,153 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:09:55,153 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:09:55,154 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:09:55,154 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:09:55,154 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:09:55,178 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:09:55,190 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:09:55,191 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:55,191 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:09:55,192 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:09:55,198 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:09:55,198 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:09:55,198 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:09:55,199 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:09:55,204 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:09:55,206 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:09:55,211 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:09:55,212 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:55,212 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:09:55,212 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:09:55,223 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:09:55,223 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:09:55,223 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:09:55,227 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:09:55,227 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:09:55,229 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:09:55,230 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:55,232 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:09:55,232 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:09:55,615 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:55,634 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:09:55,643 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:09:55,653 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:09:55,654 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:09:55,789 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:09:55,789 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:09:55,809 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:09:55,814 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:09:55,957 [main] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:09:56,015 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:09:56,110 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:09:56,110 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:09:56,116 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:09:56,138 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:09:56,240 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585804196196,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:09:56,254 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RollingFileSystemSinkTest/hdfs.keytab
2020-04-02 05:09:56,291 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6aa8e115] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:56,310 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:09:56,312 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:0
2020-04-02 05:09:56,318 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:56,346 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3776ms
2020-04-02 05:09:56,445 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:56,449 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:09:56,449 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:56,456 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:56,458 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:09:56,459 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:56,459 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:56,505 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:09:56,506 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:09:56,510 [main] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:09:56,512 [main] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:09:56,517 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40359
2020-04-02 05:09:56,520 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:56,575 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6cc558c6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:56,576 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@63f259c3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:56,620 [main] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RollingFileSystemSinkTest/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:09:56,631 [main] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RollingFileSystemSinkTest/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:09:56,640 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1a6c1270{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:09:56,652 [main] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@3a12c404(server,h=[],w=[]) for SslContextFactory@1941a8ff(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RollingFileSystemSinkTest/testMissingPropertiesWithSecureHDFS/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RollingFileSystemSinkTest/testMissingPropertiesWithSecureHDFS/trustKS.jks)
2020-04-02 05:09:56,663 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@33fe57a9{SSL,[ssl, http/1.1]}{localhost:40359}
2020-04-02 05:09:56,664 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4094ms
2020-04-02 05:09:56,677 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:09:56,678 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:09:56,678 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:09:56,678 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:09:56,678 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:09:56,678 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:09:56,679 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:09:56,679 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:09:56,680 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:56,680 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:09:56,680 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:09:56,681 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:09:56,682 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:09:56
2020-04-02 05:09:56,682 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:09:56,682 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:56,682 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:09:56,682 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:09:56,690 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:09:56,690 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:09:56,691 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:09:56,691 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:09:56,692 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:09:56,692 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:09:56,692 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:09:56,692 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:09:56,692 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:09:56,692 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:09:56,692 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:09:56,693 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:09:56,693 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:09:56,693 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:09:56,693 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:56,694 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:09:56,694 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:09:56,697 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:09:56,697 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:09:56,698 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:09:56,698 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:09:56,698 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:09:56,698 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:09:56,699 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:09:56,699 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:56,699 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:09:56,699 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:09:56,700 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:09:56,701 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:09:56,701 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:09:56,701 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:09:56,701 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:09:56,702 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:09:56,702 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:56,702 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:09:56,702 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:09:56,708 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 14459@1b26ddd29aee
2020-04-02 05:09:56,711 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 14459@1b26ddd29aee
2020-04-02 05:09:56,713 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:09:56,714 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:09:56,715 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:09:56,715 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:09:56,749 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:09:56,761 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:09:56,761 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:09:56,767 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:09:56,768 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:09:56,811 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:09:56,812 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 107 msecs
2020-04-02 05:09:57,033 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:09:57,050 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:57,067 [Socket Reader #1 for port 41908] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41908
2020-04-02 05:09:57,662 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:41908 to access this namenode/service.
2020-04-02 05:09:57,668 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:09:57,685 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:09:57,694 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@253d9f73] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:09:57,698 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:09:57,698 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:09:57,699 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:09:57,699 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:09:57,703 [main] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:09:57,707 [Thread[Thread-30,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:09:57,707 [Thread[Thread-30,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:09:57,709 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:09:57,709 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:09:57,709 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:09:57,709 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:09:57,709 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:09:57,709 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 11 msec
2020-04-02 05:09:57,754 [IPC Server listener on 41908] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41908: starting
2020-04-02 05:09:57,754 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:57,757 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:41908
2020-04-02 05:09:57,760 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:09:57,761 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:09:57,765 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 3 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:09:57,769 [CacheReplicationMonitor(938440271)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:09:57,769 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 41908 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:57,780 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:57,803 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585804197798,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:09:57,809 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RollingFileSystemSinkTest/hdfs.keytab
2020-04-02 05:09:57,880 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:57,897 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:57,905 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:57,906 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:57,910 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:57,914 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:57,918 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:57,919 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:57,926 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:57,934 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:33308
2020-04-02 05:09:57,937 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:57,937 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:57,956 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:57,958 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:57,959 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:57,960 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:57,962 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:57,963 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:57,963 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:57,964 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:57,968 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37088
2020-04-02 05:09:57,969 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:57,973 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@674c583e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:57,974 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3f23a3a0{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:57,982 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@ce5a68e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:57,983 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@9d157ff{HTTP/1.1,[http/1.1]}{localhost:37088}
2020-04-02 05:09:57,986 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5416ms
2020-04-02 05:09:58,392 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:35800
2020-04-02 05:09:58,394 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@38875e7d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:58,394 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:09:58,395 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:58,415 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:58,417 [Socket Reader #1 for port 44199] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44199
2020-04-02 05:09:58,439 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:44199
2020-04-02 05:09:58,455 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:58,459 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:58,470 [Thread-62] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41908 starting to offer service
2020-04-02 05:09:58,477 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:58,477 [IPC Server listener on 44199] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44199: starting
2020-04-02 05:09:58,479 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 44199 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:58,482 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:58,517 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585804198515,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:09:58,542 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RollingFileSystemSinkTest/hdfs.keytab
2020-04-02 05:09:58,543 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:09:58,545 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:58,548 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:58,549 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:58,553 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:58,553 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:58,554 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:58,554 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:58,556 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:58,557 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:44410
2020-04-02 05:09:58,558 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:58,558 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:58,560 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:58,566 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:58,569 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:58,569 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:58,571 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:58,582 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:58,583 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:58,583 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:58,584 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46645
2020-04-02 05:09:58,585 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:58,587 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@22db8f4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:58,588 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1d572e62{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:58,595 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@58a55449{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:58,596 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5949eba8{HTTP/1.1,[http/1.1]}{localhost:46645}
2020-04-02 05:09:58,596 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6026ms
2020-04-02 05:09:58,716 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:38686
2020-04-02 05:09:58,722 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:09:58,722 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:58,723 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:58,724 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2a2bb0eb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:58,725 [Socket Reader #1 for port 45818] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45818
2020-04-02 05:09:58,730 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:45818
2020-04-02 05:09:58,743 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:58,747 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:58,748 [Thread-87] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41908 starting to offer service
2020-04-02 05:09:58,752 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:58,752 [IPC Server listener on 45818] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45818: starting
2020-04-02 05:09:58,798 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 45818 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:58,799 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:09:58,818 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585804198816,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:09:58,821 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804198819,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:09:58,822 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RollingFileSystemSinkTest/hdfs.keytab
2020-04-02 05:09:58,823 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:09:58,823 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:09:58,830 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:58,833 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:58,833 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:58,833 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:58,834 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:58,834 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:58,835 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:58,836 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42543
2020-04-02 05:09:58,836 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:58,836 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:58,837 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:58,841 [pool-1-thread-3] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804198837,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:09:58,850 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:58,851 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:58,851 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:58,853 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:58,854 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:58,854 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:58,854 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:58,855 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35902
2020-04-02 05:09:58,855 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:58,857 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@182b435b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:58,858 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2fa7ae9{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:58,869 [Socket Reader #1 for port 41908] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:09:58,882 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2c22a348{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:58,883 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7bd69e82{HTTP/1.1,[http/1.1]}{localhost:35902}
2020-04-02 05:09:58,890 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6313ms
2020-04-02 05:09:58,892 [Socket Reader #1 for port 41908] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:09:58,929 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:43758
2020-04-02 05:09:58,930 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:09:58,930 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6831d8fd] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:58,930 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:58,930 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:58,931 [Socket Reader #1 for port 33668] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33668
2020-04-02 05:09:58,942 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:33668
2020-04-02 05:09:58,950 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:58,951 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:58,952 [Thread-111] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41908 starting to offer service
2020-04-02 05:09:58,958 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:58,962 [IPC Server listener on 33668] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33668: starting
2020-04-02 05:09:58,982 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 33668 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:58,983 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:09:59,014 [pool-1-thread-3] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585804199013,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:09:59,019 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RollingFileSystemSinkTest/hdfs.keytab
2020-04-02 05:09:59,028 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:09:59,030 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:09:59,065 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:59,066 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:59,066 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:59,067 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:59,071 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:59,071 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:59,071 [pool-1-thread-3] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804199070,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:09:59,074 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:59,075 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:32870
2020-04-02 05:09:59,075 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:59,075 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:59,078 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:59,080 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:59,081 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:59,081 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:59,085 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:59,086 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:59,086 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:59,086 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:59,088 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38196
2020-04-02 05:09:59,088 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:59,090 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@36dce7ed{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:59,091 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@33d05366{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:59,094 [Socket Reader #1 for port 41908] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:09:59,115 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@50b0bc4c{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:59,116 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@c20be82{HTTP/1.1,[http/1.1]}{localhost:38196}
2020-04-02 05:09:59,116 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6546ms
2020-04-02 05:09:59,244 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:40563
2020-04-02 05:09:59,244 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:09:59,245 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6b739528] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:59,245 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:59,245 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:59,246 [Socket Reader #1 for port 40664] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40664
2020-04-02 05:09:59,252 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40664
2020-04-02 05:09:59,257 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:59,258 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:59,259 [Thread-135] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41908 starting to offer service
2020-04-02 05:09:59,267 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:59,267 [IPC Server listener on 40664] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40664: starting
2020-04-02 05:09:59,270 [Thread-111] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41908
2020-04-02 05:09:59,270 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40664 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:59,276 [Thread-87] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41908
2020-04-02 05:09:59,277 [Thread-62] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41908
2020-04-02 05:09:59,284 [Thread-62] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:59,284 [Thread-111] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:59,286 [Thread-111] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 14459@1b26ddd29aee
2020-04-02 05:09:59,286 [Thread-62] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 14459@1b26ddd29aee
2020-04-02 05:09:59,286 [Thread-62] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1138388237. Formatting...
2020-04-02 05:09:59,286 [Thread-111] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1138388237. Formatting...
2020-04-02 05:09:59,290 [Thread-87] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:59,291 [Thread-62] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-384b983b-1323-45ce-9ae0-8d9487d7981b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:09:59,291 [Thread-111] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2b9ea28c-01e5-4fc2-8e94-2b6524b78956 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:09:59,291 [Thread-87] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 14459@1b26ddd29aee
2020-04-02 05:09:59,292 [Thread-87] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1138388237. Formatting...
2020-04-02 05:09:59,292 [Thread-87] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9b647956-d2b5-4e96-bb04-e7c5eda4d090 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:09:59,295 [Thread-111] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 14459@1b26ddd29aee
2020-04-02 05:09:59,295 [Thread-111] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1138388237. Formatting...
2020-04-02 05:09:59,295 [Thread-111] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3fd4e804-063f-4401-b136-9f7a8fda0cc2 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:09:59,298 [Thread-87] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 14459@1b26ddd29aee
2020-04-02 05:09:59,299 [Thread-87] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1138388237. Formatting...
2020-04-02 05:09:59,299 [Thread-87] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9afbae47-44fa-4e9a-afc9-71943ea78274 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:09:59,299 [Thread-62] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 14459@1b26ddd29aee
2020-04-02 05:09:59,299 [Thread-62] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1138388237. Formatting...
2020-04-02 05:09:59,300 [Thread-62] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b713497f-77e1-4980-a4fe-a29d374efa1f for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:09:59,355 [Thread-111] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,355 [Thread-111] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,356 [Thread-111] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1577367851-172.17.0.17-1585804195605 is not formatted. Formatting ...
2020-04-02 05:09:59,356 [Thread-111] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1577367851-172.17.0.17-1585804195605 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1577367851-172.17.0.17-1585804195605/current
2020-04-02 05:09:59,364 [pool-1-thread-3] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804199363,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:09:59,367 [Thread-87] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,367 [Thread-62] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,367 [Thread-87] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,368 [Thread-62] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,368 [Thread-87] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1577367851-172.17.0.17-1585804195605 is not formatted. Formatting ...
2020-04-02 05:09:59,368 [Thread-87] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1577367851-172.17.0.17-1585804195605 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1577367851-172.17.0.17-1585804195605/current
2020-04-02 05:09:59,368 [Thread-62] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1577367851-172.17.0.17-1585804195605 is not formatted. Formatting ...
2020-04-02 05:09:59,368 [Thread-62] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1577367851-172.17.0.17-1585804195605 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1577367851-172.17.0.17-1585804195605/current
2020-04-02 05:09:59,382 [Thread-111] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,382 [Thread-111] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,383 [Thread-111] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1577367851-172.17.0.17-1585804195605 is not formatted. Formatting ...
2020-04-02 05:09:59,383 [Thread-111] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1577367851-172.17.0.17-1585804195605 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1577367851-172.17.0.17-1585804195605/current
2020-04-02 05:09:59,382 [Socket Reader #1 for port 41908] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:09:59,393 [Thread-111] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1138388237;bpid=BP-1577367851-172.17.0.17-1585804195605;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1138388237;c=1585804195605;bpid=BP-1577367851-172.17.0.17-1585804195605;dnuuid=null
2020-04-02 05:09:59,396 [Thread-135] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41908
2020-04-02 05:09:59,397 [Thread-135] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:59,413 [Thread-135] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 14459@1b26ddd29aee
2020-04-02 05:09:59,413 [Thread-135] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1138388237. Formatting...
2020-04-02 05:09:59,414 [Thread-135] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2d6e42c6-4bb0-4a19-a5eb-169917cde185 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-04-02 05:09:59,414 [Thread-62] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,415 [Thread-111] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 98eef423-e3cd-466c-a485-cf70c2be9d91
2020-04-02 05:09:59,415 [Thread-87] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,415 [Thread-62] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,416 [Thread-62] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1577367851-172.17.0.17-1585804195605 is not formatted. Formatting ...
2020-04-02 05:09:59,416 [Thread-62] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1577367851-172.17.0.17-1585804195605 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1577367851-172.17.0.17-1585804195605/current
2020-04-02 05:09:59,416 [Thread-87] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,416 [Thread-87] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1577367851-172.17.0.17-1585804195605 is not formatted. Formatting ...
2020-04-02 05:09:59,416 [Thread-87] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1577367851-172.17.0.17-1585804195605 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1577367851-172.17.0.17-1585804195605/current
2020-04-02 05:09:59,418 [Thread-62] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1138388237;bpid=BP-1577367851-172.17.0.17-1585804195605;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1138388237;c=1585804195605;bpid=BP-1577367851-172.17.0.17-1585804195605;dnuuid=null
2020-04-02 05:09:59,419 [Thread-62] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID f14efb11-d1a0-47c2-a553-31b1d7502c09
2020-04-02 05:09:59,420 [Thread-87] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1138388237;bpid=BP-1577367851-172.17.0.17-1585804195605;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1138388237;c=1585804195605;bpid=BP-1577367851-172.17.0.17-1585804195605;dnuuid=null
2020-04-02 05:09:59,421 [Thread-87] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 3c5deece-3b52-48c3-bb0a-ae24222dfffa
2020-04-02 05:09:59,425 [Thread-135] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 14459@1b26ddd29aee
2020-04-02 05:09:59,426 [Thread-135] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1138388237. Formatting...
2020-04-02 05:09:59,426 [Thread-135] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2dee20dd-5d8f-4d69-9b57-181ba4562df2 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-04-02 05:09:59,439 [Thread-135] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,440 [Thread-135] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,440 [Thread-135] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1577367851-172.17.0.17-1585804195605 is not formatted. Formatting ...
2020-04-02 05:09:59,440 [Thread-135] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1577367851-172.17.0.17-1585804195605 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1577367851-172.17.0.17-1585804195605/current
2020-04-02 05:09:59,466 [Thread-135] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,466 [Thread-135] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,467 [Thread-135] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1577367851-172.17.0.17-1585804195605 is not formatted. Formatting ...
2020-04-02 05:09:59,467 [Thread-135] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1577367851-172.17.0.17-1585804195605 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1577367851-172.17.0.17-1585804195605/current
2020-04-02 05:09:59,469 [Thread-135] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1138388237;bpid=BP-1577367851-172.17.0.17-1585804195605;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1138388237;c=1585804195605;bpid=BP-1577367851-172.17.0.17-1585804195605;dnuuid=null
2020-04-02 05:09:59,476 [Thread-135] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID dc565fe1-7310-43c6-b8f4-a42a32477e4c
2020-04-02 05:09:59,560 [Thread-62] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-384b983b-1323-45ce-9ae0-8d9487d7981b
2020-04-02 05:09:59,561 [Thread-62] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:09:59,566 [Thread-62] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-b713497f-77e1-4980-a4fe-a29d374efa1f
2020-04-02 05:09:59,567 [Thread-62] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:09:59,560 [Thread-135] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-2d6e42c6-4bb0-4a19-a5eb-169917cde185
2020-04-02 05:09:59,562 [Thread-87] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-9b647956-d2b5-4e96-bb04-e7c5eda4d090
2020-04-02 05:09:59,580 [Thread-135] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:09:59,561 [Thread-111] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-2b9ea28c-01e5-4fc2-8e94-2b6524b78956
2020-04-02 05:09:59,580 [Thread-87] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:09:59,582 [Thread-111] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:09:59,582 [Thread-62] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:59,582 [Thread-135] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-2dee20dd-5d8f-4d69-9b57-181ba4562df2
2020-04-02 05:09:59,583 [Thread-135] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:09:59,584 [Thread-135] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:59,584 [Thread-87] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-9afbae47-44fa-4e9a-afc9-71943ea78274
2020-04-02 05:09:59,584 [Thread-87] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:09:59,587 [Thread-87] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:59,589 [Thread-62] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:59,591 [Thread-111] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-3fd4e804-063f-4401-b136-9f7a8fda0cc2
2020-04-02 05:09:59,592 [Thread-111] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:09:59,593 [Thread-111] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:59,593 [Thread-87] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:09:59,595 [Thread-135] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:09:59,596 [Thread-111] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:09:59,603 [Thread-62] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:59,606 [Thread-62] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:59,605 [Thread-135] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:09:59,605 [Thread-87] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:09:59,610 [Thread-87] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:59,614 [Thread-62] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:59,614 [Thread-62] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,618 [Thread-111] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:09:59,618 [Thread-111] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:09:59,618 [Thread-155] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:09:59,618 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:09:59,622 [Thread-87] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:59,622 [Thread-87] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,622 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:09:59,628 [Thread-111] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:09:59,628 [Thread-135] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:09:59,628 [Thread-158] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:09:59,628 [Thread-135] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:09:59,649 [Thread-135] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,649 [Thread-111] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,654 [Thread-159] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:09:59,654 [Thread-160] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:09:59,655 [Thread-162] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:09:59,654 [Thread-161] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:09:59,740 [Thread-160] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1577367851-172.17.0.17-1585804195605 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 84ms
2020-04-02 05:09:59,756 [Thread-158] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1577367851-172.17.0.17-1585804195605 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 119ms
2020-04-02 05:09:59,756 [Thread-161] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1577367851-172.17.0.17-1585804195605 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 100ms
2020-04-02 05:09:59,759 [Thread-162] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1577367851-172.17.0.17-1585804195605 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 103ms
2020-04-02 05:09:59,760 [Thread-111] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1577367851-172.17.0.17-1585804195605: 106ms
2020-04-02 05:09:59,763 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:09:59,763 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:09:59,763 [Thread-171] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1577367851-172.17.0.17-1585804195605/current/replicas doesn't exist 
2020-04-02 05:09:59,763 [Thread-172] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1577367851-172.17.0.17-1585804195605/current/replicas doesn't exist 
2020-04-02 05:09:59,790 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 27ms
2020-04-02 05:09:59,811 [Thread-159] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1577367851-172.17.0.17-1585804195605 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 157ms
2020-04-02 05:09:59,812 [Thread-135] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1577367851-172.17.0.17-1585804195605: 163ms
2020-04-02 05:09:59,812 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 49ms
2020-04-02 05:09:59,812 [Thread-111] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1577367851-172.17.0.17-1585804195605: 49ms
2020-04-02 05:09:59,813 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1577367851-172.17.0.17-1585804195605 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 195ms
2020-04-02 05:09:59,814 [Thread-174] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:09:59,822 [Thread-174] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1577367851-172.17.0.17-1585804195605/current/replicas doesn't exist 
2020-04-02 05:09:59,822 [Thread-174] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 0ms
2020-04-02 05:09:59,831 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1577367851-172.17.0.17-1585804195605 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 208ms
2020-04-02 05:09:59,836 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:09:59,847 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-2b9ea28c-01e5-4fc2-8e94-2b6524b78956): finished scanning block pool BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,836 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:09:59,850 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-3fd4e804-063f-4401-b136-9f7a8fda0cc2): finished scanning block pool BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,832 [Thread-173] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:09:59,858 [Thread-173] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1577367851-172.17.0.17-1585804195605/current/replicas doesn't exist 
2020-04-02 05:09:59,854 [Thread-111] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:35 AM with interval of 21600000ms
2020-04-02 05:09:59,859 [Thread-173] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 1ms
2020-04-02 05:09:59,859 [Thread-135] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1577367851-172.17.0.17-1585804195605: 47ms
2020-04-02 05:09:59,859 [Thread-155] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1577367851-172.17.0.17-1585804195605 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 242ms
2020-04-02 05:09:59,859 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:09:59,859 [Thread-135] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:45 AM with interval of 21600000ms
2020-04-02 05:09:59,873 [Thread-62] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1577367851-172.17.0.17-1585804195605: 259ms
2020-04-02 05:09:59,874 [Thread-181] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:09:59,874 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:09:59,874 [Thread-181] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1577367851-172.17.0.17-1585804195605/current/replicas doesn't exist 
2020-04-02 05:09:59,874 [Thread-87] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1577367851-172.17.0.17-1585804195605: 252ms
2020-04-02 05:09:59,874 [Thread-182] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1577367851-172.17.0.17-1585804195605/current/replicas doesn't exist 
2020-04-02 05:09:59,875 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-2d6e42c6-4bb0-4a19-a5eb-169917cde185): finished scanning block pool BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,875 [Thread-181] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:09:59,875 [Thread-183] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:09:59,875 [Thread-183] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1577367851-172.17.0.17-1585804195605/current/replicas doesn't exist 
2020-04-02 05:09:59,880 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:09:59,880 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-2dee20dd-5d8f-4d69-9b57-181ba4562df2): finished scanning block pool BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,881 [Thread-184] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:09:59,881 [Thread-184] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1577367851-172.17.0.17-1585804195605/current/replicas doesn't exist 
2020-04-02 05:09:59,883 [Thread-183] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 8ms
2020-04-02 05:09:59,888 [Thread-184] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 7ms
2020-04-02 05:09:59,888 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 14ms
2020-04-02 05:09:59,888 [Thread-87] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1577367851-172.17.0.17-1585804195605: 14ms
2020-04-02 05:09:59,889 [Thread-62] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1577367851-172.17.0.17-1585804195605: 15ms
2020-04-02 05:09:59,889 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:09:59,889 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:59,889 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1577367851-172.17.0.17-1585804195605 (Datanode Uuid dc565fe1-7310-43c6-b8f4-a42a32477e4c) service to localhost/127.0.0.1:41908 beginning handshake with NN
2020-04-02 05:09:59,889 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-9b647956-d2b5-4e96-bb04-e7c5eda4d090): finished scanning block pool BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,890 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-384b983b-1323-45ce-9ae0-8d9487d7981b): finished scanning block pool BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,891 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:59,891 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-b713497f-77e1-4980-a4fe-a29d374efa1f): finished scanning block pool BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,892 [Thread-62] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:42 AM with interval of 21600000ms
2020-04-02 05:09:59,889 [Thread-87] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:44 AM with interval of 21600000ms
2020-04-02 05:09:59,900 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1577367851-172.17.0.17-1585804195605 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:59,894 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1577367851-172.17.0.17-1585804195605 (Datanode Uuid f14efb11-d1a0-47c2-a553-31b1d7502c09) service to localhost/127.0.0.1:41908 beginning handshake with NN
2020-04-02 05:09:59,890 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1577367851-172.17.0.17-1585804195605 (Datanode Uuid 98eef423-e3cd-466c-a485-cf70c2be9d91) service to localhost/127.0.0.1:41908 beginning handshake with NN
2020-04-02 05:09:59,908 [IPC Server handler 6 on 41908] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:32870, datanodeUuid=dc565fe1-7310-43c6-b8f4-a42a32477e4c, infoPort=0, infoSecurePort=40563, ipcPort=40664, storageInfo=lv=-57;cid=testClusterID;nsid=1138388237;c=1585804195605) storage dc565fe1-7310-43c6-b8f4-a42a32477e4c
2020-04-02 05:09:59,902 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1577367851-172.17.0.17-1585804195605 (Datanode Uuid 3c5deece-3b52-48c3-bb0a-ae24222dfffa) service to localhost/127.0.0.1:41908 beginning handshake with NN
2020-04-02 05:09:59,941 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-9afbae47-44fa-4e9a-afc9-71943ea78274): finished scanning block pool BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:09:59,943 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-384b983b-1323-45ce-9ae0-8d9487d7981b): no suitable block pools found to scan.  Waiting 1814399946 ms.
2020-04-02 05:09:59,943 [IPC Server handler 6 on 41908] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32870
2020-04-02 05:09:59,943 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-9b647956-d2b5-4e96-bb04-e7c5eda4d090): no suitable block pools found to scan.  Waiting 1814399946 ms.
2020-04-02 05:09:59,943 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-b713497f-77e1-4980-a4fe-a29d374efa1f): no suitable block pools found to scan.  Waiting 1814399947 ms.
2020-04-02 05:09:59,943 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-9afbae47-44fa-4e9a-afc9-71943ea78274): no suitable block pools found to scan.  Waiting 1814399946 ms.
2020-04-02 05:09:59,943 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-3fd4e804-063f-4401-b136-9f7a8fda0cc2): no suitable block pools found to scan.  Waiting 1814399892 ms.
2020-04-02 05:09:59,943 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-2dee20dd-5d8f-4d69-9b57-181ba4562df2): no suitable block pools found to scan.  Waiting 1814399916 ms.
2020-04-02 05:09:59,944 [IPC Server handler 6 on 41908] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN dc565fe1-7310-43c6-b8f4-a42a32477e4c (127.0.0.1:32870).
2020-04-02 05:09:59,944 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-2d6e42c6-4bb0-4a19-a5eb-169917cde185): no suitable block pools found to scan.  Waiting 1814399915 ms.
2020-04-02 05:09:59,949 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-2b9ea28c-01e5-4fc2-8e94-2b6524b78956): no suitable block pools found to scan.  Waiting 1814399886 ms.
2020-04-02 05:09:59,951 [IPC Server handler 1 on 41908] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33308, datanodeUuid=f14efb11-d1a0-47c2-a553-31b1d7502c09, infoPort=0, infoSecurePort=35800, ipcPort=44199, storageInfo=lv=-57;cid=testClusterID;nsid=1138388237;c=1585804195605) storage f14efb11-d1a0-47c2-a553-31b1d7502c09
2020-04-02 05:09:59,952 [IPC Server handler 1 on 41908] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33308
2020-04-02 05:09:59,953 [IPC Server handler 1 on 41908] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f14efb11-d1a0-47c2-a553-31b1d7502c09 (127.0.0.1:33308).
2020-04-02 05:09:59,953 [IPC Server handler 5 on 41908] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44410, datanodeUuid=3c5deece-3b52-48c3-bb0a-ae24222dfffa, infoPort=0, infoSecurePort=38686, ipcPort=45818, storageInfo=lv=-57;cid=testClusterID;nsid=1138388237;c=1585804195605) storage 3c5deece-3b52-48c3-bb0a-ae24222dfffa
2020-04-02 05:09:59,954 [IPC Server handler 5 on 41908] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44410
2020-04-02 05:09:59,954 [IPC Server handler 5 on 41908] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3c5deece-3b52-48c3-bb0a-ae24222dfffa (127.0.0.1:44410).
2020-04-02 05:09:59,954 [IPC Server handler 3 on 41908] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42543, datanodeUuid=98eef423-e3cd-466c-a485-cf70c2be9d91, infoPort=0, infoSecurePort=43758, ipcPort=33668, storageInfo=lv=-57;cid=testClusterID;nsid=1138388237;c=1585804195605) storage 98eef423-e3cd-466c-a485-cf70c2be9d91
2020-04-02 05:09:59,955 [IPC Server handler 3 on 41908] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42543
2020-04-02 05:09:59,955 [IPC Server handler 3 on 41908] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 98eef423-e3cd-466c-a485-cf70c2be9d91 (127.0.0.1:42543).
2020-04-02 05:09:59,956 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1577367851-172.17.0.17-1585804195605 (Datanode Uuid 3c5deece-3b52-48c3-bb0a-ae24222dfffa) service to localhost/127.0.0.1:41908 successfully registered with NN
2020-04-02 05:09:59,956 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1577367851-172.17.0.17-1585804195605 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:09:59,956 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:09:59,956 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41908 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:59,957 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1577367851-172.17.0.17-1585804195605 (Datanode Uuid dc565fe1-7310-43c6-b8f4-a42a32477e4c) service to localhost/127.0.0.1:41908 successfully registered with NN
2020-04-02 05:09:59,957 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1577367851-172.17.0.17-1585804195605 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:09:59,957 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:09:59,957 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41908 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:59,957 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1577367851-172.17.0.17-1585804195605 (Datanode Uuid 98eef423-e3cd-466c-a485-cf70c2be9d91) service to localhost/127.0.0.1:41908 successfully registered with NN
2020-04-02 05:09:59,957 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1577367851-172.17.0.17-1585804195605 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:09:59,957 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1577367851-172.17.0.17-1585804195605 (Datanode Uuid f14efb11-d1a0-47c2-a553-31b1d7502c09) service to localhost/127.0.0.1:41908 successfully registered with NN
2020-04-02 05:09:59,957 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:09:59,957 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1577367851-172.17.0.17-1585804195605 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:09:59,960 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:09:59,960 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41908 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:59,958 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41908 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:00,007 [IPC Server handler 8 on 41908] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-384b983b-1323-45ce-9ae0-8d9487d7981b for DN 127.0.0.1:33308
2020-04-02 05:10:00,008 [IPC Server handler 8 on 41908] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b713497f-77e1-4980-a4fe-a29d374efa1f for DN 127.0.0.1:33308
2020-04-02 05:10:00,010 [IPC Server handler 0 on 41908] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9b647956-d2b5-4e96-bb04-e7c5eda4d090 for DN 127.0.0.1:44410
2020-04-02 05:10:00,011 [IPC Server handler 0 on 41908] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9afbae47-44fa-4e9a-afc9-71943ea78274 for DN 127.0.0.1:44410
2020-04-02 05:10:00,014 [IPC Server handler 2 on 41908] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2b9ea28c-01e5-4fc2-8e94-2b6524b78956 for DN 127.0.0.1:42543
2020-04-02 05:10:00,014 [IPC Server handler 2 on 41908] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3fd4e804-063f-4401-b136-9f7a8fda0cc2 for DN 127.0.0.1:42543
2020-04-02 05:10:00,015 [IPC Server handler 4 on 41908] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2d6e42c6-4bb0-4a19-a5eb-169917cde185 for DN 127.0.0.1:32870
2020-04-02 05:10:00,017 [IPC Server handler 4 on 41908] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2dee20dd-5d8f-4d69-9b57-181ba4562df2 for DN 127.0.0.1:32870
2020-04-02 05:10:00,052 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc1a8eac041f30c80: Processing first storage report for DS-2d6e42c6-4bb0-4a19-a5eb-169917cde185 from datanode dc565fe1-7310-43c6-b8f4-a42a32477e4c
2020-04-02 05:10:00,054 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc1a8eac041f30c80: from storage DS-2d6e42c6-4bb0-4a19-a5eb-169917cde185 node DatanodeRegistration(127.0.0.1:32870, datanodeUuid=dc565fe1-7310-43c6-b8f4-a42a32477e4c, infoPort=0, infoSecurePort=40563, ipcPort=40664, storageInfo=lv=-57;cid=testClusterID;nsid=1138388237;c=1585804195605), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:10:00,054 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc1a8eac041f30c80: Processing first storage report for DS-2dee20dd-5d8f-4d69-9b57-181ba4562df2 from datanode dc565fe1-7310-43c6-b8f4-a42a32477e4c
2020-04-02 05:10:00,055 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc1a8eac041f30c80: from storage DS-2dee20dd-5d8f-4d69-9b57-181ba4562df2 node DatanodeRegistration(127.0.0.1:32870, datanodeUuid=dc565fe1-7310-43c6-b8f4-a42a32477e4c, infoPort=0, infoSecurePort=40563, ipcPort=40664, storageInfo=lv=-57;cid=testClusterID;nsid=1138388237;c=1585804195605), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:00,057 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5dd195fd1d4bf0c4: Processing first storage report for DS-9afbae47-44fa-4e9a-afc9-71943ea78274 from datanode 3c5deece-3b52-48c3-bb0a-ae24222dfffa
2020-04-02 05:10:00,057 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5dd195fd1d4bf0c4: from storage DS-9afbae47-44fa-4e9a-afc9-71943ea78274 node DatanodeRegistration(127.0.0.1:44410, datanodeUuid=3c5deece-3b52-48c3-bb0a-ae24222dfffa, infoPort=0, infoSecurePort=38686, ipcPort=45818, storageInfo=lv=-57;cid=testClusterID;nsid=1138388237;c=1585804195605), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:00,057 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5dd195fd1d4bf0c4: Processing first storage report for DS-9b647956-d2b5-4e96-bb04-e7c5eda4d090 from datanode 3c5deece-3b52-48c3-bb0a-ae24222dfffa
2020-04-02 05:10:00,057 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5dd195fd1d4bf0c4: from storage DS-9b647956-d2b5-4e96-bb04-e7c5eda4d090 node DatanodeRegistration(127.0.0.1:44410, datanodeUuid=3c5deece-3b52-48c3-bb0a-ae24222dfffa, infoPort=0, infoSecurePort=38686, ipcPort=45818, storageInfo=lv=-57;cid=testClusterID;nsid=1138388237;c=1585804195605), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:00,065 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x78426fd5afbb40b3: Processing first storage report for DS-3fd4e804-063f-4401-b136-9f7a8fda0cc2 from datanode 98eef423-e3cd-466c-a485-cf70c2be9d91
2020-04-02 05:10:00,065 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x78426fd5afbb40b3: from storage DS-3fd4e804-063f-4401-b136-9f7a8fda0cc2 node DatanodeRegistration(127.0.0.1:42543, datanodeUuid=98eef423-e3cd-466c-a485-cf70c2be9d91, infoPort=0, infoSecurePort=43758, ipcPort=33668, storageInfo=lv=-57;cid=testClusterID;nsid=1138388237;c=1585804195605), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:00,065 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa5d3f6b9304baba4: Processing first storage report for DS-384b983b-1323-45ce-9ae0-8d9487d7981b from datanode f14efb11-d1a0-47c2-a553-31b1d7502c09
2020-04-02 05:10:00,065 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa5d3f6b9304baba4: from storage DS-384b983b-1323-45ce-9ae0-8d9487d7981b node DatanodeRegistration(127.0.0.1:33308, datanodeUuid=f14efb11-d1a0-47c2-a553-31b1d7502c09, infoPort=0, infoSecurePort=35800, ipcPort=44199, storageInfo=lv=-57;cid=testClusterID;nsid=1138388237;c=1585804195605), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:00,065 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x78426fd5afbb40b3: Processing first storage report for DS-2b9ea28c-01e5-4fc2-8e94-2b6524b78956 from datanode 98eef423-e3cd-466c-a485-cf70c2be9d91
2020-04-02 05:10:00,065 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x78426fd5afbb40b3: from storage DS-2b9ea28c-01e5-4fc2-8e94-2b6524b78956 node DatanodeRegistration(127.0.0.1:42543, datanodeUuid=98eef423-e3cd-466c-a485-cf70c2be9d91, infoPort=0, infoSecurePort=43758, ipcPort=33668, storageInfo=lv=-57;cid=testClusterID;nsid=1138388237;c=1585804195605), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:00,066 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa5d3f6b9304baba4: Processing first storage report for DS-b713497f-77e1-4980-a4fe-a29d374efa1f from datanode f14efb11-d1a0-47c2-a553-31b1d7502c09
2020-04-02 05:10:00,066 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa5d3f6b9304baba4: from storage DS-b713497f-77e1-4980-a4fe-a29d374efa1f node DatanodeRegistration(127.0.0.1:33308, datanodeUuid=f14efb11-d1a0-47c2-a553-31b1d7502c09, infoPort=0, infoSecurePort=35800, ipcPort=44199, storageInfo=lv=-57;cid=testClusterID;nsid=1138388237;c=1585804195605), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:00,072 [Socket Reader #1 for port 41908] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:10:00,090 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x5dd195fd1d4bf0c4,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 9 msec to generate and 50 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:00,090 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:10:00,090 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xc1a8eac041f30c80,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 50 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:00,098 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:10:00,090 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x78426fd5afbb40b3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 47 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:00,097 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xa5d3f6b9304baba4,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 52 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:00,098 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:10:00,099 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:10:00,158 [IPC Server handler 3 on 41908] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:10:00,172 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:10:00,184 [IPC Server handler 5 on 41908] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:10:00,186 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:10:00,194 [pool-1-thread-3] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585804200193,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:10:00,245 [pool-1-thread-3] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804200244,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:10:00,258 [Socket Reader #1 for port 41908] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:10:00,298 [IPC Server handler 4 on 41908] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp	dst=null	perm=hdfs:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:10:00,312 [IPC Server handler 2 on 41908] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=setPermission	src=/tmp	dst=null	perm=hdfs:supergroup:rwxrwxrwx	proto=rpc
2020-04-02 05:10:00,320 [pool-1-thread-3] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585804200319,sink/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:10:00,351 [pool-1-thread-3] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804200351,sink/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:10:00,364 [Socket Reader #1 for port 41908] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for sink/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:10:00,369 [IPC Server handler 0 on 41908] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=sink/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/test	dst=null	perm=sink:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:10:00,384 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2-testmissingpropertieswithsecurehdfs.properties
2020-04-02 05:10:00,397 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:configureSinks(508)) - Error creating sink 'mysink0'
org.apache.hadoop.metrics2.impl.MetricsConfigException: Error creating plugin: org.apache.hadoop.metrics2.sink.RollingFileSystemSinkTestBase$MockSink
	at org.apache.hadoop.metrics2.impl.MetricsConfig.getPlugin(MetricsConfig.java:211)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.newSink(MetricsSystemImpl.java:531)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configureSinks(MetricsSystemImpl.java:503)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:479)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.sink.RollingFileSystemSinkTestBase.initMetricsSystem(RollingFileSystemSinkTestBase.java:197)
	at org.apache.hadoop.metrics2.sink.RollingFileSystemSinkTestBase.initMetricsSystem(RollingFileSystemSinkTestBase.java:160)
	at org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithSecureHdfs.testMissingPropertiesWithSecureHDFS(TestRollingFileSystemSinkWithSecureHdfs.java:177)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: org.apache.hadoop.metrics2.MetricsException: org.apache.hadoop.metrics2.MetricsException: Metrics2 configuration is missing keytab-key property
	at org.apache.hadoop.metrics2.sink.RollingFileSystemSinkTestBase$MockSink.init(RollingFileSystemSinkTestBase.java:524)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.getPlugin(MetricsConfig.java:208)
	... 38 more
Caused by: org.apache.hadoop.metrics2.MetricsException: Metrics2 configuration is missing keytab-key property
	at org.apache.hadoop.metrics2.sink.RollingFileSystemSink.checkIfPropertyExists(RollingFileSystemSink.java:426)
	at org.apache.hadoop.metrics2.sink.RollingFileSystemSink.init(RollingFileSystemSink.java:251)
	at org.apache.hadoop.metrics2.sink.RollingFileSystemSinkTestBase$MockSink.init(RollingFileSystemSinkTestBase.java:520)
	... 39 more
2020-04-02 05:10:00,401 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10000 second(s).
2020-04-02 05:10:00,402 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - testmissingpropertieswithsecurehdfs metrics system started
2020-04-02 05:10:00,402 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:10:00,402 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 3
2020-04-02 05:10:00,402 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40664 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:00,403 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:00,405 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3301500b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:00,409 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-2dee20dd-5d8f-4d69-9b57-181ba4562df2) exiting.
2020-04-02 05:10:00,409 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-2d6e42c6-4bb0-4a19-a5eb-169917cde185) exiting.
2020-04-02 05:10:00,637 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@50b0bc4c{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:00,641 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@c20be82{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:00,641 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@33d05366{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:00,642 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@36dce7ed{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:00,647 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40664
2020-04-02 05:10:00,706 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:00,709 [IPC Server listener on 40664] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40664
2020-04-02 05:10:00,710 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:00,710 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1577367851-172.17.0.17-1585804195605 (Datanode Uuid dc565fe1-7310-43c6-b8f4-a42a32477e4c) service to localhost/127.0.0.1:41908
2020-04-02 05:10:00,711 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1577367851-172.17.0.17-1585804195605 (Datanode Uuid dc565fe1-7310-43c6-b8f4-a42a32477e4c)
2020-04-02 05:10:00,712 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:10:00,734 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1577367851-172.17.0.17-1585804195605] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:00,754 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1577367851-172.17.0.17-1585804195605] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:00,759 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:00,759 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:00,760 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:00,760 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:00,767 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:00,767 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:10:00,768 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33668 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:00,768 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:00,768 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7bdf6bb7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:00,771 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-3fd4e804-063f-4401-b136-9f7a8fda0cc2) exiting.
2020-04-02 05:10:00,771 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-2b9ea28c-01e5-4fc2-8e94-2b6524b78956) exiting.
2020-04-02 05:10:00,798 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2c22a348{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:00,800 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7bd69e82{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:00,800 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2fa7ae9{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:00,801 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@182b435b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:00,803 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33668
2020-04-02 05:10:00,845 [IPC Server listener on 33668] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33668
2020-04-02 05:10:00,846 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:00,850 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:00,859 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1577367851-172.17.0.17-1585804195605 (Datanode Uuid 98eef423-e3cd-466c-a485-cf70c2be9d91) service to localhost/127.0.0.1:41908
2020-04-02 05:10:00,859 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1577367851-172.17.0.17-1585804195605 (Datanode Uuid 98eef423-e3cd-466c-a485-cf70c2be9d91)
2020-04-02 05:10:00,859 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:10:00,868 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1577367851-172.17.0.17-1585804195605] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:00,881 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1577367851-172.17.0.17-1585804195605] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:00,889 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:00,894 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:00,895 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:00,896 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:00,900 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:00,900 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:10:00,900 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 45818 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:00,900 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:00,900 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@ecf9fb3] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:00,904 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-9afbae47-44fa-4e9a-afc9-71943ea78274) exiting.
2020-04-02 05:10:00,905 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-9b647956-d2b5-4e96-bb04-e7c5eda4d090) exiting.
2020-04-02 05:10:00,939 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@58a55449{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:00,940 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5949eba8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:00,941 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1d572e62{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:00,941 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@22db8f4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:00,981 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45818
2020-04-02 05:10:00,984 [IPC Server listener on 45818] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45818
2020-04-02 05:10:00,986 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:00,986 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:00,986 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1577367851-172.17.0.17-1585804195605 (Datanode Uuid 3c5deece-3b52-48c3-bb0a-ae24222dfffa) service to localhost/127.0.0.1:41908
2020-04-02 05:10:00,987 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1577367851-172.17.0.17-1585804195605 (Datanode Uuid 3c5deece-3b52-48c3-bb0a-ae24222dfffa)
2020-04-02 05:10:00,987 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:10:01,001 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1577367851-172.17.0.17-1585804195605] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:01,010 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1577367851-172.17.0.17-1585804195605] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:01,019 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:01,019 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:01,021 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:01,021 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:01,025 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:01,025 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:10:01,025 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 44199 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:01,026 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:01,026 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2cf23c81] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:01,029 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-384b983b-1323-45ce-9ae0-8d9487d7981b) exiting.
2020-04-02 05:10:01,029 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-b713497f-77e1-4980-a4fe-a29d374efa1f) exiting.
2020-04-02 05:10:01,068 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@ce5a68e{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:01,069 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@9d157ff{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:01,070 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3f23a3a0{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:01,070 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@674c583e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:01,072 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44199
2020-04-02 05:10:01,086 [IPC Server listener on 44199] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44199
2020-04-02 05:10:01,086 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:01,086 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:01,089 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1577367851-172.17.0.17-1585804195605 (Datanode Uuid f14efb11-d1a0-47c2-a553-31b1d7502c09) service to localhost/127.0.0.1:41908
2020-04-02 05:10:01,191 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1577367851-172.17.0.17-1585804195605 (Datanode Uuid f14efb11-d1a0-47c2-a553-31b1d7502c09)
2020-04-02 05:10:01,191 [BP-1577367851-172.17.0.17-1585804195605 heartbeating to localhost/127.0.0.1:41908] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1577367851-172.17.0.17-1585804195605
2020-04-02 05:10:01,212 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1577367851-172.17.0.17-1585804195605] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:01,220 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1577367851-172.17.0.17-1585804195605] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:01,240 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:01,240 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:01,243 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:01,243 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:01,249 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:01,249 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:10:01,249 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 41908 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:01,249 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:10:01,250 [Thread[Thread-30,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:10:01,254 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 6
2020-04-02 05:10:01,254 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@24fb6a80] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:10:01,260 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@7c7d3c46] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:10:01,262 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 7 Total time for transactions(ms): 23 Number of transactions batched in Syncs: 0 Number of syncs: 8 SyncTimes(ms): 1 1 
2020-04-02 05:10:01,264 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000007
2020-04-02 05:10:01,265 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000007
2020-04-02 05:10:01,267 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:10:01,271 [CacheReplicationMonitor(938440271)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:10:01,304 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41908
2020-04-02 05:10:01,306 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:10:01,316 [IPC Server listener on 41908] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41908
2020-04-02 05:10:01,321 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:10:01,322 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:01,364 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:10:01,365 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:10:01,367 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1a6c1270{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:10:01,378 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@33fe57a9{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:10:01,378 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@63f259c3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:01,379 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6cc558c6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:01,382 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:10:01,393 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:10:01,394 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithSecureHdfs#testMissingPropertiesWithSecureHDFS
[msx] writeFile testName = org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithSecureHdfs#testMissingPropertiesWithSecureHDFS
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithSecureHdfs#testWithSecureHDFS
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:10:01,486 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=4
Formatting using clusterid: testClusterID
2020-04-02 05:10:01,488 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:10:01,488 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:10:01,489 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:10:01,489 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:10:01,489 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:10:01,489 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:10:01,489 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:10:01,489 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:10:01,490 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:01,490 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:10:01,490 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:10:01,490 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:10:01,491 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:10:01
2020-04-02 05:10:01,491 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:10:01,491 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:01,491 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:10:01,491 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:10:01,498 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:10:01,498 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:10:01,499 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:10:01,499 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:10:01,499 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:10:01,499 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:10:01,500 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:10:01,500 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:10:01,500 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:10:01,500 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:10:01,500 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:10:01,500 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:10:01,500 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:10:01,501 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:10:01,501 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:01,501 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:10:01,502 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:10:01,504 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:10:01,504 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:10:01,504 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:10:01,505 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:10:01,505 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:10:01,505 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:10:01,506 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:10:01,506 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:01,506 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:10:01,506 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:10:01,507 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:10:01,507 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:10:01,508 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:10:01,508 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:10:01,508 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:10:01,508 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:10:01,508 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:01,509 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:10:01,509 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:10:01,510 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:01,513 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:10:01,515 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:10:01,525 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:10:01,527 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:10:01,537 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 409 bytes saved in 0 seconds .
2020-04-02 05:10:01,537 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 409 bytes saved in 0 seconds .
2020-04-02 05:10:01,544 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:10:01,545 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:10:01,559 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:10:01,561 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:10:01,561 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:10:01,562 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:10:01,563 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:10:01,569 [pool-1-thread-3] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585804201568,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:10:01,574 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RollingFileSystemSinkTest/hdfs.keytab
2020-04-02 05:10:01,586 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@a68df9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:01,586 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:10:01,587 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:0
2020-04-02 05:10:01,587 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:01,589 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:01,590 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:10:01,590 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:01,592 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:01,593 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:10:01,593 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:01,593 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:01,596 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:10:01,597 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:10:01,597 [main] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:10:01,597 [main] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:10:01,598 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33484
2020-04-02 05:10:01,598 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:01,600 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@169da7f2{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:01,601 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@ceb4bd2{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:01,611 [main] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RollingFileSystemSinkTest/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:10:01,612 [main] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RollingFileSystemSinkTest/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:10:01,613 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2f19f2aa{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:10:01,616 [main] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@344b8190(server,h=[],w=[]) for SslContextFactory@6a078481(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RollingFileSystemSinkTest/testWithSecureHDFS/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RollingFileSystemSinkTest/testWithSecureHDFS/trustKS.jks)
2020-04-02 05:10:01,618 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@79c5636f{SSL,[ssl, http/1.1]}{localhost:33484}
2020-04-02 05:10:01,618 [main] INFO  server.Server (Server.java:doStart(419)) - Started @9048ms
2020-04-02 05:10:01,623 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:10:01,623 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:10:01,623 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:10:01,624 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:10:01,624 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:10:01,624 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:10:01,624 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:10:01,624 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:10:01,625 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:01,625 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:10:01,626 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:10:01,626 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:10:01,626 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:10:01
2020-04-02 05:10:01,627 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:10:01,627 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:01,627 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:10:01,627 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:10:01,639 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:10:01,641 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:10:01,643 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:10:01,643 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:10:01,643 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:10:01,644 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:10:01,644 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:10:01,644 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:10:01,644 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:10:01,644 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:10:01,644 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:10:01,645 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:10:01,645 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:10:01,648 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:10:01,648 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:01,649 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:10:01,649 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:10:01,651 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:10:01,651 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:10:01,651 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:10:01,652 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:10:01,652 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:10:01,652 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:10:01,653 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:10:01,653 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:01,653 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:10:01,653 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:10:01,656 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:10:01,656 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:10:01,656 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:10:01,657 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:10:01,657 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:10:01,657 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:10:01,657 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:10:01,658 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:10:01,658 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:10:01,663 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 14459@1b26ddd29aee
2020-04-02 05:10:01,664 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 14459@1b26ddd29aee
2020-04-02 05:10:01,667 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:10:01,667 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:10:01,668 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:10:01,668 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:10:01,670 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:10:01,673 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:10:01,673 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:10:01,673 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:10:01,674 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:10:01,714 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:10:01,714 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 53 msecs
2020-04-02 05:10:01,715 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:10:01,715 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:01,716 [Socket Reader #1 for port 35190] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35190
2020-04-02 05:10:01,722 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:35190 to access this namenode/service.
2020-04-02 05:10:01,723 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:10:01,789 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:10:01,794 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:10:01,794 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@2617f816] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:10:01,794 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:10:01,801 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:10:01,802 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:10:01,804 [main] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:10:01,811 [Thread[Thread-224,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:10:01,813 [Thread[Thread-224,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:10:01,817 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:10:01,818 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:10:01,818 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:10:01,818 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:10:01,818 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:10:01,818 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 23 msec
2020-04-02 05:10:01,822 [IPC Server listener on 35190] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35190: starting
2020-04-02 05:10:01,835 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:01,836 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:35190
2020-04-02 05:10:01,837 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:10:01,852 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:10:01,853 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:10:01,863 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 35190 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:01,872 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:10:01,861 [CacheReplicationMonitor(19487881)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:10:01,896 [pool-1-thread-3] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585804201886,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:10:01,906 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RollingFileSystemSinkTest/hdfs.keytab
2020-04-02 05:10:01,907 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:10:01,907 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:10:01,924 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:10:01,925 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:10:01,925 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:01,925 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:10:01,926 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:10:01,926 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:01,927 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:10:01,933 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:39116
2020-04-02 05:10:01,933 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:10:01,933 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:10:01,934 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:01,936 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:01,936 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:10:01,937 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:01,938 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:01,939 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:10:01,939 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:01,939 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:01,940 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35267
2020-04-02 05:10:01,940 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:01,951 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@150d80c4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:01,951 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3003697{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:01,958 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2aa27288{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:10:01,959 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7f34a967{HTTP/1.1,[http/1.1]}{localhost:35267}
2020-04-02 05:10:01,959 [main] INFO  server.Server (Server.java:doStart(419)) - Started @9389ms
2020-04-02 05:10:01,978 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:36384
2020-04-02 05:10:01,979 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:10:01,979 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:10:01,979 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7ea4d397] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:01,979 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:01,980 [Socket Reader #1 for port 38367] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38367
2020-04-02 05:10:01,985 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:38367
2020-04-02 05:10:01,998 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:10:01,999 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:10:02,000 [Thread-253] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35190 starting to offer service
2020-04-02 05:10:02,012 [IPC Server listener on 38367] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38367: starting
2020-04-02 05:10:02,013 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:02,027 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 38367 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:02,028 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:10:02,070 [pool-1-thread-3] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585804202047,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:10:02,079 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RollingFileSystemSinkTest/hdfs.keytab
2020-04-02 05:10:02,079 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804202078,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:10:02,080 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:10:02,080 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:10:02,131 [Socket Reader #1 for port 35190] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:10:02,135 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:10:02,135 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:10:02,136 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:02,136 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:10:02,153 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:10:02,153 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:02,164 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:10:02,164 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:36589
2020-04-02 05:10:02,165 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:10:02,165 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:10:02,166 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:02,168 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:02,168 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:10:02,169 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:02,170 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:02,170 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:10:02,170 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:02,170 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:02,171 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45060
2020-04-02 05:10:02,171 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:02,173 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4e6d7365{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:02,173 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d4602a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:02,177 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@13e9f2e2{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:10:02,179 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@673bb956{HTTP/1.1,[http/1.1]}{localhost:45060}
2020-04-02 05:10:02,180 [main] INFO  server.Server (Server.java:doStart(419)) - Started @9610ms
2020-04-02 05:10:02,214 [Thread-253] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35190
2020-04-02 05:10:02,218 [Thread-253] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:10:02,220 [Thread-253] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 14459@1b26ddd29aee
2020-04-02 05:10:02,220 [Thread-253] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1918242394. Formatting...
2020-04-02 05:10:02,220 [Thread-253] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e9dc84fb-86af-4f67-b90e-4b7a98f25ed2 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:10:02,223 [Thread-253] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 14459@1b26ddd29aee
2020-04-02 05:10:02,223 [Thread-253] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1918242394. Formatting...
2020-04-02 05:10:02,223 [Thread-253] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-438fad0c-ccb7-4197-a063-39ff224b620b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:10:02,237 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:33446
2020-04-02 05:10:02,238 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:10:02,238 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3c4bc9fc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:02,238 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:10:02,238 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:02,240 [Socket Reader #1 for port 35910] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35910
2020-04-02 05:10:02,251 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:35910
2020-04-02 05:10:02,264 [Thread-253] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:02,266 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:10:02,267 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:10:02,267 [Thread-253] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:02,268 [Thread-253] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1664710928-172.17.0.17-1585804201510 is not formatted. Formatting ...
2020-04-02 05:10:02,268 [Thread-253] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1664710928-172.17.0.17-1585804201510 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1664710928-172.17.0.17-1585804201510/current
2020-04-02 05:10:02,268 [Thread-277] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35190 starting to offer service
2020-04-02 05:10:02,276 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:02,277 [IPC Server listener on 35910] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35910: starting
2020-04-02 05:10:02,290 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 35910 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:02,298 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:10:02,301 [Thread-253] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:02,301 [Thread-253] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:02,302 [Thread-253] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1664710928-172.17.0.17-1585804201510 is not formatted. Formatting ...
2020-04-02 05:10:02,302 [Thread-253] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1664710928-172.17.0.17-1585804201510 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1664710928-172.17.0.17-1585804201510/current
2020-04-02 05:10:02,304 [Thread-253] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1918242394;bpid=BP-1664710928-172.17.0.17-1585804201510;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1918242394;c=1585804201510;bpid=BP-1664710928-172.17.0.17-1585804201510;dnuuid=null
2020-04-02 05:10:02,308 [Thread-253] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID c3b6ea3d-09d2-44dc-a174-aa58e37450ef
2020-04-02 05:10:02,308 [pool-1-thread-3] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585804202307,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:10:02,314 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RollingFileSystemSinkTest/hdfs.keytab
2020-04-02 05:10:02,316 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:10:02,317 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:10:02,346 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-e9dc84fb-86af-4f67-b90e-4b7a98f25ed2
2020-04-02 05:10:02,347 [Thread-253] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:10:02,358 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804202357,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:10:02,370 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:10:02,370 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:10:02,370 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-438fad0c-ccb7-4197-a063-39ff224b620b
2020-04-02 05:10:02,370 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:02,370 [Thread-253] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:10:02,382 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:10:02,384 [Thread-253] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:10:02,384 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:10:02,384 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:02,385 [Thread-253] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:10:02,385 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:10:02,389 [Thread-253] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:10:02,389 [Thread-253] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:10:02,389 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:33023
2020-04-02 05:10:02,389 [Thread-253] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:10:02,389 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:10:02,389 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:10:02,393 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:02,401 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:02,401 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:10:02,407 [Thread-253] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:02,407 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:02,407 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:10:02,407 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:10:02,408 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:02,409 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:10:02,410 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:02,410 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:02,411 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44090
2020-04-02 05:10:02,411 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:02,412 [Socket Reader #1 for port 35190] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:10:02,413 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7dc51783{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:02,416 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f815e7f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:02,462 [Thread-277] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35190
2020-04-02 05:10:02,465 [Thread-277] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:10:02,467 [Thread-277] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 14459@1b26ddd29aee
2020-04-02 05:10:02,468 [Thread-277] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1918242394. Formatting...
2020-04-02 05:10:02,468 [Thread-277] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b9e46114-397e-4415-b294-2e2ef7bfee48 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:10:02,469 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1ad926d3{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:10:02,476 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3a43d133{HTTP/1.1,[http/1.1]}{localhost:44090}
2020-04-02 05:10:02,479 [main] INFO  server.Server (Server.java:doStart(419)) - Started @9908ms
2020-04-02 05:10:02,479 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1664710928-172.17.0.17-1585804201510 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 71ms
2020-04-02 05:10:02,485 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1664710928-172.17.0.17-1585804201510 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 77ms
2020-04-02 05:10:02,486 [Thread-277] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 14459@1b26ddd29aee
2020-04-02 05:10:02,486 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1664710928-172.17.0.17-1585804201510: 79ms
2020-04-02 05:10:02,486 [Thread-277] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1918242394. Formatting...
2020-04-02 05:10:02,486 [Thread-277] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a4c1bc26-8c2d-48de-847c-a66f2a022130 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:10:02,494 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:10:02,494 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:10:02,494 [Thread-302] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1664710928-172.17.0.17-1585804201510/current/replicas doesn't exist 
2020-04-02 05:10:02,495 [Thread-301] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1664710928-172.17.0.17-1585804201510/current/replicas doesn't exist 
2020-04-02 05:10:02,495 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:10:02,495 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:10:02,499 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1664710928-172.17.0.17-1585804201510: 14ms
2020-04-02 05:10:02,500 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:10:02,500 [Thread-253] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:12 AM with interval of 21600000ms
2020-04-02 05:10:02,500 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:10:02,501 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e9dc84fb-86af-4f67-b90e-4b7a98f25ed2): finished scanning block pool BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:02,504 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1664710928-172.17.0.17-1585804201510 (Datanode Uuid c3b6ea3d-09d2-44dc-a174-aa58e37450ef) service to localhost/127.0.0.1:35190 beginning handshake with NN
2020-04-02 05:10:02,500 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-438fad0c-ccb7-4197-a063-39ff224b620b): finished scanning block pool BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:02,512 [IPC Server handler 4 on 35190] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39116, datanodeUuid=c3b6ea3d-09d2-44dc-a174-aa58e37450ef, infoPort=0, infoSecurePort=36384, ipcPort=38367, storageInfo=lv=-57;cid=testClusterID;nsid=1918242394;c=1585804201510) storage c3b6ea3d-09d2-44dc-a174-aa58e37450ef
2020-04-02 05:10:02,522 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e9dc84fb-86af-4f67-b90e-4b7a98f25ed2): no suitable block pools found to scan.  Waiting 1814399978 ms.
2020-04-02 05:10:02,522 [IPC Server handler 4 on 35190] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39116
2020-04-02 05:10:02,522 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-438fad0c-ccb7-4197-a063-39ff224b620b): no suitable block pools found to scan.  Waiting 1814399978 ms.
2020-04-02 05:10:02,523 [IPC Server handler 4 on 35190] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c3b6ea3d-09d2-44dc-a174-aa58e37450ef (127.0.0.1:39116).
2020-04-02 05:10:02,532 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1664710928-172.17.0.17-1585804201510 (Datanode Uuid c3b6ea3d-09d2-44dc-a174-aa58e37450ef) service to localhost/127.0.0.1:35190 successfully registered with NN
2020-04-02 05:10:02,532 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1664710928-172.17.0.17-1585804201510 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:10:02,533 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:10:02,533 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35190 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:02,546 [IPC Server handler 3 on 35190] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e9dc84fb-86af-4f67-b90e-4b7a98f25ed2 for DN 127.0.0.1:39116
2020-04-02 05:10:02,548 [IPC Server handler 3 on 35190] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-438fad0c-ccb7-4197-a063-39ff224b620b for DN 127.0.0.1:39116
2020-04-02 05:10:02,548 [Thread-277] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:02,554 [Thread-277] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:02,554 [Thread-277] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1664710928-172.17.0.17-1585804201510 is not formatted. Formatting ...
2020-04-02 05:10:02,554 [Thread-277] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1664710928-172.17.0.17-1585804201510 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1664710928-172.17.0.17-1585804201510/current
2020-04-02 05:10:02,573 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2cede529c9d591f5: Processing first storage report for DS-e9dc84fb-86af-4f67-b90e-4b7a98f25ed2 from datanode c3b6ea3d-09d2-44dc-a174-aa58e37450ef
2020-04-02 05:10:02,574 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:45547
2020-04-02 05:10:02,574 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2cede529c9d591f5: from storage DS-e9dc84fb-86af-4f67-b90e-4b7a98f25ed2 node DatanodeRegistration(127.0.0.1:39116, datanodeUuid=c3b6ea3d-09d2-44dc-a174-aa58e37450ef, infoPort=0, infoSecurePort=36384, ipcPort=38367, storageInfo=lv=-57;cid=testClusterID;nsid=1918242394;c=1585804201510), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:10:02,574 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:10:02,574 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2cede529c9d591f5: Processing first storage report for DS-438fad0c-ccb7-4197-a063-39ff224b620b from datanode c3b6ea3d-09d2-44dc-a174-aa58e37450ef
2020-04-02 05:10:02,574 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@c96a4ea] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:02,575 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2cede529c9d591f5: from storage DS-438fad0c-ccb7-4197-a063-39ff224b620b node DatanodeRegistration(127.0.0.1:39116, datanodeUuid=c3b6ea3d-09d2-44dc-a174-aa58e37450ef, infoPort=0, infoSecurePort=36384, ipcPort=38367, storageInfo=lv=-57;cid=testClusterID;nsid=1918242394;c=1585804201510), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:10:02,574 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:10:02,575 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:02,578 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x2cede529c9d591f5,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 18 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:02,579 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:02,584 [Socket Reader #1 for port 44393] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44393
2020-04-02 05:10:02,595 [Thread-277] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:02,595 [Thread-277] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:02,596 [Thread-277] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1664710928-172.17.0.17-1585804201510 is not formatted. Formatting ...
2020-04-02 05:10:02,596 [Thread-277] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1664710928-172.17.0.17-1585804201510 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1664710928-172.17.0.17-1585804201510/current
2020-04-02 05:10:02,596 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:44393
2020-04-02 05:10:02,601 [Thread-277] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1918242394;bpid=BP-1664710928-172.17.0.17-1585804201510;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1918242394;c=1585804201510;bpid=BP-1664710928-172.17.0.17-1585804201510;dnuuid=null
2020-04-02 05:10:02,602 [Thread-277] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID fbc336ef-3cd7-4984-b863-b04d05ac2359
2020-04-02 05:10:02,610 [Thread-277] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-b9e46114-397e-4415-b294-2e2ef7bfee48
2020-04-02 05:10:02,614 [Thread-277] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:10:02,616 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:10:02,616 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:10:02,616 [Thread-313] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35190 starting to offer service
2020-04-02 05:10:02,617 [Thread-277] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-a4c1bc26-8c2d-48de-847c-a66f2a022130
2020-04-02 05:10:02,617 [Thread-277] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:10:02,620 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:02,621 [IPC Server listener on 44393] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44393: starting
2020-04-02 05:10:02,621 [Thread-277] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:10:02,622 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 44393 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:02,623 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:10:02,633 [Thread-277] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:10:02,638 [Thread-277] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:10:02,638 [Thread-277] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:10:02,638 [Thread-277] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:10:02,647 [Thread-277] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:02,648 [Thread-326] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:10:02,648 [Thread-327] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:10:02,708 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585804202704,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:10:02,748 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RollingFileSystemSinkTest/hdfs.keytab
2020-04-02 05:10:02,748 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:10:02,749 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:10:02,750 [Thread-327] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1664710928-172.17.0.17-1585804201510 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 102ms
2020-04-02 05:10:02,801 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:10:02,801 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:10:02,801 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:02,802 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:10:02,813 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:10:02,813 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:10:02,813 [Thread-326] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1664710928-172.17.0.17-1585804201510 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 165ms
2020-04-02 05:10:02,813 [Thread-277] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1664710928-172.17.0.17-1585804201510: 165ms
2020-04-02 05:10:02,813 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:10:02,814 [Thread-331] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:10:02,814 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:10:02,814 [Thread-331] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1664710928-172.17.0.17-1585804201510/current/replicas doesn't exist 
2020-04-02 05:10:02,814 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:33376
2020-04-02 05:10:02,814 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:10:02,815 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:10:02,814 [Thread-332] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1664710928-172.17.0.17-1585804201510/current/replicas doesn't exist 
2020-04-02 05:10:02,815 [Thread-331] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-04-02 05:10:02,815 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-04-02 05:10:02,815 [Thread-277] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1664710928-172.17.0.17-1585804201510: 2ms
2020-04-02 05:10:02,815 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804202814,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:10:02,815 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:10:02,816 [Thread-277] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:26 AM with interval of 21600000ms
2020-04-02 05:10:02,816 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:10:02,816 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-b9e46114-397e-4415-b294-2e2ef7bfee48): finished scanning block pool BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:02,816 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:02,820 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1664710928-172.17.0.17-1585804201510 (Datanode Uuid fbc336ef-3cd7-4984-b863-b04d05ac2359) service to localhost/127.0.0.1:35190 beginning handshake with NN
2020-04-02 05:10:02,833 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-b9e46114-397e-4415-b294-2e2ef7bfee48): no suitable block pools found to scan.  Waiting 1814399982 ms.
2020-04-02 05:10:02,833 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-a4c1bc26-8c2d-48de-847c-a66f2a022130): finished scanning block pool BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:02,837 [IPC Server handler 8 on 35190] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36589, datanodeUuid=fbc336ef-3cd7-4984-b863-b04d05ac2359, infoPort=0, infoSecurePort=33446, ipcPort=35910, storageInfo=lv=-57;cid=testClusterID;nsid=1918242394;c=1585804201510) storage fbc336ef-3cd7-4984-b863-b04d05ac2359
2020-04-02 05:10:02,837 [IPC Server handler 8 on 35190] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36589
2020-04-02 05:10:02,837 [IPC Server handler 8 on 35190] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN fbc336ef-3cd7-4984-b863-b04d05ac2359 (127.0.0.1:36589).
2020-04-02 05:10:02,838 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:10:02,838 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-a4c1bc26-8c2d-48de-847c-a66f2a022130): no suitable block pools found to scan.  Waiting 1814399978 ms.
2020-04-02 05:10:02,839 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:10:02,839 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1664710928-172.17.0.17-1585804201510 (Datanode Uuid fbc336ef-3cd7-4984-b863-b04d05ac2359) service to localhost/127.0.0.1:35190 successfully registered with NN
2020-04-02 05:10:02,839 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:10:02,839 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1664710928-172.17.0.17-1585804201510 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:10:02,846 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:10:02,847 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35190 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:02,850 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:10:02,855 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:10:02,855 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:10:02,855 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:10:02,856 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 36381
2020-04-02 05:10:02,859 [IPC Server handler 9 on 35190] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b9e46114-397e-4415-b294-2e2ef7bfee48 for DN 127.0.0.1:36589
2020-04-02 05:10:02,859 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:10:02,868 [IPC Server handler 9 on 35190] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a4c1bc26-8c2d-48de-847c-a66f2a022130 for DN 127.0.0.1:36589
2020-04-02 05:10:02,874 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3088660d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:10:02,877 [Socket Reader #1 for port 35190] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:10:02,877 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@32fdec40{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:10:02,878 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x46151ea317eb801d: Processing first storage report for DS-b9e46114-397e-4415-b294-2e2ef7bfee48 from datanode fbc336ef-3cd7-4984-b863-b04d05ac2359
2020-04-02 05:10:02,878 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x46151ea317eb801d: from storage DS-b9e46114-397e-4415-b294-2e2ef7bfee48 node DatanodeRegistration(127.0.0.1:36589, datanodeUuid=fbc336ef-3cd7-4984-b863-b04d05ac2359, infoPort=0, infoSecurePort=33446, ipcPort=35910, storageInfo=lv=-57;cid=testClusterID;nsid=1918242394;c=1585804201510), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:02,886 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x46151ea317eb801d: Processing first storage report for DS-a4c1bc26-8c2d-48de-847c-a66f2a022130 from datanode fbc336ef-3cd7-4984-b863-b04d05ac2359
2020-04-02 05:10:02,888 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x46151ea317eb801d: from storage DS-a4c1bc26-8c2d-48de-847c-a66f2a022130 node DatanodeRegistration(127.0.0.1:36589, datanodeUuid=fbc336ef-3cd7-4984-b863-b04d05ac2359, infoPort=0, infoSecurePort=33446, ipcPort=35910, storageInfo=lv=-57;cid=testClusterID;nsid=1918242394;c=1585804201510), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:10:02,888 [Thread-313] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35190
2020-04-02 05:10:02,890 [Thread-313] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:10:02,890 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x46151ea317eb801d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 14 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:02,890 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:02,891 [Thread-313] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 14459@1b26ddd29aee
2020-04-02 05:10:02,892 [Thread-313] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1918242394. Formatting...
2020-04-02 05:10:02,892 [Thread-313] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0002a66f-9c97-4a4f-8988-dc79a8942358 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:10:02,894 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@55120f99{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:10:02,896 [Thread-313] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 14459@1b26ddd29aee
2020-04-02 05:10:02,896 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@794b435f{HTTP/1.1,[http/1.1]}{localhost:36381}
2020-04-02 05:10:02,896 [Thread-313] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1918242394. Formatting...
2020-04-02 05:10:02,896 [main] INFO  server.Server (Server.java:doStart(419)) - Started @10326ms
2020-04-02 05:10:02,896 [Thread-313] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-466f9fd8-2989-492c-86c5-b87646ec23ea for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:10:02,910 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:33222
2020-04-02 05:10:02,911 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:10:02,911 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@323659f8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:10:02,911 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:10:02,911 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:10:02,912 [Socket Reader #1 for port 36656] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36656
2020-04-02 05:10:02,914 [Thread-313] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:02,915 [Thread-313] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:02,915 [Thread-313] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1664710928-172.17.0.17-1585804201510 is not formatted. Formatting ...
2020-04-02 05:10:02,915 [Thread-313] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1664710928-172.17.0.17-1585804201510 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1664710928-172.17.0.17-1585804201510/current
2020-04-02 05:10:02,917 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:36656
2020-04-02 05:10:02,927 [Thread-313] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:02,927 [Thread-313] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:02,927 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:10:02,927 [Thread-313] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1664710928-172.17.0.17-1585804201510 is not formatted. Formatting ...
2020-04-02 05:10:02,928 [Thread-313] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1664710928-172.17.0.17-1585804201510 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1664710928-172.17.0.17-1585804201510/current
2020-04-02 05:10:02,928 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:10:02,930 [Thread-347] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35190 starting to offer service
2020-04-02 05:10:02,936 [Thread-313] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1918242394;bpid=BP-1664710928-172.17.0.17-1585804201510;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1918242394;c=1585804201510;bpid=BP-1664710928-172.17.0.17-1585804201510;dnuuid=null
2020-04-02 05:10:02,940 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:10:02,940 [IPC Server listener on 36656] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36656: starting
2020-04-02 05:10:02,941 [Thread-313] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID cd26a2d8-0daf-4bc7-b49c-4d5cde2e38bb
2020-04-02 05:10:02,941 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 36656 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:02,949 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-0002a66f-9c97-4a4f-8988-dc79a8942358
2020-04-02 05:10:02,949 [Thread-313] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:10:02,951 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-466f9fd8-2989-492c-86c5-b87646ec23ea
2020-04-02 05:10:02,951 [Thread-313] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:10:02,951 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804202951,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:10:02,952 [Thread-313] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:10:02,953 [Thread-313] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:10:02,966 [Thread-313] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:10:02,966 [Thread-313] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:10:02,967 [Thread-313] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:10:02,981 [Thread-313] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:02,981 [Thread-363] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:10:02,982 [Thread-362] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:10:02,982 [Socket Reader #1 for port 35190] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:10:03,016 [Thread-347] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35190
2020-04-02 05:10:03,023 [Thread-347] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:10:03,024 [pool-1-thread-3] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804203017,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:10:03,024 [Thread-347] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 14459@1b26ddd29aee
2020-04-02 05:10:03,025 [Thread-347] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1918242394. Formatting...
2020-04-02 05:10:03,028 [Thread-347] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-28a793e1-0a00-45c2-ba2f-286748afec35 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-04-02 05:10:03,054 [Thread-347] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 14459@1b26ddd29aee
2020-04-02 05:10:03,055 [Thread-347] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1918242394. Formatting...
2020-04-02 05:10:03,055 [Thread-347] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1701bf7f-2789-4507-bd1a-a9ed1c947c27 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-04-02 05:10:03,057 [Thread-363] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1664710928-172.17.0.17-1585804201510 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 75ms
2020-04-02 05:10:03,061 [Socket Reader #1 for port 35190] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:10:03,061 [Thread-362] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1664710928-172.17.0.17-1585804201510 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 78ms
2020-04-02 05:10:03,061 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1664710928-172.17.0.17-1585804201510: 81ms
2020-04-02 05:10:03,078 [Thread-366] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:10:03,078 [Thread-366] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1664710928-172.17.0.17-1585804201510/current/replicas doesn't exist 
2020-04-02 05:10:03,079 [Thread-366] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 1ms
2020-04-02 05:10:03,082 [Thread-367] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:10:03,082 [IPC Server handler 3 on 35190] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:10:03,082 [Thread-367] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1664710928-172.17.0.17-1585804201510/current/replicas doesn't exist 
2020-04-02 05:10:03,083 [Thread-367] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 1ms
2020-04-02 05:10:03,083 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1664710928-172.17.0.17-1585804201510: 21ms
2020-04-02 05:10:03,083 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:10:03,083 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:10:03,084 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:10:03,084 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:10:03,084 [Thread-313] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:11 AM with interval of 21600000ms
2020-04-02 05:10:03,084 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-0002a66f-9c97-4a4f-8988-dc79a8942358): finished scanning block pool BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:03,087 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1664710928-172.17.0.17-1585804201510 (Datanode Uuid cd26a2d8-0daf-4bc7-b49c-4d5cde2e38bb) service to localhost/127.0.0.1:35190 beginning handshake with NN
2020-04-02 05:10:03,089 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-0002a66f-9c97-4a4f-8988-dc79a8942358): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-04-02 05:10:03,089 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-466f9fd8-2989-492c-86c5-b87646ec23ea): finished scanning block pool BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:03,090 [IPC Server handler 5 on 35190] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33023, datanodeUuid=cd26a2d8-0daf-4bc7-b49c-4d5cde2e38bb, infoPort=0, infoSecurePort=45547, ipcPort=44393, storageInfo=lv=-57;cid=testClusterID;nsid=1918242394;c=1585804201510) storage cd26a2d8-0daf-4bc7-b49c-4d5cde2e38bb
2020-04-02 05:10:03,090 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-466f9fd8-2989-492c-86c5-b87646ec23ea): no suitable block pools found to scan.  Waiting 1814399993 ms.
2020-04-02 05:10:03,090 [IPC Server handler 5 on 35190] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33023
2020-04-02 05:10:03,090 [IPC Server handler 5 on 35190] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN cd26a2d8-0daf-4bc7-b49c-4d5cde2e38bb (127.0.0.1:33023).
2020-04-02 05:10:03,091 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1664710928-172.17.0.17-1585804201510 (Datanode Uuid cd26a2d8-0daf-4bc7-b49c-4d5cde2e38bb) service to localhost/127.0.0.1:35190 successfully registered with NN
2020-04-02 05:10:03,091 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1664710928-172.17.0.17-1585804201510 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:10:03,091 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:10:03,091 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35190 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:03,094 [Thread-347] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:03,096 [Thread-347] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:03,096 [Thread-347] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1664710928-172.17.0.17-1585804201510 is not formatted. Formatting ...
2020-04-02 05:10:03,096 [Thread-347] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1664710928-172.17.0.17-1585804201510 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1664710928-172.17.0.17-1585804201510/current
2020-04-02 05:10:03,098 [IPC Server handler 6 on 35190] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0002a66f-9c97-4a4f-8988-dc79a8942358 for DN 127.0.0.1:33023
2020-04-02 05:10:03,099 [IPC Server handler 6 on 35190] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-466f9fd8-2989-492c-86c5-b87646ec23ea for DN 127.0.0.1:33023
2020-04-02 05:10:03,105 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xda052afd63de95cb: Processing first storage report for DS-0002a66f-9c97-4a4f-8988-dc79a8942358 from datanode cd26a2d8-0daf-4bc7-b49c-4d5cde2e38bb
2020-04-02 05:10:03,105 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xda052afd63de95cb: from storage DS-0002a66f-9c97-4a4f-8988-dc79a8942358 node DatanodeRegistration(127.0.0.1:33023, datanodeUuid=cd26a2d8-0daf-4bc7-b49c-4d5cde2e38bb, infoPort=0, infoSecurePort=45547, ipcPort=44393, storageInfo=lv=-57;cid=testClusterID;nsid=1918242394;c=1585804201510), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:03,105 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xda052afd63de95cb: Processing first storage report for DS-466f9fd8-2989-492c-86c5-b87646ec23ea from datanode cd26a2d8-0daf-4bc7-b49c-4d5cde2e38bb
2020-04-02 05:10:03,105 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xda052afd63de95cb: from storage DS-466f9fd8-2989-492c-86c5-b87646ec23ea node DatanodeRegistration(127.0.0.1:33023, datanodeUuid=cd26a2d8-0daf-4bc7-b49c-4d5cde2e38bb, infoPort=0, infoSecurePort=45547, ipcPort=44393, storageInfo=lv=-57;cid=testClusterID;nsid=1918242394;c=1585804201510), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:03,108 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xda052afd63de95cb,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:03,108 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:03,119 [Thread-347] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:03,120 [Thread-347] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:03,120 [Thread-347] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1664710928-172.17.0.17-1585804201510 is not formatted. Formatting ...
2020-04-02 05:10:03,120 [Thread-347] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1664710928-172.17.0.17-1585804201510 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1664710928-172.17.0.17-1585804201510/current
2020-04-02 05:10:03,122 [Thread-347] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1918242394;bpid=BP-1664710928-172.17.0.17-1585804201510;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1918242394;c=1585804201510;bpid=BP-1664710928-172.17.0.17-1585804201510;dnuuid=null
2020-04-02 05:10:03,124 [Thread-347] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 3cb51a55-9cf8-43ce-bf5c-332fa37d1aef
2020-04-02 05:10:03,127 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-28a793e1-0a00-45c2-ba2f-286748afec35
2020-04-02 05:10:03,129 [Thread-347] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:10:03,135 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-1701bf7f-2789-4507-bd1a-a9ed1c947c27
2020-04-02 05:10:03,137 [Thread-347] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:10:03,138 [Thread-347] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:10:03,139 [Thread-347] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:10:03,140 [Thread-347] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:10:03,140 [Thread-347] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:10:03,140 [Thread-347] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:10:03,144 [Thread-347] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:03,145 [Thread-373] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:10:03,145 [Thread-374] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:10:03,186 [Thread-374] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1664710928-172.17.0.17-1585804201510 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 41ms
2020-04-02 05:10:03,188 [Thread-373] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1664710928-172.17.0.17-1585804201510 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 43ms
2020-04-02 05:10:03,188 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1664710928-172.17.0.17-1585804201510: 45ms
2020-04-02 05:10:03,189 [Thread-377] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:10:03,189 [Thread-378] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:10:03,189 [Thread-377] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1664710928-172.17.0.17-1585804201510/current/replicas doesn't exist 
2020-04-02 05:10:03,190 [Thread-377] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 1ms
2020-04-02 05:10:03,189 [Thread-378] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1664710928-172.17.0.17-1585804201510/current/replicas doesn't exist 
2020-04-02 05:10:03,190 [IPC Server handler 7 on 35190] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:10:03,190 [Thread-378] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 1ms
2020-04-02 05:10:03,190 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1664710928-172.17.0.17-1585804201510: 1ms
2020-04-02 05:10:03,191 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:10:03,191 [Thread-347] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:52 AM with interval of 21600000ms
2020-04-02 05:10:03,191 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-28a793e1-0a00-45c2-ba2f-286748afec35): finished scanning block pool BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:03,191 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:10:03,193 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1664710928-172.17.0.17-1585804201510 (Datanode Uuid 3cb51a55-9cf8-43ce-bf5c-332fa37d1aef) service to localhost/127.0.0.1:35190 beginning handshake with NN
2020-04-02 05:10:03,193 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1664710928-172.17.0.17-1585804201510 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:10:03,193 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-28a793e1-0a00-45c2-ba2f-286748afec35): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:10:03,193 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:10:03,195 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-1701bf7f-2789-4507-bd1a-a9ed1c947c27): finished scanning block pool BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:03,196 [IPC Server handler 8 on 35190] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33376, datanodeUuid=3cb51a55-9cf8-43ce-bf5c-332fa37d1aef, infoPort=0, infoSecurePort=33222, ipcPort=36656, storageInfo=lv=-57;cid=testClusterID;nsid=1918242394;c=1585804201510) storage 3cb51a55-9cf8-43ce-bf5c-332fa37d1aef
2020-04-02 05:10:03,196 [IPC Server handler 8 on 35190] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33376
2020-04-02 05:10:03,196 [IPC Server handler 8 on 35190] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3cb51a55-9cf8-43ce-bf5c-332fa37d1aef (127.0.0.1:33376).
2020-04-02 05:10:03,196 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-1701bf7f-2789-4507-bd1a-a9ed1c947c27): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:10:03,197 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1664710928-172.17.0.17-1585804201510 (Datanode Uuid 3cb51a55-9cf8-43ce-bf5c-332fa37d1aef) service to localhost/127.0.0.1:35190 successfully registered with NN
2020-04-02 05:10:03,197 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1664710928-172.17.0.17-1585804201510 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:10:03,197 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:10:03,198 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35190 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:10:03,203 [IPC Server handler 9 on 35190] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-28a793e1-0a00-45c2-ba2f-286748afec35 for DN 127.0.0.1:33376
2020-04-02 05:10:03,212 [IPC Server handler 9 on 35190] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1701bf7f-2789-4507-bd1a-a9ed1c947c27 for DN 127.0.0.1:33376
2020-04-02 05:10:03,226 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x44ec1f2395c2e0fa: Processing first storage report for DS-1701bf7f-2789-4507-bd1a-a9ed1c947c27 from datanode 3cb51a55-9cf8-43ce-bf5c-332fa37d1aef
2020-04-02 05:10:03,226 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x44ec1f2395c2e0fa: from storage DS-1701bf7f-2789-4507-bd1a-a9ed1c947c27 node DatanodeRegistration(127.0.0.1:33376, datanodeUuid=3cb51a55-9cf8-43ce-bf5c-332fa37d1aef, infoPort=0, infoSecurePort=33222, ipcPort=36656, storageInfo=lv=-57;cid=testClusterID;nsid=1918242394;c=1585804201510), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:10:03,226 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x44ec1f2395c2e0fa: Processing first storage report for DS-28a793e1-0a00-45c2-ba2f-286748afec35 from datanode 3cb51a55-9cf8-43ce-bf5c-332fa37d1aef
2020-04-02 05:10:03,227 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x44ec1f2395c2e0fa: from storage DS-28a793e1-0a00-45c2-ba2f-286748afec35 node DatanodeRegistration(127.0.0.1:33376, datanodeUuid=3cb51a55-9cf8-43ce-bf5c-332fa37d1aef, infoPort=0, infoSecurePort=33222, ipcPort=36656, storageInfo=lv=-57;cid=testClusterID;nsid=1918242394;c=1585804201510), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:10:03,229 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x44ec1f2395c2e0fa,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 12 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:10:03,229 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:03,299 [IPC Server handler 0 on 35190] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:10:03,300 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:10:03,306 [IPC Server handler 4 on 35190] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:10:03,307 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:10:03,314 [pool-1-thread-3] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585804203313,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:10:03,331 [pool-1-thread-3] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804203330,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:10:03,344 [Socket Reader #1 for port 35190] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:10:03,352 [IPC Server handler 3 on 35190] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp	dst=null	perm=hdfs:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:10:03,354 [IPC Server handler 5 on 35190] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=setPermission	src=/tmp	dst=null	perm=hdfs:supergroup:rwxrwxrwx	proto=rpc
2020-04-02 05:10:03,362 [pool-1-thread-3] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585804203362,sink/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:10:03,470 [pool-1-thread-3] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804203470,sink/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:10:03,488 [Socket Reader #1 for port 35190] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for sink/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:10:03,492 [IPC Server handler 6 on 35190] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=sink/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/test	dst=null	perm=sink:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:10:03,497 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2-testwithsecurehdfs.properties
2020-04-02 05:10:03,506 [pool-1-thread-3] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585804203505,sink/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:10:03,512 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user sink/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RollingFileSystemSinkTest/sink.keytab
2020-04-02 05:10:03,516 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink mysink0 started
2020-04-02 05:10:03,518 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10000 second(s).
2020-04-02 05:10:03,518 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - testwithsecurehdfs metrics system started
2020-04-02 05:10:03,527 [IPC Server handler 1 on 35190] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=sink/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/test	dst=null	perm=sink:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:10:03,530 [IPC Server handler 7 on 35190] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=sink/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/test/202004020500	dst=null	perm=sink:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:10:03,566 [IPC Server handler 8 on 35190] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=sink/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=create	src=/tmp/test/202004020500/testsrc-1b26ddd29aee.log	dst=null	perm=sink:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:10:03,626 [IPC Server handler 9 on 35190] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:36589, 127.0.0.1:33023, 127.0.0.1:39116 for /tmp/test/202004020500/testsrc-1b26ddd29aee.log
2020-04-02 05:10:03,717 [DataXceiver for client DFSClient_NONMAPREDUCE_-1120120443_1 at /127.0.0.1:59958 [Receiving block BP-1664710928-172.17.0.17-1585804201510:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1664710928-172.17.0.17-1585804201510:blk_1073741825_1001 src: /127.0.0.1:59958 dest: /127.0.0.1:36589
2020-04-02 05:10:03,754 [DataXceiver for client DFSClient_NONMAPREDUCE_-1120120443_1 at /127.0.0.1:57844 [Receiving block BP-1664710928-172.17.0.17-1585804201510:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1664710928-172.17.0.17-1585804201510:blk_1073741825_1001 src: /127.0.0.1:57844 dest: /127.0.0.1:33023
2020-04-02 05:10:03,768 [DataXceiver for client DFSClient_NONMAPREDUCE_-1120120443_1 at /127.0.0.1:37946 [Receiving block BP-1664710928-172.17.0.17-1585804201510:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1664710928-172.17.0.17-1585804201510:blk_1073741825_1001 src: /127.0.0.1:37946 dest: /127.0.0.1:39116
2020-04-02 05:10:03,806 [IPC Server handler 0 on 35190] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3274)) - BLOCK* fsync: /tmp/test/202004020500/testsrc-1b26ddd29aee.log for DFSClient_NONMAPREDUCE_-1120120443_1
2020-04-02 05:10:03,814 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping testwithsecurehdfs metrics system...
2020-04-02 05:10:03,825 [mysink0] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - mysink0 thread interrupted.
2020-04-02 05:10:03,849 [PacketResponder: BP-1664710928-172.17.0.17-1585804201510:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37946, dest: /127.0.0.1:39116, bytes: 244, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1120120443_1, offset: 0, srvID: c3b6ea3d-09d2-44dc-a174-aa58e37450ef, blockid: BP-1664710928-172.17.0.17-1585804201510:blk_1073741825_1001, duration(ns): 60392014
2020-04-02 05:10:03,849 [PacketResponder: BP-1664710928-172.17.0.17-1585804201510:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1664710928-172.17.0.17-1585804201510:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:03,858 [PacketResponder: BP-1664710928-172.17.0.17-1585804201510:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39116]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57844, dest: /127.0.0.1:33023, bytes: 244, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1120120443_1, offset: 0, srvID: cd26a2d8-0daf-4bc7-b49c-4d5cde2e38bb, blockid: BP-1664710928-172.17.0.17-1585804201510:blk_1073741825_1001, duration(ns): 77122960
2020-04-02 05:10:03,860 [PacketResponder: BP-1664710928-172.17.0.17-1585804201510:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39116]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1664710928-172.17.0.17-1585804201510:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39116] terminating
2020-04-02 05:10:03,865 [PacketResponder: BP-1664710928-172.17.0.17-1585804201510:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33023, 127.0.0.1:39116]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59958, dest: /127.0.0.1:36589, bytes: 244, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1120120443_1, offset: 0, srvID: fbc336ef-3cd7-4984-b863-b04d05ac2359, blockid: BP-1664710928-172.17.0.17-1585804201510:blk_1073741825_1001, duration(ns): 78756060
2020-04-02 05:10:03,866 [PacketResponder: BP-1664710928-172.17.0.17-1585804201510:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33023, 127.0.0.1:39116]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1664710928-172.17.0.17-1585804201510:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33023, 127.0.0.1:39116] terminating
2020-04-02 05:10:03,872 [IPC Server handler 4 on 35190] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/test/202004020500/testsrc-1b26ddd29aee.log
2020-04-02 05:10:04,279 [IPC Server handler 1 on 35190] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/test/202004020500/testsrc-1b26ddd29aee.log is closed by DFSClient_NONMAPREDUCE_-1120120443_1
2020-04-02 05:10:04,282 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - testwithsecurehdfs metrics system stopped.
2020-04-02 05:10:04,293 [IPC Server handler 7 on 35190] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=sink/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/test	dst=null	perm=null	proto=rpc
2020-04-02 05:10:04,309 [IPC Server handler 8 on 35190] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=sink/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/test/202004020500/testsrc-1b26ddd29aee.log.1	dst=null	perm=null	proto=rpc
2020-04-02 05:10:04,315 [IPC Server handler 9 on 35190] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=sink/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=open	src=/tmp/test/202004020500/testsrc-1b26ddd29aee.log	dst=null	perm=null	proto=rpc
2020-04-02 05:10:04,370 [IPC Server handler 2 on 35190] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=sink/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/test/202004020500	dst=null	perm=null	proto=rpc
2020-04-02 05:10:04,373 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:10:04,373 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 3
2020-04-02 05:10:04,373 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 36656 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:04,373 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:04,373 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7f9e1534] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:04,377 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-1701bf7f-2789-4507-bd1a-a9ed1c947c27) exiting.
2020-04-02 05:10:04,377 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-28a793e1-0a00-45c2-ba2f-286748afec35) exiting.
2020-04-02 05:10:04,392 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@55120f99{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:04,393 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@794b435f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:04,394 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@32fdec40{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:04,394 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3088660d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:04,396 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36656
2020-04-02 05:10:04,400 [IPC Server listener on 36656] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36656
2020-04-02 05:10:04,401 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:04,401 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:04,401 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1664710928-172.17.0.17-1585804201510 (Datanode Uuid 3cb51a55-9cf8-43ce-bf5c-332fa37d1aef) service to localhost/127.0.0.1:35190
2020-04-02 05:10:04,403 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1664710928-172.17.0.17-1585804201510 (Datanode Uuid 3cb51a55-9cf8-43ce-bf5c-332fa37d1aef)
2020-04-02 05:10:04,403 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:04,414 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1664710928-172.17.0.17-1585804201510] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:04,424 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1664710928-172.17.0.17-1585804201510] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:04,427 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:04,428 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:04,429 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:04,429 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:04,430 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:04,430 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:10:04,430 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 44393 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:04,431 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@78b236a0] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:04,431 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:04,432 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-0002a66f-9c97-4a4f-8988-dc79a8942358) exiting.
2020-04-02 05:10:04,432 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-466f9fd8-2989-492c-86c5-b87646ec23ea) exiting.
2020-04-02 05:10:04,449 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1ad926d3{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:04,450 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3a43d133{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:04,450 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f815e7f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:04,450 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7dc51783{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:04,451 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44393
2020-04-02 05:10:04,460 [IPC Server listener on 44393] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44393
2020-04-02 05:10:04,460 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:04,460 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:04,460 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1664710928-172.17.0.17-1585804201510 (Datanode Uuid cd26a2d8-0daf-4bc7-b49c-4d5cde2e38bb) service to localhost/127.0.0.1:35190
2020-04-02 05:10:04,461 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1664710928-172.17.0.17-1585804201510 (Datanode Uuid cd26a2d8-0daf-4bc7-b49c-4d5cde2e38bb)
2020-04-02 05:10:04,461 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:04,484 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1664710928-172.17.0.17-1585804201510] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:04,498 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:04,499 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:04,503 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:04,503 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:04,516 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:04,516 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:10:04,516 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1664710928-172.17.0.17-1585804201510] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:04,516 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 35910 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:04,517 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:04,517 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6d868997] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:04,523 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-a4c1bc26-8c2d-48de-847c-a66f2a022130) exiting.
2020-04-02 05:10:04,524 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-b9e46114-397e-4415-b294-2e2ef7bfee48) exiting.
2020-04-02 05:10:04,550 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@13e9f2e2{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:04,551 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@673bb956{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:04,551 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d4602a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:04,552 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4e6d7365{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:04,554 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35910
2020-04-02 05:10:04,557 [IPC Server listener on 35910] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35910
2020-04-02 05:10:04,557 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:04,557 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:04,557 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1664710928-172.17.0.17-1585804201510 (Datanode Uuid fbc336ef-3cd7-4984-b863-b04d05ac2359) service to localhost/127.0.0.1:35190
2020-04-02 05:10:04,558 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1664710928-172.17.0.17-1585804201510 (Datanode Uuid fbc336ef-3cd7-4984-b863-b04d05ac2359)
2020-04-02 05:10:04,558 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:04,570 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1664710928-172.17.0.17-1585804201510] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:04,579 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1664710928-172.17.0.17-1585804201510] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:04,590 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:04,590 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:04,591 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:04,591 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:04,594 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:04,595 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:10:04,595 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 38367 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:04,595 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:10:04,596 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@63a5d002] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:10:04,602 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-438fad0c-ccb7-4197-a063-39ff224b620b) exiting.
2020-04-02 05:10:04,602 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e9dc84fb-86af-4f67-b90e-4b7a98f25ed2) exiting.
2020-04-02 05:10:04,637 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2aa27288{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:10:04,637 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7f34a967{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:10:04,638 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3003697{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:04,638 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@150d80c4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:04,639 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38367
2020-04-02 05:10:04,640 [IPC Server listener on 38367] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38367
2020-04-02 05:10:04,643 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:04,644 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:10:04,644 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1664710928-172.17.0.17-1585804201510 (Datanode Uuid c3b6ea3d-09d2-44dc-a174-aa58e37450ef) service to localhost/127.0.0.1:35190
2020-04-02 05:10:04,746 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1664710928-172.17.0.17-1585804201510 (Datanode Uuid c3b6ea3d-09d2-44dc-a174-aa58e37450ef)
2020-04-02 05:10:04,746 [BP-1664710928-172.17.0.17-1585804201510 heartbeating to localhost/127.0.0.1:35190] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1664710928-172.17.0.17-1585804201510
2020-04-02 05:10:04,755 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1664710928-172.17.0.17-1585804201510] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:04,763 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1664710928-172.17.0.17-1585804201510] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:10:04,778 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:10:04,778 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:10:04,780 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:10:04,780 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:10:04,796 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:10:04,796 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:10:04,796 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 35190 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:10:04,796 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:10:04,796 [Thread[Thread-224,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:10:04,797 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 13
2020-04-02 05:10:04,797 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@31be6b49] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:10:04,798 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 14 Total time for transactions(ms): 16 Number of transactions batched in Syncs: 1 Number of syncs: 14 SyncTimes(ms): 5 4 
2020-04-02 05:10:04,798 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@219f4597] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:10:04,799 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000014
2020-04-02 05:10:04,799 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000014
2020-04-02 05:10:04,800 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:10:04,800 [CacheReplicationMonitor(19487881)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:10:04,836 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35190
2020-04-02 05:10:04,839 [IPC Server listener on 35190] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35190
2020-04-02 05:10:04,839 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:10:04,849 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:10:04,839 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:10:04,870 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:10:04,870 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:10:04,872 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2f19f2aa{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:10:04,873 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@79c5636f{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:10:04,873 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@ceb4bd2{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:10:04,874 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@169da7f2{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:10:04,874 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:10:04,878 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:10:04,879 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithSecureHdfs#testWithSecureHDFS
[msx] writeFile testName = org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithSecureHdfs#testWithSecureHDFS
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:10:04,894 [main] INFO  impl.DefaultInternalKdcServerImpl (DefaultInternalKdcServerImpl.java:doStop(102)) - Default Internal kdc server stopped.
2020-04-02 05:10:05,895 [main] INFO  minikdc.MiniKdc (MiniKdc.java:stop(359)) - MiniKdc stopped.
[msx] all testRunFinished

[msx] before_class
2020-04-02 05:05:14,120 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(225)) - Configuration:
2020-04-02 05:05:14,125 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(226)) - ---------------------------------------------------------------
2020-04-02 05:05:14,127 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   debug: false
2020-04-02 05:05:14,127 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   transport: TCP
2020-04-02 05:05:14,128 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   max.ticket.lifetime: 86400000
2020-04-02 05:05:14,128 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   org.name: EXAMPLE
2020-04-02 05:05:14,128 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   kdc.port: 0
2020-04-02 05:05:14,129 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   org.domain: COM
2020-04-02 05:05:14,129 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   max.renewable.lifetime: 604800000
2020-04-02 05:05:14,130 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   instance: DefaultKrbServer
2020-04-02 05:05:14,130 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   kdc.bind.address: localhost
2020-04-02 05:05:14,130 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(230)) - ---------------------------------------------------------------
2020-04-02 05:05:14,250 [main] INFO  minikdc.MiniKdc (MiniKdc.java:start(285)) - MiniKdc started.
[msx] test Started org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testServerSaslNoClientSasl
[msx] unitTestCounterInClass = 0
2020-04-02 05:05:14,937 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=3
Formatting using clusterid: testClusterID
2020-04-02 05:05:15,415 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:15,428 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:15,432 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:15,434 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:15,440 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:05:15,440 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:15,440 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:15,440 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:15,481 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:15,484 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:05:15,485 [Thread-1] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:15,485 [Thread-1] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:15,488 [Thread-1] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:15,488 [Thread-1] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:15
2020-04-02 05:05:15,490 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:15,490 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:15,491 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:05:15,492 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:15,509 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:15,509 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:15,526 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:15,526 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:15,527 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:15,527 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:15,527 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:15,527 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:15,527 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:15,527 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:15,527 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:15,528 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:15,528 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:15,548 [Thread-1] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:05:15,559 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:15,560 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:15,560 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:05:15,560 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:15,566 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:15,567 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:15,567 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:15,567 [Thread-1] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:15,572 [Thread-1] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:15,574 [Thread-1] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:15,579 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:15,580 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:15,580 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:05:15,580 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:15,590 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:15,590 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:15,590 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:15,594 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:15,595 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:15,597 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:15,597 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:15,598 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:05:15,598 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:15,822 [Thread-1] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:15,834 [Thread-1] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:05:15,837 [Thread-1] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:05:15,847 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:15,847 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:15,959 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:05:15,959 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:05:15,976 [Thread-1] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:05:15,979 [Thread-1] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:16,108 [Thread-1] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:05:16,159 [Thread-1] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:05:16,234 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:05:16,235 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:05:16,238 [Thread-1] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:16,257 [Thread-1] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:05:16,354 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803916324,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:16,366 [Thread-1] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:16,392 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7896dd5f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:16,405 [Thread-1] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:16,406 [Thread-1] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:0
2020-04-02 05:05:16,410 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:16,423 [Thread-1] INFO  util.log (Log.java:initialized(192)) - Logging initialized @2982ms
2020-04-02 05:05:16,543 [Thread-1] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:16,545 [Thread-1] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:16,546 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:16,551 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:16,553 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:16,554 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:16,554 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:16,589 [Thread-1] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:16,589 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:16,591 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:05:16,592 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:05:16,595 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41007
2020-04-02 05:05:16,597 [Thread-1] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:16,632 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2161af9b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:16,633 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4e8ff92b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:16,667 [Thread-1] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:16,671 [Thread-1] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:16,678 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@686ca46e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:16,689 [Thread-1] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@a51aa42(server,h=[],w=[]) for SslContextFactory@462ec93e(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/trustKS.jks)
2020-04-02 05:05:16,696 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@518576df{SSL,[ssl, http/1.1]}{localhost:41007}
2020-04-02 05:05:16,696 [Thread-1] INFO  server.Server (Server.java:doStart(419)) - Started @3254ms
2020-04-02 05:05:16,719 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:16,720 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:16,720 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:16,720 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:16,721 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:16,721 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:16,721 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:16,721 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:16,722 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:16,722 [Thread-1] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:16,722 [Thread-1] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:16,723 [Thread-1] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:16,723 [Thread-1] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:16
2020-04-02 05:05:16,723 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:16,723 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:16,724 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:05:16,724 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:16,727 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:16,727 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:16,746 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:16,746 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:16,746 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:16,747 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:16,747 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:16,747 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:16,747 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:16,747 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:16,747 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:16,747 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:16,747 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:16,748 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:16,748 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:16,748 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:05:16,748 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:16,754 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:16,755 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:16,755 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:16,756 [Thread-1] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:16,756 [Thread-1] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:16,756 [Thread-1] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:16,756 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:16,757 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:16,757 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:05:16,757 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:16,758 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:16,759 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:16,759 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:16,759 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:16,759 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:16,760 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:16,760 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:16,760 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:05:16,761 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:16,770 [Thread-1] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:16,774 [Thread-1] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:16,777 [Thread-1] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:05:16,777 [Thread-1] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:05:16,779 [Thread-1] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:05:16,779 [Thread-1] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:16,832 [Thread-1] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:16,843 [Thread-1] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:16,843 [Thread-1] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:16,850 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:16,860 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:05:16,891 [Thread-1] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:16,891 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 128 msecs
2020-04-02 05:05:17,051 [Thread-1] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:05:17,061 [Thread-1] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:17,075 [Socket Reader #1 for port 37139] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37139
2020-04-02 05:05:17,637 [Thread-1] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:37139 to access this namenode/service.
2020-04-02 05:05:17,642 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:17,666 [Thread-1] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:17,677 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@49d7df72] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:05:17,679 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:17,680 [Thread-1] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:05:17,680 [Thread-1] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:05:17,680 [Thread-1] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:17,680 [Thread-1] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:17,685 [Thread[Thread-31,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:05:17,685 [Thread[Thread-31,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:17,687 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:17,688 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:17,688 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:17,688 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:17,688 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:17,688 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2020-04-02 05:05:17,719 [IPC Server listener on 37139] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37139: starting
2020-04-02 05:05:17,719 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:17,721 [Thread-1] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:37139
2020-04-02 05:05:17,725 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:17,725 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:17,729 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 4 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:17,734 [CacheReplicationMonitor(795293137)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:17,734 [Thread-1] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 37139 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:17,743 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:17,765 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803917763,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:17,770 [Thread-1] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:17,844 [Thread-1] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:17,879 [Thread-1] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:17,891 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:17,891 [Thread-1] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:17,894 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:17,897 [Thread-1] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:17,900 [Thread-1] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:17,901 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:17,905 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:17,913 [Thread-1] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:41375
2020-04-02 05:05:17,915 [Thread-1] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:17,915 [Thread-1] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:17,932 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:17,934 [Thread-1] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:17,934 [Thread-1] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:17,935 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:17,936 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:17,937 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:17,937 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:17,938 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:17,941 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38729
2020-04-02 05:05:17,941 [Thread-1] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:17,942 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@18a1a9a6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:17,943 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@341aa31b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:17,948 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@466d4333{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:17,949 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4b9f5b0e{HTTP/1.1,[http/1.1]}{localhost:38729}
2020-04-02 05:05:17,950 [Thread-1] INFO  server.Server (Server.java:doStart(419)) - Started @4508ms
2020-04-02 05:05:18,247 [Thread-1] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:35068
2020-04-02 05:05:18,247 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5fe31bf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:18,248 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:18,248 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:18,261 [Thread-1] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:18,262 [Socket Reader #1 for port 44024] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44024
2020-04-02 05:05:18,267 [Thread-1] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:44024
2020-04-02 05:05:18,281 [Thread-1] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:18,283 [Thread-1] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:18,290 [Thread-63] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37139 starting to offer service
2020-04-02 05:05:18,295 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:18,295 [IPC Server listener on 44024] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44024: starting
2020-04-02 05:05:18,302 [Thread-1] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 44024 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:18,303 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:18,318 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803918316,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:18,324 [Thread-1] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:18,325 [Thread-1] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:18,326 [Thread-1] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:18,329 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:18,330 [Thread-1] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:18,331 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:18,332 [Thread-1] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:18,333 [Thread-1] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:18,333 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:18,334 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:18,335 [Thread-1] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:35723
2020-04-02 05:05:18,335 [Thread-1] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:18,335 [Thread-1] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:18,337 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:18,339 [Thread-1] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:18,339 [Thread-1] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:18,340 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:18,341 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:18,342 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:18,342 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:18,342 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:18,343 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42096
2020-04-02 05:05:18,343 [Thread-1] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:18,345 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1f2b8c3c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:18,345 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@31cb811d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:18,350 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6094a29e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:18,351 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@20b0303f{HTTP/1.1,[http/1.1]}{localhost:42096}
2020-04-02 05:05:18,351 [Thread-1] INFO  server.Server (Server.java:doStart(419)) - Started @4910ms
2020-04-02 05:05:18,430 [Thread-1] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:33986
2020-04-02 05:05:18,430 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:18,430 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2ce8b08] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:18,431 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:18,431 [Thread-1] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:18,432 [Socket Reader #1 for port 41978] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41978
2020-04-02 05:05:18,437 [Thread-1] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:41978
2020-04-02 05:05:18,442 [Thread-1] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:18,442 [Thread-1] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:18,443 [Thread-88] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37139 starting to offer service
2020-04-02 05:05:18,444 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:18,444 [IPC Server listener on 41978] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41978: starting
2020-04-02 05:05:18,448 [Thread-1] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 41978 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:18,451 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:18,461 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803918460,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:18,467 [Thread-1] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:18,468 [Thread-1] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:18,469 [Thread-1] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:18,472 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:18,472 [Thread-1] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:18,472 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:18,472 [Thread-1] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:18,473 [Thread-1] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:18,473 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:18,475 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:18,476 [Thread-1] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37665
2020-04-02 05:05:18,476 [Thread-1] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:18,476 [Thread-1] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:18,478 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:18,481 [Thread-1] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:18,482 [Thread-1] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:18,482 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:18,484 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:18,485 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:18,485 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:18,486 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:18,487 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41459
2020-04-02 05:05:18,487 [Thread-1] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:18,489 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7d96e2a3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:18,490 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6697275e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:18,497 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@43e950ba{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:18,499 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1f409cd2{HTTP/1.1,[http/1.1]}{localhost:41459}
2020-04-02 05:05:18,499 [Thread-1] INFO  server.Server (Server.java:doStart(419)) - Started @5057ms
2020-04-02 05:05:18,513 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803918512,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:18,514 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803918512,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:18,516 [Thread-1] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:41165
2020-04-02 05:05:18,517 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:18,517 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:18,517 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3218dee] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:18,518 [Thread-1] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:18,519 [Socket Reader #1 for port 36974] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36974
2020-04-02 05:05:18,522 [Thread-1] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:36974
2020-04-02 05:05:18,526 [Thread-1] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:18,526 [Thread-1] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:18,527 [Thread-112] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37139 starting to offer service
2020-04-02 05:05:18,529 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:18,529 [IPC Server listener on 36974] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36974: starting
2020-04-02 05:05:18,535 [Thread-1] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 36974 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:18,560 [Socket Reader #1 for port 37139] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:18,562 [Socket Reader #1 for port 37139] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:18,586 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803918574,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:18,606 [Socket Reader #1 for port 37139] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:18,798 [Thread-88] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37139
2020-04-02 05:05:18,802 [Thread-112] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37139
2020-04-02 05:05:18,802 [Thread-63] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37139
2020-04-02 05:05:18,828 [Thread-88] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:18,829 [Thread-63] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:18,829 [Thread-112] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:18,830 [Thread-88] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:18,831 [Thread-112] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:18,831 [Thread-112] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 2117453193. Formatting...
2020-04-02 05:05:18,832 [Thread-63] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:18,832 [Thread-63] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 2117453193. Formatting...
2020-04-02 05:05:18,831 [Thread-88] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 2117453193. Formatting...
2020-04-02 05:05:18,832 [Thread-63] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b8c08fb7-b24c-4390-99e6-274973128307 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:05:18,832 [Thread-112] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-eceb1fc8-44e1-43c6-8a01-0887434de3e3 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:05:18,833 [Thread-88] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-89909ed6-8561-4163-8b79-77ed22295c50 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:05:18,836 [Thread-88] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:18,836 [Thread-88] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 2117453193. Formatting...
2020-04-02 05:05:18,836 [Thread-88] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6f1bbf6e-ad94-4f6c-8b05-270b64906631 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:05:18,838 [Thread-112] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:18,838 [Thread-112] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 2117453193. Formatting...
2020-04-02 05:05:18,838 [Thread-112] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-48df290b-c543-40bc-b4f7-07d11f6d5f21 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:05:18,845 [Thread-63] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:18,846 [Thread-63] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 2117453193. Formatting...
2020-04-02 05:05:18,846 [Thread-63] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-89d50d99-c455-4189-ac7f-fca74271e815 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:05:18,855 [Thread-112] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:18,856 [Thread-112] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:18,856 [Thread-88] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:18,856 [Thread-112] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1756661227-172.17.0.5-1585803915812 is not formatted. Formatting ...
2020-04-02 05:05:18,857 [Thread-88] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:18,857 [Thread-112] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1756661227-172.17.0.5-1585803915812 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1756661227-172.17.0.5-1585803915812/current
2020-04-02 05:05:18,857 [Thread-88] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1756661227-172.17.0.5-1585803915812 is not formatted. Formatting ...
2020-04-02 05:05:18,858 [Thread-88] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1756661227-172.17.0.5-1585803915812 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1756661227-172.17.0.5-1585803915812/current
2020-04-02 05:05:18,872 [Thread-63] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:18,873 [Thread-63] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:18,873 [Thread-112] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:18,873 [Thread-88] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:18,873 [Thread-63] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1756661227-172.17.0.5-1585803915812 is not formatted. Formatting ...
2020-04-02 05:05:18,873 [Thread-112] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:18,874 [Thread-88] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:18,874 [Thread-112] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1756661227-172.17.0.5-1585803915812 is not formatted. Formatting ...
2020-04-02 05:05:18,874 [Thread-88] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1756661227-172.17.0.5-1585803915812 is not formatted. Formatting ...
2020-04-02 05:05:18,874 [Thread-88] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1756661227-172.17.0.5-1585803915812 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1756661227-172.17.0.5-1585803915812/current
2020-04-02 05:05:18,874 [Thread-63] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1756661227-172.17.0.5-1585803915812 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1756661227-172.17.0.5-1585803915812/current
2020-04-02 05:05:18,874 [Thread-112] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1756661227-172.17.0.5-1585803915812 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1756661227-172.17.0.5-1585803915812/current
2020-04-02 05:05:18,876 [Thread-112] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=2117453193;bpid=BP-1756661227-172.17.0.5-1585803915812;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=2117453193;c=1585803915812;bpid=BP-1756661227-172.17.0.5-1585803915812;dnuuid=null
2020-04-02 05:05:18,876 [Thread-88] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=2117453193;bpid=BP-1756661227-172.17.0.5-1585803915812;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=2117453193;c=1585803915812;bpid=BP-1756661227-172.17.0.5-1585803915812;dnuuid=null
2020-04-02 05:05:18,878 [Thread-88] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 01669730-e6cc-4c5a-9bfe-0e73ffb4ea45
2020-04-02 05:05:18,879 [Thread-112] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 8bad9b76-efe5-484a-9558-cd19a557c01d
2020-04-02 05:05:18,886 [Thread-63] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:18,887 [Thread-63] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:18,887 [Thread-63] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1756661227-172.17.0.5-1585803915812 is not formatted. Formatting ...
2020-04-02 05:05:18,887 [Thread-63] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1756661227-172.17.0.5-1585803915812 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1756661227-172.17.0.5-1585803915812/current
2020-04-02 05:05:18,889 [Thread-63] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=2117453193;bpid=BP-1756661227-172.17.0.5-1585803915812;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=2117453193;c=1585803915812;bpid=BP-1756661227-172.17.0.5-1585803915812;dnuuid=null
2020-04-02 05:05:18,893 [Thread-63] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 256b297c-9a03-4507-aa4c-30b3a8e2f3f9
2020-04-02 05:05:19,011 [Thread-63] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-b8c08fb7-b24c-4390-99e6-274973128307
2020-04-02 05:05:19,011 [Thread-63] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:05:19,011 [Thread-88] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-89909ed6-8561-4163-8b79-77ed22295c50
2020-04-02 05:05:19,020 [Thread-63] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-89d50d99-c455-4189-ac7f-fca74271e815
2020-04-02 05:05:19,011 [Thread-112] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-eceb1fc8-44e1-43c6-8a01-0887434de3e3
2020-04-02 05:05:19,022 [Thread-63] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:05:19,022 [Thread-88] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:05:19,022 [Thread-112] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:05:19,024 [Thread-112] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-48df290b-c543-40bc-b4f7-07d11f6d5f21
2020-04-02 05:05:19,025 [Thread-112] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:05:19,026 [Thread-88] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-6f1bbf6e-ad94-4f6c-8b05-270b64906631
2020-04-02 05:05:19,026 [Thread-88] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:05:19,026 [Thread-112] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:19,027 [Thread-88] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:19,027 [Thread-63] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:19,032 [Thread-112] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:19,033 [Thread-63] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:19,034 [Thread-88] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:19,043 [Thread-63] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:19,043 [Thread-88] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:19,043 [Thread-112] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:19,045 [Thread-63] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:19,045 [Thread-88] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:19,045 [Thread-63] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:19,045 [Thread-112] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:19,046 [Thread-88] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:19,047 [Thread-63] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:19,047 [Thread-112] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:19,047 [Thread-88] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:19,048 [Thread-112] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:19,048 [Thread-132] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:19,048 [Thread-134] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:05:19,048 [Thread-133] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:05:19,049 [Thread-135] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:19,049 [Thread-137] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:05:19,049 [Thread-136] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:05:19,073 [Socket Reader #1 for port 37139] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:19,092 [Thread-135] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1756661227-172.17.0.5-1585803915812 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 43ms
2020-04-02 05:05:19,092 [Thread-132] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1756661227-172.17.0.5-1585803915812 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 44ms
2020-04-02 05:05:19,093 [Thread-63] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1756661227-172.17.0.5-1585803915812: 45ms
2020-04-02 05:05:19,093 [Thread-134] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1756661227-172.17.0.5-1585803915812 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 45ms
2020-04-02 05:05:19,096 [Thread-133] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1756661227-172.17.0.5-1585803915812 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 47ms
2020-04-02 05:05:19,096 [Thread-137] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1756661227-172.17.0.5-1585803915812 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 47ms
2020-04-02 05:05:19,096 [Thread-136] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1756661227-172.17.0.5-1585803915812 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 47ms
2020-04-02 05:05:19,096 [Thread-88] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1756661227-172.17.0.5-1585803915812: 48ms
2020-04-02 05:05:19,096 [Thread-112] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1756661227-172.17.0.5-1585803915812: 48ms
2020-04-02 05:05:19,096 [Thread-145] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:19,096 [Thread-146] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:19,097 [Thread-145] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1756661227-172.17.0.5-1585803915812/current/replicas doesn't exist 
2020-04-02 05:05:19,098 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:05:19,097 [Thread-146] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1756661227-172.17.0.5-1585803915812/current/replicas doesn't exist 
2020-04-02 05:05:19,097 [Thread-148] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:05:19,097 [Thread-147] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:05:19,098 [Thread-148] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1756661227-172.17.0.5-1585803915812/current/replicas doesn't exist 
2020-04-02 05:05:19,098 [Thread-149] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1756661227-172.17.0.5-1585803915812/current/replicas doesn't exist 
2020-04-02 05:05:19,098 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:05:19,098 [Thread-147] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1756661227-172.17.0.5-1585803915812/current/replicas doesn't exist 
2020-04-02 05:05:19,099 [Thread-150] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1756661227-172.17.0.5-1585803915812/current/replicas doesn't exist 
2020-04-02 05:05:19,100 [Thread-145] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 3ms
2020-04-02 05:05:19,100 [Thread-147] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 2ms
2020-04-02 05:05:19,100 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 1ms
2020-04-02 05:05:19,100 [Thread-146] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 3ms
2020-04-02 05:05:19,100 [Thread-63] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1756661227-172.17.0.5-1585803915812: 5ms
2020-04-02 05:05:19,101 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 3ms
2020-04-02 05:05:19,107 [Thread-88] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1756661227-172.17.0.5-1585803915812: 10ms
2020-04-02 05:05:19,109 [Thread-148] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 11ms
2020-04-02 05:05:19,109 [Thread-112] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1756661227-172.17.0.5-1585803915812: 12ms
2020-04-02 05:05:19,111 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:19,112 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-48df290b-c543-40bc-b4f7-07d11f6d5f21): finished scanning block pool BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:19,111 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:19,111 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:19,115 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-6f1bbf6e-ad94-4f6c-8b05-270b64906631): finished scanning block pool BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:19,115 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-89909ed6-8561-4163-8b79-77ed22295c50): finished scanning block pool BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:19,111 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:19,119 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-eceb1fc8-44e1-43c6-8a01-0887434de3e3): finished scanning block pool BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:19,119 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:19,120 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1756661227-172.17.0.5-1585803915812 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:19,120 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-b8c08fb7-b24c-4390-99e6-274973128307): finished scanning block pool BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:19,120 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-89d50d99-c455-4189-ac7f-fca74271e815): finished scanning block pool BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:19,128 [Thread-112] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:43 AM with interval of 21600000ms
2020-04-02 05:05:19,128 [Thread-88] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:46 AM with interval of 21600000ms
2020-04-02 05:05:19,131 [Thread-63] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:08 AM with interval of 21600000ms
2020-04-02 05:05:19,146 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1756661227-172.17.0.5-1585803915812 (Datanode Uuid 256b297c-9a03-4507-aa4c-30b3a8e2f3f9) service to localhost/127.0.0.1:37139 beginning handshake with NN
2020-04-02 05:05:19,146 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1756661227-172.17.0.5-1585803915812 (Datanode Uuid 01669730-e6cc-4c5a-9bfe-0e73ffb4ea45) service to localhost/127.0.0.1:37139 beginning handshake with NN
2020-04-02 05:05:19,146 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1756661227-172.17.0.5-1585803915812 (Datanode Uuid 8bad9b76-efe5-484a-9558-cd19a557c01d) service to localhost/127.0.0.1:37139 beginning handshake with NN
2020-04-02 05:05:19,164 [IPC Server handler 4 on 37139] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41375, datanodeUuid=256b297c-9a03-4507-aa4c-30b3a8e2f3f9, infoPort=0, infoSecurePort=35068, ipcPort=44024, storageInfo=lv=-57;cid=testClusterID;nsid=2117453193;c=1585803915812) storage 256b297c-9a03-4507-aa4c-30b3a8e2f3f9
2020-04-02 05:05:19,165 [IPC Server handler 3 on 37139] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:19,167 [IPC Server handler 4 on 37139] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41375
2020-04-02 05:05:19,168 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-48df290b-c543-40bc-b4f7-07d11f6d5f21): no suitable block pools found to scan.  Waiting 1814399942 ms.
2020-04-02 05:05:19,168 [IPC Server handler 4 on 37139] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 256b297c-9a03-4507-aa4c-30b3a8e2f3f9 (127.0.0.1:41375).
2020-04-02 05:05:19,168 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-b8c08fb7-b24c-4390-99e6-274973128307): no suitable block pools found to scan.  Waiting 1814399951 ms.
2020-04-02 05:05:19,168 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-6f1bbf6e-ad94-4f6c-8b05-270b64906631): no suitable block pools found to scan.  Waiting 1814399942 ms.
2020-04-02 05:05:19,168 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-eceb1fc8-44e1-43c6-8a01-0887434de3e3): no suitable block pools found to scan.  Waiting 1814399943 ms.
2020-04-02 05:05:19,168 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-89d50d99-c455-4189-ac7f-fca74271e815): no suitable block pools found to scan.  Waiting 1814399951 ms.
2020-04-02 05:05:19,168 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-89909ed6-8561-4163-8b79-77ed22295c50): no suitable block pools found to scan.  Waiting 1814399943 ms.
2020-04-02 05:05:19,170 [IPC Server handler 5 on 37139] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35723, datanodeUuid=01669730-e6cc-4c5a-9bfe-0e73ffb4ea45, infoPort=0, infoSecurePort=33986, ipcPort=41978, storageInfo=lv=-57;cid=testClusterID;nsid=2117453193;c=1585803915812) storage 01669730-e6cc-4c5a-9bfe-0e73ffb4ea45
2020-04-02 05:05:19,171 [IPC Server handler 5 on 37139] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35723
2020-04-02 05:05:19,171 [IPC Server handler 5 on 37139] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 01669730-e6cc-4c5a-9bfe-0e73ffb4ea45 (127.0.0.1:35723).
2020-04-02 05:05:19,171 [IPC Server handler 7 on 37139] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37665, datanodeUuid=8bad9b76-efe5-484a-9558-cd19a557c01d, infoPort=0, infoSecurePort=41165, ipcPort=36974, storageInfo=lv=-57;cid=testClusterID;nsid=2117453193;c=1585803915812) storage 8bad9b76-efe5-484a-9558-cd19a557c01d
2020-04-02 05:05:19,171 [IPC Server handler 7 on 37139] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37665
2020-04-02 05:05:19,171 [IPC Server handler 7 on 37139] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8bad9b76-efe5-484a-9558-cd19a557c01d (127.0.0.1:37665).
2020-04-02 05:05:19,175 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:19,175 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:19,179 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1756661227-172.17.0.5-1585803915812 (Datanode Uuid 8bad9b76-efe5-484a-9558-cd19a557c01d) service to localhost/127.0.0.1:37139 successfully registered with NN
2020-04-02 05:05:19,179 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1756661227-172.17.0.5-1585803915812 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:19,180 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:19,180 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37139 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:19,182 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1756661227-172.17.0.5-1585803915812 (Datanode Uuid 01669730-e6cc-4c5a-9bfe-0e73ffb4ea45) service to localhost/127.0.0.1:37139 successfully registered with NN
2020-04-02 05:05:19,182 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1756661227-172.17.0.5-1585803915812 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:19,182 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:19,182 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37139 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:19,184 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1756661227-172.17.0.5-1585803915812 (Datanode Uuid 256b297c-9a03-4507-aa4c-30b3a8e2f3f9) service to localhost/127.0.0.1:37139 successfully registered with NN
2020-04-02 05:05:19,184 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1756661227-172.17.0.5-1585803915812 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:19,184 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:19,185 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37139 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:19,198 [IPC Server handler 9 on 37139] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b8c08fb7-b24c-4390-99e6-274973128307 for DN 127.0.0.1:41375
2020-04-02 05:05:19,199 [IPC Server handler 9 on 37139] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-89d50d99-c455-4189-ac7f-fca74271e815 for DN 127.0.0.1:41375
2020-04-02 05:05:19,200 [IPC Server handler 8 on 37139] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-89909ed6-8561-4163-8b79-77ed22295c50 for DN 127.0.0.1:35723
2020-04-02 05:05:19,201 [IPC Server handler 8 on 37139] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6f1bbf6e-ad94-4f6c-8b05-270b64906631 for DN 127.0.0.1:35723
2020-04-02 05:05:19,201 [IPC Server handler 6 on 37139] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-eceb1fc8-44e1-43c6-8a01-0887434de3e3 for DN 127.0.0.1:37665
2020-04-02 05:05:19,201 [IPC Server handler 6 on 37139] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-48df290b-c543-40bc-b4f7-07d11f6d5f21 for DN 127.0.0.1:37665
2020-04-02 05:05:19,230 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x315a17422ac93eaf: Processing first storage report for DS-eceb1fc8-44e1-43c6-8a01-0887434de3e3 from datanode 8bad9b76-efe5-484a-9558-cd19a557c01d
2020-04-02 05:05:19,232 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x315a17422ac93eaf: from storage DS-eceb1fc8-44e1-43c6-8a01-0887434de3e3 node DatanodeRegistration(127.0.0.1:37665, datanodeUuid=8bad9b76-efe5-484a-9558-cd19a557c01d, infoPort=0, infoSecurePort=41165, ipcPort=36974, storageInfo=lv=-57;cid=testClusterID;nsid=2117453193;c=1585803915812), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:05:19,233 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa09ee1051b270b32: Processing first storage report for DS-89909ed6-8561-4163-8b79-77ed22295c50 from datanode 01669730-e6cc-4c5a-9bfe-0e73ffb4ea45
2020-04-02 05:05:19,233 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa09ee1051b270b32: from storage DS-89909ed6-8561-4163-8b79-77ed22295c50 node DatanodeRegistration(127.0.0.1:35723, datanodeUuid=01669730-e6cc-4c5a-9bfe-0e73ffb4ea45, infoPort=0, infoSecurePort=33986, ipcPort=41978, storageInfo=lv=-57;cid=testClusterID;nsid=2117453193;c=1585803915812), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:19,233 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb97f2bf3ca7efc3b: Processing first storage report for DS-b8c08fb7-b24c-4390-99e6-274973128307 from datanode 256b297c-9a03-4507-aa4c-30b3a8e2f3f9
2020-04-02 05:05:19,233 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb97f2bf3ca7efc3b: from storage DS-b8c08fb7-b24c-4390-99e6-274973128307 node DatanodeRegistration(127.0.0.1:41375, datanodeUuid=256b297c-9a03-4507-aa4c-30b3a8e2f3f9, infoPort=0, infoSecurePort=35068, ipcPort=44024, storageInfo=lv=-57;cid=testClusterID;nsid=2117453193;c=1585803915812), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:19,233 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x315a17422ac93eaf: Processing first storage report for DS-48df290b-c543-40bc-b4f7-07d11f6d5f21 from datanode 8bad9b76-efe5-484a-9558-cd19a557c01d
2020-04-02 05:05:19,233 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x315a17422ac93eaf: from storage DS-48df290b-c543-40bc-b4f7-07d11f6d5f21 node DatanodeRegistration(127.0.0.1:37665, datanodeUuid=8bad9b76-efe5-484a-9558-cd19a557c01d, infoPort=0, infoSecurePort=41165, ipcPort=36974, storageInfo=lv=-57;cid=testClusterID;nsid=2117453193;c=1585803915812), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:19,233 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa09ee1051b270b32: Processing first storage report for DS-6f1bbf6e-ad94-4f6c-8b05-270b64906631 from datanode 01669730-e6cc-4c5a-9bfe-0e73ffb4ea45
2020-04-02 05:05:19,233 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa09ee1051b270b32: from storage DS-6f1bbf6e-ad94-4f6c-8b05-270b64906631 node DatanodeRegistration(127.0.0.1:35723, datanodeUuid=01669730-e6cc-4c5a-9bfe-0e73ffb4ea45, infoPort=0, infoSecurePort=33986, ipcPort=41978, storageInfo=lv=-57;cid=testClusterID;nsid=2117453193;c=1585803915812), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:05:19,234 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb97f2bf3ca7efc3b: Processing first storage report for DS-89d50d99-c455-4189-ac7f-fca74271e815 from datanode 256b297c-9a03-4507-aa4c-30b3a8e2f3f9
2020-04-02 05:05:19,234 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb97f2bf3ca7efc3b: from storage DS-89d50d99-c455-4189-ac7f-fca74271e815 node DatanodeRegistration(127.0.0.1:41375, datanodeUuid=256b297c-9a03-4507-aa4c-30b3a8e2f3f9, infoPort=0, infoSecurePort=35068, ipcPort=44024, storageInfo=lv=-57;cid=testClusterID;nsid=2117453193;c=1585803915812), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:19,251 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xb97f2bf3ca7efc3b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 33 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:19,251 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xa09ee1051b270b32,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 33 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:19,251 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x315a17422ac93eaf,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 33 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:19,252 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:19,252 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:19,252 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:19,279 [IPC Server handler 3 on 37139] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:19,288 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:19,297 [IPC Server handler 4 on 37139] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:19,299 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:19,348 [IPC Server handler 7 on 37139] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=create	src=/file1	dst=null	perm=hdfs:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:05:19,400 [IPC Server handler 5 on 37139] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:41375, 127.0.0.1:37665, 127.0.0.1:35723 for /file1
2020-04-02 05:05:19,481 [org.apache.hadoop.hdfs.server.datanode.DataXceiver@500921] INFO  datanode.DataNode (DataXceiver.java:run(245)) - Failed to read expected SASL data transfer protection handshake from client at /127.0.0.1:38438. Perhaps the client is running an older version of Hadoop which does not support SASL data transfer protection
org.apache.hadoop.hdfs.protocol.datatransfer.sasl.InvalidMagicNumberException: Received 1c50cb instead of deadbeef from client.
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferServer.doSaslHandshake(SaslDataTransferServer.java:364)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferServer.getSaslStreams(SaslDataTransferServer.java:300)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferServer.receive(SaslDataTransferServer.java:127)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:232)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:05:19,485 [Thread-160] INFO  hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1790)) - Exception in createBlockOutputStream blk_1073741825_1001
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:377)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:547)
	at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1762)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1679)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
2020-04-02 05:05:19,486 [Thread-160] WARN  hdfs.DataStreamer (DataStreamer.java:nextBlockOutputStream(1683)) - Abandoning BP-1756661227-172.17.0.5-1585803915812:blk_1073741825_1001
2020-04-02 05:05:19,492 [Thread-160] WARN  hdfs.DataStreamer (DataStreamer.java:nextBlockOutputStream(1688)) - Excluding datanode DatanodeInfoWithStorage[127.0.0.1:41375,DS-b8c08fb7-b24c-4390-99e6-274973128307,DISK]
2020-04-02 05:05:19,501 [IPC Server handler 9 on 37139] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2020-04-02 05:05:19,501 [IPC Server handler 9 on 37139] WARN  protocol.BlockStoragePolicy (BlockStoragePolicy.java:chooseStorageTypes(161)) - Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2020-04-02 05:05:19,501 [IPC Server handler 9 on 37139] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2020-04-02 05:05:19,502 [IPC Server handler 9 on 37139] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:35723, 127.0.0.1:37665 for /file1
2020-04-02 05:05:19,505 [org.apache.hadoop.hdfs.server.datanode.DataXceiver@31b94efa] INFO  datanode.DataNode (DataXceiver.java:run(245)) - Failed to read expected SASL data transfer protection handshake from client at /127.0.0.1:37636. Perhaps the client is running an older version of Hadoop which does not support SASL data transfer protection
org.apache.hadoop.hdfs.protocol.datatransfer.sasl.InvalidMagicNumberException: Received 1c50cf instead of deadbeef from client.
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferServer.doSaslHandshake(SaslDataTransferServer.java:364)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferServer.getSaslStreams(SaslDataTransferServer.java:300)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferServer.receive(SaslDataTransferServer.java:127)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:232)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:05:19,507 [Thread-160] INFO  hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1790)) - Exception in createBlockOutputStream blk_1073741826_1002
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:377)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:547)
	at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1762)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1679)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
2020-04-02 05:05:19,507 [Thread-160] WARN  hdfs.DataStreamer (DataStreamer.java:nextBlockOutputStream(1683)) - Abandoning BP-1756661227-172.17.0.5-1585803915812:blk_1073741826_1002
2020-04-02 05:05:19,510 [Thread-160] WARN  hdfs.DataStreamer (DataStreamer.java:nextBlockOutputStream(1688)) - Excluding datanode DatanodeInfoWithStorage[127.0.0.1:35723,DS-89909ed6-8561-4163-8b79-77ed22295c50,DISK]
2020-04-02 05:05:19,514 [IPC Server handler 1 on 37139] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2020-04-02 05:05:19,514 [IPC Server handler 1 on 37139] WARN  protocol.BlockStoragePolicy (BlockStoragePolicy.java:chooseStorageTypes(161)) - Failed to place enough replicas: expected size is 2 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2020-04-02 05:05:19,514 [IPC Server handler 1 on 37139] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2020-04-02 05:05:19,515 [IPC Server handler 1 on 37139] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:37665 for /file1
2020-04-02 05:05:19,520 [org.apache.hadoop.hdfs.server.datanode.DataXceiver@24ecb6be] INFO  datanode.DataNode (DataXceiver.java:run(245)) - Failed to read expected SASL data transfer protection handshake from client at /127.0.0.1:42270. Perhaps the client is running an older version of Hadoop which does not support SASL data transfer protection
org.apache.hadoop.hdfs.protocol.datatransfer.sasl.InvalidMagicNumberException: Received 1c50d2 instead of deadbeef from client.
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferServer.doSaslHandshake(SaslDataTransferServer.java:364)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferServer.getSaslStreams(SaslDataTransferServer.java:300)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferServer.receive(SaslDataTransferServer.java:127)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:232)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:05:19,527 [Thread-160] INFO  hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1790)) - Exception in createBlockOutputStream blk_1073741827_1003
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:377)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:547)
	at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1762)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1679)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
2020-04-02 05:05:19,528 [Thread-160] WARN  hdfs.DataStreamer (DataStreamer.java:nextBlockOutputStream(1683)) - Abandoning BP-1756661227-172.17.0.5-1585803915812:blk_1073741827_1003
2020-04-02 05:05:19,532 [Thread-160] WARN  hdfs.DataStreamer (DataStreamer.java:nextBlockOutputStream(1688)) - Excluding datanode DatanodeInfoWithStorage[127.0.0.1:37665,DS-eceb1fc8-44e1-43c6-8a01-0887434de3e3,DISK]
2020-04-02 05:05:19,536 [IPC Server handler 3 on 37139] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2020-04-02 05:05:19,537 [IPC Server handler 3 on 37139] WARN  protocol.BlockStoragePolicy (BlockStoragePolicy.java:chooseStorageTypes(161)) - Failed to place enough replicas: expected size is 3 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2020-04-02 05:05:19,537 [IPC Server handler 3 on 37139] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2020-04-02 05:05:19,538 [IPC Server handler 3 on 37139] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 3 on 37139, call Call#23 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 127.0.0.1:43445
java.io.IOException: File /file1 could only be written to 0 of the 1 minReplication nodes. There are 3 datanode(s) running and 3 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2121)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:295)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2702)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:05:19,545 [Thread-160] WARN  hdfs.DataStreamer (DataStreamer.java:run(826)) - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /file1 could only be written to 0 of the 1 minReplication nodes. There are 3 datanode(s) running and 3 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2121)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:295)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2702)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy26.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:510)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy30.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1866)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
2020-04-02 05:05:19,557 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:05:19,557 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:05:19,557 [Thread-1] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 36974 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:19,558 [Thread-1] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:19,558 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7b7887e6] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:19,560 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-eceb1fc8-44e1-43c6-8a01-0887434de3e3) exiting.
2020-04-02 05:05:19,561 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-48df290b-c543-40bc-b4f7-07d11f6d5f21) exiting.
2020-04-02 05:05:19,648 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@43e950ba{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:19,653 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1f409cd2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:19,653 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6697275e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:19,654 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7d96e2a3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:19,672 [Thread-1] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36974
2020-04-02 05:05:19,686 [IPC Server listener on 36974] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36974
2020-04-02 05:05:19,689 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:19,689 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:19,689 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1756661227-172.17.0.5-1585803915812 (Datanode Uuid 8bad9b76-efe5-484a-9558-cd19a557c01d) service to localhost/127.0.0.1:37139
2020-04-02 05:05:19,689 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1756661227-172.17.0.5-1585803915812 (Datanode Uuid 8bad9b76-efe5-484a-9558-cd19a557c01d)
2020-04-02 05:05:19,689 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:19,699 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1756661227-172.17.0.5-1585803915812] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:19,708 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1756661227-172.17.0.5-1585803915812] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:19,713 [Thread-1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:19,713 [Thread-1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:19,714 [Thread-1] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:19,714 [Thread-1] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:19,721 [Thread-1] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:19,721 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:05:19,721 [Thread-1] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 41978 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:19,721 [Thread-1] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:19,721 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6331f4a1] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:19,723 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-6f1bbf6e-ad94-4f6c-8b05-270b64906631) exiting.
2020-04-02 05:05:19,723 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-89909ed6-8561-4163-8b79-77ed22295c50) exiting.
2020-04-02 05:05:19,755 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6094a29e{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:19,756 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@20b0303f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:19,757 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@31cb811d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:19,757 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1f2b8c3c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:19,757 [Thread-1] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41978
2020-04-02 05:05:19,760 [IPC Server listener on 41978] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41978
2020-04-02 05:05:19,760 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:19,761 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:19,767 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1756661227-172.17.0.5-1585803915812 (Datanode Uuid 01669730-e6cc-4c5a-9bfe-0e73ffb4ea45) service to localhost/127.0.0.1:37139
2020-04-02 05:05:19,771 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1756661227-172.17.0.5-1585803915812 (Datanode Uuid 01669730-e6cc-4c5a-9bfe-0e73ffb4ea45)
2020-04-02 05:05:19,771 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:19,778 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1756661227-172.17.0.5-1585803915812] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:19,784 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1756661227-172.17.0.5-1585803915812] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:19,788 [Thread-1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:19,788 [Thread-1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:19,789 [Thread-1] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:19,789 [Thread-1] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:19,791 [Thread-1] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:19,791 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:05:19,791 [Thread-1] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 44024 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:19,791 [Thread-1] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:19,791 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@37dfb479] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:19,792 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-89d50d99-c455-4189-ac7f-fca74271e815) exiting.
2020-04-02 05:05:19,792 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-b8c08fb7-b24c-4390-99e6-274973128307) exiting.
2020-04-02 05:05:19,813 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@466d4333{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:19,814 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4b9f5b0e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:19,814 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@341aa31b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:19,814 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@18a1a9a6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:19,815 [Thread-1] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44024
2020-04-02 05:05:19,817 [IPC Server listener on 44024] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44024
2020-04-02 05:05:19,817 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:19,817 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:19,818 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1756661227-172.17.0.5-1585803915812 (Datanode Uuid 256b297c-9a03-4507-aa4c-30b3a8e2f3f9) service to localhost/127.0.0.1:37139
2020-04-02 05:05:19,919 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1756661227-172.17.0.5-1585803915812 (Datanode Uuid 256b297c-9a03-4507-aa4c-30b3a8e2f3f9)
2020-04-02 05:05:19,919 [BP-1756661227-172.17.0.5-1585803915812 heartbeating to localhost/127.0.0.1:37139] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1756661227-172.17.0.5-1585803915812
2020-04-02 05:05:19,929 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1756661227-172.17.0.5-1585803915812] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:19,946 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1756661227-172.17.0.5-1585803915812] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:19,956 [Thread-1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:19,961 [Thread-1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:19,967 [Thread-1] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:19,968 [Thread-1] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:19,971 [Thread-1] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:19,971 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:05:19,971 [Thread-1] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 37139 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:19,971 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:19,971 [Thread[Thread-31,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:05:19,972 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 16
2020-04-02 05:05:19,972 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@1609d9a8] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:05:19,975 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@3fefc5c0] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:05:19,977 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 17 Total time for transactions(ms): 24 Number of transactions batched in Syncs: 3 Number of syncs: 15 SyncTimes(ms): 1 1 
2020-04-02 05:05:19,979 [Thread-1] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000017
2020-04-02 05:05:19,979 [Thread-1] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000017
2020-04-02 05:05:19,980 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:05:19,981 [CacheReplicationMonitor(795293137)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:05:19,996 [Thread-1] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37139
2020-04-02 05:05:19,998 [IPC Server listener on 37139] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37139
2020-04-02 05:05:20,002 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:05:20,002 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:05:20,005 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:20,045 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:20,046 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:05:20,047 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@686ca46e{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:05:20,050 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@518576df{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:05:20,050 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4e8ff92b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:20,051 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2161af9b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:20,062 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:05:20,076 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:05:20,077 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testServerSaslNoClientSasl
[msx] writeFile testName = org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testServerSaslNoClientSasl
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testSaslDataTransferWithTrustedServerUntrustedClient
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Finished org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testSaslDataTransferWithTrustedServerUntrustedClient
[msx] writeFile testName = org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testSaslDataTransferWithTrustedServerUntrustedClient
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testClientAndServerDoNotHaveCommonQop
[msx] perform reset as unitTestCounterInClass 2 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:05:20,338 [Thread-169] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=3
2020-04-02 05:05:20,346 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803920345,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:20,352 [Thread-169] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
Formatting using clusterid: testClusterID
2020-04-02 05:05:20,353 [Thread-169] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:20,353 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:20,354 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:20,354 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:20,354 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:20,354 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:20,354 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:20,354 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:20,355 [Thread-169] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:20,355 [Thread-169] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:20,355 [Thread-169] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:20,355 [Thread-169] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:20,356 [Thread-169] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:20
2020-04-02 05:05:20,356 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:20,356 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:20,356 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 37.5 MB
2020-04-02 05:05:20,356 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:20,360 [Thread-169] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:20,360 [Thread-169] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:20,361 [Thread-169] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:20,361 [Thread-169] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:20,361 [Thread-169] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:20,361 [Thread-169] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:20,361 [Thread-169] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:20,361 [Thread-169] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:20,361 [Thread-169] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:20,361 [Thread-169] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:20,361 [Thread-169] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:20,361 [Thread-169] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:20,361 [Thread-169] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:20,362 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:20,362 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:20,362 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.7 MB
2020-04-02 05:05:20,362 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:20,364 [Thread-169] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:20,364 [Thread-169] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:20,364 [Thread-169] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:20,364 [Thread-169] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:20,364 [Thread-169] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:20,364 [Thread-169] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:20,364 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:20,364 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:20,364 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.7 MB
2020-04-02 05:05:20,364 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:20,365 [Thread-169] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:20,365 [Thread-169] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:20,365 [Thread-169] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:20,366 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:20,366 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:20,366 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:20,366 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:20,366 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 575.8 KB
2020-04-02 05:05:20,366 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:20,367 [Thread-169] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:20,371 [Thread-169] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:05:20,373 [Thread-169] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:05:20,377 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:20,377 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:20,389 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:05:20,389 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:05:20,394 [Thread-169] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:05:20,397 [Thread-169] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:20,402 [Thread-169] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:05:20,404 [Thread-169] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:05:20,404 [Thread-169] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:05:20,405 [Thread-169] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:20,406 [Thread-169] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:05:20,413 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803920412,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:20,419 [Thread-169] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:20,433 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@243fbd1b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:20,434 [Thread-169] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:20,434 [Thread-169] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:0
2020-04-02 05:05:20,435 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:20,436 [Thread-169] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:20,437 [Thread-169] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:20,437 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:20,438 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:20,439 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:20,439 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:20,439 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:20,441 [Thread-169] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:20,441 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:20,441 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:05:20,441 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:05:20,441 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35259
2020-04-02 05:05:20,441 [Thread-169] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:20,443 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@8d3e314{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:20,444 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@15fae622{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:20,448 [Thread-169] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:20,448 [Thread-169] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:20,449 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@35bc46a4{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:20,451 [Thread-169] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@63234926(server,h=[],w=[]) for SslContextFactory@1c074d4e(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/trustKS.jks)
2020-04-02 05:05:20,455 [Thread-169] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@19106020{SSL,[ssl, http/1.1]}{localhost:35259}
2020-04-02 05:05:20,455 [Thread-169] INFO  server.Server (Server.java:doStart(419)) - Started @7013ms
2020-04-02 05:05:20,457 [Thread-169] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:20,458 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:20,458 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:20,459 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:20,459 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:20,459 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:20,459 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:20,459 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:20,459 [Thread-169] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:20,460 [Thread-169] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:20,460 [Thread-169] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:20,460 [Thread-169] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:20,460 [Thread-169] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:20
2020-04-02 05:05:20,460 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:20,460 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:20,460 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 37.5 MB
2020-04-02 05:05:20,461 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:20,463 [Thread-169] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:20,464 [Thread-169] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:20,464 [Thread-169] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:20,464 [Thread-169] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:20,464 [Thread-169] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:20,464 [Thread-169] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:20,465 [Thread-169] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:20,465 [Thread-169] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:20,465 [Thread-169] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:20,465 [Thread-169] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:20,465 [Thread-169] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:20,465 [Thread-169] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:20,465 [Thread-169] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:20,465 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:20,465 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:20,465 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.7 MB
2020-04-02 05:05:20,466 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:20,468 [Thread-169] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:20,468 [Thread-169] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:20,468 [Thread-169] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:20,468 [Thread-169] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:20,468 [Thread-169] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:20,468 [Thread-169] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:20,468 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:20,468 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:20,468 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.7 MB
2020-04-02 05:05:20,468 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:20,469 [Thread-169] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:20,469 [Thread-169] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:20,469 [Thread-169] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:20,469 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:20,470 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:20,470 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:20,470 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:20,470 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 575.8 KB
2020-04-02 05:05:20,470 [Thread-169] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:20,472 [Thread-169] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:20,473 [Thread-169] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:20,474 [Thread-169] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:05:20,474 [Thread-169] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:05:20,475 [Thread-169] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:05:20,475 [Thread-169] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:20,476 [Thread-169] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:20,477 [Thread-169] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:20,477 [Thread-169] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:20,477 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:20,477 [Thread-169] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:05:20,490 [Thread-169] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:20,490 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 19 msecs
2020-04-02 05:05:20,490 [Thread-169] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:05:20,491 [Thread-169] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:20,492 [Socket Reader #1 for port 40041] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40041
2020-04-02 05:05:20,497 [Thread-169] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:40041 to access this namenode/service.
2020-04-02 05:05:20,498 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:20,535 [Thread-169] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:20,538 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@318f9683] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:05:20,540 [Thread-169] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:20,540 [Thread-169] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:05:20,540 [Thread-169] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:05:20,540 [Thread-169] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:20,551 [Thread-169] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:20,555 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:20,555 [Thread[Thread-197,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:05:20,555 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:20,557 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:20,557 [Thread[Thread-197,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:20,557 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:20,560 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:20,560 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 20 msec
2020-04-02 05:05:20,565 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:20,565 [IPC Server listener on 40041] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40041: starting
2020-04-02 05:05:20,566 [Thread-169] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:40041
2020-04-02 05:05:20,567 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:20,567 [Thread-169] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:20,568 [Thread-169] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:20,569 [Thread-169] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 40041 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:20,574 [CacheReplicationMonitor(1365563793)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:20,585 [Thread-169] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:20,591 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803920590,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:20,596 [Thread-169] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:20,597 [Thread-169] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:20,598 [Thread-169] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:20,610 [Thread-169] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:20,611 [Thread-169] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:20,611 [Thread-169] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:20,611 [Thread-169] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:20,612 [Thread-169] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:20,612 [Thread-169] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:20,613 [Thread-169] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:20,614 [Thread-169] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:44276
2020-04-02 05:05:20,614 [Thread-169] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:20,614 [Thread-169] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:20,615 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:20,618 [Thread-169] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:20,619 [Thread-169] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:20,619 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:20,621 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:20,621 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:20,621 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:20,621 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:20,622 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37743
2020-04-02 05:05:20,622 [Thread-169] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:20,631 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7c5a4964{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:20,632 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@202eefde{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:20,637 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2a7c8ae1{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:20,640 [Thread-169] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@58ce166d{HTTP/1.1,[http/1.1]}{localhost:37743}
2020-04-02 05:05:20,641 [Thread-169] INFO  server.Server (Server.java:doStart(419)) - Started @7199ms
2020-04-02 05:05:20,764 [Thread-169] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:36090
2020-04-02 05:05:20,765 [Thread-169] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:20,765 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@263b839] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:20,765 [Thread-169] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:20,765 [Thread-169] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:20,766 [Socket Reader #1 for port 36770] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36770
2020-04-02 05:05:20,773 [Thread-169] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:36770
2020-04-02 05:05:20,782 [Thread-169] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:20,782 [Thread-169] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:20,783 [Thread-226] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40041 starting to offer service
2020-04-02 05:05:20,814 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:20,814 [IPC Server listener on 36770] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36770: starting
2020-04-02 05:05:20,820 [Thread-169] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 36770 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:20,823 [Thread-169] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:20,836 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803920836,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:20,836 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803920836,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:20,841 [Thread-169] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:20,845 [Thread-169] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:20,846 [Thread-169] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:20,860 [Thread-169] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:20,860 [Thread-169] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:20,860 [Thread-169] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:20,860 [Thread-169] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:20,861 [Thread-169] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:20,861 [Thread-169] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:20,862 [Thread-169] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:20,885 [Thread-169] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:33213
2020-04-02 05:05:20,885 [Thread-169] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:20,885 [Thread-169] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:20,889 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:20,891 [Thread-169] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:20,892 [Thread-169] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:20,892 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:20,893 [Socket Reader #1 for port 40041] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:20,893 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:20,899 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:20,925 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:20,925 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:20,926 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 36506
2020-04-02 05:05:20,926 [Thread-169] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:20,934 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4180c4ca{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:20,947 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@76f7de98{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:20,948 [Thread-226] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40041
2020-04-02 05:05:20,953 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5f54418c{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:20,954 [Thread-169] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@63db1d83{HTTP/1.1,[http/1.1]}{localhost:36506}
2020-04-02 05:05:20,954 [Thread-169] INFO  server.Server (Server.java:doStart(419)) - Started @7512ms
2020-04-02 05:05:20,964 [Thread-226] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:20,965 [Thread-226] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:20,966 [Thread-226] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1779644608. Formatting...
2020-04-02 05:05:20,966 [Thread-226] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-59fe4c53-a604-41b7-b053-735ede622bd2 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:05:20,969 [Thread-226] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:20,969 [Thread-226] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1779644608. Formatting...
2020-04-02 05:05:20,969 [Thread-226] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-fa82164b-d741-4359-b666-0b24dc694860 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:05:20,978 [Thread-226] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:20,978 [Thread-226] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:20,979 [Thread-226] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-473321646-172.17.0.5-1585803920367 is not formatted. Formatting ...
2020-04-02 05:05:20,979 [Thread-226] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-473321646-172.17.0.5-1585803920367 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-473321646-172.17.0.5-1585803920367/current
2020-04-02 05:05:20,983 [Thread-169] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:46638
2020-04-02 05:05:20,984 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@653ebb61] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:20,984 [Thread-169] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:20,984 [Thread-169] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:20,985 [Thread-169] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:20,985 [Socket Reader #1 for port 36136] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36136
2020-04-02 05:05:21,002 [Thread-169] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:36136
2020-04-02 05:05:21,011 [Thread-169] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:21,012 [Thread-169] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:21,012 [Thread-226] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,013 [Thread-250] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40041 starting to offer service
2020-04-02 05:05:21,018 [Thread-226] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,018 [Thread-226] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-473321646-172.17.0.5-1585803920367 is not formatted. Formatting ...
2020-04-02 05:05:21,018 [Thread-226] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-473321646-172.17.0.5-1585803920367 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-473321646-172.17.0.5-1585803920367/current
2020-04-02 05:05:21,020 [Thread-226] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1779644608;bpid=BP-473321646-172.17.0.5-1585803920367;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1779644608;c=1585803920367;bpid=BP-473321646-172.17.0.5-1585803920367;dnuuid=null
2020-04-02 05:05:21,021 [Thread-226] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID e2690242-9057-4981-9a6a-8f4502626b80
2020-04-02 05:05:21,022 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:21,025 [IPC Server listener on 36136] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36136: starting
2020-04-02 05:05:21,033 [Thread-169] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 36136 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:21,038 [Thread-169] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:21,054 [Thread-226] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-59fe4c53-a604-41b7-b053-735ede622bd2
2020-04-02 05:05:21,057 [Thread-226] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:05:21,067 [Thread-226] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-fa82164b-d741-4359-b666-0b24dc694860
2020-04-02 05:05:21,067 [Thread-226] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:05:21,071 [Thread-226] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:21,071 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803921065,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:21,072 [Thread-226] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:21,073 [Thread-226] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:21,090 [Thread-226] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:21,090 [Thread-226] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:21,078 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803921077,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:21,093 [Thread-226] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,096 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:21,096 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:21,097 [Thread-169] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:21,098 [Thread-169] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:21,102 [Thread-169] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:21,135 [Socket Reader #1 for port 40041] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:21,140 [Thread-169] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:21,143 [Thread-169] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:21,144 [Thread-169] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:21,147 [Thread-169] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:21,148 [Thread-169] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:21,148 [Thread-169] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:21,148 [Thread-250] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40041
2020-04-02 05:05:21,150 [Thread-250] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:21,150 [Thread-169] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:21,151 [Thread-169] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37567
2020-04-02 05:05:21,151 [Thread-169] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:21,151 [Thread-169] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:21,152 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:21,152 [Thread-250] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:21,153 [Thread-250] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1779644608. Formatting...
2020-04-02 05:05:21,153 [Thread-250] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5644d64e-e996-41a6-a6f5-86b70ec32d22 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:05:21,153 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-473321646-172.17.0.5-1585803920367 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 57ms
2020-04-02 05:05:21,157 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-473321646-172.17.0.5-1585803920367 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 61ms
2020-04-02 05:05:21,157 [Thread-226] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-473321646-172.17.0.5-1585803920367: 62ms
2020-04-02 05:05:21,157 [Thread-169] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:21,158 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:21,158 [Thread-272] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:21,158 [Thread-169] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:21,158 [Thread-271] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-473321646-172.17.0.5-1585803920367/current/replicas doesn't exist 
2020-04-02 05:05:21,158 [Thread-272] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-473321646-172.17.0.5-1585803920367/current/replicas doesn't exist 
2020-04-02 05:05:21,158 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:21,159 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:05:21,159 [Thread-272] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:05:21,159 [Thread-226] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-473321646-172.17.0.5-1585803920367: 2ms
2020-04-02 05:05:21,159 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:21,160 [Thread-250] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:21,160 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-59fe4c53-a604-41b7-b053-735ede622bd2): finished scanning block pool BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,159 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:21,160 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:21,160 [Thread-250] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1779644608. Formatting...
2020-04-02 05:05:21,160 [Thread-226] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:57 AM with interval of 21600000ms
2020-04-02 05:05:21,161 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-fa82164b-d741-4359-b666-0b24dc694860): finished scanning block pool BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,161 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-59fe4c53-a604-41b7-b053-735ede622bd2): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:05:21,161 [Thread-250] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e2f3ddf0-caa6-4802-ad11-abfc5a4a698b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:05:21,161 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:21,165 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-473321646-172.17.0.5-1585803920367 (Datanode Uuid e2690242-9057-4981-9a6a-8f4502626b80) service to localhost/127.0.0.1:40041 beginning handshake with NN
2020-04-02 05:05:21,165 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:21,165 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-fa82164b-d741-4359-b666-0b24dc694860): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-04-02 05:05:21,165 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:21,172 [Thread-169] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44391
2020-04-02 05:05:21,172 [Thread-169] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:21,172 [IPC Server handler 2 on 40041] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44276, datanodeUuid=e2690242-9057-4981-9a6a-8f4502626b80, infoPort=0, infoSecurePort=36090, ipcPort=36770, storageInfo=lv=-57;cid=testClusterID;nsid=1779644608;c=1585803920367) storage e2690242-9057-4981-9a6a-8f4502626b80
2020-04-02 05:05:21,173 [IPC Server handler 2 on 40041] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44276
2020-04-02 05:05:21,173 [IPC Server handler 2 on 40041] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e2690242-9057-4981-9a6a-8f4502626b80 (127.0.0.1:44276).
2020-04-02 05:05:21,177 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1d56f038{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:21,177 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-473321646-172.17.0.5-1585803920367 (Datanode Uuid e2690242-9057-4981-9a6a-8f4502626b80) service to localhost/127.0.0.1:40041 successfully registered with NN
2020-04-02 05:05:21,177 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-473321646-172.17.0.5-1585803920367 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:21,177 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:21,177 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40041 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:21,178 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@512aa589{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:21,188 [IPC Server handler 3 on 40041] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-59fe4c53-a604-41b7-b053-735ede622bd2 for DN 127.0.0.1:44276
2020-04-02 05:05:21,188 [IPC Server handler 3 on 40041] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fa82164b-d741-4359-b666-0b24dc694860 for DN 127.0.0.1:44276
2020-04-02 05:05:21,195 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@60535361{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:21,196 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x29ed2d908740b15f: Processing first storage report for DS-59fe4c53-a604-41b7-b053-735ede622bd2 from datanode e2690242-9057-4981-9a6a-8f4502626b80
2020-04-02 05:05:21,196 [Thread-169] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@14d1c092{HTTP/1.1,[http/1.1]}{localhost:44391}
2020-04-02 05:05:21,199 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x29ed2d908740b15f: from storage DS-59fe4c53-a604-41b7-b053-735ede622bd2 node DatanodeRegistration(127.0.0.1:44276, datanodeUuid=e2690242-9057-4981-9a6a-8f4502626b80, infoPort=0, infoSecurePort=36090, ipcPort=36770, storageInfo=lv=-57;cid=testClusterID;nsid=1779644608;c=1585803920367), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:21,199 [Thread-169] INFO  server.Server (Server.java:doStart(419)) - Started @7758ms
2020-04-02 05:05:21,199 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x29ed2d908740b15f: Processing first storage report for DS-fa82164b-d741-4359-b666-0b24dc694860 from datanode e2690242-9057-4981-9a6a-8f4502626b80
2020-04-02 05:05:21,200 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x29ed2d908740b15f: from storage DS-fa82164b-d741-4359-b666-0b24dc694860 node DatanodeRegistration(127.0.0.1:44276, datanodeUuid=e2690242-9057-4981-9a6a-8f4502626b80, infoPort=0, infoSecurePort=36090, ipcPort=36770, storageInfo=lv=-57;cid=testClusterID;nsid=1779644608;c=1585803920367), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:21,201 [Thread-250] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,204 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x29ed2d908740b15f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 8 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:21,204 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,204 [Thread-250] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,207 [Thread-250] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-473321646-172.17.0.5-1585803920367 is not formatted. Formatting ...
2020-04-02 05:05:21,207 [Thread-250] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-473321646-172.17.0.5-1585803920367 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-473321646-172.17.0.5-1585803920367/current
2020-04-02 05:05:21,219 [Thread-250] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,219 [Thread-250] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,219 [Thread-250] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-473321646-172.17.0.5-1585803920367 is not formatted. Formatting ...
2020-04-02 05:05:21,219 [Thread-250] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-473321646-172.17.0.5-1585803920367 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-473321646-172.17.0.5-1585803920367/current
2020-04-02 05:05:21,227 [Thread-250] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1779644608;bpid=BP-473321646-172.17.0.5-1585803920367;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1779644608;c=1585803920367;bpid=BP-473321646-172.17.0.5-1585803920367;dnuuid=null
2020-04-02 05:05:21,227 [Thread-169] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:44744
2020-04-02 05:05:21,228 [Thread-169] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:21,228 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@a7ecfdd] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:21,228 [Thread-169] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:21,229 [Thread-169] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:21,229 [Thread-250] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 12bd8206-e09a-4a4f-a634-aa68be51e4bd
2020-04-02 05:05:21,229 [Socket Reader #1 for port 43320] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43320
2020-04-02 05:05:21,234 [Thread-250] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5644d64e-e996-41a6-a6f5-86b70ec32d22
2020-04-02 05:05:21,236 [Thread-250] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:05:21,238 [Thread-169] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43320
2020-04-02 05:05:21,239 [Thread-250] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-e2f3ddf0-caa6-4802-ad11-abfc5a4a698b
2020-04-02 05:05:21,241 [Thread-250] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:05:21,241 [Thread-250] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:21,250 [Thread-250] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:21,254 [Thread-250] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:21,254 [Thread-250] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:21,255 [Thread-250] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:21,259 [Thread-250] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,260 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:05:21,260 [Thread-169] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:21,260 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:05:21,260 [Thread-169] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:21,261 [Thread-289] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40041 starting to offer service
2020-04-02 05:05:21,263 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:21,264 [IPC Server listener on 43320] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43320: starting
2020-04-02 05:05:21,272 [Thread-169] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43320 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:21,294 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-473321646-172.17.0.5-1585803920367 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 34ms
2020-04-02 05:05:21,299 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-473321646-172.17.0.5-1585803920367 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 39ms
2020-04-02 05:05:21,299 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803921298,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:21,303 [Thread-250] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-473321646-172.17.0.5-1585803920367: 44ms
2020-04-02 05:05:21,304 [Thread-304] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:05:21,304 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:05:21,304 [Thread-304] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-473321646-172.17.0.5-1585803920367/current/replicas doesn't exist 
2020-04-02 05:05:21,304 [Thread-305] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-473321646-172.17.0.5-1585803920367/current/replicas doesn't exist 
2020-04-02 05:05:21,305 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-04-02 05:05:21,305 [Thread-304] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-04-02 05:05:21,308 [Thread-250] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-473321646-172.17.0.5-1585803920367: 5ms
2020-04-02 05:05:21,309 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:21,309 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:21,309 [Thread-250] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:45 AM with interval of 21600000ms
2020-04-02 05:05:21,309 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-5644d64e-e996-41a6-a6f5-86b70ec32d22): finished scanning block pool BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,309 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-e2f3ddf0-caa6-4802-ad11-abfc5a4a698b): finished scanning block pool BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,312 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-473321646-172.17.0.5-1585803920367 (Datanode Uuid 12bd8206-e09a-4a4f-a634-aa68be51e4bd) service to localhost/127.0.0.1:40041 beginning handshake with NN
2020-04-02 05:05:21,315 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-e2f3ddf0-caa6-4802-ad11-abfc5a4a698b): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:05:21,315 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-5644d64e-e996-41a6-a6f5-86b70ec32d22): no suitable block pools found to scan.  Waiting 1814399993 ms.
2020-04-02 05:05:21,320 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803921315,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:21,324 [IPC Server handler 5 on 40041] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33213, datanodeUuid=12bd8206-e09a-4a4f-a634-aa68be51e4bd, infoPort=0, infoSecurePort=46638, ipcPort=36136, storageInfo=lv=-57;cid=testClusterID;nsid=1779644608;c=1585803920367) storage 12bd8206-e09a-4a4f-a634-aa68be51e4bd
2020-04-02 05:05:21,325 [IPC Server handler 5 on 40041] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33213
2020-04-02 05:05:21,325 [IPC Server handler 5 on 40041] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 12bd8206-e09a-4a4f-a634-aa68be51e4bd (127.0.0.1:33213).
2020-04-02 05:05:21,326 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-473321646-172.17.0.5-1585803920367 (Datanode Uuid 12bd8206-e09a-4a4f-a634-aa68be51e4bd) service to localhost/127.0.0.1:40041 successfully registered with NN
2020-04-02 05:05:21,326 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-473321646-172.17.0.5-1585803920367 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:21,326 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:21,327 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40041 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:21,335 [Socket Reader #1 for port 40041] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:21,339 [IPC Server handler 6 on 40041] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5644d64e-e996-41a6-a6f5-86b70ec32d22 for DN 127.0.0.1:33213
2020-04-02 05:05:21,344 [IPC Server handler 6 on 40041] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e2f3ddf0-caa6-4802-ad11-abfc5a4a698b for DN 127.0.0.1:33213
2020-04-02 05:05:21,350 [Socket Reader #1 for port 40041] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:21,350 [Thread-289] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40041
2020-04-02 05:05:21,352 [Thread-289] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:21,357 [Thread-289] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:21,364 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa3f4c7682befb238: Processing first storage report for DS-5644d64e-e996-41a6-a6f5-86b70ec32d22 from datanode 12bd8206-e09a-4a4f-a634-aa68be51e4bd
2020-04-02 05:05:21,364 [Thread-289] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1779644608. Formatting...
2020-04-02 05:05:21,365 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa3f4c7682befb238: from storage DS-5644d64e-e996-41a6-a6f5-86b70ec32d22 node DatanodeRegistration(127.0.0.1:33213, datanodeUuid=12bd8206-e09a-4a4f-a634-aa68be51e4bd, infoPort=0, infoSecurePort=46638, ipcPort=36136, storageInfo=lv=-57;cid=testClusterID;nsid=1779644608;c=1585803920367), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:05:21,365 [Thread-289] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c58ac40b-bb57-446b-b62e-af3d2236e55a for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:05:21,365 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa3f4c7682befb238: Processing first storage report for DS-e2f3ddf0-caa6-4802-ad11-abfc5a4a698b from datanode 12bd8206-e09a-4a4f-a634-aa68be51e4bd
2020-04-02 05:05:21,365 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa3f4c7682befb238: from storage DS-e2f3ddf0-caa6-4802-ad11-abfc5a4a698b node DatanodeRegistration(127.0.0.1:33213, datanodeUuid=12bd8206-e09a-4a4f-a634-aa68be51e4bd, infoPort=0, infoSecurePort=46638, ipcPort=36136, storageInfo=lv=-57;cid=testClusterID;nsid=1779644608;c=1585803920367), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:21,369 [IPC Server handler 9 on 40041] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:21,378 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xa3f4c7682befb238,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 22 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:21,379 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,382 [Thread-169] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:21,382 [Thread-169] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:21,382 [Thread-289] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:21,383 [Thread-289] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1779644608. Formatting...
2020-04-02 05:05:21,383 [Thread-289] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3e32c979-647f-4c70-9575-d137d2cdec53 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:05:21,400 [Thread-289] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,400 [Thread-289] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,400 [Thread-289] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-473321646-172.17.0.5-1585803920367 is not formatted. Formatting ...
2020-04-02 05:05:21,401 [Thread-289] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-473321646-172.17.0.5-1585803920367 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-473321646-172.17.0.5-1585803920367/current
2020-04-02 05:05:21,410 [Thread-289] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,410 [Thread-289] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,411 [Thread-289] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-473321646-172.17.0.5-1585803920367 is not formatted. Formatting ...
2020-04-02 05:05:21,411 [Thread-289] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-473321646-172.17.0.5-1585803920367 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-473321646-172.17.0.5-1585803920367/current
2020-04-02 05:05:21,413 [Thread-289] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1779644608;bpid=BP-473321646-172.17.0.5-1585803920367;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1779644608;c=1585803920367;bpid=BP-473321646-172.17.0.5-1585803920367;dnuuid=null
2020-04-02 05:05:21,414 [Thread-289] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID ecff7edf-ed59-4801-a4f4-4be17a1ae967
2020-04-02 05:05:21,418 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c58ac40b-bb57-446b-b62e-af3d2236e55a
2020-04-02 05:05:21,420 [Thread-289] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:05:21,422 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-3e32c979-647f-4c70-9575-d137d2cdec53
2020-04-02 05:05:21,423 [Thread-289] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:05:21,425 [Thread-289] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:21,427 [Thread-289] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:21,429 [Thread-289] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:21,429 [Thread-289] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:21,429 [Thread-289] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:21,433 [Thread-289] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,433 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:05:21,433 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:05:21,476 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-473321646-172.17.0.5-1585803920367 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 43ms
2020-04-02 05:05:21,476 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-473321646-172.17.0.5-1585803920367 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 43ms
2020-04-02 05:05:21,476 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-473321646-172.17.0.5-1585803920367: 44ms
2020-04-02 05:05:21,477 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:05:21,477 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:05:21,477 [Thread-315] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-473321646-172.17.0.5-1585803920367/current/replicas doesn't exist 
2020-04-02 05:05:21,477 [Thread-316] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-473321646-172.17.0.5-1585803920367/current/replicas doesn't exist 
2020-04-02 05:05:21,478 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 1ms
2020-04-02 05:05:21,478 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 1ms
2020-04-02 05:05:21,478 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-473321646-172.17.0.5-1585803920367: 1ms
2020-04-02 05:05:21,478 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:21,478 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-473321646-172.17.0.5-1585803920367 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:21,479 [Thread-289] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:44 AM with interval of 21600000ms
2020-04-02 05:05:21,479 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-3e32c979-647f-4c70-9575-d137d2cdec53): finished scanning block pool BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,479 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c58ac40b-bb57-446b-b62e-af3d2236e55a): finished scanning block pool BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,482 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-473321646-172.17.0.5-1585803920367 (Datanode Uuid ecff7edf-ed59-4801-a4f4-4be17a1ae967) service to localhost/127.0.0.1:40041 beginning handshake with NN
2020-04-02 05:05:21,482 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c58ac40b-bb57-446b-b62e-af3d2236e55a): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:05:21,482 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-3e32c979-647f-4c70-9575-d137d2cdec53): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:05:21,488 [IPC Server handler 0 on 40041] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:21,488 [IPC Server handler 1 on 40041] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37567, datanodeUuid=ecff7edf-ed59-4801-a4f4-4be17a1ae967, infoPort=0, infoSecurePort=44744, ipcPort=43320, storageInfo=lv=-57;cid=testClusterID;nsid=1779644608;c=1585803920367) storage ecff7edf-ed59-4801-a4f4-4be17a1ae967
2020-04-02 05:05:21,488 [IPC Server handler 1 on 40041] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37567
2020-04-02 05:05:21,488 [IPC Server handler 1 on 40041] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ecff7edf-ed59-4801-a4f4-4be17a1ae967 (127.0.0.1:37567).
2020-04-02 05:05:21,489 [Thread-169] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:21,489 [Thread-169] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:21,490 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-473321646-172.17.0.5-1585803920367 (Datanode Uuid ecff7edf-ed59-4801-a4f4-4be17a1ae967) service to localhost/127.0.0.1:40041 successfully registered with NN
2020-04-02 05:05:21,490 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-473321646-172.17.0.5-1585803920367 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:21,490 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:21,490 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40041 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:21,497 [IPC Server handler 2 on 40041] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c58ac40b-bb57-446b-b62e-af3d2236e55a for DN 127.0.0.1:37567
2020-04-02 05:05:21,497 [IPC Server handler 2 on 40041] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3e32c979-647f-4c70-9575-d137d2cdec53 for DN 127.0.0.1:37567
2020-04-02 05:05:21,501 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xaf8b4577bb09de63: Processing first storage report for DS-c58ac40b-bb57-446b-b62e-af3d2236e55a from datanode ecff7edf-ed59-4801-a4f4-4be17a1ae967
2020-04-02 05:05:21,501 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xaf8b4577bb09de63: from storage DS-c58ac40b-bb57-446b-b62e-af3d2236e55a node DatanodeRegistration(127.0.0.1:37567, datanodeUuid=ecff7edf-ed59-4801-a4f4-4be17a1ae967, infoPort=0, infoSecurePort=44744, ipcPort=43320, storageInfo=lv=-57;cid=testClusterID;nsid=1779644608;c=1585803920367), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:21,501 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xaf8b4577bb09de63: Processing first storage report for DS-3e32c979-647f-4c70-9575-d137d2cdec53 from datanode ecff7edf-ed59-4801-a4f4-4be17a1ae967
2020-04-02 05:05:21,501 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xaf8b4577bb09de63: from storage DS-3e32c979-647f-4c70-9575-d137d2cdec53 node DatanodeRegistration(127.0.0.1:37567, datanodeUuid=ecff7edf-ed59-4801-a4f4-4be17a1ae967, infoPort=0, infoSecurePort=44744, ipcPort=43320, storageInfo=lv=-57;cid=testClusterID;nsid=1779644608;c=1585803920367), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:05:21,502 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xaf8b4577bb09de63,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:21,502 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,594 [IPC Server handler 4 on 40041] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:21,595 [Thread-169] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:21,614 [IPC Server handler 5 on 40041] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:21,616 [Thread-169] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:21,629 [IPC Server handler 6 on 40041] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=create	src=/file1	dst=null	perm=hdfs:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:05:21,638 [IPC Server handler 7 on 40041] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:37567, 127.0.0.1:33213, 127.0.0.1:44276 for /file1
2020-04-02 05:05:21,660 [Thread-320] INFO  hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1790)) - Exception in createBlockOutputStream blk_1073741825_1001
javax.security.sasl.SaslException: DIGEST-MD5: No common protection layer between client and server
	at com.sun.security.sasl.digest.DigestMD5Client.checkQopSupport(DigestMD5Client.java:418)
	at com.sun.security.sasl.digest.DigestMD5Client.evaluateChallenge(DigestMD5Client.java:221)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslParticipant.evaluateChallengeOrResponse(SaslParticipant.java:113)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.doSaslHandshake(SaslDataTransferClient.java:456)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.getSaslStreams(SaslDataTransferClient.java:393)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.send(SaslDataTransferClient.java:267)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.checkTrustAndSend(SaslDataTransferClient.java:215)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.socketSend(SaslDataTransferClient.java:183)
	at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1731)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1679)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
2020-04-02 05:05:21,663 [org.apache.hadoop.hdfs.server.datanode.DataXceiver@b4862a9] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:37567:DataXceiver error processing unknown operation  src: /127.0.0.1:53494 dst: /127.0.0.1:37567
java.io.IOException: DIGEST-MD5: No common protection layer between client and server
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil.readSaslMessageAndNegotiationCipherOptions(DataTransferSaslUtil.java:240)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferServer.doSaslHandshake(SaslDataTransferServer.java:374)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferServer.getSaslStreams(SaslDataTransferServer.java:300)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferServer.receive(SaslDataTransferServer.java:127)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:232)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:05:21,664 [Thread-320] WARN  hdfs.DataStreamer (DataStreamer.java:nextBlockOutputStream(1683)) - Abandoning BP-473321646-172.17.0.5-1585803920367:blk_1073741825_1001
2020-04-02 05:05:21,694 [Thread-320] WARN  hdfs.DataStreamer (DataStreamer.java:nextBlockOutputStream(1688)) - Excluding datanode DatanodeInfoWithStorage[127.0.0.1:37567,DS-c58ac40b-bb57-446b-b62e-af3d2236e55a,DISK]
2020-04-02 05:05:21,696 [IPC Server handler 0 on 40041] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2020-04-02 05:05:21,696 [IPC Server handler 0 on 40041] WARN  protocol.BlockStoragePolicy (BlockStoragePolicy.java:chooseStorageTypes(161)) - Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2020-04-02 05:05:21,696 [IPC Server handler 0 on 40041] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2020-04-02 05:05:21,699 [IPC Server handler 0 on 40041] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:33213, 127.0.0.1:44276 for /file1
2020-04-02 05:05:21,703 [Thread-320] INFO  hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1790)) - Exception in createBlockOutputStream blk_1073741826_1002
javax.security.sasl.SaslException: DIGEST-MD5: No common protection layer between client and server
	at com.sun.security.sasl.digest.DigestMD5Client.checkQopSupport(DigestMD5Client.java:418)
	at com.sun.security.sasl.digest.DigestMD5Client.evaluateChallenge(DigestMD5Client.java:221)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslParticipant.evaluateChallengeOrResponse(SaslParticipant.java:113)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.doSaslHandshake(SaslDataTransferClient.java:456)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.getSaslStreams(SaslDataTransferClient.java:393)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.send(SaslDataTransferClient.java:267)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.checkTrustAndSend(SaslDataTransferClient.java:215)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.socketSend(SaslDataTransferClient.java:183)
	at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1731)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1679)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
2020-04-02 05:05:21,706 [org.apache.hadoop.hdfs.server.datanode.DataXceiver@198158cd] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:33213:DataXceiver error processing unknown operation  src: /127.0.0.1:46626 dst: /127.0.0.1:33213
java.io.IOException: DIGEST-MD5: No common protection layer between client and server
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil.readSaslMessageAndNegotiationCipherOptions(DataTransferSaslUtil.java:240)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferServer.doSaslHandshake(SaslDataTransferServer.java:374)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferServer.getSaslStreams(SaslDataTransferServer.java:300)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferServer.receive(SaslDataTransferServer.java:127)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:232)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:05:21,706 [Thread-320] WARN  hdfs.DataStreamer (DataStreamer.java:nextBlockOutputStream(1683)) - Abandoning BP-473321646-172.17.0.5-1585803920367:blk_1073741826_1002
2020-04-02 05:05:21,710 [Thread-320] WARN  hdfs.DataStreamer (DataStreamer.java:nextBlockOutputStream(1688)) - Excluding datanode DatanodeInfoWithStorage[127.0.0.1:33213,DS-5644d64e-e996-41a6-a6f5-86b70ec32d22,DISK]
2020-04-02 05:05:21,712 [IPC Server handler 2 on 40041] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2020-04-02 05:05:21,713 [IPC Server handler 2 on 40041] WARN  protocol.BlockStoragePolicy (BlockStoragePolicy.java:chooseStorageTypes(161)) - Failed to place enough replicas: expected size is 2 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2020-04-02 05:05:21,713 [IPC Server handler 2 on 40041] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2020-04-02 05:05:21,713 [IPC Server handler 2 on 40041] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:44276 for /file1
2020-04-02 05:05:21,716 [Thread-320] INFO  hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1790)) - Exception in createBlockOutputStream blk_1073741827_1003
javax.security.sasl.SaslException: DIGEST-MD5: No common protection layer between client and server
	at com.sun.security.sasl.digest.DigestMD5Client.checkQopSupport(DigestMD5Client.java:418)
	at com.sun.security.sasl.digest.DigestMD5Client.evaluateChallenge(DigestMD5Client.java:221)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslParticipant.evaluateChallengeOrResponse(SaslParticipant.java:113)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.doSaslHandshake(SaslDataTransferClient.java:456)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.getSaslStreams(SaslDataTransferClient.java:393)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.send(SaslDataTransferClient.java:267)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.checkTrustAndSend(SaslDataTransferClient.java:215)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.socketSend(SaslDataTransferClient.java:183)
	at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1731)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1679)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
2020-04-02 05:05:21,718 [org.apache.hadoop.hdfs.server.datanode.DataXceiver@521f585d] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:44276:DataXceiver error processing unknown operation  src: /127.0.0.1:43544 dst: /127.0.0.1:44276
java.io.IOException: DIGEST-MD5: No common protection layer between client and server
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil.readSaslMessageAndNegotiationCipherOptions(DataTransferSaslUtil.java:240)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferServer.doSaslHandshake(SaslDataTransferServer.java:374)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferServer.getSaslStreams(SaslDataTransferServer.java:300)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferServer.receive(SaslDataTransferServer.java:127)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:232)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:05:21,718 [Thread-320] WARN  hdfs.DataStreamer (DataStreamer.java:nextBlockOutputStream(1683)) - Abandoning BP-473321646-172.17.0.5-1585803920367:blk_1073741827_1003
2020-04-02 05:05:21,722 [Thread-320] WARN  hdfs.DataStreamer (DataStreamer.java:nextBlockOutputStream(1688)) - Excluding datanode DatanodeInfoWithStorage[127.0.0.1:44276,DS-59fe4c53-a604-41b7-b053-735ede622bd2,DISK]
2020-04-02 05:05:21,724 [IPC Server handler 4 on 40041] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2020-04-02 05:05:21,725 [IPC Server handler 4 on 40041] WARN  protocol.BlockStoragePolicy (BlockStoragePolicy.java:chooseStorageTypes(161)) - Failed to place enough replicas: expected size is 3 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2020-04-02 05:05:21,725 [IPC Server handler 4 on 40041] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(429)) - Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2020-04-02 05:05:21,725 [IPC Server handler 4 on 40041] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 4 on 40041, call Call#48 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 127.0.0.1:46162
java.io.IOException: File /file1 could only be written to 0 of the 1 minReplication nodes. There are 3 datanode(s) running and 3 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2121)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:295)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2702)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:05:21,728 [Thread-320] WARN  hdfs.DataStreamer (DataStreamer.java:run(826)) - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /file1 could only be written to 0 of the 1 minReplication nodes. There are 3 datanode(s) running and 3 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2121)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:295)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2702)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy26.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:510)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy30.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1866)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
2020-04-02 05:05:21,747 [Thread-169] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:05:21,747 [Thread-169] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:05:21,747 [Thread-169] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43320 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:21,748 [Thread-169] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:21,748 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@321d0a80] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:21,750 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-3e32c979-647f-4c70-9575-d137d2cdec53) exiting.
2020-04-02 05:05:21,750 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c58ac40b-bb57-446b-b62e-af3d2236e55a) exiting.
2020-04-02 05:05:21,764 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@60535361{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:21,793 [Thread-169] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@14d1c092{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:21,808 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@512aa589{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:21,823 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1d56f038{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:21,824 [Thread-169] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43320
2020-04-02 05:05:21,835 [IPC Server listener on 43320] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43320
2020-04-02 05:05:21,836 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:21,836 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:21,837 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-473321646-172.17.0.5-1585803920367 (Datanode Uuid ecff7edf-ed59-4801-a4f4-4be17a1ae967) service to localhost/127.0.0.1:40041
2020-04-02 05:05:21,838 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-473321646-172.17.0.5-1585803920367 (Datanode Uuid ecff7edf-ed59-4801-a4f4-4be17a1ae967)
2020-04-02 05:05:21,838 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,850 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-473321646-172.17.0.5-1585803920367] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:21,858 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-473321646-172.17.0.5-1585803920367] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:21,869 [Thread-169] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:21,869 [Thread-169] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:21,871 [Thread-169] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:21,871 [Thread-169] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:21,875 [Thread-169] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:21,875 [Thread-169] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:05:21,875 [Thread-169] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 36136 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:21,875 [Thread-169] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:21,875 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6c978d79] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:21,877 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-e2f3ddf0-caa6-4802-ad11-abfc5a4a698b) exiting.
2020-04-02 05:05:21,877 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-5644d64e-e996-41a6-a6f5-86b70ec32d22) exiting.
2020-04-02 05:05:21,895 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5f54418c{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:21,896 [Thread-169] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@63db1d83{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:21,896 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@76f7de98{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:21,896 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4180c4ca{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:21,897 [Thread-169] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36136
2020-04-02 05:05:21,916 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:21,916 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:21,918 [IPC Server listener on 36136] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36136
2020-04-02 05:05:21,925 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-473321646-172.17.0.5-1585803920367 (Datanode Uuid 12bd8206-e09a-4a4f-a634-aa68be51e4bd) service to localhost/127.0.0.1:40041
2020-04-02 05:05:21,926 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-473321646-172.17.0.5-1585803920367 (Datanode Uuid 12bd8206-e09a-4a4f-a634-aa68be51e4bd)
2020-04-02 05:05:21,927 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:21,945 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-473321646-172.17.0.5-1585803920367] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:21,957 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-473321646-172.17.0.5-1585803920367] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:21,965 [Thread-169] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:21,966 [Thread-169] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:21,967 [Thread-169] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:21,967 [Thread-169] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:21,970 [Thread-169] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:21,971 [Thread-169] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:05:21,971 [Thread-169] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 36770 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:21,971 [Thread-169] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:21,971 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@45dcae94] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:21,974 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-fa82164b-d741-4359-b666-0b24dc694860) exiting.
2020-04-02 05:05:21,974 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-59fe4c53-a604-41b7-b053-735ede622bd2) exiting.
2020-04-02 05:05:21,990 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2a7c8ae1{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:21,990 [Thread-169] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@58ce166d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:21,991 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@202eefde{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:21,991 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7c5a4964{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:21,992 [Thread-169] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36770
2020-04-02 05:05:21,995 [IPC Server listener on 36770] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36770
2020-04-02 05:05:21,995 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:21,995 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:21,995 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-473321646-172.17.0.5-1585803920367 (Datanode Uuid e2690242-9057-4981-9a6a-8f4502626b80) service to localhost/127.0.0.1:40041
2020-04-02 05:05:22,096 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-473321646-172.17.0.5-1585803920367 (Datanode Uuid e2690242-9057-4981-9a6a-8f4502626b80)
2020-04-02 05:05:22,096 [BP-473321646-172.17.0.5-1585803920367 heartbeating to localhost/127.0.0.1:40041] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-473321646-172.17.0.5-1585803920367
2020-04-02 05:05:22,109 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-473321646-172.17.0.5-1585803920367] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:22,129 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-473321646-172.17.0.5-1585803920367] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:22,143 [Thread-169] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:22,144 [Thread-169] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:22,145 [Thread-169] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:22,145 [Thread-169] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:22,148 [Thread-169] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:22,149 [Thread-169] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:05:22,149 [Thread-169] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 40041 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:22,149 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:22,149 [Thread[Thread-197,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:05:22,149 [Thread-169] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 16
2020-04-02 05:05:22,149 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5b66f714] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:05:22,149 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@93fbb06] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:05:22,150 [Thread-169] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 17 Total time for transactions(ms): 9 Number of transactions batched in Syncs: 3 Number of syncs: 15 SyncTimes(ms): 3 3 
2020-04-02 05:05:22,150 [Thread-169] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000017
2020-04-02 05:05:22,151 [Thread-169] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000017
2020-04-02 05:05:22,151 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:05:22,151 [CacheReplicationMonitor(1365563793)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:05:22,178 [Thread-169] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40041
2020-04-02 05:05:22,180 [IPC Server listener on 40041] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40041
2020-04-02 05:05:22,180 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:22,181 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:05:22,182 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:05:22,194 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:22,195 [Thread-169] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:05:22,196 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@35bc46a4{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:05:22,197 [Thread-169] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@19106020{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:05:22,198 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@15fae622{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:22,198 [Thread-169] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@8d3e314{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:22,199 [Thread-169] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:05:22,206 [Thread-169] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:05:22,206 [Thread-169] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testClientAndServerDoNotHaveCommonQop
[msx] writeFile testName = org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testClientAndServerDoNotHaveCommonQop
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testAuthentication
[msx] perform reset as unitTestCounterInClass 3 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:05:22,288 [Thread-325] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=3
2020-04-02 05:05:22,298 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803922298,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:22,303 [Thread-325] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
Formatting using clusterid: testClusterID
2020-04-02 05:05:22,304 [Thread-325] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:22,304 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:22,304 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:22,304 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:22,304 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:22,304 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:22,304 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:22,305 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:22,305 [Thread-325] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:22,305 [Thread-325] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:22,305 [Thread-325] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:22,306 [Thread-325] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:22,306 [Thread-325] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:22
2020-04-02 05:05:22,306 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:22,306 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:22,306 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 37.5 MB
2020-04-02 05:05:22,306 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:22,387 [Thread-325] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:22,396 [Thread-325] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:22,401 [Thread-325] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:22,402 [Thread-325] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:22,402 [Thread-325] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:22,402 [Thread-325] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:22,402 [Thread-325] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:22,402 [Thread-325] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:22,402 [Thread-325] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:22,402 [Thread-325] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:22,402 [Thread-325] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:22,402 [Thread-325] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:22,403 [Thread-325] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:22,403 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:22,403 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:22,403 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.7 MB
2020-04-02 05:05:22,404 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:22,412 [Thread-325] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:22,413 [Thread-325] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:22,413 [Thread-325] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:22,413 [Thread-325] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:22,413 [Thread-325] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:22,413 [Thread-325] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:22,414 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:22,414 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:22,414 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.7 MB
2020-04-02 05:05:22,415 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:22,415 [Thread-325] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:22,416 [Thread-325] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:22,416 [Thread-325] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:22,416 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:22,416 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:22,417 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:22,417 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:22,417 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 575.8 KB
2020-04-02 05:05:22,417 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:22,419 [Thread-325] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:22,422 [Thread-325] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:05:22,424 [Thread-325] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:05:22,430 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:22,430 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:22,436 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:05:22,442 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:05:22,445 [Thread-325] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:05:22,447 [Thread-325] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:22,453 [Thread-325] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:05:22,456 [Thread-325] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:05:22,456 [Thread-325] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:05:22,457 [Thread-325] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:22,457 [Thread-325] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:05:22,463 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803922462,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:22,468 [Thread-325] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:22,477 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3e16fc3c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:22,477 [Thread-325] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:22,478 [Thread-325] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:0
2020-04-02 05:05:22,479 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:22,483 [Thread-325] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:22,483 [Thread-325] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:22,484 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:22,485 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:22,486 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:22,486 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:22,486 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:22,489 [Thread-325] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:22,489 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:22,489 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:05:22,489 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:05:22,490 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37483
2020-04-02 05:05:22,490 [Thread-325] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:22,494 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5ac0c702{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:22,494 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@15f6c82c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:22,500 [Thread-325] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:22,500 [Thread-325] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:22,501 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@18be6c7e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:22,503 [Thread-325] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@cef04bf(server,h=[],w=[]) for SslContextFactory@6b374709(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/trustKS.jks)
2020-04-02 05:05:22,504 [Thread-325] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@584eb320{SSL,[ssl, http/1.1]}{localhost:37483}
2020-04-02 05:05:22,504 [Thread-325] INFO  server.Server (Server.java:doStart(419)) - Started @9063ms
2020-04-02 05:05:22,505 [Thread-325] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:22,505 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:22,516 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:22,516 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:22,516 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:22,516 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:22,516 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:22,516 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:22,517 [Thread-325] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:22,517 [Thread-325] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:22,517 [Thread-325] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:22,517 [Thread-325] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:22,517 [Thread-325] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:22
2020-04-02 05:05:22,517 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:22,517 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:22,518 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 37.5 MB
2020-04-02 05:05:22,518 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:22,524 [Thread-325] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:22,524 [Thread-325] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:22,524 [Thread-325] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:22,524 [Thread-325] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:22,524 [Thread-325] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:22,524 [Thread-325] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:22,524 [Thread-325] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:22,524 [Thread-325] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:22,524 [Thread-325] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:22,524 [Thread-325] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:22,525 [Thread-325] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:22,525 [Thread-325] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:22,525 [Thread-325] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:22,525 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:22,525 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:22,525 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.7 MB
2020-04-02 05:05:22,525 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:22,528 [Thread-325] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:22,528 [Thread-325] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:22,528 [Thread-325] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:22,528 [Thread-325] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:22,528 [Thread-325] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:22,528 [Thread-325] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:22,528 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:22,528 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:22,528 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.7 MB
2020-04-02 05:05:22,528 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:22,529 [Thread-325] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:22,529 [Thread-325] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:22,529 [Thread-325] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:22,529 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:22,529 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:22,529 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:22,529 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:22,530 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 575.8 KB
2020-04-02 05:05:22,530 [Thread-325] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:22,532 [Thread-325] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:22,532 [Thread-325] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:22,533 [Thread-325] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:05:22,534 [Thread-325] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:05:22,534 [Thread-325] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:05:22,534 [Thread-325] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:22,535 [Thread-325] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:22,536 [Thread-325] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:22,536 [Thread-325] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:22,536 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:22,536 [Thread-325] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:05:22,557 [Thread-325] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:22,557 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 27 msecs
2020-04-02 05:05:22,558 [Thread-325] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:05:22,558 [Thread-325] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:22,559 [Socket Reader #1 for port 42074] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42074
2020-04-02 05:05:22,564 [Thread-325] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:42074 to access this namenode/service.
2020-04-02 05:05:22,575 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:22,622 [Thread-325] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:22,624 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@1698d109] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:05:22,626 [Thread-325] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:22,626 [Thread-325] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:05:22,626 [Thread-325] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:05:22,627 [Thread-325] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:22,631 [Thread-325] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:22,634 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:22,634 [Thread[Thread-353,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:05:22,634 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:22,636 [Thread[Thread-353,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:22,636 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:22,637 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:22,637 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:22,637 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 10 msec
2020-04-02 05:05:22,644 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:22,644 [IPC Server listener on 42074] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42074: starting
2020-04-02 05:05:22,651 [Thread-325] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:42074
2020-04-02 05:05:22,651 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:22,651 [Thread-325] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:22,652 [Thread-325] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:22,662 [Thread-325] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 42074 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:22,665 [CacheReplicationMonitor(2111111090)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:22,673 [Thread-325] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:22,679 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803922678,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:22,684 [Thread-325] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:22,685 [Thread-325] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:22,686 [Thread-325] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:22,694 [Thread-325] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:22,695 [Thread-325] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:22,696 [Thread-325] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:22,697 [Thread-325] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:22,697 [Thread-325] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:22,698 [Thread-325] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:22,699 [Thread-325] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:22,702 [Thread-325] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40992
2020-04-02 05:05:22,702 [Thread-325] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:22,702 [Thread-325] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:22,703 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:22,705 [Thread-325] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:22,706 [Thread-325] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:22,706 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:22,707 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:22,708 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:22,708 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:22,708 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:22,709 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 36467
2020-04-02 05:05:22,709 [Thread-325] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:22,711 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6a90eeaf{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:22,711 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@20401fea{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:22,715 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4c1f8752{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:22,716 [Thread-325] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5e057ed3{HTTP/1.1,[http/1.1]}{localhost:36467}
2020-04-02 05:05:22,719 [Thread-325] INFO  server.Server (Server.java:doStart(419)) - Started @9277ms
2020-04-02 05:05:22,732 [Thread-325] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:43737
2020-04-02 05:05:22,732 [Thread-325] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:22,732 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@61011305] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:22,732 [Thread-325] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:22,733 [Thread-325] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:22,734 [Socket Reader #1 for port 40834] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40834
2020-04-02 05:05:22,737 [Thread-325] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40834
2020-04-02 05:05:22,743 [Thread-325] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:22,743 [Thread-325] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:22,744 [Thread-382] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42074 starting to offer service
2020-04-02 05:05:22,750 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:22,750 [IPC Server listener on 40834] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40834: starting
2020-04-02 05:05:22,754 [Thread-325] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40834 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:22,755 [Thread-325] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:22,769 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803922764,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:22,773 [Thread-325] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:22,774 [Thread-325] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:22,774 [Thread-325] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:22,785 [Thread-325] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:22,787 [Thread-325] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:22,787 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803922780,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:22,787 [Thread-325] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:22,787 [Thread-325] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:22,788 [Thread-325] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:22,788 [Thread-325] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:22,789 [Thread-325] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:22,796 [Thread-325] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:43809
2020-04-02 05:05:22,796 [Thread-325] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:22,796 [Thread-325] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:22,797 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:22,808 [Thread-325] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:22,809 [Thread-325] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:22,810 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:22,811 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:22,812 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:22,812 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:22,813 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:22,813 [Socket Reader #1 for port 42074] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:22,814 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35917
2020-04-02 05:05:22,832 [Thread-325] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:22,846 [Thread-382] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42074
2020-04-02 05:05:22,848 [Thread-382] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:22,848 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4ba88185{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:22,849 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1ed98ee7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:22,851 [Thread-382] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:22,851 [Thread-382] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 740123034. Formatting...
2020-04-02 05:05:22,852 [Thread-382] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b3cc6efa-fad7-4471-b9af-b9ec6babd129 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:05:22,854 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5935c370{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:22,855 [Thread-325] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@391b408b{HTTP/1.1,[http/1.1]}{localhost:35917}
2020-04-02 05:05:22,855 [Thread-325] INFO  server.Server (Server.java:doStart(419)) - Started @9414ms
2020-04-02 05:05:22,856 [Thread-382] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:22,856 [Thread-382] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 740123034. Formatting...
2020-04-02 05:05:22,857 [Thread-382] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6c3d7974-e4bc-4957-b995-6cf3c95029bc for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:05:22,877 [Thread-325] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:39110
2020-04-02 05:05:22,878 [Thread-325] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:22,878 [Thread-325] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:22,878 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7731e894] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:22,878 [Thread-325] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:22,879 [Socket Reader #1 for port 43247] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43247
2020-04-02 05:05:22,882 [Thread-382] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:22,882 [Thread-382] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:22,882 [Thread-382] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-747474997-172.17.0.5-1585803922419 is not formatted. Formatting ...
2020-04-02 05:05:22,882 [Thread-382] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-747474997-172.17.0.5-1585803922419 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-747474997-172.17.0.5-1585803922419/current
2020-04-02 05:05:22,883 [Thread-325] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43247
2020-04-02 05:05:22,892 [Thread-382] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:22,892 [Thread-382] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:22,893 [Thread-382] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-747474997-172.17.0.5-1585803922419 is not formatted. Formatting ...
2020-04-02 05:05:22,893 [Thread-382] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-747474997-172.17.0.5-1585803922419 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-747474997-172.17.0.5-1585803922419/current
2020-04-02 05:05:22,897 [Thread-382] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=740123034;bpid=BP-747474997-172.17.0.5-1585803922419;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=740123034;c=1585803922419;bpid=BP-747474997-172.17.0.5-1585803922419;dnuuid=null
2020-04-02 05:05:22,899 [Thread-382] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 5433bbeb-5caf-418b-91c3-d450ec96a57b
2020-04-02 05:05:22,902 [Thread-325] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:22,902 [Thread-325] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:22,904 [Thread-406] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42074 starting to offer service
2020-04-02 05:05:22,905 [Thread-382] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-b3cc6efa-fad7-4471-b9af-b9ec6babd129
2020-04-02 05:05:22,905 [Thread-382] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:05:22,909 [IPC Server listener on 43247] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43247: starting
2020-04-02 05:05:22,960 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:22,965 [Thread-382] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-6c3d7974-e4bc-4957-b995-6cf3c95029bc
2020-04-02 05:05:22,965 [Thread-382] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:05:22,966 [Thread-382] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:22,969 [Thread-382] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:22,974 [Thread-325] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43247 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:22,986 [Thread-382] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:22,986 [Thread-382] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:22,986 [Thread-382] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:22,993 [Thread-325] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:23,002 [Thread-382] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:23,002 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803923001,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:23,002 [Thread-420] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:23,003 [Thread-421] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:23,004 [Thread-325] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:23,004 [Thread-325] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:23,009 [Thread-325] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:23,015 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803923015,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:23,016 [Thread-325] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:23,021 [Thread-325] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:23,024 [Thread-325] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:23,024 [Thread-325] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:23,025 [Thread-325] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:23,025 [Thread-325] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:23,040 [Thread-325] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:23,041 [Thread-325] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:43108
2020-04-02 05:05:23,042 [Thread-325] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:23,042 [Thread-325] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:23,052 [Thread-420] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-747474997-172.17.0.5-1585803922419 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 49ms
2020-04-02 05:05:23,052 [Thread-421] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-747474997-172.17.0.5-1585803922419 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 48ms
2020-04-02 05:05:23,052 [Thread-382] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-747474997-172.17.0.5-1585803922419: 51ms
2020-04-02 05:05:23,053 [Thread-427] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:23,053 [Thread-428] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:23,053 [Thread-427] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-747474997-172.17.0.5-1585803922419/current/replicas doesn't exist 
2020-04-02 05:05:23,053 [Thread-428] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-747474997-172.17.0.5-1585803922419/current/replicas doesn't exist 
2020-04-02 05:05:23,053 [Thread-428] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:05:23,054 [Thread-427] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:05:23,061 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:23,063 [Thread-325] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:23,063 [Thread-382] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-747474997-172.17.0.5-1585803922419: 11ms
2020-04-02 05:05:23,068 [Thread-325] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:23,069 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:23,069 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:23,069 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:23,070 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-6c3d7974-e4bc-4957-b995-6cf3c95029bc): finished scanning block pool BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:23,070 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-b3cc6efa-fad7-4471-b9af-b9ec6babd129): finished scanning block pool BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:23,070 [Thread-382] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:28 AM with interval of 21600000ms
2020-04-02 05:05:23,070 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-6c3d7974-e4bc-4957-b995-6cf3c95029bc): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:05:23,070 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-b3cc6efa-fad7-4471-b9af-b9ec6babd129): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:05:23,072 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-747474997-172.17.0.5-1585803922419 (Datanode Uuid 5433bbeb-5caf-418b-91c3-d450ec96a57b) service to localhost/127.0.0.1:42074 beginning handshake with NN
2020-04-02 05:05:23,073 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:23,073 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:23,073 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:23,073 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:23,076 [IPC Server handler 1 on 42074] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40992, datanodeUuid=5433bbeb-5caf-418b-91c3-d450ec96a57b, infoPort=0, infoSecurePort=43737, ipcPort=40834, storageInfo=lv=-57;cid=testClusterID;nsid=740123034;c=1585803922419) storage 5433bbeb-5caf-418b-91c3-d450ec96a57b
2020-04-02 05:05:23,076 [Thread-325] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42148
2020-04-02 05:05:23,076 [Thread-325] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:23,076 [IPC Server handler 1 on 42074] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40992
2020-04-02 05:05:23,076 [IPC Server handler 1 on 42074] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5433bbeb-5caf-418b-91c3-d450ec96a57b (127.0.0.1:40992).
2020-04-02 05:05:23,076 [Socket Reader #1 for port 42074] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:23,086 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@41edea64{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:23,086 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@50a74a15{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:23,086 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-747474997-172.17.0.5-1585803922419 (Datanode Uuid 5433bbeb-5caf-418b-91c3-d450ec96a57b) service to localhost/127.0.0.1:42074 successfully registered with NN
2020-04-02 05:05:23,087 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-747474997-172.17.0.5-1585803922419 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:23,087 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:23,087 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42074 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:23,092 [IPC Server handler 3 on 42074] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b3cc6efa-fad7-4471-b9af-b9ec6babd129 for DN 127.0.0.1:40992
2020-04-02 05:05:23,092 [IPC Server handler 3 on 42074] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6c3d7974-e4bc-4957-b995-6cf3c95029bc for DN 127.0.0.1:40992
2020-04-02 05:05:23,099 [Thread-406] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42074
2020-04-02 05:05:23,101 [Thread-406] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:23,103 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd9dcccb75e0cf92b: Processing first storage report for DS-b3cc6efa-fad7-4471-b9af-b9ec6babd129 from datanode 5433bbeb-5caf-418b-91c3-d450ec96a57b
2020-04-02 05:05:23,105 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd9dcccb75e0cf92b: from storage DS-b3cc6efa-fad7-4471-b9af-b9ec6babd129 node DatanodeRegistration(127.0.0.1:40992, datanodeUuid=5433bbeb-5caf-418b-91c3-d450ec96a57b, infoPort=0, infoSecurePort=43737, ipcPort=40834, storageInfo=lv=-57;cid=testClusterID;nsid=740123034;c=1585803922419), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:23,105 [Thread-406] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:23,106 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd9dcccb75e0cf92b: Processing first storage report for DS-6c3d7974-e4bc-4957-b995-6cf3c95029bc from datanode 5433bbeb-5caf-418b-91c3-d450ec96a57b
2020-04-02 05:05:23,106 [Thread-406] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 740123034. Formatting...
2020-04-02 05:05:23,106 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@204b5ef3{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:23,106 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd9dcccb75e0cf92b: from storage DS-6c3d7974-e4bc-4957-b995-6cf3c95029bc node DatanodeRegistration(127.0.0.1:40992, datanodeUuid=5433bbeb-5caf-418b-91c3-d450ec96a57b, infoPort=0, infoSecurePort=43737, ipcPort=40834, storageInfo=lv=-57;cid=testClusterID;nsid=740123034;c=1585803922419), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:23,106 [Thread-406] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-46324f9c-1db9-426b-b523-b82cc821ebda for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:05:23,108 [Thread-325] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2003ef7d{HTTP/1.1,[http/1.1]}{localhost:42148}
2020-04-02 05:05:23,108 [Thread-325] INFO  server.Server (Server.java:doStart(419)) - Started @9667ms
2020-04-02 05:05:23,110 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xd9dcccb75e0cf92b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 10 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:23,111 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:23,114 [Thread-406] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:23,114 [Thread-406] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 740123034. Formatting...
2020-04-02 05:05:23,115 [Thread-406] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-14255d53-3eff-4329-9894-3c69dad18c42 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:05:23,125 [Thread-325] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:40596
2020-04-02 05:05:23,126 [Thread-325] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:23,126 [Thread-325] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:23,126 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@753928f8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:23,126 [Thread-325] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:23,127 [Socket Reader #1 for port 43450] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43450
2020-04-02 05:05:23,132 [Thread-325] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43450
2020-04-02 05:05:23,133 [Thread-406] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:23,134 [Thread-406] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:23,134 [Thread-406] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-747474997-172.17.0.5-1585803922419 is not formatted. Formatting ...
2020-04-02 05:05:23,134 [Thread-406] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-747474997-172.17.0.5-1585803922419 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-747474997-172.17.0.5-1585803922419/current
2020-04-02 05:05:23,141 [Thread-325] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:23,142 [Thread-325] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:23,143 [Thread-441] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42074 starting to offer service
2020-04-02 05:05:23,146 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:23,146 [IPC Server listener on 43450] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43450: starting
2020-04-02 05:05:23,149 [Thread-325] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43450 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:23,155 [Thread-406] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:23,156 [Thread-406] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:23,156 [Thread-406] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-747474997-172.17.0.5-1585803922419 is not formatted. Formatting ...
2020-04-02 05:05:23,156 [Thread-406] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-747474997-172.17.0.5-1585803922419 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-747474997-172.17.0.5-1585803922419/current
2020-04-02 05:05:23,158 [Thread-406] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=740123034;bpid=BP-747474997-172.17.0.5-1585803922419;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=740123034;c=1585803922419;bpid=BP-747474997-172.17.0.5-1585803922419;dnuuid=null
2020-04-02 05:05:23,164 [Thread-406] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID b921e859-1336-4da9-9fb3-c1d34a277df0
2020-04-02 05:05:23,167 [Thread-406] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-46324f9c-1db9-426b-b523-b82cc821ebda
2020-04-02 05:05:23,170 [Thread-406] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:05:23,172 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803923171,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:23,175 [Thread-406] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-14255d53-3eff-4329-9894-3c69dad18c42
2020-04-02 05:05:23,176 [Thread-406] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:05:23,176 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803923175,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:23,179 [Thread-406] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:23,180 [Thread-406] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:23,180 [Thread-406] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:23,181 [Thread-406] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:23,181 [Thread-406] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:23,181 [Thread-406] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:23,184 [Thread-456] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:05:23,184 [Thread-457] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:05:23,188 [Socket Reader #1 for port 42074] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:23,199 [Socket Reader #1 for port 42074] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:23,212 [IPC Server handler 5 on 42074] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:23,219 [Thread-441] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42074
2020-04-02 05:05:23,219 [Thread-325] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:23,222 [Thread-325] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:23,222 [Thread-441] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:23,225 [Thread-441] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:23,225 [Thread-441] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 740123034. Formatting...
2020-04-02 05:05:23,226 [Thread-441] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f46bf234-79cb-4cdf-8b6d-e55d16f2a84a for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:05:23,228 [Thread-441] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:23,229 [Thread-441] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 740123034. Formatting...
2020-04-02 05:05:23,229 [Thread-441] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2c1272f1-c929-49f1-a0e3-8fe300574472 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:05:23,232 [Thread-456] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-747474997-172.17.0.5-1585803922419 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 49ms
2020-04-02 05:05:23,234 [Thread-457] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-747474997-172.17.0.5-1585803922419 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 50ms
2020-04-02 05:05:23,234 [Thread-406] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-747474997-172.17.0.5-1585803922419: 50ms
2020-04-02 05:05:23,235 [Thread-460] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:05:23,235 [Thread-461] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:05:23,235 [Thread-460] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-747474997-172.17.0.5-1585803922419/current/replicas doesn't exist 
2020-04-02 05:05:23,235 [Thread-461] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-747474997-172.17.0.5-1585803922419/current/replicas doesn't exist 
2020-04-02 05:05:23,235 [Thread-461] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 0ms
2020-04-02 05:05:23,238 [Thread-460] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 3ms
2020-04-02 05:05:23,238 [Thread-406] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-747474997-172.17.0.5-1585803922419: 4ms
2020-04-02 05:05:23,238 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:23,238 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:23,238 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-14255d53-3eff-4329-9894-3c69dad18c42): finished scanning block pool BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:23,238 [Thread-406] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:47 AM with interval of 21600000ms
2020-04-02 05:05:23,238 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-46324f9c-1db9-426b-b523-b82cc821ebda): finished scanning block pool BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:23,239 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-14255d53-3eff-4329-9894-3c69dad18c42): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:05:23,239 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-46324f9c-1db9-426b-b523-b82cc821ebda): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:05:23,244 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-747474997-172.17.0.5-1585803922419 (Datanode Uuid b921e859-1336-4da9-9fb3-c1d34a277df0) service to localhost/127.0.0.1:42074 beginning handshake with NN
2020-04-02 05:05:23,245 [Thread-441] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:23,245 [Thread-441] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:23,245 [Thread-441] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-747474997-172.17.0.5-1585803922419 is not formatted. Formatting ...
2020-04-02 05:05:23,245 [Thread-441] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-747474997-172.17.0.5-1585803922419 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-747474997-172.17.0.5-1585803922419/current
2020-04-02 05:05:23,246 [IPC Server handler 8 on 42074] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43809, datanodeUuid=b921e859-1336-4da9-9fb3-c1d34a277df0, infoPort=0, infoSecurePort=39110, ipcPort=43247, storageInfo=lv=-57;cid=testClusterID;nsid=740123034;c=1585803922419) storage b921e859-1336-4da9-9fb3-c1d34a277df0
2020-04-02 05:05:23,246 [IPC Server handler 8 on 42074] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43809
2020-04-02 05:05:23,246 [IPC Server handler 8 on 42074] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b921e859-1336-4da9-9fb3-c1d34a277df0 (127.0.0.1:43809).
2020-04-02 05:05:23,247 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-747474997-172.17.0.5-1585803922419 (Datanode Uuid b921e859-1336-4da9-9fb3-c1d34a277df0) service to localhost/127.0.0.1:42074 successfully registered with NN
2020-04-02 05:05:23,247 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-747474997-172.17.0.5-1585803922419 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:23,247 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:23,247 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42074 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:23,253 [IPC Server handler 9 on 42074] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-46324f9c-1db9-426b-b523-b82cc821ebda for DN 127.0.0.1:43809
2020-04-02 05:05:23,257 [IPC Server handler 9 on 42074] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-14255d53-3eff-4329-9894-3c69dad18c42 for DN 127.0.0.1:43809
2020-04-02 05:05:23,261 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5ac7532a23c25171: Processing first storage report for DS-46324f9c-1db9-426b-b523-b82cc821ebda from datanode b921e859-1336-4da9-9fb3-c1d34a277df0
2020-04-02 05:05:23,261 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5ac7532a23c25171: from storage DS-46324f9c-1db9-426b-b523-b82cc821ebda node DatanodeRegistration(127.0.0.1:43809, datanodeUuid=b921e859-1336-4da9-9fb3-c1d34a277df0, infoPort=0, infoSecurePort=39110, ipcPort=43247, storageInfo=lv=-57;cid=testClusterID;nsid=740123034;c=1585803922419), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:23,261 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5ac7532a23c25171: Processing first storage report for DS-14255d53-3eff-4329-9894-3c69dad18c42 from datanode b921e859-1336-4da9-9fb3-c1d34a277df0
2020-04-02 05:05:23,261 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5ac7532a23c25171: from storage DS-14255d53-3eff-4329-9894-3c69dad18c42 node DatanodeRegistration(127.0.0.1:43809, datanodeUuid=b921e859-1336-4da9-9fb3-c1d34a277df0, infoPort=0, infoSecurePort=39110, ipcPort=43247, storageInfo=lv=-57;cid=testClusterID;nsid=740123034;c=1585803922419), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:23,264 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x5ac7532a23c25171,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:23,264 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:23,271 [Thread-441] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:23,271 [Thread-441] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:23,272 [Thread-441] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-747474997-172.17.0.5-1585803922419 is not formatted. Formatting ...
2020-04-02 05:05:23,272 [Thread-441] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-747474997-172.17.0.5-1585803922419 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-747474997-172.17.0.5-1585803922419/current
2020-04-02 05:05:23,274 [Thread-441] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=740123034;bpid=BP-747474997-172.17.0.5-1585803922419;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=740123034;c=1585803922419;bpid=BP-747474997-172.17.0.5-1585803922419;dnuuid=null
2020-04-02 05:05:23,275 [Thread-441] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 27b5718d-4fe8-4304-9c2b-eac3bd81cbe1
2020-04-02 05:05:23,278 [Thread-441] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-f46bf234-79cb-4cdf-8b6d-e55d16f2a84a
2020-04-02 05:05:23,281 [Thread-441] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:05:23,284 [Thread-441] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-2c1272f1-c929-49f1-a0e3-8fe300574472
2020-04-02 05:05:23,284 [Thread-441] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:05:23,284 [Thread-441] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:23,285 [Thread-441] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:23,290 [Thread-441] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:23,290 [Thread-441] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:23,290 [Thread-441] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:23,291 [Thread-441] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:23,293 [Thread-467] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:05:23,293 [Thread-468] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:05:23,328 [IPC Server handler 0 on 42074] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:23,329 [Thread-325] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:23,330 [Thread-325] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:23,338 [Thread-468] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-747474997-172.17.0.5-1585803922419 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 45ms
2020-04-02 05:05:23,342 [Thread-467] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-747474997-172.17.0.5-1585803922419 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 49ms
2020-04-02 05:05:23,342 [Thread-441] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-747474997-172.17.0.5-1585803922419: 51ms
2020-04-02 05:05:23,343 [Thread-471] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:05:23,343 [Thread-471] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-747474997-172.17.0.5-1585803922419/current/replicas doesn't exist 
2020-04-02 05:05:23,343 [Thread-472] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:05:23,343 [Thread-472] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-747474997-172.17.0.5-1585803922419/current/replicas doesn't exist 
2020-04-02 05:05:23,343 [Thread-471] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 0ms
2020-04-02 05:05:23,343 [Thread-472] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 0ms
2020-04-02 05:05:23,343 [Thread-441] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-747474997-172.17.0.5-1585803922419: 0ms
2020-04-02 05:05:23,344 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:23,344 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-747474997-172.17.0.5-1585803922419 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:23,344 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-2c1272f1-c929-49f1-a0e3-8fe300574472): finished scanning block pool BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:23,344 [Thread-441] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:52 AM with interval of 21600000ms
2020-04-02 05:05:23,344 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-f46bf234-79cb-4cdf-8b6d-e55d16f2a84a): finished scanning block pool BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:23,344 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-2c1272f1-c929-49f1-a0e3-8fe300574472): no suitable block pools found to scan.  Waiting 1814400000 ms.
2020-04-02 05:05:23,347 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-747474997-172.17.0.5-1585803922419 (Datanode Uuid 27b5718d-4fe8-4304-9c2b-eac3bd81cbe1) service to localhost/127.0.0.1:42074 beginning handshake with NN
2020-04-02 05:05:23,347 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-f46bf234-79cb-4cdf-8b6d-e55d16f2a84a): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:05:23,348 [IPC Server handler 1 on 42074] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43108, datanodeUuid=27b5718d-4fe8-4304-9c2b-eac3bd81cbe1, infoPort=0, infoSecurePort=40596, ipcPort=43450, storageInfo=lv=-57;cid=testClusterID;nsid=740123034;c=1585803922419) storage 27b5718d-4fe8-4304-9c2b-eac3bd81cbe1
2020-04-02 05:05:23,348 [IPC Server handler 1 on 42074] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43108
2020-04-02 05:05:23,349 [IPC Server handler 1 on 42074] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 27b5718d-4fe8-4304-9c2b-eac3bd81cbe1 (127.0.0.1:43108).
2020-04-02 05:05:23,349 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-747474997-172.17.0.5-1585803922419 (Datanode Uuid 27b5718d-4fe8-4304-9c2b-eac3bd81cbe1) service to localhost/127.0.0.1:42074 successfully registered with NN
2020-04-02 05:05:23,350 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-747474997-172.17.0.5-1585803922419 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:23,350 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:23,350 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42074 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:23,355 [IPC Server handler 2 on 42074] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f46bf234-79cb-4cdf-8b6d-e55d16f2a84a for DN 127.0.0.1:43108
2020-04-02 05:05:23,356 [IPC Server handler 2 on 42074] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2c1272f1-c929-49f1-a0e3-8fe300574472 for DN 127.0.0.1:43108
2020-04-02 05:05:23,360 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x690b33abfb8f5009: Processing first storage report for DS-2c1272f1-c929-49f1-a0e3-8fe300574472 from datanode 27b5718d-4fe8-4304-9c2b-eac3bd81cbe1
2020-04-02 05:05:23,361 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x690b33abfb8f5009: from storage DS-2c1272f1-c929-49f1-a0e3-8fe300574472 node DatanodeRegistration(127.0.0.1:43108, datanodeUuid=27b5718d-4fe8-4304-9c2b-eac3bd81cbe1, infoPort=0, infoSecurePort=40596, ipcPort=43450, storageInfo=lv=-57;cid=testClusterID;nsid=740123034;c=1585803922419), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:05:23,361 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x690b33abfb8f5009: Processing first storage report for DS-f46bf234-79cb-4cdf-8b6d-e55d16f2a84a from datanode 27b5718d-4fe8-4304-9c2b-eac3bd81cbe1
2020-04-02 05:05:23,361 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x690b33abfb8f5009: from storage DS-f46bf234-79cb-4cdf-8b6d-e55d16f2a84a node DatanodeRegistration(127.0.0.1:43108, datanodeUuid=27b5718d-4fe8-4304-9c2b-eac3bd81cbe1, infoPort=0, infoSecurePort=40596, ipcPort=43450, storageInfo=lv=-57;cid=testClusterID;nsid=740123034;c=1585803922419), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:23,364 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x690b33abfb8f5009,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:23,364 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:23,431 [IPC Server handler 4 on 42074] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:23,433 [Thread-325] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:23,440 [IPC Server handler 5 on 42074] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:23,442 [Thread-325] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:23,447 [IPC Server handler 6 on 42074] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=create	src=/file1	dst=null	perm=hdfs:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:05:23,465 [IPC Server handler 8 on 42074] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:40992, 127.0.0.1:43108, 127.0.0.1:43809 for /file1
2020-04-02 05:05:23,499 [DataXceiver for client DFSClient_NONMAPREDUCE_187887932_1443 at /127.0.0.1:45178 [Receiving block BP-747474997-172.17.0.5-1585803922419:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-747474997-172.17.0.5-1585803922419:blk_1073741825_1001 src: /127.0.0.1:45178 dest: /127.0.0.1:40992
2020-04-02 05:05:23,537 [DataXceiver for client DFSClient_NONMAPREDUCE_187887932_1443 at /127.0.0.1:54160 [Receiving block BP-747474997-172.17.0.5-1585803922419:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-747474997-172.17.0.5-1585803922419:blk_1073741825_1001 src: /127.0.0.1:54160 dest: /127.0.0.1:43108
2020-04-02 05:05:23,556 [DataXceiver for client DFSClient_NONMAPREDUCE_187887932_1443 at /127.0.0.1:51918 [Receiving block BP-747474997-172.17.0.5-1585803922419:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-747474997-172.17.0.5-1585803922419:blk_1073741825_1001 src: /127.0.0.1:51918 dest: /127.0.0.1:43809
2020-04-02 05:05:23,647 [PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51918, dest: /127.0.0.1:43809, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_187887932_1443, offset: 0, srvID: b921e859-1336-4da9-9fb3-c1d34a277df0, blockid: BP-747474997-172.17.0.5-1585803922419:blk_1073741825_1001, duration(ns): 70399954
2020-04-02 05:05:23,647 [PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:23,652 [PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43809]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54160, dest: /127.0.0.1:43108, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_187887932_1443, offset: 0, srvID: 27b5718d-4fe8-4304-9c2b-eac3bd81cbe1, blockid: BP-747474997-172.17.0.5-1585803922419:blk_1073741825_1001, duration(ns): 78596741
2020-04-02 05:05:23,654 [PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43809]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43809] terminating
2020-04-02 05:05:23,658 [PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43108, 127.0.0.1:43809]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45178, dest: /127.0.0.1:40992, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_187887932_1443, offset: 0, srvID: 5433bbeb-5caf-418b-91c3-d450ec96a57b, blockid: BP-747474997-172.17.0.5-1585803922419:blk_1073741825_1001, duration(ns): 85167673
2020-04-02 05:05:23,658 [PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43108, 127.0.0.1:43809]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43108, 127.0.0.1:43809] terminating
2020-04-02 05:05:23,676 [IPC Server handler 7 on 42074] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:43108, 127.0.0.1:43809, 127.0.0.1:40992 for /file1
2020-04-02 05:05:23,691 [DataXceiver for client DFSClient_NONMAPREDUCE_187887932_1443 at /127.0.0.1:54178 [Receiving block BP-747474997-172.17.0.5-1585803922419:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-747474997-172.17.0.5-1585803922419:blk_1073741826_1002 src: /127.0.0.1:54178 dest: /127.0.0.1:43108
2020-04-02 05:05:23,709 [DataXceiver for client DFSClient_NONMAPREDUCE_187887932_1443 at /127.0.0.1:51936 [Receiving block BP-747474997-172.17.0.5-1585803922419:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-747474997-172.17.0.5-1585803922419:blk_1073741826_1002 src: /127.0.0.1:51936 dest: /127.0.0.1:43809
2020-04-02 05:05:23,715 [DataXceiver for client DFSClient_NONMAPREDUCE_187887932_1443 at /127.0.0.1:45204 [Receiving block BP-747474997-172.17.0.5-1585803922419:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-747474997-172.17.0.5-1585803922419:blk_1073741826_1002 src: /127.0.0.1:45204 dest: /127.0.0.1:40992
2020-04-02 05:05:23,773 [PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45204, dest: /127.0.0.1:40992, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_187887932_1443, offset: 0, srvID: 5433bbeb-5caf-418b-91c3-d450ec96a57b, blockid: BP-747474997-172.17.0.5-1585803922419:blk_1073741826_1002, duration(ns): 53221556
2020-04-02 05:05:23,774 [PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:23,777 [PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40992]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51936, dest: /127.0.0.1:43809, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_187887932_1443, offset: 0, srvID: b921e859-1336-4da9-9fb3-c1d34a277df0, blockid: BP-747474997-172.17.0.5-1585803922419:blk_1073741826_1002, duration(ns): 56973224
2020-04-02 05:05:23,777 [PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40992]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40992] terminating
2020-04-02 05:05:23,781 [PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43809, 127.0.0.1:40992]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54178, dest: /127.0.0.1:43108, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_187887932_1443, offset: 0, srvID: 27b5718d-4fe8-4304-9c2b-eac3bd81cbe1, blockid: BP-747474997-172.17.0.5-1585803922419:blk_1073741826_1002, duration(ns): 59779193
2020-04-02 05:05:23,782 [PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43809, 127.0.0.1:40992]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43809, 127.0.0.1:40992] terminating
2020-04-02 05:05:23,788 [IPC Server handler 6 on 42074] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:43809, 127.0.0.1:43108, 127.0.0.1:40992 for /file1
2020-04-02 05:05:23,799 [DataXceiver for client DFSClient_NONMAPREDUCE_187887932_1443 at /127.0.0.1:51944 [Receiving block BP-747474997-172.17.0.5-1585803922419:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-747474997-172.17.0.5-1585803922419:blk_1073741827_1003 src: /127.0.0.1:51944 dest: /127.0.0.1:43809
2020-04-02 05:05:23,819 [DataXceiver for client DFSClient_NONMAPREDUCE_187887932_1443 at /127.0.0.1:54190 [Receiving block BP-747474997-172.17.0.5-1585803922419:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-747474997-172.17.0.5-1585803922419:blk_1073741827_1003 src: /127.0.0.1:54190 dest: /127.0.0.1:43108
2020-04-02 05:05:23,826 [DataXceiver for client DFSClient_NONMAPREDUCE_187887932_1443 at /127.0.0.1:45212 [Receiving block BP-747474997-172.17.0.5-1585803922419:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-747474997-172.17.0.5-1585803922419:blk_1073741827_1003 src: /127.0.0.1:45212 dest: /127.0.0.1:40992
2020-04-02 05:05:23,863 [PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45212, dest: /127.0.0.1:40992, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_187887932_1443, offset: 0, srvID: 5433bbeb-5caf-418b-91c3-d450ec96a57b, blockid: BP-747474997-172.17.0.5-1585803922419:blk_1073741827_1003, duration(ns): 33433744
2020-04-02 05:05:23,863 [PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:23,867 [PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40992]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54190, dest: /127.0.0.1:43108, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_187887932_1443, offset: 0, srvID: 27b5718d-4fe8-4304-9c2b-eac3bd81cbe1, blockid: BP-747474997-172.17.0.5-1585803922419:blk_1073741827_1003, duration(ns): 36750513
2020-04-02 05:05:23,868 [PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40992]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40992] terminating
2020-04-02 05:05:23,874 [PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43108, 127.0.0.1:40992]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51944, dest: /127.0.0.1:43809, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_187887932_1443, offset: 0, srvID: b921e859-1336-4da9-9fb3-c1d34a277df0, blockid: BP-747474997-172.17.0.5-1585803922419:blk_1073741827_1003, duration(ns): 42001544
2020-04-02 05:05:23,874 [PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43108, 127.0.0.1:40992]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-747474997-172.17.0.5-1585803922419:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43108, 127.0.0.1:40992] terminating
2020-04-02 05:05:23,879 [IPC Server handler 2 on 42074] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /file1 is closed by DFSClient_NONMAPREDUCE_187887932_1443
2020-04-02 05:05:23,897 [IPC Server handler 0 on 42074] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null	proto=rpc
2020-04-02 05:05:24,008 [IPC Server handler 1 on 42074] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null	proto=rpc
2020-04-02 05:05:24,011 [Thread-325] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:05:24,011 [Thread-325] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:05:24,012 [Thread-325] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43450 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:24,012 [Thread-325] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:24,012 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4d2fc77f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:24,014 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-f46bf234-79cb-4cdf-8b6d-e55d16f2a84a) exiting.
2020-04-02 05:05:24,014 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-2c1272f1-c929-49f1-a0e3-8fe300574472) exiting.
2020-04-02 05:05:24,028 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@204b5ef3{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:24,029 [Thread-325] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2003ef7d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:24,029 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@50a74a15{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:24,030 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@41edea64{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:24,031 [Thread-325] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43450
2020-04-02 05:05:24,034 [IPC Server listener on 43450] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43450
2020-04-02 05:05:24,034 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:24,037 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:24,037 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-747474997-172.17.0.5-1585803922419 (Datanode Uuid 27b5718d-4fe8-4304-9c2b-eac3bd81cbe1) service to localhost/127.0.0.1:42074
2020-04-02 05:05:24,037 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-747474997-172.17.0.5-1585803922419 (Datanode Uuid 27b5718d-4fe8-4304-9c2b-eac3bd81cbe1)
2020-04-02 05:05:24,037 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:24,049 [Thread-325] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:24,049 [Thread-325] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:24,050 [Thread-325] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:24,051 [Thread-325] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:24,056 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-747474997-172.17.0.5-1585803922419] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:24,068 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-747474997-172.17.0.5-1585803922419] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:24,078 [Thread-325] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:24,078 [Thread-325] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:05:24,078 [Thread-325] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43247 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:24,078 [Thread-325] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:24,081 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-14255d53-3eff-4329-9894-3c69dad18c42) exiting.
2020-04-02 05:05:24,081 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@29d18449] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:24,081 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-46324f9c-1db9-426b-b523-b82cc821ebda) exiting.
2020-04-02 05:05:24,120 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5935c370{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:24,121 [Thread-325] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@391b408b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:24,122 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1ed98ee7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:24,122 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4ba88185{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:24,135 [Thread-325] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43247
2020-04-02 05:05:24,155 [IPC Server listener on 43247] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43247
2020-04-02 05:05:24,156 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:24,159 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:24,159 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-747474997-172.17.0.5-1585803922419 (Datanode Uuid b921e859-1336-4da9-9fb3-c1d34a277df0) service to localhost/127.0.0.1:42074
2020-04-02 05:05:24,159 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-747474997-172.17.0.5-1585803922419 (Datanode Uuid b921e859-1336-4da9-9fb3-c1d34a277df0)
2020-04-02 05:05:24,159 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:24,171 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-747474997-172.17.0.5-1585803922419] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:24,206 [Thread-325] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:24,206 [Thread-325] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:24,208 [Thread-325] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:24,208 [Thread-325] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:24,231 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-747474997-172.17.0.5-1585803922419] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:24,250 [Thread-325] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:24,251 [Thread-325] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:05:24,251 [Thread-325] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40834 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:24,251 [Thread-325] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:24,251 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@75779bfc] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:24,286 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-6c3d7974-e4bc-4957-b995-6cf3c95029bc) exiting.
2020-04-02 05:05:24,286 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-b3cc6efa-fad7-4471-b9af-b9ec6babd129) exiting.
2020-04-02 05:05:24,315 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4c1f8752{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:24,316 [Thread-325] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5e057ed3{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:24,316 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@20401fea{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:24,317 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6a90eeaf{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:24,318 [Thread-325] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40834
2020-04-02 05:05:24,325 [IPC Server listener on 40834] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40834
2020-04-02 05:05:24,325 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:24,325 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:24,325 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-747474997-172.17.0.5-1585803922419 (Datanode Uuid 5433bbeb-5caf-418b-91c3-d450ec96a57b) service to localhost/127.0.0.1:42074
2020-04-02 05:05:24,427 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-747474997-172.17.0.5-1585803922419 (Datanode Uuid 5433bbeb-5caf-418b-91c3-d450ec96a57b)
2020-04-02 05:05:24,428 [BP-747474997-172.17.0.5-1585803922419 heartbeating to localhost/127.0.0.1:42074] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-747474997-172.17.0.5-1585803922419
2020-04-02 05:05:24,436 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-747474997-172.17.0.5-1585803922419] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:24,453 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-747474997-172.17.0.5-1585803922419] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:24,456 [Thread-325] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:24,456 [Thread-325] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:24,463 [Thread-325] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:24,463 [Thread-325] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:24,463 [Thread-325] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:24,464 [Thread-325] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:05:24,464 [Thread-325] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 42074 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:24,464 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:24,464 [Thread[Thread-353,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:05:24,464 [Thread-325] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 14
2020-04-02 05:05:24,464 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@52bc95d5] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:05:24,465 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@55f76d25] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:05:24,465 [Thread-325] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 15 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 4 Number of syncs: 12 SyncTimes(ms): 3 5 
2020-04-02 05:05:24,466 [Thread-325] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000015
2020-04-02 05:05:24,467 [Thread-325] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000015
2020-04-02 05:05:24,467 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:05:24,477 [CacheReplicationMonitor(2111111090)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:05:24,480 [Thread-325] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42074
2020-04-02 05:05:24,486 [IPC Server listener on 42074] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42074
2020-04-02 05:05:24,488 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:24,488 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:05:24,488 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:05:24,496 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:24,496 [Thread-325] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:05:24,497 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@18be6c7e{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:05:24,499 [Thread-325] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@584eb320{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:05:24,499 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@15f6c82c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:24,499 [Thread-325] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5ac0c702{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:24,500 [Thread-325] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:05:24,503 [Thread-325] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:05:24,503 [Thread-325] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testAuthentication
[msx] writeFile testName = org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testAuthentication
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testPrivacy
[msx] perform reset as unitTestCounterInClass 4 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:05:24,590 [Thread-502] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=3
2020-04-02 05:05:24,598 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803924597,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:24,608 [Thread-502] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
Formatting using clusterid: testClusterID
2020-04-02 05:05:24,609 [Thread-502] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:24,609 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:24,610 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:24,610 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:24,610 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:24,610 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:24,610 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:24,610 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:24,610 [Thread-502] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:24,611 [Thread-502] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:24,611 [Thread-502] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:24,611 [Thread-502] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:24,611 [Thread-502] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:24
2020-04-02 05:05:24,611 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:24,612 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:24,612 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 37.5 MB
2020-04-02 05:05:24,612 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:24,617 [Thread-502] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:24,617 [Thread-502] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:24,618 [Thread-502] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:24,618 [Thread-502] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:24,618 [Thread-502] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:24,618 [Thread-502] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:24,618 [Thread-502] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:24,618 [Thread-502] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:24,618 [Thread-502] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:24,618 [Thread-502] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:24,618 [Thread-502] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:24,619 [Thread-502] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:24,619 [Thread-502] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:24,619 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:24,619 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:24,619 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.7 MB
2020-04-02 05:05:24,619 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:24,622 [Thread-502] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:24,622 [Thread-502] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:24,622 [Thread-502] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:24,622 [Thread-502] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:24,622 [Thread-502] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:24,622 [Thread-502] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:24,622 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:24,622 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:24,623 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.7 MB
2020-04-02 05:05:24,623 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:24,624 [Thread-502] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:24,624 [Thread-502] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:24,624 [Thread-502] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:24,624 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:24,624 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:24,624 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:24,624 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:24,625 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 575.8 KB
2020-04-02 05:05:24,625 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:24,626 [Thread-502] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:24,629 [Thread-502] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:05:24,631 [Thread-502] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:05:24,635 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:24,635 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:24,643 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:05:24,647 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:05:24,651 [Thread-502] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:05:24,652 [Thread-502] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:24,659 [Thread-502] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:05:24,661 [Thread-502] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:05:24,661 [Thread-502] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:05:24,662 [Thread-502] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:24,663 [Thread-502] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:05:24,669 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803924668,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:24,673 [Thread-502] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:24,685 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6676c114] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:24,685 [Thread-502] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:24,686 [Thread-502] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:0
2020-04-02 05:05:24,686 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:24,689 [Thread-502] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:24,690 [Thread-502] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:24,691 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:24,692 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:24,693 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:24,693 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:24,693 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:24,696 [Thread-502] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:24,696 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:24,697 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:05:24,697 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:05:24,697 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40981
2020-04-02 05:05:24,697 [Thread-502] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:24,700 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62c72e91{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:24,700 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4862bf1{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:24,706 [Thread-502] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:24,707 [Thread-502] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:24,708 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@39315968{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:24,711 [Thread-502] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@9fb5a3c(server,h=[],w=[]) for SslContextFactory@5c27ac9e(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/trustKS.jks)
2020-04-02 05:05:24,713 [Thread-502] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7f5e193{SSL,[ssl, http/1.1]}{localhost:40981}
2020-04-02 05:05:24,716 [Thread-502] INFO  server.Server (Server.java:doStart(419)) - Started @11274ms
2020-04-02 05:05:24,717 [Thread-502] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:24,718 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:24,718 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:24,718 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:24,718 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:24,718 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:24,718 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:24,718 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:24,719 [Thread-502] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:24,719 [Thread-502] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:24,719 [Thread-502] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:24,719 [Thread-502] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:24,720 [Thread-502] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:24
2020-04-02 05:05:24,720 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:24,720 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:24,720 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 37.5 MB
2020-04-02 05:05:24,720 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:24,727 [Thread-502] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:24,728 [Thread-502] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:24,728 [Thread-502] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:24,728 [Thread-502] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:24,728 [Thread-502] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:24,728 [Thread-502] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:24,729 [Thread-502] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:24,729 [Thread-502] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:24,729 [Thread-502] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:24,729 [Thread-502] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:24,729 [Thread-502] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:24,729 [Thread-502] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:24,729 [Thread-502] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:24,729 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:24,729 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:24,729 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.7 MB
2020-04-02 05:05:24,729 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:24,733 [Thread-502] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:24,733 [Thread-502] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:24,733 [Thread-502] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:24,733 [Thread-502] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:24,733 [Thread-502] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:24,733 [Thread-502] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:24,733 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:24,733 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:24,733 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.7 MB
2020-04-02 05:05:24,733 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:24,735 [Thread-502] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:24,735 [Thread-502] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:24,735 [Thread-502] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:24,735 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:24,735 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:24,735 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:24,735 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:24,735 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 575.8 KB
2020-04-02 05:05:24,735 [Thread-502] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:24,737 [Thread-502] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:24,738 [Thread-502] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:24,740 [Thread-502] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:05:24,740 [Thread-502] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:05:24,740 [Thread-502] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:05:24,740 [Thread-502] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:24,742 [Thread-502] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:24,742 [Thread-502] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:24,742 [Thread-502] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:24,743 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:24,743 [Thread-502] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:05:24,757 [Thread-502] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:24,757 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 21 msecs
2020-04-02 05:05:24,758 [Thread-502] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:05:24,758 [Thread-502] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:24,759 [Socket Reader #1 for port 46526] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46526
2020-04-02 05:05:24,768 [Thread-502] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:46526 to access this namenode/service.
2020-04-02 05:05:24,769 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:24,797 [Thread-502] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:24,800 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@6678727] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:05:24,803 [Thread-502] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:24,803 [Thread-502] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:05:24,803 [Thread-502] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:05:24,803 [Thread-502] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:24,810 [Thread-502] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:24,814 [Thread[Thread-530,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:05:24,814 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:24,814 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:24,814 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:24,814 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:24,814 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:24,814 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 11 msec
2020-04-02 05:05:24,817 [Thread[Thread-530,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:24,821 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:24,822 [IPC Server listener on 46526] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46526: starting
2020-04-02 05:05:24,832 [Thread-502] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:46526
2020-04-02 05:05:24,832 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:24,832 [Thread-502] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:24,833 [Thread-502] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:24,837 [Thread-502] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 46526 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:24,843 [CacheReplicationMonitor(2116413957)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:24,853 [Thread-502] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:24,857 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803924856,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:24,862 [Thread-502] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:24,864 [Thread-502] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:24,865 [Thread-502] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:24,874 [Thread-502] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:24,876 [Thread-502] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:24,877 [Thread-502] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:24,877 [Thread-502] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:24,879 [Thread-502] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:24,879 [Thread-502] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:24,880 [Thread-502] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:24,880 [Thread-502] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42710
2020-04-02 05:05:24,880 [Thread-502] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:24,881 [Thread-502] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:24,881 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:24,883 [Thread-502] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:24,898 [Thread-502] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:24,899 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:24,900 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:24,900 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:24,900 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:24,900 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:24,903 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39077
2020-04-02 05:05:24,904 [Thread-502] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:24,905 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@44e9561c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:24,906 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3b3fce14{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:24,911 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2a6ad8a1{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:24,912 [Thread-502] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@fd4c6e4{HTTP/1.1,[http/1.1]}{localhost:39077}
2020-04-02 05:05:24,916 [Thread-502] INFO  server.Server (Server.java:doStart(419)) - Started @11475ms
2020-04-02 05:05:24,930 [Thread-502] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:44956
2020-04-02 05:05:24,930 [Thread-502] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:24,930 [Thread-502] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:24,931 [Thread-502] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:24,932 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4234529] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:24,938 [Socket Reader #1 for port 40151] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40151
2020-04-02 05:05:24,943 [Thread-502] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40151
2020-04-02 05:05:24,949 [Thread-502] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:24,949 [Thread-502] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:24,950 [Thread-559] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46526 starting to offer service
2020-04-02 05:05:24,957 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:24,957 [IPC Server listener on 40151] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40151: starting
2020-04-02 05:05:24,962 [Thread-502] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40151 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:24,963 [Thread-502] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:24,968 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803924967,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:24,981 [Thread-502] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:24,981 [Thread-502] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:24,983 [Thread-502] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:24,986 [Thread-502] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:24,986 [Thread-502] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:24,987 [Thread-502] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:24,987 [Thread-502] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:24,987 [Thread-502] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:24,987 [Thread-502] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:24,988 [Thread-502] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:24,988 [Thread-502] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:45761
2020-04-02 05:05:24,988 [Thread-502] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:24,988 [Thread-502] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:24,989 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803924988,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:24,989 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:24,990 [Thread-502] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:24,991 [Thread-502] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:24,991 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:24,991 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:24,992 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:24,992 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:24,992 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:24,992 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42720
2020-04-02 05:05:24,993 [Thread-502] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:24,994 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3535ff21{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:24,994 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4f20474d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:25,000 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1102eb4{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:25,000 [Thread-502] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@317dab51{HTTP/1.1,[http/1.1]}{localhost:42720}
2020-04-02 05:05:25,004 [Thread-502] INFO  server.Server (Server.java:doStart(419)) - Started @11562ms
2020-04-02 05:05:25,006 [Socket Reader #1 for port 46526] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:25,012 [Thread-559] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46526
2020-04-02 05:05:25,013 [Thread-559] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:25,016 [Thread-559] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:25,016 [Thread-559] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1686464030. Formatting...
2020-04-02 05:05:25,016 [Thread-559] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-75111ead-5685-4334-b744-c23f4bcb8d19 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:05:25,019 [Thread-559] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:25,021 [Thread-559] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1686464030. Formatting...
2020-04-02 05:05:25,023 [Thread-559] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3efa597d-aeaa-448d-a6ba-652e24f1c138 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:05:25,023 [Thread-502] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:41293
2020-04-02 05:05:25,023 [Thread-502] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:25,023 [Thread-502] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:25,023 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2c9805c6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:25,024 [Thread-502] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:25,025 [Socket Reader #1 for port 32790] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 32790
2020-04-02 05:05:25,029 [Thread-502] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:32790
2020-04-02 05:05:25,036 [Thread-559] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,036 [Thread-502] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:25,037 [Thread-559] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,037 [Thread-502] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:25,037 [Thread-559] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1574911259-172.17.0.5-1585803924626 is not formatted. Formatting ...
2020-04-02 05:05:25,037 [Thread-559] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1574911259-172.17.0.5-1585803924626 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1574911259-172.17.0.5-1585803924626/current
2020-04-02 05:05:25,038 [Thread-583] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46526 starting to offer service
2020-04-02 05:05:25,044 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:25,045 [IPC Server listener on 32790] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 32790: starting
2020-04-02 05:05:25,048 [Thread-559] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,049 [Thread-559] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,049 [Thread-559] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1574911259-172.17.0.5-1585803924626 is not formatted. Formatting ...
2020-04-02 05:05:25,049 [Thread-559] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1574911259-172.17.0.5-1585803924626 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1574911259-172.17.0.5-1585803924626/current
2020-04-02 05:05:25,051 [Thread-559] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1686464030;bpid=BP-1574911259-172.17.0.5-1585803924626;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1686464030;c=1585803924626;bpid=BP-1574911259-172.17.0.5-1585803924626;dnuuid=null
2020-04-02 05:05:25,052 [Thread-559] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 5c6b34ce-7dfc-4ba3-ad5b-d5e04ce9e056
2020-04-02 05:05:25,053 [Thread-502] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 32790 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:25,067 [Thread-559] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-75111ead-5685-4334-b744-c23f4bcb8d19
2020-04-02 05:05:25,067 [Thread-559] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:05:25,067 [Thread-502] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:25,074 [Thread-559] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-3efa597d-aeaa-448d-a6ba-652e24f1c138
2020-04-02 05:05:25,075 [Thread-559] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:05:25,075 [Thread-559] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:25,110 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803925109,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:25,111 [Thread-502] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:25,112 [Thread-502] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:25,112 [Thread-502] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:25,132 [Thread-502] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:25,132 [Thread-502] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:25,133 [Thread-502] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:25,133 [Thread-559] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:25,133 [Thread-502] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:25,134 [Thread-502] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:25,134 [Thread-559] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:25,134 [Thread-502] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:25,134 [Thread-559] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:25,135 [Thread-559] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:25,135 [Thread-502] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:25,136 [Thread-502] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40606
2020-04-02 05:05:25,136 [Thread-502] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:25,136 [Thread-502] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:25,137 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803925136,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:25,138 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:25,142 [Thread-559] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,143 [Thread-600] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:25,143 [Thread-601] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:25,143 [Thread-502] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:25,144 [Thread-502] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:25,151 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:25,159 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:25,167 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:25,167 [Socket Reader #1 for port 46526] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:25,168 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:25,168 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:25,175 [Thread-502] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33374
2020-04-02 05:05:25,175 [Thread-502] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:25,182 [Thread-601] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1574911259-172.17.0.5-1585803924626 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 39ms
2020-04-02 05:05:25,191 [Thread-583] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46526
2020-04-02 05:05:25,194 [Thread-583] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:25,195 [Thread-583] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:25,196 [Thread-583] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1686464030. Formatting...
2020-04-02 05:05:25,196 [Thread-583] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ca13b8a0-ad6e-4bcb-b83e-3c653bc7309d for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:05:25,197 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d480e1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:25,200 [Thread-583] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:25,200 [Thread-583] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1686464030. Formatting...
2020-04-02 05:05:25,200 [Thread-583] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f3bf30e4-397f-49d9-ae6c-dff0ff7148d7 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:05:25,202 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6662cefa{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:25,207 [Thread-600] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1574911259-172.17.0.5-1585803924626 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 64ms
2020-04-02 05:05:25,209 [Thread-559] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1574911259-172.17.0.5-1585803924626: 67ms
2020-04-02 05:05:25,227 [Thread-608] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:25,228 [Thread-608] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1574911259-172.17.0.5-1585803924626/current/replicas doesn't exist 
2020-04-02 05:05:25,228 [Thread-607] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:25,228 [Thread-607] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1574911259-172.17.0.5-1585803924626/current/replicas doesn't exist 
2020-04-02 05:05:25,228 [Thread-608] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 0ms
2020-04-02 05:05:25,235 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5a3ff7af{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:25,236 [Thread-502] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@577617be{HTTP/1.1,[http/1.1]}{localhost:33374}
2020-04-02 05:05:25,238 [Thread-607] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 10ms
2020-04-02 05:05:25,239 [Thread-502] INFO  server.Server (Server.java:doStart(419)) - Started @11797ms
2020-04-02 05:05:25,239 [Thread-559] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1574911259-172.17.0.5-1585803924626: 29ms
2020-04-02 05:05:25,239 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:25,240 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:25,240 [Thread-559] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:41 AM with interval of 21600000ms
2020-04-02 05:05:25,240 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-3efa597d-aeaa-448d-a6ba-652e24f1c138): finished scanning block pool BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,240 [Thread-583] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,240 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-75111ead-5685-4334-b744-c23f4bcb8d19): finished scanning block pool BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,240 [Thread-583] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,240 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-3efa597d-aeaa-448d-a6ba-652e24f1c138): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:05:25,240 [Thread-583] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1574911259-172.17.0.5-1585803924626 is not formatted. Formatting ...
2020-04-02 05:05:25,240 [Thread-583] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1574911259-172.17.0.5-1585803924626 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1574911259-172.17.0.5-1585803924626/current
2020-04-02 05:05:25,241 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-75111ead-5685-4334-b744-c23f4bcb8d19): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:05:25,244 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1574911259-172.17.0.5-1585803924626 (Datanode Uuid 5c6b34ce-7dfc-4ba3-ad5b-d5e04ce9e056) service to localhost/127.0.0.1:46526 beginning handshake with NN
2020-04-02 05:05:25,248 [IPC Server handler 2 on 46526] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42710, datanodeUuid=5c6b34ce-7dfc-4ba3-ad5b-d5e04ce9e056, infoPort=0, infoSecurePort=44956, ipcPort=40151, storageInfo=lv=-57;cid=testClusterID;nsid=1686464030;c=1585803924626) storage 5c6b34ce-7dfc-4ba3-ad5b-d5e04ce9e056
2020-04-02 05:05:25,248 [IPC Server handler 2 on 46526] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42710
2020-04-02 05:05:25,249 [IPC Server handler 2 on 46526] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5c6b34ce-7dfc-4ba3-ad5b-d5e04ce9e056 (127.0.0.1:42710).
2020-04-02 05:05:25,260 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1574911259-172.17.0.5-1585803924626 (Datanode Uuid 5c6b34ce-7dfc-4ba3-ad5b-d5e04ce9e056) service to localhost/127.0.0.1:46526 successfully registered with NN
2020-04-02 05:05:25,260 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1574911259-172.17.0.5-1585803924626 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:25,260 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:25,260 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46526 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:25,276 [IPC Server handler 3 on 46526] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-75111ead-5685-4334-b744-c23f4bcb8d19 for DN 127.0.0.1:42710
2020-04-02 05:05:25,277 [IPC Server handler 3 on 46526] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3efa597d-aeaa-448d-a6ba-652e24f1c138 for DN 127.0.0.1:42710
2020-04-02 05:05:25,280 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd76be5b381fb6bd1: Processing first storage report for DS-75111ead-5685-4334-b744-c23f4bcb8d19 from datanode 5c6b34ce-7dfc-4ba3-ad5b-d5e04ce9e056
2020-04-02 05:05:25,281 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd76be5b381fb6bd1: from storage DS-75111ead-5685-4334-b744-c23f4bcb8d19 node DatanodeRegistration(127.0.0.1:42710, datanodeUuid=5c6b34ce-7dfc-4ba3-ad5b-d5e04ce9e056, infoPort=0, infoSecurePort=44956, ipcPort=40151, storageInfo=lv=-57;cid=testClusterID;nsid=1686464030;c=1585803924626), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:25,282 [Thread-583] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,282 [Thread-583] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,282 [Thread-583] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1574911259-172.17.0.5-1585803924626 is not formatted. Formatting ...
2020-04-02 05:05:25,283 [Thread-583] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1574911259-172.17.0.5-1585803924626 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1574911259-172.17.0.5-1585803924626/current
2020-04-02 05:05:25,283 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd76be5b381fb6bd1: Processing first storage report for DS-3efa597d-aeaa-448d-a6ba-652e24f1c138 from datanode 5c6b34ce-7dfc-4ba3-ad5b-d5e04ce9e056
2020-04-02 05:05:25,283 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd76be5b381fb6bd1: from storage DS-3efa597d-aeaa-448d-a6ba-652e24f1c138 node DatanodeRegistration(127.0.0.1:42710, datanodeUuid=5c6b34ce-7dfc-4ba3-ad5b-d5e04ce9e056, infoPort=0, infoSecurePort=44956, ipcPort=40151, storageInfo=lv=-57;cid=testClusterID;nsid=1686464030;c=1585803924626), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:25,285 [Thread-583] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1686464030;bpid=BP-1574911259-172.17.0.5-1585803924626;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1686464030;c=1585803924626;bpid=BP-1574911259-172.17.0.5-1585803924626;dnuuid=null
2020-04-02 05:05:25,290 [Thread-502] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:36330
2020-04-02 05:05:25,291 [Thread-502] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:25,291 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@87d8ebc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:25,291 [Thread-502] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:25,294 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xd76be5b381fb6bd1,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 15 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:25,294 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,295 [Thread-583] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 9fb543c9-0b69-464f-820b-4a49cd979f9d
2020-04-02 05:05:25,297 [Thread-583] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-ca13b8a0-ad6e-4bcb-b83e-3c653bc7309d
2020-04-02 05:05:25,297 [Thread-583] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:05:25,304 [Thread-583] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-f3bf30e4-397f-49d9-ae6c-dff0ff7148d7
2020-04-02 05:05:25,306 [Thread-583] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:05:25,307 [Thread-583] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:25,308 [Thread-502] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:25,308 [Thread-583] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:25,308 [Socket Reader #1 for port 39259] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39259
2020-04-02 05:05:25,312 [Thread-583] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:25,312 [Thread-583] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:25,312 [Thread-583] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:25,312 [Thread-583] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,313 [Thread-617] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:05:25,313 [Thread-618] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:05:25,319 [Thread-502] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:39259
2020-04-02 05:05:25,345 [Thread-502] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:25,346 [Thread-502] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:25,346 [Thread-624] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46526 starting to offer service
2020-04-02 05:05:25,347 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:25,347 [IPC Server listener on 39259] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39259: starting
2020-04-02 05:05:25,348 [Thread-502] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 39259 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:25,360 [Thread-617] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1574911259-172.17.0.5-1585803924626 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 47ms
2020-04-02 05:05:25,362 [Thread-618] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1574911259-172.17.0.5-1585803924626 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 49ms
2020-04-02 05:05:25,364 [Thread-583] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1574911259-172.17.0.5-1585803924626: 51ms
2020-04-02 05:05:25,365 [Thread-637] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:05:25,365 [Thread-637] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1574911259-172.17.0.5-1585803924626/current/replicas doesn't exist 
2020-04-02 05:05:25,365 [Thread-637] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 0ms
2020-04-02 05:05:25,366 [Thread-638] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:05:25,366 [Thread-638] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1574911259-172.17.0.5-1585803924626/current/replicas doesn't exist 
2020-04-02 05:05:25,366 [Thread-638] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 0ms
2020-04-02 05:05:25,368 [Thread-583] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1574911259-172.17.0.5-1585803924626: 5ms
2020-04-02 05:05:25,369 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:25,370 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-ca13b8a0-ad6e-4bcb-b83e-3c653bc7309d): finished scanning block pool BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,370 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-ca13b8a0-ad6e-4bcb-b83e-3c653bc7309d): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:05:25,371 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:25,371 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-f3bf30e4-397f-49d9-ae6c-dff0ff7148d7): finished scanning block pool BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,371 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803925371,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:25,371 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-f3bf30e4-397f-49d9-ae6c-dff0ff7148d7): no suitable block pools found to scan.  Waiting 1814400000 ms.
2020-04-02 05:05:25,372 [Thread-583] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:44 AM with interval of 21600000ms
2020-04-02 05:05:25,380 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1574911259-172.17.0.5-1585803924626 (Datanode Uuid 9fb543c9-0b69-464f-820b-4a49cd979f9d) service to localhost/127.0.0.1:46526 beginning handshake with NN
2020-04-02 05:05:25,381 [IPC Server handler 5 on 46526] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45761, datanodeUuid=9fb543c9-0b69-464f-820b-4a49cd979f9d, infoPort=0, infoSecurePort=41293, ipcPort=32790, storageInfo=lv=-57;cid=testClusterID;nsid=1686464030;c=1585803924626) storage 9fb543c9-0b69-464f-820b-4a49cd979f9d
2020-04-02 05:05:25,382 [IPC Server handler 5 on 46526] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45761
2020-04-02 05:05:25,382 [IPC Server handler 5 on 46526] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9fb543c9-0b69-464f-820b-4a49cd979f9d (127.0.0.1:45761).
2020-04-02 05:05:25,382 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803925382,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:25,386 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1574911259-172.17.0.5-1585803924626 (Datanode Uuid 9fb543c9-0b69-464f-820b-4a49cd979f9d) service to localhost/127.0.0.1:46526 successfully registered with NN
2020-04-02 05:05:25,389 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1574911259-172.17.0.5-1585803924626 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:25,389 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:25,394 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46526 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:25,399 [Socket Reader #1 for port 46526] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:25,427 [Socket Reader #1 for port 46526] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:25,427 [IPC Server handler 6 on 46526] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:25,428 [Thread-502] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:25,428 [Thread-502] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:25,430 [IPC Server handler 6 on 46526] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ca13b8a0-ad6e-4bcb-b83e-3c653bc7309d for DN 127.0.0.1:45761
2020-04-02 05:05:25,437 [IPC Server handler 6 on 46526] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f3bf30e4-397f-49d9-ae6c-dff0ff7148d7 for DN 127.0.0.1:45761
2020-04-02 05:05:25,443 [Thread-624] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46526
2020-04-02 05:05:25,445 [Thread-624] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:25,446 [Thread-624] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:25,446 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x8bda00afe37b5b35: Processing first storage report for DS-f3bf30e4-397f-49d9-ae6c-dff0ff7148d7 from datanode 9fb543c9-0b69-464f-820b-4a49cd979f9d
2020-04-02 05:05:25,446 [Thread-624] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1686464030. Formatting...
2020-04-02 05:05:25,447 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x8bda00afe37b5b35: from storage DS-f3bf30e4-397f-49d9-ae6c-dff0ff7148d7 node DatanodeRegistration(127.0.0.1:45761, datanodeUuid=9fb543c9-0b69-464f-820b-4a49cd979f9d, infoPort=0, infoSecurePort=41293, ipcPort=32790, storageInfo=lv=-57;cid=testClusterID;nsid=1686464030;c=1585803924626), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:05:25,447 [Thread-624] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-918ddbc7-032f-48f0-8d69-fb4467993ea3 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:05:25,447 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x8bda00afe37b5b35: Processing first storage report for DS-ca13b8a0-ad6e-4bcb-b83e-3c653bc7309d from datanode 9fb543c9-0b69-464f-820b-4a49cd979f9d
2020-04-02 05:05:25,447 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x8bda00afe37b5b35: from storage DS-ca13b8a0-ad6e-4bcb-b83e-3c653bc7309d node DatanodeRegistration(127.0.0.1:45761, datanodeUuid=9fb543c9-0b69-464f-820b-4a49cd979f9d, infoPort=0, infoSecurePort=41293, ipcPort=32790, storageInfo=lv=-57;cid=testClusterID;nsid=1686464030;c=1585803924626), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:25,454 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x8bda00afe37b5b35,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 11 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:25,454 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,456 [Thread-624] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:25,457 [Thread-624] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1686464030. Formatting...
2020-04-02 05:05:25,457 [Thread-624] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-346a6bd3-3d2c-4fc4-b32b-ace6e88fecb0 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:05:25,468 [Thread-624] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,468 [Thread-624] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,468 [Thread-624] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1574911259-172.17.0.5-1585803924626 is not formatted. Formatting ...
2020-04-02 05:05:25,468 [Thread-624] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1574911259-172.17.0.5-1585803924626 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1574911259-172.17.0.5-1585803924626/current
2020-04-02 05:05:25,478 [Thread-624] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,478 [Thread-624] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,478 [Thread-624] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1574911259-172.17.0.5-1585803924626 is not formatted. Formatting ...
2020-04-02 05:05:25,478 [Thread-624] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1574911259-172.17.0.5-1585803924626 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1574911259-172.17.0.5-1585803924626/current
2020-04-02 05:05:25,480 [Thread-624] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1686464030;bpid=BP-1574911259-172.17.0.5-1585803924626;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1686464030;c=1585803924626;bpid=BP-1574911259-172.17.0.5-1585803924626;dnuuid=null
2020-04-02 05:05:25,482 [Thread-624] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 279bc06e-374c-42c9-91ee-cdeccf83b9d1
2020-04-02 05:05:25,483 [Thread-624] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-918ddbc7-032f-48f0-8d69-fb4467993ea3
2020-04-02 05:05:25,483 [Thread-624] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:05:25,488 [Thread-624] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-346a6bd3-3d2c-4fc4-b32b-ace6e88fecb0
2020-04-02 05:05:25,491 [Thread-624] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:05:25,491 [Thread-624] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:25,492 [Thread-624] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:25,494 [Thread-624] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:25,494 [Thread-624] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:25,501 [Thread-624] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:25,501 [Thread-624] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,507 [Thread-644] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:05:25,507 [Thread-645] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:05:25,558 [IPC Server handler 0 on 46526] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:25,560 [Thread-502] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:25,560 [Thread-502] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:25,564 [Thread-645] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1574911259-172.17.0.5-1585803924626 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 57ms
2020-04-02 05:05:25,568 [Thread-644] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1574911259-172.17.0.5-1585803924626 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 61ms
2020-04-02 05:05:25,571 [Thread-624] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1574911259-172.17.0.5-1585803924626: 70ms
2020-04-02 05:05:25,574 [Thread-648] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:05:25,574 [Thread-649] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:05:25,574 [Thread-648] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1574911259-172.17.0.5-1585803924626/current/replicas doesn't exist 
2020-04-02 05:05:25,574 [Thread-649] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1574911259-172.17.0.5-1585803924626/current/replicas doesn't exist 
2020-04-02 05:05:25,574 [Thread-648] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 1ms
2020-04-02 05:05:25,575 [Thread-649] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 1ms
2020-04-02 05:05:25,575 [Thread-624] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1574911259-172.17.0.5-1585803924626: 4ms
2020-04-02 05:05:25,575 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:25,575 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1574911259-172.17.0.5-1585803924626 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:25,576 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-346a6bd3-3d2c-4fc4-b32b-ace6e88fecb0): finished scanning block pool BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,576 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-918ddbc7-032f-48f0-8d69-fb4467993ea3): finished scanning block pool BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,576 [Thread-624] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 11:02 AM with interval of 21600000ms
2020-04-02 05:05:25,576 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-918ddbc7-032f-48f0-8d69-fb4467993ea3): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:05:25,579 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1574911259-172.17.0.5-1585803924626 (Datanode Uuid 279bc06e-374c-42c9-91ee-cdeccf83b9d1) service to localhost/127.0.0.1:46526 beginning handshake with NN
2020-04-02 05:05:25,576 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-346a6bd3-3d2c-4fc4-b32b-ace6e88fecb0): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:05:25,581 [IPC Server handler 1 on 46526] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40606, datanodeUuid=279bc06e-374c-42c9-91ee-cdeccf83b9d1, infoPort=0, infoSecurePort=36330, ipcPort=39259, storageInfo=lv=-57;cid=testClusterID;nsid=1686464030;c=1585803924626) storage 279bc06e-374c-42c9-91ee-cdeccf83b9d1
2020-04-02 05:05:25,581 [IPC Server handler 1 on 46526] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40606
2020-04-02 05:05:25,581 [IPC Server handler 1 on 46526] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 279bc06e-374c-42c9-91ee-cdeccf83b9d1 (127.0.0.1:40606).
2020-04-02 05:05:25,583 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1574911259-172.17.0.5-1585803924626 (Datanode Uuid 279bc06e-374c-42c9-91ee-cdeccf83b9d1) service to localhost/127.0.0.1:46526 successfully registered with NN
2020-04-02 05:05:25,583 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1574911259-172.17.0.5-1585803924626 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:25,584 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:25,584 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46526 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:25,589 [IPC Server handler 2 on 46526] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-918ddbc7-032f-48f0-8d69-fb4467993ea3 for DN 127.0.0.1:40606
2020-04-02 05:05:25,589 [IPC Server handler 2 on 46526] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-346a6bd3-3d2c-4fc4-b32b-ace6e88fecb0 for DN 127.0.0.1:40606
2020-04-02 05:05:25,591 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf36088b51f720dfd: Processing first storage report for DS-346a6bd3-3d2c-4fc4-b32b-ace6e88fecb0 from datanode 279bc06e-374c-42c9-91ee-cdeccf83b9d1
2020-04-02 05:05:25,591 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf36088b51f720dfd: from storage DS-346a6bd3-3d2c-4fc4-b32b-ace6e88fecb0 node DatanodeRegistration(127.0.0.1:40606, datanodeUuid=279bc06e-374c-42c9-91ee-cdeccf83b9d1, infoPort=0, infoSecurePort=36330, ipcPort=39259, storageInfo=lv=-57;cid=testClusterID;nsid=1686464030;c=1585803924626), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:25,591 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf36088b51f720dfd: Processing first storage report for DS-918ddbc7-032f-48f0-8d69-fb4467993ea3 from datanode 279bc06e-374c-42c9-91ee-cdeccf83b9d1
2020-04-02 05:05:25,591 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf36088b51f720dfd: from storage DS-918ddbc7-032f-48f0-8d69-fb4467993ea3 node DatanodeRegistration(127.0.0.1:40606, datanodeUuid=279bc06e-374c-42c9-91ee-cdeccf83b9d1, infoPort=0, infoSecurePort=36330, ipcPort=39259, storageInfo=lv=-57;cid=testClusterID;nsid=1686464030;c=1585803924626), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:25,592 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xf36088b51f720dfd,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:25,592 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:25,662 [IPC Server handler 4 on 46526] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:25,663 [Thread-502] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:25,668 [IPC Server handler 5 on 46526] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:25,669 [Thread-502] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:25,675 [IPC Server handler 7 on 46526] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=create	src=/file1	dst=null	perm=hdfs:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:05:25,688 [IPC Server handler 6 on 46526] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:40606, 127.0.0.1:42710, 127.0.0.1:45761 for /file1
2020-04-02 05:05:25,718 [DataXceiver for client DFSClient_NONMAPREDUCE_837433679_2157 at /127.0.0.1:50834 [Receiving block BP-1574911259-172.17.0.5-1585803924626:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1574911259-172.17.0.5-1585803924626:blk_1073741825_1001 src: /127.0.0.1:50834 dest: /127.0.0.1:40606
2020-04-02 05:05:25,730 [DataXceiver for client DFSClient_NONMAPREDUCE_837433679_2157 at /127.0.0.1:52928 [Receiving block BP-1574911259-172.17.0.5-1585803924626:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1574911259-172.17.0.5-1585803924626:blk_1073741825_1001 src: /127.0.0.1:52928 dest: /127.0.0.1:42710
2020-04-02 05:05:25,747 [DataXceiver for client DFSClient_NONMAPREDUCE_837433679_2157 at /127.0.0.1:45912 [Receiving block BP-1574911259-172.17.0.5-1585803924626:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1574911259-172.17.0.5-1585803924626:blk_1073741825_1001 src: /127.0.0.1:45912 dest: /127.0.0.1:45761
2020-04-02 05:05:25,802 [PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45912, dest: /127.0.0.1:45761, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_837433679_2157, offset: 0, srvID: 9fb543c9-0b69-464f-820b-4a49cd979f9d, blockid: BP-1574911259-172.17.0.5-1585803924626:blk_1073741825_1001, duration(ns): 48687944
2020-04-02 05:05:25,803 [PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:25,809 [PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45761]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52928, dest: /127.0.0.1:42710, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_837433679_2157, offset: 0, srvID: 5c6b34ce-7dfc-4ba3-ad5b-d5e04ce9e056, blockid: BP-1574911259-172.17.0.5-1585803924626:blk_1073741825_1001, duration(ns): 56775943
2020-04-02 05:05:25,809 [PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45761]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45761] terminating
2020-04-02 05:05:25,816 [PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42710, 127.0.0.1:45761]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50834, dest: /127.0.0.1:40606, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_837433679_2157, offset: 0, srvID: 279bc06e-374c-42c9-91ee-cdeccf83b9d1, blockid: BP-1574911259-172.17.0.5-1585803924626:blk_1073741825_1001, duration(ns): 62462623
2020-04-02 05:05:25,816 [PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42710, 127.0.0.1:45761]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42710, 127.0.0.1:45761] terminating
2020-04-02 05:05:25,827 [IPC Server handler 2 on 46526] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:42710, 127.0.0.1:40606, 127.0.0.1:45761 for /file1
2020-04-02 05:05:25,839 [DataXceiver for client DFSClient_NONMAPREDUCE_837433679_2157 at /127.0.0.1:52932 [Receiving block BP-1574911259-172.17.0.5-1585803924626:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1574911259-172.17.0.5-1585803924626:blk_1073741826_1002 src: /127.0.0.1:52932 dest: /127.0.0.1:42710
2020-04-02 05:05:25,844 [DataXceiver for client DFSClient_NONMAPREDUCE_837433679_2157 at /127.0.0.1:50842 [Receiving block BP-1574911259-172.17.0.5-1585803924626:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1574911259-172.17.0.5-1585803924626:blk_1073741826_1002 src: /127.0.0.1:50842 dest: /127.0.0.1:40606
2020-04-02 05:05:25,848 [DataXceiver for client DFSClient_NONMAPREDUCE_837433679_2157 at /127.0.0.1:45920 [Receiving block BP-1574911259-172.17.0.5-1585803924626:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1574911259-172.17.0.5-1585803924626:blk_1073741826_1002 src: /127.0.0.1:45920 dest: /127.0.0.1:45761
2020-04-02 05:05:25,899 [PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45920, dest: /127.0.0.1:45761, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_837433679_2157, offset: 0, srvID: 9fb543c9-0b69-464f-820b-4a49cd979f9d, blockid: BP-1574911259-172.17.0.5-1585803924626:blk_1073741826_1002, duration(ns): 45687667
2020-04-02 05:05:25,899 [PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:25,903 [PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45761]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50842, dest: /127.0.0.1:40606, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_837433679_2157, offset: 0, srvID: 279bc06e-374c-42c9-91ee-cdeccf83b9d1, blockid: BP-1574911259-172.17.0.5-1585803924626:blk_1073741826_1002, duration(ns): 49910584
2020-04-02 05:05:25,903 [PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45761]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45761] terminating
2020-04-02 05:05:25,906 [PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40606, 127.0.0.1:45761]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52932, dest: /127.0.0.1:42710, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_837433679_2157, offset: 0, srvID: 5c6b34ce-7dfc-4ba3-ad5b-d5e04ce9e056, blockid: BP-1574911259-172.17.0.5-1585803924626:blk_1073741826_1002, duration(ns): 53211154
2020-04-02 05:05:25,907 [PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40606, 127.0.0.1:45761]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40606, 127.0.0.1:45761] terminating
2020-04-02 05:05:25,910 [IPC Server handler 7 on 46526] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:45761, 127.0.0.1:40606, 127.0.0.1:42710 for /file1
2020-04-02 05:05:25,923 [DataXceiver for client DFSClient_NONMAPREDUCE_837433679_2157 at /127.0.0.1:45926 [Receiving block BP-1574911259-172.17.0.5-1585803924626:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1574911259-172.17.0.5-1585803924626:blk_1073741827_1003 src: /127.0.0.1:45926 dest: /127.0.0.1:45761
2020-04-02 05:05:25,928 [DataXceiver for client DFSClient_NONMAPREDUCE_837433679_2157 at /127.0.0.1:50854 [Receiving block BP-1574911259-172.17.0.5-1585803924626:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1574911259-172.17.0.5-1585803924626:blk_1073741827_1003 src: /127.0.0.1:50854 dest: /127.0.0.1:40606
2020-04-02 05:05:25,934 [DataXceiver for client DFSClient_NONMAPREDUCE_837433679_2157 at /127.0.0.1:52948 [Receiving block BP-1574911259-172.17.0.5-1585803924626:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1574911259-172.17.0.5-1585803924626:blk_1073741827_1003 src: /127.0.0.1:52948 dest: /127.0.0.1:42710
2020-04-02 05:05:25,988 [PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52948, dest: /127.0.0.1:42710, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_837433679_2157, offset: 0, srvID: 5c6b34ce-7dfc-4ba3-ad5b-d5e04ce9e056, blockid: BP-1574911259-172.17.0.5-1585803924626:blk_1073741827_1003, duration(ns): 41661580
2020-04-02 05:05:25,988 [PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:26,000 [PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42710]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50854, dest: /127.0.0.1:40606, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_837433679_2157, offset: 0, srvID: 279bc06e-374c-42c9-91ee-cdeccf83b9d1, blockid: BP-1574911259-172.17.0.5-1585803924626:blk_1073741827_1003, duration(ns): 57781873
2020-04-02 05:05:26,001 [PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42710]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42710] terminating
2020-04-02 05:05:26,009 [PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40606, 127.0.0.1:42710]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45926, dest: /127.0.0.1:45761, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_837433679_2157, offset: 0, srvID: 9fb543c9-0b69-464f-820b-4a49cd979f9d, blockid: BP-1574911259-172.17.0.5-1585803924626:blk_1073741827_1003, duration(ns): 65053286
2020-04-02 05:05:26,009 [PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40606, 127.0.0.1:42710]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1574911259-172.17.0.5-1585803924626:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40606, 127.0.0.1:42710] terminating
2020-04-02 05:05:26,011 [IPC Server handler 0 on 46526] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /file1 is closed by DFSClient_NONMAPREDUCE_837433679_2157
2020-04-02 05:05:26,017 [IPC Server handler 1 on 46526] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null	proto=rpc
2020-04-02 05:05:26,051 [IPC Server handler 2 on 46526] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null	proto=rpc
2020-04-02 05:05:26,054 [Thread-502] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:05:26,054 [Thread-502] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:05:26,054 [Thread-502] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 39259 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:26,054 [Thread-502] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:26,054 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5e463030] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:26,057 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-346a6bd3-3d2c-4fc4-b32b-ace6e88fecb0) exiting.
2020-04-02 05:05:26,057 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-918ddbc7-032f-48f0-8d69-fb4467993ea3) exiting.
2020-04-02 05:05:26,099 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5a3ff7af{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:26,099 [Thread-502] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@577617be{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:26,099 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6662cefa{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:26,100 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6d480e1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:26,100 [Thread-502] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39259
2020-04-02 05:05:26,103 [IPC Server listener on 39259] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39259
2020-04-02 05:05:26,104 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:26,104 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:26,104 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1574911259-172.17.0.5-1585803924626 (Datanode Uuid 279bc06e-374c-42c9-91ee-cdeccf83b9d1) service to localhost/127.0.0.1:46526
2020-04-02 05:05:26,104 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1574911259-172.17.0.5-1585803924626 (Datanode Uuid 279bc06e-374c-42c9-91ee-cdeccf83b9d1)
2020-04-02 05:05:26,104 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:26,121 [Thread-502] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:26,121 [Thread-502] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:26,123 [Thread-502] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:26,123 [Thread-502] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:26,134 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1574911259-172.17.0.5-1585803924626] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:26,143 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1574911259-172.17.0.5-1585803924626] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:26,144 [Thread-502] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:26,144 [Thread-502] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:05:26,144 [Thread-502] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 32790 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:26,144 [Thread-502] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:26,144 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5d0ebe41] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:26,147 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-ca13b8a0-ad6e-4bcb-b83e-3c653bc7309d) exiting.
2020-04-02 05:05:26,147 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-f3bf30e4-397f-49d9-ae6c-dff0ff7148d7) exiting.
2020-04-02 05:05:26,167 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1102eb4{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:26,168 [Thread-502] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@317dab51{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:26,168 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4f20474d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:26,169 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3535ff21{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:26,170 [Thread-502] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 32790
2020-04-02 05:05:26,181 [IPC Server listener on 32790] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 32790
2020-04-02 05:05:26,181 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:26,181 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1574911259-172.17.0.5-1585803924626 (Datanode Uuid 9fb543c9-0b69-464f-820b-4a49cd979f9d) service to localhost/127.0.0.1:46526
2020-04-02 05:05:26,181 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1574911259-172.17.0.5-1585803924626 (Datanode Uuid 9fb543c9-0b69-464f-820b-4a49cd979f9d)
2020-04-02 05:05:26,181 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:26,181 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:26,192 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1574911259-172.17.0.5-1585803924626] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:26,200 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1574911259-172.17.0.5-1585803924626] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:26,218 [Thread-502] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:26,219 [Thread-502] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:26,222 [Thread-502] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:26,222 [Thread-502] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:26,238 [Thread-502] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:26,241 [Thread-502] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:05:26,241 [Thread-502] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40151 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:26,247 [Thread-502] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:26,247 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@c010f99] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:26,267 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-75111ead-5685-4334-b744-c23f4bcb8d19) exiting.
2020-04-02 05:05:26,267 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-3efa597d-aeaa-448d-a6ba-652e24f1c138) exiting.
2020-04-02 05:05:26,328 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2a6ad8a1{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:26,329 [Thread-502] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@fd4c6e4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:26,330 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3b3fce14{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:26,330 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@44e9561c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:26,332 [Thread-502] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40151
2020-04-02 05:05:26,360 [IPC Server listener on 40151] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40151
2020-04-02 05:05:26,361 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:26,370 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:26,370 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1574911259-172.17.0.5-1585803924626 (Datanode Uuid 5c6b34ce-7dfc-4ba3-ad5b-d5e04ce9e056) service to localhost/127.0.0.1:46526
2020-04-02 05:05:26,474 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1574911259-172.17.0.5-1585803924626 (Datanode Uuid 5c6b34ce-7dfc-4ba3-ad5b-d5e04ce9e056)
2020-04-02 05:05:26,474 [BP-1574911259-172.17.0.5-1585803924626 heartbeating to localhost/127.0.0.1:46526] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1574911259-172.17.0.5-1585803924626
2020-04-02 05:05:26,484 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1574911259-172.17.0.5-1585803924626] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:26,493 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1574911259-172.17.0.5-1585803924626] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:26,509 [Thread-502] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:26,509 [Thread-502] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:26,512 [Thread-502] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:26,512 [Thread-502] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:26,531 [Thread-502] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:26,531 [Thread-502] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:05:26,533 [Thread-502] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 46526 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:26,535 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:26,539 [Thread[Thread-530,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:05:26,541 [Thread-502] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 14
2020-04-02 05:05:26,541 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@113814a6] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:05:26,541 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@16e8ab0e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:05:26,542 [Thread-502] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 15 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 3 Number of syncs: 13 SyncTimes(ms): 4 2 
2020-04-02 05:05:26,543 [Thread-502] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000015
2020-04-02 05:05:26,543 [Thread-502] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000015
2020-04-02 05:05:26,544 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:05:26,544 [CacheReplicationMonitor(2116413957)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:05:26,568 [Thread-502] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46526
2020-04-02 05:05:26,576 [IPC Server listener on 46526] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46526
2020-04-02 05:05:26,576 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:05:26,584 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:05:26,576 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:26,601 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:26,602 [Thread-502] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:05:26,615 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@39315968{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:05:26,631 [Thread-502] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7f5e193{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:05:26,631 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4862bf1{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:26,632 [Thread-502] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62c72e91{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:26,636 [Thread-502] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:05:26,645 [Thread-502] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:05:26,645 [Thread-502] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testPrivacy
[msx] writeFile testName = org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testPrivacy
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testSaslDataTransferWithTrustedServerTrustedClient
[msx] perform reset as unitTestCounterInClass 5 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Finished org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testSaslDataTransferWithTrustedServerTrustedClient
[msx] writeFile testName = org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testSaslDataTransferWithTrustedServerTrustedClient
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testDataNodeAbortsIfNotHttpsOnly
[msx] perform reset as unitTestCounterInClass 6 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:05:26,768 [Thread-679] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=3
2020-04-02 05:05:26,779 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803926778,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:26,781 [Thread-679] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
Formatting using clusterid: testClusterID
2020-04-02 05:05:26,781 [Thread-679] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:26,782 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:26,782 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:26,782 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:26,782 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:26,782 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:26,782 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:26,783 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:26,783 [Thread-679] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:26,783 [Thread-679] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:26,783 [Thread-679] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:26,784 [Thread-679] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:26,784 [Thread-679] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:26
2020-04-02 05:05:26,784 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:26,784 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:26,784 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 37.5 MB
2020-04-02 05:05:26,784 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:26,906 [Thread-679] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:26,906 [Thread-679] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:26,906 [Thread-679] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:26,907 [Thread-679] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:26,907 [Thread-679] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:26,907 [Thread-679] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:26,907 [Thread-679] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:26,907 [Thread-679] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:26,907 [Thread-679] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:26,907 [Thread-679] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:26,907 [Thread-679] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:26,907 [Thread-679] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:26,907 [Thread-679] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:26,907 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:26,907 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:26,907 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.7 MB
2020-04-02 05:05:26,907 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:26,912 [Thread-679] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:26,914 [Thread-679] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:26,914 [Thread-679] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:26,924 [Thread-679] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:26,973 [Thread-679] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:26,976 [Thread-679] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:26,988 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:26,990 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:26,992 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.7 MB
2020-04-02 05:05:26,993 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:26,993 [Thread-679] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:26,994 [Thread-679] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:26,994 [Thread-679] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:26,994 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:26,998 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:26,998 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:26,998 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:26,999 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 575.8 KB
2020-04-02 05:05:26,999 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:27,003 [Thread-679] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-36424511-172.17.0.5-1585803927003
2020-04-02 05:05:27,005 [Thread-679] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:05:27,011 [Thread-679] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:05:27,012 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:27,012 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:27,022 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:05:27,022 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:05:27,025 [Thread-679] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:05:27,027 [Thread-679] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:27,032 [Thread-679] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:05:27,034 [Thread-679] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:05:27,034 [Thread-679] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:05:27,035 [Thread-679] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:27,035 [Thread-679] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:05:27,043 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803927042,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:27,045 [Thread-679] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:27,054 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1c0ccf7f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:27,054 [Thread-679] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:27,054 [Thread-679] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:05:27,055 [Thread-679] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:0
2020-04-02 05:05:27,055 [Thread-679] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:27,057 [Thread-679] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:27,057 [Thread-679] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:27,057 [Thread-679] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:27,059 [Thread-679] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:27,059 [Thread-679] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:27,059 [Thread-679] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:27,059 [Thread-679] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:27,062 [Thread-679] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:27,062 [Thread-679] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:27,062 [Thread-679] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:05:27,062 [Thread-679] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:05:27,063 [Thread-679] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45299
2020-04-02 05:05:27,063 [Thread-679] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41981
2020-04-02 05:05:27,063 [Thread-679] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:27,076 [Thread-679] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@154df390{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:27,077 [Thread-679] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7332e3e4{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:27,080 [Thread-679] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:27,081 [Thread-679] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:27,082 [Thread-679] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@319b7903{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:27,082 [Thread-679] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4322163a{HTTP/1.1,[http/1.1]}{localhost:45299}
2020-04-02 05:05:27,084 [Thread-679] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@1f29305(server,h=[],w=[]) for SslContextFactory@5944c32f(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/trustKS.jks)
2020-04-02 05:05:27,085 [Thread-679] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@33fdfa65{SSL,[ssl, http/1.1]}{localhost:41981}
2020-04-02 05:05:27,085 [Thread-679] INFO  server.Server (Server.java:doStart(419)) - Started @13644ms
2020-04-02 05:05:27,093 [Thread-679] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:27,093 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:27,093 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:27,093 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:27,093 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:27,093 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:27,093 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:27,094 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:27,094 [Thread-679] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:27,094 [Thread-679] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:27,094 [Thread-679] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:27,094 [Thread-679] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:27,095 [Thread-679] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:27
2020-04-02 05:05:27,095 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:27,095 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:27,095 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 37.5 MB
2020-04-02 05:05:27,095 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:27,102 [Thread-679] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:27,102 [Thread-679] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:27,102 [Thread-679] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:27,103 [Thread-679] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:27,103 [Thread-679] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:27,103 [Thread-679] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:27,103 [Thread-679] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:27,103 [Thread-679] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:27,103 [Thread-679] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:27,103 [Thread-679] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:27,104 [Thread-679] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:27,104 [Thread-679] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:27,104 [Thread-679] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:27,104 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:27,104 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:27,105 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.7 MB
2020-04-02 05:05:27,105 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:27,107 [Thread-679] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:27,108 [Thread-679] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:27,108 [Thread-679] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:27,108 [Thread-679] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:27,108 [Thread-679] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:27,108 [Thread-679] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:27,108 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:27,109 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:27,109 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.7 MB
2020-04-02 05:05:27,109 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:27,110 [Thread-679] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:27,110 [Thread-679] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:27,110 [Thread-679] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:27,110 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:27,111 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:27,111 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:27,111 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:27,111 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 575.8 KB
2020-04-02 05:05:27,112 [Thread-679] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:27,114 [Thread-679] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:27,115 [Thread-679] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:27,116 [Thread-679] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:05:27,116 [Thread-679] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:05:27,117 [Thread-679] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:05:27,117 [Thread-679] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:27,118 [Thread-679] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:27,118 [Thread-679] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:27,118 [Thread-679] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:27,119 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:27,119 [Thread-679] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:05:27,128 [Thread-679] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:27,128 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 15 msecs
2020-04-02 05:05:27,128 [Thread-679] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:05:27,129 [Thread-679] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:27,129 [Socket Reader #1 for port 37991] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37991
2020-04-02 05:05:27,140 [Thread-679] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:37991 to access this namenode/service.
2020-04-02 05:05:27,141 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:27,171 [Thread-679] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:27,174 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@a608c63] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:05:27,178 [Thread-679] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:27,178 [Thread-679] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:05:27,178 [Thread-679] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:05:27,178 [Thread-679] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:27,183 [Thread-679] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:27,187 [Thread[Thread-715,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:05:27,187 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:27,188 [Thread[Thread-715,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:27,189 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:27,194 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:27,194 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:27,194 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:27,194 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 16 msec
2020-04-02 05:05:27,208 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:27,209 [IPC Server listener on 37991] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37991: starting
2020-04-02 05:05:27,213 [Thread-679] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:37991
2020-04-02 05:05:27,218 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:27,218 [Thread-679] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:27,220 [Thread-679] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:27,221 [Thread-679] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 37991 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:27,225 [CacheReplicationMonitor(626634066)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:27,244 [Thread-679] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:27,250 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803927250,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:27,252 [Thread-679] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:27,253 [Thread-679] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:27,253 [Thread-679] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:27,254 [Thread-679] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:27,254 [Thread-679] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:27,255 [Thread-679] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:27,255 [Thread-679] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:27,255 [Thread-679] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:27,255 [Thread-679] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:27,256 [Thread-679] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:05:27,256 [Thread-679] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:05:27,256 [Thread-679] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 37991 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:27,256 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:27,256 [Thread[Thread-715,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:05:27,257 [Thread-679] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 3
2020-04-02 05:05:27,257 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@7cdde8fb] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:05:27,257 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@21c80273] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:05:27,257 [Thread-679] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 4 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 2 2 
2020-04-02 05:05:27,260 [Thread-679] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000004
2020-04-02 05:05:27,261 [Thread-679] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000004
2020-04-02 05:05:27,261 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:05:27,263 [CacheReplicationMonitor(626634066)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:05:27,265 [Thread-679] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37991
2020-04-02 05:05:27,267 [IPC Server listener on 37991] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37991
2020-04-02 05:05:27,268 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:27,271 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:05:27,272 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:05:27,282 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:27,282 [Thread-679] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:05:27,284 [Thread-679] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@319b7903{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:05:27,294 [Thread-679] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4322163a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:27,296 [Thread-679] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@33fdfa65{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:05:27,297 [Thread-679] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7332e3e4{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:27,297 [Thread-679] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@154df390{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
[msx] test Finished org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testDataNodeAbortsIfNotHttpsOnly
[msx] writeFile testName = org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testDataNodeAbortsIfNotHttpsOnly
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testSaslDataTransferWithUntrustedServerUntrustedClient
[msx] perform reset as unitTestCounterInClass 7 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Finished org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testSaslDataTransferWithUntrustedServerUntrustedClient
[msx] writeFile testName = org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testSaslDataTransferWithUntrustedServerUntrustedClient
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testNoSaslAndSecurePortsIgnored
[msx] perform reset as unitTestCounterInClass 8 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:05:27,396 [Thread-734] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=3
2020-04-02 05:05:27,403 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803927402,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:27,406 [Thread-734] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
Formatting using clusterid: testClusterID
2020-04-02 05:05:27,406 [Thread-734] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:27,407 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:27,407 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:27,407 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:27,407 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:27,407 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:27,407 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:27,407 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:27,408 [Thread-734] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:27,408 [Thread-734] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:27,408 [Thread-734] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:27,408 [Thread-734] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:27,408 [Thread-734] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:27
2020-04-02 05:05:27,408 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:27,408 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:27,408 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 37.5 MB
2020-04-02 05:05:27,408 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:27,415 [Thread-734] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:27,415 [Thread-734] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:27,416 [Thread-734] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:27,416 [Thread-734] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:27,416 [Thread-734] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:27,416 [Thread-734] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:27,416 [Thread-734] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:27,416 [Thread-734] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:27,416 [Thread-734] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:27,416 [Thread-734] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:27,416 [Thread-734] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:27,416 [Thread-734] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:27,416 [Thread-734] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:27,417 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:27,417 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:27,417 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.7 MB
2020-04-02 05:05:27,417 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:27,420 [Thread-734] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:27,420 [Thread-734] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:27,420 [Thread-734] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:27,420 [Thread-734] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:27,420 [Thread-734] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:27,420 [Thread-734] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:27,420 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:27,420 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:27,420 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.7 MB
2020-04-02 05:05:27,421 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:27,421 [Thread-734] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:27,421 [Thread-734] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:27,422 [Thread-734] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:27,422 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:27,422 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:27,422 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:27,422 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:27,422 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 575.8 KB
2020-04-02 05:05:27,422 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:27,423 [Thread-734] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:27,426 [Thread-734] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:05:27,428 [Thread-734] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:05:27,429 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:27,429 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:27,436 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:05:27,440 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:05:27,442 [Thread-734] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:05:27,443 [Thread-734] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:27,444 [Thread-734] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:05:27,444 [Thread-734] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:27,444 [Thread-734] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:05:27,449 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803927448,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:27,453 [Thread-734] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:27,459 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6edbc614] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:27,459 [Thread-734] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:27,460 [Thread-734] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:0
2020-04-02 05:05:27,460 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:27,462 [Thread-734] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:27,462 [Thread-734] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:27,462 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:27,464 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:27,464 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:27,464 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:27,464 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:27,467 [Thread-734] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:27,467 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:27,467 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:05:27,467 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:05:27,467 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37203
2020-04-02 05:05:27,467 [Thread-734] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:27,469 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2d92d421{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:27,469 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1797e353{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:27,472 [Thread-734] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:27,473 [Thread-734] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:27,474 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@714608c1{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:27,476 [Thread-734] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@2e92d723(server,h=[],w=[]) for SslContextFactory@4416b34(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/trustKS.jks)
2020-04-02 05:05:27,479 [Thread-734] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@345f05bb{SSL,[ssl, http/1.1]}{localhost:37203}
2020-04-02 05:05:27,479 [Thread-734] INFO  server.Server (Server.java:doStart(419)) - Started @14037ms
2020-04-02 05:05:27,480 [Thread-734] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:27,481 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:27,481 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:27,481 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:27,481 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:27,481 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:27,481 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:27,482 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:27,482 [Thread-734] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:27,482 [Thread-734] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:27,482 [Thread-734] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:27,483 [Thread-734] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:27,483 [Thread-734] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:27
2020-04-02 05:05:27,483 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:27,483 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:27,483 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 37.5 MB
2020-04-02 05:05:27,483 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:27,488 [Thread-734] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:27,489 [Thread-734] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:27,489 [Thread-734] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:27,489 [Thread-734] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:27,489 [Thread-734] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:27,489 [Thread-734] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:27,490 [Thread-734] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:27,490 [Thread-734] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:27,490 [Thread-734] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:27,490 [Thread-734] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:27,490 [Thread-734] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:27,490 [Thread-734] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:27,490 [Thread-734] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:27,490 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:27,490 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:27,491 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.7 MB
2020-04-02 05:05:27,491 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:27,493 [Thread-734] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:27,493 [Thread-734] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:27,493 [Thread-734] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:27,493 [Thread-734] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:27,494 [Thread-734] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:27,494 [Thread-734] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:27,494 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:27,494 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:27,494 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.7 MB
2020-04-02 05:05:27,494 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:27,495 [Thread-734] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:27,495 [Thread-734] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:27,495 [Thread-734] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:27,495 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:27,495 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:27,496 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:27,496 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:27,496 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 575.8 KB
2020-04-02 05:05:27,496 [Thread-734] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:27,499 [Thread-734] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:27,500 [Thread-734] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:27,502 [Thread-734] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:05:27,502 [Thread-734] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:05:27,503 [Thread-734] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:05:27,503 [Thread-734] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:27,505 [Thread-734] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:27,505 [Thread-734] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:27,506 [Thread-734] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:27,506 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:27,506 [Thread-734] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:05:27,515 [Thread-734] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:27,516 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 19 msecs
2020-04-02 05:05:27,516 [Thread-734] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:05:27,516 [Thread-734] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:27,517 [Socket Reader #1 for port 38829] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38829
2020-04-02 05:05:27,522 [Thread-734] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:38829 to access this namenode/service.
2020-04-02 05:05:27,522 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:27,552 [Thread-734] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:27,554 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@421a33f0] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:05:27,557 [Thread-734] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:27,557 [Thread-734] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:05:27,557 [Thread-734] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:05:27,557 [Thread-734] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:27,563 [Thread-734] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:27,572 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:27,572 [Thread[Thread-761,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:05:27,572 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:27,572 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:27,572 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:27,572 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:27,572 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 15 msec
2020-04-02 05:05:27,576 [Thread[Thread-761,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:27,578 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:27,578 [IPC Server listener on 38829] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38829: starting
2020-04-02 05:05:27,587 [Thread-734] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:38829
2020-04-02 05:05:27,588 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:27,588 [Thread-734] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:27,588 [Thread-734] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:27,596 [Thread-734] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 38829 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:27,598 [CacheReplicationMonitor(168127360)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:27,606 [Thread-734] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:27,620 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803927620,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:27,626 [Thread-734] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:27,627 [Thread-734] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:27,627 [Thread-734] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:27,628 [Thread-734] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:27,628 [Thread-734] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:27,628 [Thread-734] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:27,628 [Thread-734] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:27,629 [Thread-734] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:27,629 [Thread-734] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:27,629 [Thread-734] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:27,641 [Thread-734] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:43702
2020-04-02 05:05:27,641 [Thread-734] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:27,641 [Thread-734] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:27,642 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:27,648 [Thread-734] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:27,651 [Thread-734] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:27,651 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:27,656 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:27,656 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:27,656 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:27,657 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:27,657 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38613
2020-04-02 05:05:27,658 [Thread-734] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:27,660 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@777d83bb{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:27,666 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@97848c9{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:27,677 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@13c6726a{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:27,677 [Thread-734] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5a05c682{HTTP/1.1,[http/1.1]}{localhost:38613}
2020-04-02 05:05:27,680 [Thread-734] INFO  server.Server (Server.java:doStart(419)) - Started @14238ms
2020-04-02 05:05:27,693 [Thread-734] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:42106
2020-04-02 05:05:27,695 [Thread-734] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:27,695 [Thread-734] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:27,695 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@650254b1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:27,696 [Thread-734] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:27,696 [Socket Reader #1 for port 38338] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38338
2020-04-02 05:05:27,700 [Thread-734] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:38338
2020-04-02 05:05:27,708 [Thread-734] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:27,708 [Thread-734] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:27,709 [Thread-790] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38829 starting to offer service
2020-04-02 05:05:27,714 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:27,714 [IPC Server listener on 38338] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38338: starting
2020-04-02 05:05:27,722 [Thread-734] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 38338 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:27,722 [Thread-734] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:27,740 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803927739,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:27,744 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803927743,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:27,768 [Thread-734] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:27,769 [Thread-734] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:27,772 [Thread-734] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:27,774 [Thread-734] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:27,774 [Thread-734] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:27,780 [Thread-734] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:27,780 [Thread-734] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:27,780 [Socket Reader #1 for port 38829] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:27,780 [Thread-734] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:27,781 [Thread-734] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:27,781 [Thread-734] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:27,785 [Thread-734] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:33285
2020-04-02 05:05:27,785 [Thread-734] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:27,786 [Thread-734] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:27,787 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:27,788 [Thread-790] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38829
2020-04-02 05:05:27,789 [Thread-790] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:27,790 [Thread-734] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:27,790 [Thread-734] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:27,791 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:27,791 [Thread-790] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:27,791 [Thread-790] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1695900160. Formatting...
2020-04-02 05:05:27,791 [Thread-790] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b294d2b5-2e9e-453e-8d2c-843ffb545e3e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:05:27,792 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:27,792 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:27,792 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:27,792 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:27,793 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35619
2020-04-02 05:05:27,793 [Thread-734] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:27,794 [Thread-790] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:27,794 [Thread-790] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1695900160. Formatting...
2020-04-02 05:05:27,794 [Thread-790] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ba242e12-8131-42ff-be6e-8b572db4c2bc for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:05:27,794 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1cb2e321{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:27,795 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7cac4f39{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:27,799 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@522b705c{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:27,800 [Thread-734] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6c4ac802{HTTP/1.1,[http/1.1]}{localhost:35619}
2020-04-02 05:05:27,802 [Thread-734] INFO  server.Server (Server.java:doStart(419)) - Started @14360ms
2020-04-02 05:05:27,804 [Thread-790] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:27,804 [Thread-790] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:27,804 [Thread-790] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-604133109-172.17.0.5-1585803927423 is not formatted. Formatting ...
2020-04-02 05:05:27,804 [Thread-790] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-604133109-172.17.0.5-1585803927423 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-604133109-172.17.0.5-1585803927423/current
2020-04-02 05:05:27,812 [Thread-790] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:27,812 [Thread-790] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:27,812 [Thread-790] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-604133109-172.17.0.5-1585803927423 is not formatted. Formatting ...
2020-04-02 05:05:27,812 [Thread-790] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-604133109-172.17.0.5-1585803927423 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-604133109-172.17.0.5-1585803927423/current
2020-04-02 05:05:27,817 [Thread-734] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:42442
2020-04-02 05:05:27,817 [Thread-734] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:27,818 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@f43bf1c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:27,818 [Thread-734] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:27,818 [Thread-734] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:27,818 [Thread-790] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1695900160;bpid=BP-604133109-172.17.0.5-1585803927423;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1695900160;c=1585803927423;bpid=BP-604133109-172.17.0.5-1585803927423;dnuuid=null
2020-04-02 05:05:27,819 [Socket Reader #1 for port 35032] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35032
2020-04-02 05:05:27,820 [Thread-790] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID acd9669f-a068-4c78-8b5e-76a9f02b67e8
2020-04-02 05:05:27,825 [Thread-790] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-b294d2b5-2e9e-453e-8d2c-843ffb545e3e
2020-04-02 05:05:27,827 [Thread-790] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:05:27,830 [Thread-790] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-ba242e12-8131-42ff-be6e-8b572db4c2bc
2020-04-02 05:05:27,831 [Thread-790] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:05:27,831 [Thread-790] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:27,832 [Thread-790] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:27,833 [Thread-790] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:27,833 [Thread-790] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:27,833 [Thread-790] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:27,839 [Thread-790] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:27,839 [Thread-734] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:35032
2020-04-02 05:05:27,839 [Thread-814] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:27,839 [Thread-815] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:27,845 [Thread-734] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:27,845 [Thread-734] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:27,846 [Thread-818] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38829 starting to offer service
2020-04-02 05:05:27,849 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:27,849 [IPC Server listener on 35032] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35032: starting
2020-04-02 05:05:27,862 [Thread-734] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 35032 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:27,863 [Thread-734] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:27,871 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803927870,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:27,872 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803927872,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:27,873 [Thread-734] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:27,873 [Thread-734] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:27,874 [Thread-815] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-604133109-172.17.0.5-1585803927423 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 35ms
2020-04-02 05:05:27,877 [Thread-734] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:27,887 [Thread-814] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-604133109-172.17.0.5-1585803927423 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 48ms
2020-04-02 05:05:27,887 [Thread-790] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-604133109-172.17.0.5-1585803927423: 48ms
2020-04-02 05:05:27,888 [Thread-832] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:27,888 [Thread-832] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-604133109-172.17.0.5-1585803927423/current/replicas doesn't exist 
2020-04-02 05:05:27,888 [Thread-734] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:27,888 [Thread-734] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:27,889 [Thread-734] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:27,889 [Thread-734] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:27,889 [Thread-734] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:27,889 [Thread-734] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:27,890 [Thread-734] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:27,888 [Thread-832] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 0ms
2020-04-02 05:05:27,891 [Thread-734] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:41925
2020-04-02 05:05:27,891 [Thread-734] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:27,891 [Thread-734] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:27,890 [Socket Reader #1 for port 38829] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:27,892 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:27,888 [Thread-833] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:27,905 [Thread-818] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38829
2020-04-02 05:05:27,906 [Thread-833] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-604133109-172.17.0.5-1585803927423/current/replicas doesn't exist 
2020-04-02 05:05:27,910 [Thread-734] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:27,910 [Thread-818] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:27,910 [Thread-734] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:27,910 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:27,910 [Thread-833] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 4ms
2020-04-02 05:05:27,911 [Thread-790] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-604133109-172.17.0.5-1585803927423: 24ms
2020-04-02 05:05:27,911 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:27,911 [Thread-790] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:36 AM with interval of 21600000ms
2020-04-02 05:05:27,911 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:27,912 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:27,912 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:27,912 [Thread-734] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39858
2020-04-02 05:05:27,912 [Thread-734] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:27,911 [Thread-818] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:27,912 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:27,913 [Thread-818] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1695900160. Formatting...
2020-04-02 05:05:27,913 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:27,915 [Thread-818] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9a61c67f-cf5d-49a3-a780-d8cc46f75509 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:05:27,915 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-ba242e12-8131-42ff-be6e-8b572db4c2bc): finished scanning block pool BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:27,917 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-604133109-172.17.0.5-1585803927423 (Datanode Uuid acd9669f-a068-4c78-8b5e-76a9f02b67e8) service to localhost/127.0.0.1:38829 beginning handshake with NN
2020-04-02 05:05:27,918 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-b294d2b5-2e9e-453e-8d2c-843ffb545e3e): finished scanning block pool BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:27,918 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-ba242e12-8131-42ff-be6e-8b572db4c2bc): no suitable block pools found to scan.  Waiting 1814399993 ms.
2020-04-02 05:05:27,918 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@41154397{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:27,918 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-b294d2b5-2e9e-453e-8d2c-843ffb545e3e): no suitable block pools found to scan.  Waiting 1814399993 ms.
2020-04-02 05:05:27,921 [IPC Server handler 3 on 38829] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43702, datanodeUuid=acd9669f-a068-4c78-8b5e-76a9f02b67e8, infoPort=0, infoSecurePort=42106, ipcPort=38338, storageInfo=lv=-57;cid=testClusterID;nsid=1695900160;c=1585803927423) storage acd9669f-a068-4c78-8b5e-76a9f02b67e8
2020-04-02 05:05:27,921 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3bc1dc8{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:27,921 [IPC Server handler 3 on 38829] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43702
2020-04-02 05:05:27,921 [IPC Server handler 3 on 38829] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN acd9669f-a068-4c78-8b5e-76a9f02b67e8 (127.0.0.1:43702).
2020-04-02 05:05:27,924 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-604133109-172.17.0.5-1585803927423 (Datanode Uuid acd9669f-a068-4c78-8b5e-76a9f02b67e8) service to localhost/127.0.0.1:38829 successfully registered with NN
2020-04-02 05:05:27,925 [Thread-818] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:27,925 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-604133109-172.17.0.5-1585803927423 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:27,925 [Thread-818] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1695900160. Formatting...
2020-04-02 05:05:27,925 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:27,925 [Thread-818] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8bbb3049-107e-4fdf-81ad-500f7b314c7d for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:05:27,925 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38829 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:27,931 [IPC Server handler 1 on 38829] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b294d2b5-2e9e-453e-8d2c-843ffb545e3e for DN 127.0.0.1:43702
2020-04-02 05:05:27,931 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1b528258{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:27,931 [IPC Server handler 1 on 38829] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ba242e12-8131-42ff-be6e-8b572db4c2bc for DN 127.0.0.1:43702
2020-04-02 05:05:27,933 [Thread-734] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6e30b8be{HTTP/1.1,[http/1.1]}{localhost:39858}
2020-04-02 05:05:27,934 [Thread-734] INFO  server.Server (Server.java:doStart(419)) - Started @14493ms
2020-04-02 05:05:27,936 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb30cd931867baf9d: Processing first storage report for DS-ba242e12-8131-42ff-be6e-8b572db4c2bc from datanode acd9669f-a068-4c78-8b5e-76a9f02b67e8
2020-04-02 05:05:27,936 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb30cd931867baf9d: from storage DS-ba242e12-8131-42ff-be6e-8b572db4c2bc node DatanodeRegistration(127.0.0.1:43702, datanodeUuid=acd9669f-a068-4c78-8b5e-76a9f02b67e8, infoPort=0, infoSecurePort=42106, ipcPort=38338, storageInfo=lv=-57;cid=testClusterID;nsid=1695900160;c=1585803927423), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:27,936 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb30cd931867baf9d: Processing first storage report for DS-b294d2b5-2e9e-453e-8d2c-843ffb545e3e from datanode acd9669f-a068-4c78-8b5e-76a9f02b67e8
2020-04-02 05:05:27,936 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb30cd931867baf9d: from storage DS-b294d2b5-2e9e-453e-8d2c-843ffb545e3e node DatanodeRegistration(127.0.0.1:43702, datanodeUuid=acd9669f-a068-4c78-8b5e-76a9f02b67e8, infoPort=0, infoSecurePort=42106, ipcPort=38338, storageInfo=lv=-57;cid=testClusterID;nsid=1695900160;c=1585803927423), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:27,936 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xb30cd931867baf9d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:27,937 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:27,941 [Thread-818] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:27,941 [Thread-818] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:27,942 [Thread-818] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-604133109-172.17.0.5-1585803927423 is not formatted. Formatting ...
2020-04-02 05:05:27,942 [Thread-818] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-604133109-172.17.0.5-1585803927423 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-604133109-172.17.0.5-1585803927423/current
2020-04-02 05:05:27,945 [Thread-734] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:43744
2020-04-02 05:05:27,946 [Thread-734] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:27,946 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1ee6266b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:27,946 [Thread-734] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:27,946 [Thread-734] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:27,947 [Socket Reader #1 for port 33872] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33872
2020-04-02 05:05:27,954 [Thread-734] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:33872
2020-04-02 05:05:27,957 [Thread-818] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:27,958 [Thread-818] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:27,958 [Thread-818] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-604133109-172.17.0.5-1585803927423 is not formatted. Formatting ...
2020-04-02 05:05:27,958 [Thread-818] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-604133109-172.17.0.5-1585803927423 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-604133109-172.17.0.5-1585803927423/current
2020-04-02 05:05:27,959 [Thread-818] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1695900160;bpid=BP-604133109-172.17.0.5-1585803927423;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1695900160;c=1585803927423;bpid=BP-604133109-172.17.0.5-1585803927423;dnuuid=null
2020-04-02 05:05:27,961 [Thread-818] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 92edfe99-db48-4865-a4f6-7ff029cae2f0
2020-04-02 05:05:27,962 [Thread-818] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-9a61c67f-cf5d-49a3-a780-d8cc46f75509
2020-04-02 05:05:27,962 [Thread-818] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:05:27,975 [Thread-734] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:27,976 [Thread-734] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:27,976 [Thread-818] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8bbb3049-107e-4fdf-81ad-500f7b314c7d
2020-04-02 05:05:27,976 [Thread-818] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:05:27,977 [Thread-818] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:27,978 [Thread-818] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:27,983 [Thread-851] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38829 starting to offer service
2020-04-02 05:05:27,993 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:27,993 [IPC Server listener on 33872] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33872: starting
2020-04-02 05:05:28,003 [Thread-818] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:28,003 [Thread-818] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:28,004 [Thread-818] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:28,004 [Thread-734] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 33872 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:28,004 [Thread-818] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:28,004 [Thread-863] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:05:28,004 [Thread-864] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:05:28,027 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803928027,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:28,032 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803928027,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:28,033 [Socket Reader #1 for port 38829] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:28,048 [IPC Server handler 5 on 38829] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:28,048 [Socket Reader #1 for port 38829] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:28,049 [Thread-734] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:28,049 [Thread-734] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:28,062 [Thread-863] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-604133109-172.17.0.5-1585803927423 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 58ms
2020-04-02 05:05:28,063 [Thread-851] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38829
2020-04-02 05:05:28,066 [Thread-851] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:28,067 [Thread-851] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:28,067 [Thread-851] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1695900160. Formatting...
2020-04-02 05:05:28,068 [Thread-851] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-85212e2d-f6a5-404d-9f18-716af5377b26 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:05:28,068 [Thread-864] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-604133109-172.17.0.5-1585803927423 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 65ms
2020-04-02 05:05:28,069 [Thread-818] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-604133109-172.17.0.5-1585803927423: 65ms
2020-04-02 05:05:28,069 [Thread-868] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:05:28,069 [Thread-869] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:05:28,069 [Thread-868] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-604133109-172.17.0.5-1585803927423/current/replicas doesn't exist 
2020-04-02 05:05:28,070 [Thread-869] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-604133109-172.17.0.5-1585803927423/current/replicas doesn't exist 
2020-04-02 05:05:28,070 [Thread-868] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-04-02 05:05:28,070 [Thread-851] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:28,070 [Thread-869] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 0ms
2020-04-02 05:05:28,070 [Thread-851] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1695900160. Formatting...
2020-04-02 05:05:28,070 [Thread-818] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-604133109-172.17.0.5-1585803927423: 1ms
2020-04-02 05:05:28,071 [Thread-851] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2d7cfe3c-c73d-4be6-b9eb-df37b529b077 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:05:28,071 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:28,071 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:28,071 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-8bbb3049-107e-4fdf-81ad-500f7b314c7d): finished scanning block pool BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:28,071 [Thread-818] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:16 AM with interval of 21600000ms
2020-04-02 05:05:28,071 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-9a61c67f-cf5d-49a3-a780-d8cc46f75509): finished scanning block pool BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:28,072 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-8bbb3049-107e-4fdf-81ad-500f7b314c7d): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:05:28,074 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-604133109-172.17.0.5-1585803927423 (Datanode Uuid 92edfe99-db48-4865-a4f6-7ff029cae2f0) service to localhost/127.0.0.1:38829 beginning handshake with NN
2020-04-02 05:05:28,074 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-9a61c67f-cf5d-49a3-a780-d8cc46f75509): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:05:28,076 [IPC Server handler 7 on 38829] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33285, datanodeUuid=92edfe99-db48-4865-a4f6-7ff029cae2f0, infoPort=0, infoSecurePort=42442, ipcPort=35032, storageInfo=lv=-57;cid=testClusterID;nsid=1695900160;c=1585803927423) storage 92edfe99-db48-4865-a4f6-7ff029cae2f0
2020-04-02 05:05:28,077 [IPC Server handler 7 on 38829] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33285
2020-04-02 05:05:28,077 [IPC Server handler 7 on 38829] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 92edfe99-db48-4865-a4f6-7ff029cae2f0 (127.0.0.1:33285).
2020-04-02 05:05:28,078 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-604133109-172.17.0.5-1585803927423 (Datanode Uuid 92edfe99-db48-4865-a4f6-7ff029cae2f0) service to localhost/127.0.0.1:38829 successfully registered with NN
2020-04-02 05:05:28,078 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-604133109-172.17.0.5-1585803927423 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:28,079 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:28,079 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38829 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:28,086 [IPC Server handler 8 on 38829] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9a61c67f-cf5d-49a3-a780-d8cc46f75509 for DN 127.0.0.1:33285
2020-04-02 05:05:28,091 [IPC Server handler 8 on 38829] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8bbb3049-107e-4fdf-81ad-500f7b314c7d for DN 127.0.0.1:33285
2020-04-02 05:05:28,092 [Thread-851] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:28,092 [Thread-851] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:28,093 [Thread-851] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-604133109-172.17.0.5-1585803927423 is not formatted. Formatting ...
2020-04-02 05:05:28,093 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf8034e1e3aa2886: Processing first storage report for DS-9a61c67f-cf5d-49a3-a780-d8cc46f75509 from datanode 92edfe99-db48-4865-a4f6-7ff029cae2f0
2020-04-02 05:05:28,093 [Thread-851] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-604133109-172.17.0.5-1585803927423 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-604133109-172.17.0.5-1585803927423/current
2020-04-02 05:05:28,093 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf8034e1e3aa2886: from storage DS-9a61c67f-cf5d-49a3-a780-d8cc46f75509 node DatanodeRegistration(127.0.0.1:33285, datanodeUuid=92edfe99-db48-4865-a4f6-7ff029cae2f0, infoPort=0, infoSecurePort=42442, ipcPort=35032, storageInfo=lv=-57;cid=testClusterID;nsid=1695900160;c=1585803927423), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:28,093 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf8034e1e3aa2886: Processing first storage report for DS-8bbb3049-107e-4fdf-81ad-500f7b314c7d from datanode 92edfe99-db48-4865-a4f6-7ff029cae2f0
2020-04-02 05:05:28,093 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf8034e1e3aa2886: from storage DS-8bbb3049-107e-4fdf-81ad-500f7b314c7d node DatanodeRegistration(127.0.0.1:33285, datanodeUuid=92edfe99-db48-4865-a4f6-7ff029cae2f0, infoPort=0, infoSecurePort=42442, ipcPort=35032, storageInfo=lv=-57;cid=testClusterID;nsid=1695900160;c=1585803927423), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:28,094 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xf8034e1e3aa2886,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:28,094 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:28,103 [Thread-851] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:28,103 [Thread-851] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:28,104 [Thread-851] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-604133109-172.17.0.5-1585803927423 is not formatted. Formatting ...
2020-04-02 05:05:28,104 [Thread-851] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-604133109-172.17.0.5-1585803927423 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-604133109-172.17.0.5-1585803927423/current
2020-04-02 05:05:28,105 [Thread-851] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1695900160;bpid=BP-604133109-172.17.0.5-1585803927423;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1695900160;c=1585803927423;bpid=BP-604133109-172.17.0.5-1585803927423;dnuuid=null
2020-04-02 05:05:28,107 [Thread-851] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 72056b25-89a4-48ff-a467-a303b1583b42
2020-04-02 05:05:28,108 [Thread-851] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-85212e2d-f6a5-404d-9f18-716af5377b26
2020-04-02 05:05:28,111 [Thread-851] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:05:28,112 [Thread-851] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-2d7cfe3c-c73d-4be6-b9eb-df37b529b077
2020-04-02 05:05:28,112 [Thread-851] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:05:28,115 [Thread-851] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:28,115 [Thread-851] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:28,116 [Thread-851] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:28,116 [Thread-851] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:28,116 [Thread-851] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:28,116 [Thread-851] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:28,117 [Thread-875] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:05:28,117 [Thread-876] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:05:28,148 [Thread-875] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-604133109-172.17.0.5-1585803927423 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 31ms
2020-04-02 05:05:28,149 [Thread-876] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-604133109-172.17.0.5-1585803927423 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 32ms
2020-04-02 05:05:28,152 [Thread-851] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-604133109-172.17.0.5-1585803927423: 36ms
2020-04-02 05:05:28,152 [Thread-879] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:05:28,152 [Thread-880] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:05:28,152 [IPC Server handler 0 on 38829] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:28,152 [Thread-880] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-604133109-172.17.0.5-1585803927423/current/replicas doesn't exist 
2020-04-02 05:05:28,152 [Thread-879] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-604133109-172.17.0.5-1585803927423/current/replicas doesn't exist 
2020-04-02 05:05:28,153 [Thread-880] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 1ms
2020-04-02 05:05:28,153 [Thread-734] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:28,156 [Thread-734] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:28,156 [Thread-879] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 4ms
2020-04-02 05:05:28,161 [Thread-851] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-604133109-172.17.0.5-1585803927423: 10ms
2020-04-02 05:05:28,162 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:28,162 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-604133109-172.17.0.5-1585803927423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:28,162 [Thread-851] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:03 AM with interval of 21600000ms
2020-04-02 05:05:28,162 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-85212e2d-f6a5-404d-9f18-716af5377b26): finished scanning block pool BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:28,162 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-2d7cfe3c-c73d-4be6-b9eb-df37b529b077): finished scanning block pool BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:28,166 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-604133109-172.17.0.5-1585803927423 (Datanode Uuid 72056b25-89a4-48ff-a467-a303b1583b42) service to localhost/127.0.0.1:38829 beginning handshake with NN
2020-04-02 05:05:28,166 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-85212e2d-f6a5-404d-9f18-716af5377b26): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:05:28,166 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-2d7cfe3c-c73d-4be6-b9eb-df37b529b077): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:05:28,167 [IPC Server handler 2 on 38829] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41925, datanodeUuid=72056b25-89a4-48ff-a467-a303b1583b42, infoPort=0, infoSecurePort=43744, ipcPort=33872, storageInfo=lv=-57;cid=testClusterID;nsid=1695900160;c=1585803927423) storage 72056b25-89a4-48ff-a467-a303b1583b42
2020-04-02 05:05:28,167 [IPC Server handler 2 on 38829] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41925
2020-04-02 05:05:28,167 [IPC Server handler 2 on 38829] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 72056b25-89a4-48ff-a467-a303b1583b42 (127.0.0.1:41925).
2020-04-02 05:05:28,168 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-604133109-172.17.0.5-1585803927423 (Datanode Uuid 72056b25-89a4-48ff-a467-a303b1583b42) service to localhost/127.0.0.1:38829 successfully registered with NN
2020-04-02 05:05:28,168 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-604133109-172.17.0.5-1585803927423 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:28,168 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:28,169 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38829 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:28,183 [IPC Server handler 3 on 38829] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-85212e2d-f6a5-404d-9f18-716af5377b26 for DN 127.0.0.1:41925
2020-04-02 05:05:28,184 [IPC Server handler 3 on 38829] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2d7cfe3c-c73d-4be6-b9eb-df37b529b077 for DN 127.0.0.1:41925
2020-04-02 05:05:28,188 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5f4a8429feb1024f: Processing first storage report for DS-85212e2d-f6a5-404d-9f18-716af5377b26 from datanode 72056b25-89a4-48ff-a467-a303b1583b42
2020-04-02 05:05:28,188 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5f4a8429feb1024f: from storage DS-85212e2d-f6a5-404d-9f18-716af5377b26 node DatanodeRegistration(127.0.0.1:41925, datanodeUuid=72056b25-89a4-48ff-a467-a303b1583b42, infoPort=0, infoSecurePort=43744, ipcPort=33872, storageInfo=lv=-57;cid=testClusterID;nsid=1695900160;c=1585803927423), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:05:28,189 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5f4a8429feb1024f: Processing first storage report for DS-2d7cfe3c-c73d-4be6-b9eb-df37b529b077 from datanode 72056b25-89a4-48ff-a467-a303b1583b42
2020-04-02 05:05:28,189 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5f4a8429feb1024f: from storage DS-2d7cfe3c-c73d-4be6-b9eb-df37b529b077 node DatanodeRegistration(127.0.0.1:41925, datanodeUuid=72056b25-89a4-48ff-a467-a303b1583b42, infoPort=0, infoSecurePort=43744, ipcPort=33872, storageInfo=lv=-57;cid=testClusterID;nsid=1695900160;c=1585803927423), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:28,190 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x5f4a8429feb1024f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:28,190 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:28,259 [IPC Server handler 4 on 38829] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:28,260 [Thread-734] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:28,263 [IPC Server handler 5 on 38829] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:28,264 [Thread-734] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:28,267 [IPC Server handler 6 on 38829] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=create	src=/file1	dst=null	perm=hdfs:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:05:28,275 [IPC Server handler 7 on 38829] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:41925, 127.0.0.1:43702, 127.0.0.1:33285 for /file1
2020-04-02 05:05:28,284 [DataXceiver for client DFSClient_NONMAPREDUCE_-107601396_2940 at /127.0.0.1:44620 [Receiving block BP-604133109-172.17.0.5-1585803927423:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-604133109-172.17.0.5-1585803927423:blk_1073741825_1001 src: /127.0.0.1:44620 dest: /127.0.0.1:41925
2020-04-02 05:05:28,300 [DataXceiver for client DFSClient_NONMAPREDUCE_-107601396_2940 at /127.0.0.1:39270 [Receiving block BP-604133109-172.17.0.5-1585803927423:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-604133109-172.17.0.5-1585803927423:blk_1073741825_1001 src: /127.0.0.1:39270 dest: /127.0.0.1:43702
2020-04-02 05:05:28,311 [DataXceiver for client DFSClient_NONMAPREDUCE_-107601396_2940 at /127.0.0.1:49848 [Receiving block BP-604133109-172.17.0.5-1585803927423:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-604133109-172.17.0.5-1585803927423:blk_1073741825_1001 src: /127.0.0.1:49848 dest: /127.0.0.1:33285
2020-04-02 05:05:28,352 [PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49848, dest: /127.0.0.1:33285, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-107601396_2940, offset: 0, srvID: 92edfe99-db48-4865-a4f6-7ff029cae2f0, blockid: BP-604133109-172.17.0.5-1585803927423:blk_1073741825_1001, duration(ns): 20955166
2020-04-02 05:05:28,353 [PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:28,360 [PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33285]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39270, dest: /127.0.0.1:43702, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-107601396_2940, offset: 0, srvID: acd9669f-a068-4c78-8b5e-76a9f02b67e8, blockid: BP-604133109-172.17.0.5-1585803927423:blk_1073741825_1001, duration(ns): 24460341
2020-04-02 05:05:28,360 [PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33285]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33285] terminating
2020-04-02 05:05:28,361 [PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43702, 127.0.0.1:33285]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44620, dest: /127.0.0.1:41925, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-107601396_2940, offset: 0, srvID: 72056b25-89a4-48ff-a467-a303b1583b42, blockid: BP-604133109-172.17.0.5-1585803927423:blk_1073741825_1001, duration(ns): 29717171
2020-04-02 05:05:28,362 [PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43702, 127.0.0.1:33285]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43702, 127.0.0.1:33285] terminating
2020-04-02 05:05:28,372 [IPC Server handler 3 on 38829] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:41925, 127.0.0.1:43702, 127.0.0.1:33285 for /file1
2020-04-02 05:05:28,395 [DataXceiver for client DFSClient_NONMAPREDUCE_-107601396_2940 at /127.0.0.1:44630 [Receiving block BP-604133109-172.17.0.5-1585803927423:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-604133109-172.17.0.5-1585803927423:blk_1073741826_1002 src: /127.0.0.1:44630 dest: /127.0.0.1:41925
2020-04-02 05:05:28,397 [DataXceiver for client DFSClient_NONMAPREDUCE_-107601396_2940 at /127.0.0.1:39280 [Receiving block BP-604133109-172.17.0.5-1585803927423:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-604133109-172.17.0.5-1585803927423:blk_1073741826_1002 src: /127.0.0.1:39280 dest: /127.0.0.1:43702
2020-04-02 05:05:28,398 [DataXceiver for client DFSClient_NONMAPREDUCE_-107601396_2940 at /127.0.0.1:49858 [Receiving block BP-604133109-172.17.0.5-1585803927423:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-604133109-172.17.0.5-1585803927423:blk_1073741826_1002 src: /127.0.0.1:49858 dest: /127.0.0.1:33285
2020-04-02 05:05:28,403 [PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49858, dest: /127.0.0.1:33285, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-107601396_2940, offset: 0, srvID: 92edfe99-db48-4865-a4f6-7ff029cae2f0, blockid: BP-604133109-172.17.0.5-1585803927423:blk_1073741826_1002, duration(ns): 2864299
2020-04-02 05:05:28,404 [PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:28,405 [PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33285]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39280, dest: /127.0.0.1:43702, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-107601396_2940, offset: 0, srvID: acd9669f-a068-4c78-8b5e-76a9f02b67e8, blockid: BP-604133109-172.17.0.5-1585803927423:blk_1073741826_1002, duration(ns): 4404988
2020-04-02 05:05:28,405 [PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33285]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33285] terminating
2020-04-02 05:05:28,407 [PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43702, 127.0.0.1:33285]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44630, dest: /127.0.0.1:41925, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-107601396_2940, offset: 0, srvID: 72056b25-89a4-48ff-a467-a303b1583b42, blockid: BP-604133109-172.17.0.5-1585803927423:blk_1073741826_1002, duration(ns): 5770127
2020-04-02 05:05:28,407 [PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43702, 127.0.0.1:33285]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43702, 127.0.0.1:33285] terminating
2020-04-02 05:05:28,409 [IPC Server handler 6 on 38829] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:43702, 127.0.0.1:41925, 127.0.0.1:33285 for /file1
2020-04-02 05:05:28,413 [DataXceiver for client DFSClient_NONMAPREDUCE_-107601396_2940 at /127.0.0.1:39284 [Receiving block BP-604133109-172.17.0.5-1585803927423:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-604133109-172.17.0.5-1585803927423:blk_1073741827_1003 src: /127.0.0.1:39284 dest: /127.0.0.1:43702
2020-04-02 05:05:28,414 [DataXceiver for client DFSClient_NONMAPREDUCE_-107601396_2940 at /127.0.0.1:44638 [Receiving block BP-604133109-172.17.0.5-1585803927423:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-604133109-172.17.0.5-1585803927423:blk_1073741827_1003 src: /127.0.0.1:44638 dest: /127.0.0.1:41925
2020-04-02 05:05:28,422 [DataXceiver for client DFSClient_NONMAPREDUCE_-107601396_2940 at /127.0.0.1:49864 [Receiving block BP-604133109-172.17.0.5-1585803927423:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-604133109-172.17.0.5-1585803927423:blk_1073741827_1003 src: /127.0.0.1:49864 dest: /127.0.0.1:33285
2020-04-02 05:05:28,441 [PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49864, dest: /127.0.0.1:33285, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-107601396_2940, offset: 0, srvID: 92edfe99-db48-4865-a4f6-7ff029cae2f0, blockid: BP-604133109-172.17.0.5-1585803927423:blk_1073741827_1003, duration(ns): 11513873
2020-04-02 05:05:28,441 [PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:28,444 [PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33285]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44638, dest: /127.0.0.1:41925, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-107601396_2940, offset: 0, srvID: 72056b25-89a4-48ff-a467-a303b1583b42, blockid: BP-604133109-172.17.0.5-1585803927423:blk_1073741827_1003, duration(ns): 9085402
2020-04-02 05:05:28,444 [PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33285]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33285] terminating
2020-04-02 05:05:28,445 [PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41925, 127.0.0.1:33285]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39284, dest: /127.0.0.1:43702, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-107601396_2940, offset: 0, srvID: acd9669f-a068-4c78-8b5e-76a9f02b67e8, blockid: BP-604133109-172.17.0.5-1585803927423:blk_1073741827_1003, duration(ns): 9371225
2020-04-02 05:05:28,446 [PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41925, 127.0.0.1:33285]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-604133109-172.17.0.5-1585803927423:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41925, 127.0.0.1:33285] terminating
2020-04-02 05:05:28,451 [IPC Server handler 0 on 38829] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /file1 is closed by DFSClient_NONMAPREDUCE_-107601396_2940
2020-04-02 05:05:28,454 [IPC Server handler 2 on 38829] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null	proto=rpc
2020-04-02 05:05:28,471 [IPC Server handler 3 on 38829] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null	proto=rpc
2020-04-02 05:05:28,477 [Thread-734] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:05:28,477 [Thread-734] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:05:28,477 [Thread-734] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33872 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:28,477 [Thread-734] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:28,477 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@26795f78] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:28,481 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-2d7cfe3c-c73d-4be6-b9eb-df37b529b077) exiting.
2020-04-02 05:05:28,481 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-85212e2d-f6a5-404d-9f18-716af5377b26) exiting.
2020-04-02 05:05:28,493 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1b528258{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:28,493 [Thread-734] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6e30b8be{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:28,494 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3bc1dc8{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:28,494 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@41154397{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:28,495 [Thread-734] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33872
2020-04-02 05:05:28,497 [IPC Server listener on 33872] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33872
2020-04-02 05:05:28,499 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:28,499 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:28,504 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-604133109-172.17.0.5-1585803927423 (Datanode Uuid 72056b25-89a4-48ff-a467-a303b1583b42) service to localhost/127.0.0.1:38829
2020-04-02 05:05:28,504 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-604133109-172.17.0.5-1585803927423 (Datanode Uuid 72056b25-89a4-48ff-a467-a303b1583b42)
2020-04-02 05:05:28,504 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:28,515 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-604133109-172.17.0.5-1585803927423] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:28,526 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-604133109-172.17.0.5-1585803927423] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:28,548 [Thread-734] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:28,552 [Thread-734] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:28,554 [Thread-734] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:28,554 [Thread-734] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:28,557 [Thread-734] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:28,557 [Thread-734] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:05:28,557 [Thread-734] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 35032 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:28,557 [Thread-734] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:28,557 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1bc1d873] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:28,561 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-8bbb3049-107e-4fdf-81ad-500f7b314c7d) exiting.
2020-04-02 05:05:28,562 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-9a61c67f-cf5d-49a3-a780-d8cc46f75509) exiting.
2020-04-02 05:05:28,575 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@522b705c{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:28,576 [Thread-734] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6c4ac802{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:28,576 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7cac4f39{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:28,576 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1cb2e321{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:28,577 [Thread-734] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35032
2020-04-02 05:05:28,581 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:28,582 [IPC Server listener on 35032] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35032
2020-04-02 05:05:28,582 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:28,582 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-604133109-172.17.0.5-1585803927423 (Datanode Uuid 92edfe99-db48-4865-a4f6-7ff029cae2f0) service to localhost/127.0.0.1:38829
2020-04-02 05:05:28,582 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-604133109-172.17.0.5-1585803927423 (Datanode Uuid 92edfe99-db48-4865-a4f6-7ff029cae2f0)
2020-04-02 05:05:28,582 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:28,590 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-604133109-172.17.0.5-1585803927423] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:28,598 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-604133109-172.17.0.5-1585803927423] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:28,614 [Thread-734] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:28,614 [Thread-734] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:28,615 [Thread-734] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:28,615 [Thread-734] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:28,618 [Thread-734] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:28,618 [Thread-734] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:05:28,618 [Thread-734] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 38338 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:28,619 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7f24d929] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:28,619 [Thread-734] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:28,621 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-b294d2b5-2e9e-453e-8d2c-843ffb545e3e) exiting.
2020-04-02 05:05:28,622 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-ba242e12-8131-42ff-be6e-8b572db4c2bc) exiting.
2020-04-02 05:05:28,638 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@13c6726a{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:28,639 [Thread-734] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5a05c682{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:28,639 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@97848c9{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:28,639 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@777d83bb{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:28,640 [Thread-734] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38338
2020-04-02 05:05:28,647 [IPC Server listener on 38338] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38338
2020-04-02 05:05:28,647 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:28,647 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:28,647 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-604133109-172.17.0.5-1585803927423 (Datanode Uuid acd9669f-a068-4c78-8b5e-76a9f02b67e8) service to localhost/127.0.0.1:38829
2020-04-02 05:05:28,748 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-604133109-172.17.0.5-1585803927423 (Datanode Uuid acd9669f-a068-4c78-8b5e-76a9f02b67e8)
2020-04-02 05:05:28,748 [BP-604133109-172.17.0.5-1585803927423 heartbeating to localhost/127.0.0.1:38829] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-604133109-172.17.0.5-1585803927423
2020-04-02 05:05:28,756 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-604133109-172.17.0.5-1585803927423] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:28,765 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-604133109-172.17.0.5-1585803927423] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:28,773 [Thread-734] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:28,773 [Thread-734] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:28,775 [Thread-734] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:28,775 [Thread-734] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:28,777 [Thread-734] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:28,778 [Thread-734] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:05:28,778 [Thread-734] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 38829 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:28,778 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:28,778 [Thread[Thread-761,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:05:28,778 [Thread-734] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 14
2020-04-02 05:05:28,778 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@25ea9a55] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:05:28,778 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@391c453e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:05:28,779 [Thread-734] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 15 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 3 Number of syncs: 13 SyncTimes(ms): 8 2 
2020-04-02 05:05:28,779 [Thread-734] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000015
2020-04-02 05:05:28,779 [Thread-734] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000015
2020-04-02 05:05:28,780 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:05:28,780 [CacheReplicationMonitor(168127360)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:05:28,791 [Thread-734] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38829
2020-04-02 05:05:28,793 [IPC Server listener on 38829] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38829
2020-04-02 05:05:28,793 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:28,805 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:05:28,805 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:05:28,818 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:28,818 [Thread-734] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:05:28,825 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@714608c1{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:05:28,827 [Thread-734] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@345f05bb{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:05:28,827 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1797e353{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:28,828 [Thread-734] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2d92d421{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
[msx] test Finished org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testNoSaslAndSecurePortsIgnored
[msx] writeFile testName = org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testNoSaslAndSecurePortsIgnored
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#TestPeerFromSocketAndKeyReadTimeout
[msx] perform reset as unitTestCounterInClass 9 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Finished org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#TestPeerFromSocketAndKeyReadTimeout
[msx] writeFile testName = org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#TestPeerFromSocketAndKeyReadTimeout
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testDataNodeStartIfHttpsQopPrivacy
[msx] perform reset as unitTestCounterInClass 10 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:05:28,934 [Thread-910] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=3
2020-04-02 05:05:28,940 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803928939,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:28,941 [Thread-910] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
Formatting using clusterid: testClusterID
2020-04-02 05:05:28,941 [Thread-910] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:28,942 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:28,942 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:28,942 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:28,942 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:28,942 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:28,942 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:28,942 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:28,943 [Thread-910] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:28,943 [Thread-910] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:28,943 [Thread-910] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:28,943 [Thread-910] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:28,943 [Thread-910] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:28
2020-04-02 05:05:28,943 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:28,943 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:28,944 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 37.5 MB
2020-04-02 05:05:28,944 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:28,948 [Thread-910] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:28,948 [Thread-910] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:28,949 [Thread-910] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:28,949 [Thread-910] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:28,949 [Thread-910] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:28,949 [Thread-910] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:28,949 [Thread-910] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:28,949 [Thread-910] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:28,949 [Thread-910] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:28,949 [Thread-910] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:28,949 [Thread-910] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:28,949 [Thread-910] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:28,949 [Thread-910] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:28,950 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:28,950 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:28,950 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.7 MB
2020-04-02 05:05:28,950 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:28,953 [Thread-910] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:28,953 [Thread-910] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:28,953 [Thread-910] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:28,953 [Thread-910] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:28,953 [Thread-910] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:28,953 [Thread-910] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:28,953 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:28,953 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:28,954 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.7 MB
2020-04-02 05:05:28,954 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:28,955 [Thread-910] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:28,955 [Thread-910] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:28,955 [Thread-910] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:28,955 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:28,955 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:28,955 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:28,955 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:28,956 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 575.8 KB
2020-04-02 05:05:28,956 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:28,957 [Thread-910] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:28,961 [Thread-910] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:05:28,963 [Thread-910] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:05:28,964 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:28,964 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:28,968 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:05:28,984 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:05:28,986 [Thread-910] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:05:28,987 [Thread-910] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:28,988 [Thread-910] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:05:28,988 [Thread-910] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:28,988 [Thread-910] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:05:28,992 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803928992,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:28,993 [Thread-910] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:28,999 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6a1e2e15] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:28,999 [Thread-910] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:28,999 [Thread-910] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:0
2020-04-02 05:05:28,999 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:29,001 [Thread-910] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:29,001 [Thread-910] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:29,001 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:29,002 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:29,002 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:29,002 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:29,002 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:29,004 [Thread-910] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:29,004 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:29,004 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:05:29,004 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:05:29,004 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39277
2020-04-02 05:05:29,004 [Thread-910] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:29,006 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@11abc13{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:29,006 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5cb09476{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:29,009 [Thread-910] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:29,009 [Thread-910] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:29,010 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@c627ec{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:29,011 [Thread-910] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@1158222(server,h=[],w=[]) for SslContextFactory@45be6cc8(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/trustKS.jks)
2020-04-02 05:05:29,012 [Thread-910] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@74823076{SSL,[ssl, http/1.1]}{localhost:39277}
2020-04-02 05:05:29,012 [Thread-910] INFO  server.Server (Server.java:doStart(419)) - Started @15571ms
2020-04-02 05:05:29,013 [Thread-910] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:29,013 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:29,013 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:29,013 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:29,013 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:29,013 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:29,014 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:29,014 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:29,014 [Thread-910] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:29,014 [Thread-910] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:29,014 [Thread-910] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:29,014 [Thread-910] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:29,014 [Thread-910] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:29
2020-04-02 05:05:29,014 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:29,015 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:29,017 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 37.5 MB
2020-04-02 05:05:29,017 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:29,021 [Thread-910] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:29,022 [Thread-910] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:29,022 [Thread-910] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:29,022 [Thread-910] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:29,022 [Thread-910] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:29,022 [Thread-910] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:29,022 [Thread-910] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:29,022 [Thread-910] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:29,022 [Thread-910] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:29,023 [Thread-910] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:29,023 [Thread-910] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:29,023 [Thread-910] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:29,023 [Thread-910] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:29,023 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:29,023 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:29,023 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.7 MB
2020-04-02 05:05:29,023 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:29,026 [Thread-910] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:29,026 [Thread-910] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:29,026 [Thread-910] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:29,026 [Thread-910] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:29,026 [Thread-910] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:29,026 [Thread-910] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:29,026 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:29,026 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:29,026 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.7 MB
2020-04-02 05:05:29,026 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:29,027 [Thread-910] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:29,027 [Thread-910] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:29,027 [Thread-910] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:29,027 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:29,028 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:29,028 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:29,028 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:29,028 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 575.8 KB
2020-04-02 05:05:29,028 [Thread-910] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:29,030 [Thread-910] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:29,030 [Thread-910] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:29,031 [Thread-910] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:05:29,032 [Thread-910] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:05:29,032 [Thread-910] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:05:29,032 [Thread-910] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:29,033 [Thread-910] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:29,033 [Thread-910] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:29,033 [Thread-910] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:29,033 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:29,034 [Thread-910] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:05:29,051 [Thread-910] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:29,051 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 22 msecs
2020-04-02 05:05:29,051 [Thread-910] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:05:29,051 [Thread-910] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:29,052 [Socket Reader #1 for port 46638] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46638
2020-04-02 05:05:29,057 [Thread-910] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:46638 to access this namenode/service.
2020-04-02 05:05:29,057 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:29,079 [Thread-910] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:29,082 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@5e0de7bc] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:05:29,084 [Thread-910] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:29,084 [Thread-910] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:05:29,085 [Thread-910] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:05:29,085 [Thread-910] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:29,090 [Thread-910] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:29,094 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:29,094 [Thread[Thread-937,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:05:29,094 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:29,095 [Thread[Thread-937,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:29,095 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:29,097 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:29,097 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:29,097 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 12 msec
2020-04-02 05:05:29,099 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:29,101 [IPC Server listener on 46638] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46638: starting
2020-04-02 05:05:29,104 [Thread-910] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:46638
2020-04-02 05:05:29,105 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:29,105 [Thread-910] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:29,107 [Thread-910] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:29,109 [Thread-910] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 46638 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:29,112 [CacheReplicationMonitor(894484145)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:29,128 [Thread-910] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:29,132 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803929131,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:29,134 [Thread-910] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:29,134 [Thread-910] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:29,135 [Thread-910] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:29,136 [Thread-910] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:29,139 [Thread-910] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:29,139 [Thread-910] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:29,139 [Thread-910] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:29,139 [Thread-910] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:29,139 [Thread-910] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:29,140 [Thread-910] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:29,140 [Thread-910] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:41024
2020-04-02 05:05:29,140 [Thread-910] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:29,140 [Thread-910] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:29,141 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:29,142 [Thread-910] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:29,143 [Thread-910] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:29,143 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:29,144 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:29,145 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:29,145 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:29,145 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:29,146 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35367
2020-04-02 05:05:29,146 [Thread-910] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:29,147 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@15b8b1e1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:29,148 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@10854a39{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:29,151 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@11aa36e8{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:29,152 [Thread-910] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@19affe3d{HTTP/1.1,[http/1.1]}{localhost:35367}
2020-04-02 05:05:29,154 [Thread-910] INFO  server.Server (Server.java:doStart(419)) - Started @15713ms
2020-04-02 05:05:29,169 [Thread-910] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:46434
2020-04-02 05:05:29,169 [Thread-910] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:29,169 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4e173141] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:29,169 [Thread-910] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:29,170 [Thread-910] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:29,171 [Socket Reader #1 for port 34493] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34493
2020-04-02 05:05:29,175 [Thread-910] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:34493
2020-04-02 05:05:29,182 [Thread-910] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:29,182 [Thread-910] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:29,183 [Thread-966] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46638 starting to offer service
2020-04-02 05:05:29,187 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:29,187 [IPC Server listener on 34493] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34493: starting
2020-04-02 05:05:29,197 [Thread-910] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 34493 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:29,215 [Thread-910] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:29,222 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803929222,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:29,222 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803929222,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:29,227 [Thread-910] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:29,228 [Thread-910] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:29,228 [Thread-910] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:29,229 [Thread-910] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:29,231 [Thread-910] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:29,231 [Thread-910] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:29,231 [Thread-910] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:29,232 [Thread-910] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:29,232 [Thread-910] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:29,232 [Socket Reader #1 for port 46638] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:29,232 [Thread-910] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:29,235 [Thread-910] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:35186
2020-04-02 05:05:29,235 [Thread-910] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:29,235 [Thread-910] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:29,236 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:29,236 [Thread-966] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46638
2020-04-02 05:05:29,238 [Thread-966] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:29,239 [Thread-966] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:29,239 [Thread-910] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:29,240 [Thread-966] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1294654841. Formatting...
2020-04-02 05:05:29,240 [Thread-966] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d4f60963-5c43-402e-b85a-626bd3836a41 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:05:29,240 [Thread-910] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:29,240 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:29,242 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:29,242 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:29,242 [Thread-966] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:29,242 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:29,242 [Thread-966] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1294654841. Formatting...
2020-04-02 05:05:29,242 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:29,243 [Thread-966] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-955d50cb-4e91-4299-894a-b986afa0547b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:05:29,243 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33764
2020-04-02 05:05:29,243 [Thread-910] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:29,245 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4cea5dec{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:29,245 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7c0671f3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:29,248 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5e05ab6a{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:29,249 [Thread-910] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2874d96b{HTTP/1.1,[http/1.1]}{localhost:33764}
2020-04-02 05:05:29,251 [Thread-910] INFO  server.Server (Server.java:doStart(419)) - Started @15809ms
2020-04-02 05:05:29,254 [Thread-966] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,254 [Thread-966] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,255 [Thread-966] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1330165299-172.17.0.5-1585803928957 is not formatted. Formatting ...
2020-04-02 05:05:29,255 [Thread-966] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1330165299-172.17.0.5-1585803928957 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1330165299-172.17.0.5-1585803928957/current
2020-04-02 05:05:29,262 [Thread-910] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:34862
2020-04-02 05:05:29,263 [Thread-910] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:29,263 [Thread-910] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:29,263 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6d14b8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:29,263 [Thread-910] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:29,264 [Socket Reader #1 for port 41062] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41062
2020-04-02 05:05:29,267 [Thread-910] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:41062
2020-04-02 05:05:29,270 [Thread-966] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,270 [Thread-966] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,270 [Thread-966] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1330165299-172.17.0.5-1585803928957 is not formatted. Formatting ...
2020-04-02 05:05:29,270 [Thread-966] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1330165299-172.17.0.5-1585803928957 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1330165299-172.17.0.5-1585803928957/current
2020-04-02 05:05:29,272 [Thread-966] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1294654841;bpid=BP-1330165299-172.17.0.5-1585803928957;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1294654841;c=1585803928957;bpid=BP-1330165299-172.17.0.5-1585803928957;dnuuid=null
2020-04-02 05:05:29,273 [Thread-966] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 80417d3d-bf5c-45e1-84d8-7453e47e4f35
2020-04-02 05:05:29,274 [Thread-910] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:29,275 [Thread-910] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:29,280 [Thread-990] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46638 starting to offer service
2020-04-02 05:05:29,280 [Thread-966] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-d4f60963-5c43-402e-b85a-626bd3836a41
2020-04-02 05:05:29,280 [Thread-966] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:05:29,283 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:29,289 [IPC Server listener on 41062] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41062: starting
2020-04-02 05:05:29,293 [Thread-966] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-955d50cb-4e91-4299-894a-b986afa0547b
2020-04-02 05:05:29,295 [Thread-966] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:05:29,295 [Thread-910] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 41062 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:29,295 [Thread-966] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:29,297 [Thread-966] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:29,296 [Thread-910] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:29,301 [Thread-966] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:29,301 [Thread-966] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:29,302 [Thread-966] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:29,302 [Thread-966] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,304 [Thread-1004] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:29,304 [Thread-1005] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:29,306 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803929305,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:29,306 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803929305,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:29,308 [Thread-910] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:29,310 [Thread-910] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:29,311 [Thread-910] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:29,312 [Thread-910] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:29,315 [Thread-910] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:29,315 [Thread-910] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:29,315 [Thread-910] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:29,316 [Thread-910] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:29,316 [Thread-910] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:29,317 [Thread-910] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:29,317 [Thread-910] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:39177
2020-04-02 05:05:29,317 [Thread-910] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:29,317 [Thread-910] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:29,318 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:29,319 [Socket Reader #1 for port 46638] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:29,322 [Thread-910] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:29,322 [Thread-910] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:29,322 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:29,323 [Thread-990] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46638
2020-04-02 05:05:29,325 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:29,325 [Thread-990] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:29,325 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:29,325 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:29,326 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:29,326 [Thread-910] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46624
2020-04-02 05:05:29,326 [Thread-990] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:29,326 [Thread-910] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:29,327 [Thread-990] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1294654841. Formatting...
2020-04-02 05:05:29,327 [Thread-990] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-93a272b3-692e-4ff1-b302-c9f489fea1cc for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:05:29,328 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7137b9cf{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:29,328 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@41016b62{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:29,329 [Thread-990] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:29,329 [Thread-990] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1294654841. Formatting...
2020-04-02 05:05:29,329 [Thread-990] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0183655f-d291-4c67-98f3-45a47ab9edff for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:05:29,331 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1e786eaa{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:29,332 [Thread-910] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7134aa30{HTTP/1.1,[http/1.1]}{localhost:46624}
2020-04-02 05:05:29,334 [Thread-1005] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1330165299-172.17.0.5-1585803928957 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 29ms
2020-04-02 05:05:29,334 [Thread-910] INFO  server.Server (Server.java:doStart(419)) - Started @15892ms
2020-04-02 05:05:29,338 [Thread-1004] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1330165299-172.17.0.5-1585803928957 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 34ms
2020-04-02 05:05:29,338 [Thread-966] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1330165299-172.17.0.5-1585803928957: 34ms
2020-04-02 05:05:29,338 [Thread-1014] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:29,338 [Thread-1015] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:29,338 [Thread-1014] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1330165299-172.17.0.5-1585803928957/current/replicas doesn't exist 
2020-04-02 05:05:29,339 [Thread-1015] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1330165299-172.17.0.5-1585803928957/current/replicas doesn't exist 
2020-04-02 05:05:29,339 [Thread-1014] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:05:29,339 [Thread-1015] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 0ms
2020-04-02 05:05:29,339 [Thread-966] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1330165299-172.17.0.5-1585803928957: 1ms
2020-04-02 05:05:29,340 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:29,340 [Thread-966] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:43 AM with interval of 21600000ms
2020-04-02 05:05:29,340 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-d4f60963-5c43-402e-b85a-626bd3836a41): finished scanning block pool BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,340 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:29,342 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-955d50cb-4e91-4299-894a-b986afa0547b): finished scanning block pool BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,343 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1330165299-172.17.0.5-1585803928957 (Datanode Uuid 80417d3d-bf5c-45e1-84d8-7453e47e4f35) service to localhost/127.0.0.1:46638 beginning handshake with NN
2020-04-02 05:05:29,343 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-d4f60963-5c43-402e-b85a-626bd3836a41): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:05:29,343 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-955d50cb-4e91-4299-894a-b986afa0547b): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:05:29,343 [Thread-990] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,343 [Thread-990] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,343 [Thread-990] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1330165299-172.17.0.5-1585803928957 is not formatted. Formatting ...
2020-04-02 05:05:29,343 [Thread-990] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1330165299-172.17.0.5-1585803928957 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1330165299-172.17.0.5-1585803928957/current
2020-04-02 05:05:29,346 [IPC Server handler 3 on 46638] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41024, datanodeUuid=80417d3d-bf5c-45e1-84d8-7453e47e4f35, infoPort=0, infoSecurePort=46434, ipcPort=34493, storageInfo=lv=-57;cid=testClusterID;nsid=1294654841;c=1585803928957) storage 80417d3d-bf5c-45e1-84d8-7453e47e4f35
2020-04-02 05:05:29,346 [IPC Server handler 3 on 46638] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41024
2020-04-02 05:05:29,347 [IPC Server handler 3 on 46638] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 80417d3d-bf5c-45e1-84d8-7453e47e4f35 (127.0.0.1:41024).
2020-04-02 05:05:29,352 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1330165299-172.17.0.5-1585803928957 (Datanode Uuid 80417d3d-bf5c-45e1-84d8-7453e47e4f35) service to localhost/127.0.0.1:46638 successfully registered with NN
2020-04-02 05:05:29,352 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1330165299-172.17.0.5-1585803928957 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:29,353 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:29,353 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46638 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:29,359 [Thread-910] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:35026
2020-04-02 05:05:29,363 [IPC Server handler 1 on 46638] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d4f60963-5c43-402e-b85a-626bd3836a41 for DN 127.0.0.1:41024
2020-04-02 05:05:29,363 [IPC Server handler 1 on 46638] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-955d50cb-4e91-4299-894a-b986afa0547b for DN 127.0.0.1:41024
2020-04-02 05:05:29,363 [Thread-910] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:29,364 [Thread-910] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:29,363 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2c487d94] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:29,366 [Thread-910] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:29,367 [Socket Reader #1 for port 43093] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43093
2020-04-02 05:05:29,371 [Thread-910] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43093
2020-04-02 05:05:29,373 [Thread-990] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,373 [Thread-990] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,373 [Thread-990] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1330165299-172.17.0.5-1585803928957 is not formatted. Formatting ...
2020-04-02 05:05:29,373 [Thread-990] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1330165299-172.17.0.5-1585803928957 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1330165299-172.17.0.5-1585803928957/current
2020-04-02 05:05:29,373 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x95852357f26c1eba: Processing first storage report for DS-d4f60963-5c43-402e-b85a-626bd3836a41 from datanode 80417d3d-bf5c-45e1-84d8-7453e47e4f35
2020-04-02 05:05:29,374 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x95852357f26c1eba: from storage DS-d4f60963-5c43-402e-b85a-626bd3836a41 node DatanodeRegistration(127.0.0.1:41024, datanodeUuid=80417d3d-bf5c-45e1-84d8-7453e47e4f35, infoPort=0, infoSecurePort=46434, ipcPort=34493, storageInfo=lv=-57;cid=testClusterID;nsid=1294654841;c=1585803928957), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:29,374 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x95852357f26c1eba: Processing first storage report for DS-955d50cb-4e91-4299-894a-b986afa0547b from datanode 80417d3d-bf5c-45e1-84d8-7453e47e4f35
2020-04-02 05:05:29,374 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x95852357f26c1eba: from storage DS-955d50cb-4e91-4299-894a-b986afa0547b node DatanodeRegistration(127.0.0.1:41024, datanodeUuid=80417d3d-bf5c-45e1-84d8-7453e47e4f35, infoPort=0, infoSecurePort=46434, ipcPort=34493, storageInfo=lv=-57;cid=testClusterID;nsid=1294654841;c=1585803928957), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:29,375 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x95852357f26c1eba,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 8 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:29,375 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,375 [Thread-990] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1294654841;bpid=BP-1330165299-172.17.0.5-1585803928957;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1294654841;c=1585803928957;bpid=BP-1330165299-172.17.0.5-1585803928957;dnuuid=null
2020-04-02 05:05:29,377 [Thread-990] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID fec50a01-c199-4781-9641-86878f9712d9
2020-04-02 05:05:29,379 [Thread-990] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-93a272b3-692e-4ff1-b302-c9f489fea1cc
2020-04-02 05:05:29,379 [Thread-990] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:05:29,382 [Thread-910] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:29,382 [Thread-910] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:29,382 [Thread-990] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-0183655f-d291-4c67-98f3-45a47ab9edff
2020-04-02 05:05:29,382 [Thread-1027] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46638 starting to offer service
2020-04-02 05:05:29,383 [Thread-990] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:05:29,386 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:29,386 [Thread-990] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:29,386 [IPC Server listener on 43093] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43093: starting
2020-04-02 05:05:29,392 [Thread-990] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:29,392 [Thread-910] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43093 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:29,394 [Thread-990] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:29,394 [Thread-990] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:29,394 [Thread-990] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:29,394 [Thread-990] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,394 [Thread-1039] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:05:29,394 [Thread-1040] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:05:29,402 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803929402,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:29,404 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803929403,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:29,408 [Socket Reader #1 for port 46638] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:29,409 [Socket Reader #1 for port 46638] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:29,414 [IPC Server handler 6 on 46638] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:29,414 [Thread-1027] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46638
2020-04-02 05:05:29,416 [Thread-1027] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:29,417 [Thread-910] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:29,417 [Thread-910] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:29,418 [Thread-1027] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:29,418 [Thread-1027] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1294654841. Formatting...
2020-04-02 05:05:29,418 [Thread-1027] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3a90d60a-a6f7-4de6-bde4-69dbb67ed122 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:05:29,421 [Thread-1027] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:29,421 [Thread-1027] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1294654841. Formatting...
2020-04-02 05:05:29,422 [Thread-1027] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5cbc4b8e-68ba-4eda-950d-4189f8de26c7 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:05:29,425 [Thread-1039] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1330165299-172.17.0.5-1585803928957 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 31ms
2020-04-02 05:05:29,426 [Thread-1040] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1330165299-172.17.0.5-1585803928957 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 31ms
2020-04-02 05:05:29,426 [Thread-990] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1330165299-172.17.0.5-1585803928957: 32ms
2020-04-02 05:05:29,426 [Thread-1044] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:05:29,426 [Thread-1045] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:05:29,427 [Thread-1044] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1330165299-172.17.0.5-1585803928957/current/replicas doesn't exist 
2020-04-02 05:05:29,427 [Thread-1045] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1330165299-172.17.0.5-1585803928957/current/replicas doesn't exist 
2020-04-02 05:05:29,427 [Thread-1044] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 0ms
2020-04-02 05:05:29,427 [Thread-1045] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 0ms
2020-04-02 05:05:29,427 [Thread-990] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1330165299-172.17.0.5-1585803928957: 1ms
2020-04-02 05:05:29,428 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:29,428 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:29,428 [Thread-990] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:31 AM with interval of 21600000ms
2020-04-02 05:05:29,428 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-0183655f-d291-4c67-98f3-45a47ab9edff): finished scanning block pool BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,428 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-93a272b3-692e-4ff1-b302-c9f489fea1cc): finished scanning block pool BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,431 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1330165299-172.17.0.5-1585803928957 (Datanode Uuid fec50a01-c199-4781-9641-86878f9712d9) service to localhost/127.0.0.1:46638 beginning handshake with NN
2020-04-02 05:05:29,431 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-0183655f-d291-4c67-98f3-45a47ab9edff): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:05:29,431 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-93a272b3-692e-4ff1-b302-c9f489fea1cc): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:05:29,432 [IPC Server handler 8 on 46638] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35186, datanodeUuid=fec50a01-c199-4781-9641-86878f9712d9, infoPort=0, infoSecurePort=34862, ipcPort=41062, storageInfo=lv=-57;cid=testClusterID;nsid=1294654841;c=1585803928957) storage fec50a01-c199-4781-9641-86878f9712d9
2020-04-02 05:05:29,432 [IPC Server handler 8 on 46638] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35186
2020-04-02 05:05:29,432 [IPC Server handler 8 on 46638] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN fec50a01-c199-4781-9641-86878f9712d9 (127.0.0.1:35186).
2020-04-02 05:05:29,433 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1330165299-172.17.0.5-1585803928957 (Datanode Uuid fec50a01-c199-4781-9641-86878f9712d9) service to localhost/127.0.0.1:46638 successfully registered with NN
2020-04-02 05:05:29,433 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1330165299-172.17.0.5-1585803928957 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:29,433 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:29,433 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46638 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:29,439 [IPC Server handler 7 on 46638] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-93a272b3-692e-4ff1-b302-c9f489fea1cc for DN 127.0.0.1:35186
2020-04-02 05:05:29,439 [Thread-1027] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,441 [Thread-1027] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,443 [IPC Server handler 7 on 46638] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0183655f-d291-4c67-98f3-45a47ab9edff for DN 127.0.0.1:35186
2020-04-02 05:05:29,443 [Thread-1027] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1330165299-172.17.0.5-1585803928957 is not formatted. Formatting ...
2020-04-02 05:05:29,444 [Thread-1027] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1330165299-172.17.0.5-1585803928957 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1330165299-172.17.0.5-1585803928957/current
2020-04-02 05:05:29,446 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb75da2d253cedefc: Processing first storage report for DS-0183655f-d291-4c67-98f3-45a47ab9edff from datanode fec50a01-c199-4781-9641-86878f9712d9
2020-04-02 05:05:29,446 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb75da2d253cedefc: from storage DS-0183655f-d291-4c67-98f3-45a47ab9edff node DatanodeRegistration(127.0.0.1:35186, datanodeUuid=fec50a01-c199-4781-9641-86878f9712d9, infoPort=0, infoSecurePort=34862, ipcPort=41062, storageInfo=lv=-57;cid=testClusterID;nsid=1294654841;c=1585803928957), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:29,446 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb75da2d253cedefc: Processing first storage report for DS-93a272b3-692e-4ff1-b302-c9f489fea1cc from datanode fec50a01-c199-4781-9641-86878f9712d9
2020-04-02 05:05:29,446 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb75da2d253cedefc: from storage DS-93a272b3-692e-4ff1-b302-c9f489fea1cc node DatanodeRegistration(127.0.0.1:35186, datanodeUuid=fec50a01-c199-4781-9641-86878f9712d9, infoPort=0, infoSecurePort=34862, ipcPort=41062, storageInfo=lv=-57;cid=testClusterID;nsid=1294654841;c=1585803928957), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:29,447 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xb75da2d253cedefc,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:29,447 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,453 [Thread-1027] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,453 [Thread-1027] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,453 [Thread-1027] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1330165299-172.17.0.5-1585803928957 is not formatted. Formatting ...
2020-04-02 05:05:29,453 [Thread-1027] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1330165299-172.17.0.5-1585803928957 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1330165299-172.17.0.5-1585803928957/current
2020-04-02 05:05:29,455 [Thread-1027] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1294654841;bpid=BP-1330165299-172.17.0.5-1585803928957;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1294654841;c=1585803928957;bpid=BP-1330165299-172.17.0.5-1585803928957;dnuuid=null
2020-04-02 05:05:29,456 [Thread-1027] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 651aebb3-c17b-4e6b-8ff1-b7a8e05b1721
2020-04-02 05:05:29,458 [Thread-1027] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-3a90d60a-a6f7-4de6-bde4-69dbb67ed122
2020-04-02 05:05:29,458 [Thread-1027] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:05:29,461 [Thread-1027] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5cbc4b8e-68ba-4eda-950d-4189f8de26c7
2020-04-02 05:05:29,461 [Thread-1027] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:05:29,464 [Thread-1027] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:29,464 [Thread-1027] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:29,465 [Thread-1027] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:29,465 [Thread-1027] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:29,465 [Thread-1027] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:29,465 [Thread-1027] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,465 [Thread-1051] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:05:29,465 [Thread-1052] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:05:29,490 [Thread-1052] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1330165299-172.17.0.5-1585803928957 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 24ms
2020-04-02 05:05:29,493 [Thread-1051] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1330165299-172.17.0.5-1585803928957 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 27ms
2020-04-02 05:05:29,493 [Thread-1027] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1330165299-172.17.0.5-1585803928957: 28ms
2020-04-02 05:05:29,494 [Thread-1055] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:05:29,494 [Thread-1056] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:05:29,494 [Thread-1055] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1330165299-172.17.0.5-1585803928957/current/replicas doesn't exist 
2020-04-02 05:05:29,494 [Thread-1056] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1330165299-172.17.0.5-1585803928957/current/replicas doesn't exist 
2020-04-02 05:05:29,494 [Thread-1055] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 0ms
2020-04-02 05:05:29,494 [Thread-1056] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 0ms
2020-04-02 05:05:29,494 [Thread-1027] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1330165299-172.17.0.5-1585803928957: 1ms
2020-04-02 05:05:29,495 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:29,495 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1330165299-172.17.0.5-1585803928957 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:29,495 [Thread-1027] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:37 AM with interval of 21600000ms
2020-04-02 05:05:29,495 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-5cbc4b8e-68ba-4eda-950d-4189f8de26c7): finished scanning block pool BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,495 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-3a90d60a-a6f7-4de6-bde4-69dbb67ed122): finished scanning block pool BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,496 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-3a90d60a-a6f7-4de6-bde4-69dbb67ed122): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:05:29,496 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-5cbc4b8e-68ba-4eda-950d-4189f8de26c7): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:05:29,498 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1330165299-172.17.0.5-1585803928957 (Datanode Uuid 651aebb3-c17b-4e6b-8ff1-b7a8e05b1721) service to localhost/127.0.0.1:46638 beginning handshake with NN
2020-04-02 05:05:29,499 [IPC Server handler 0 on 46638] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39177, datanodeUuid=651aebb3-c17b-4e6b-8ff1-b7a8e05b1721, infoPort=0, infoSecurePort=35026, ipcPort=43093, storageInfo=lv=-57;cid=testClusterID;nsid=1294654841;c=1585803928957) storage 651aebb3-c17b-4e6b-8ff1-b7a8e05b1721
2020-04-02 05:05:29,499 [IPC Server handler 0 on 46638] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39177
2020-04-02 05:05:29,499 [IPC Server handler 0 on 46638] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 651aebb3-c17b-4e6b-8ff1-b7a8e05b1721 (127.0.0.1:39177).
2020-04-02 05:05:29,500 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1330165299-172.17.0.5-1585803928957 (Datanode Uuid 651aebb3-c17b-4e6b-8ff1-b7a8e05b1721) service to localhost/127.0.0.1:46638 successfully registered with NN
2020-04-02 05:05:29,500 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1330165299-172.17.0.5-1585803928957 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:29,500 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:29,500 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46638 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:29,505 [IPC Server handler 2 on 46638] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3a90d60a-a6f7-4de6-bde4-69dbb67ed122 for DN 127.0.0.1:39177
2020-04-02 05:05:29,506 [IPC Server handler 2 on 46638] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5cbc4b8e-68ba-4eda-950d-4189f8de26c7 for DN 127.0.0.1:39177
2020-04-02 05:05:29,508 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2bd78f9b371aa727: Processing first storage report for DS-5cbc4b8e-68ba-4eda-950d-4189f8de26c7 from datanode 651aebb3-c17b-4e6b-8ff1-b7a8e05b1721
2020-04-02 05:05:29,508 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2bd78f9b371aa727: from storage DS-5cbc4b8e-68ba-4eda-950d-4189f8de26c7 node DatanodeRegistration(127.0.0.1:39177, datanodeUuid=651aebb3-c17b-4e6b-8ff1-b7a8e05b1721, infoPort=0, infoSecurePort=35026, ipcPort=43093, storageInfo=lv=-57;cid=testClusterID;nsid=1294654841;c=1585803928957), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:29,508 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2bd78f9b371aa727: Processing first storage report for DS-3a90d60a-a6f7-4de6-bde4-69dbb67ed122 from datanode 651aebb3-c17b-4e6b-8ff1-b7a8e05b1721
2020-04-02 05:05:29,508 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2bd78f9b371aa727: from storage DS-3a90d60a-a6f7-4de6-bde4-69dbb67ed122 node DatanodeRegistration(127.0.0.1:39177, datanodeUuid=651aebb3-c17b-4e6b-8ff1-b7a8e05b1721, infoPort=0, infoSecurePort=35026, ipcPort=43093, storageInfo=lv=-57;cid=testClusterID;nsid=1294654841;c=1585803928957), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:05:29,509 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x2bd78f9b371aa727,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:29,510 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,518 [IPC Server handler 1 on 46638] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:29,530 [Thread-910] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:29,533 [IPC Server handler 4 on 46638] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:29,534 [Thread-910] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:29,534 [Thread-910] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:05:29,534 [Thread-910] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:05:29,534 [Thread-910] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43093 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:29,534 [Thread-910] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:29,534 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6729d7d0] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:29,537 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-5cbc4b8e-68ba-4eda-950d-4189f8de26c7) exiting.
2020-04-02 05:05:29,537 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-3a90d60a-a6f7-4de6-bde4-69dbb67ed122) exiting.
2020-04-02 05:05:29,558 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1e786eaa{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:29,559 [Thread-910] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7134aa30{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:29,559 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@41016b62{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:29,559 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7137b9cf{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:29,560 [Thread-910] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43093
2020-04-02 05:05:29,564 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:29,564 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:29,564 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1330165299-172.17.0.5-1585803928957 (Datanode Uuid 651aebb3-c17b-4e6b-8ff1-b7a8e05b1721) service to localhost/127.0.0.1:46638
2020-04-02 05:05:29,564 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1330165299-172.17.0.5-1585803928957 (Datanode Uuid 651aebb3-c17b-4e6b-8ff1-b7a8e05b1721)
2020-04-02 05:05:29,564 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,570 [IPC Server listener on 43093] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43093
2020-04-02 05:05:29,577 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1330165299-172.17.0.5-1585803928957] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:29,586 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1330165299-172.17.0.5-1585803928957] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:29,600 [Thread-910] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:29,600 [Thread-910] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:29,602 [Thread-910] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:29,602 [Thread-910] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:29,605 [Thread-910] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:29,605 [Thread-910] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:05:29,606 [Thread-910] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 41062 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:29,606 [Thread-910] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:29,606 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1dd168d6] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:29,608 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-0183655f-d291-4c67-98f3-45a47ab9edff) exiting.
2020-04-02 05:05:29,608 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-93a272b3-692e-4ff1-b302-c9f489fea1cc) exiting.
2020-04-02 05:05:29,621 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5e05ab6a{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:29,622 [Thread-910] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2874d96b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:29,622 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7c0671f3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:29,622 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4cea5dec{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:29,623 [Thread-910] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41062
2020-04-02 05:05:29,627 [IPC Server listener on 41062] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41062
2020-04-02 05:05:29,627 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:29,630 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:29,630 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1330165299-172.17.0.5-1585803928957 (Datanode Uuid fec50a01-c199-4781-9641-86878f9712d9) service to localhost/127.0.0.1:46638
2020-04-02 05:05:29,630 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1330165299-172.17.0.5-1585803928957 (Datanode Uuid fec50a01-c199-4781-9641-86878f9712d9)
2020-04-02 05:05:29,630 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,642 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1330165299-172.17.0.5-1585803928957] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:29,652 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1330165299-172.17.0.5-1585803928957] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:29,660 [Thread-910] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:29,660 [Thread-910] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:29,662 [Thread-910] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:29,663 [Thread-910] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:29,667 [Thread-910] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:29,667 [Thread-910] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:05:29,667 [Thread-910] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 34493 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:29,667 [Thread-910] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:29,667 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@37bf3a85] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:29,670 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-d4f60963-5c43-402e-b85a-626bd3836a41) exiting.
2020-04-02 05:05:29,670 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-955d50cb-4e91-4299-894a-b986afa0547b) exiting.
2020-04-02 05:05:29,700 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@11aa36e8{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:29,705 [Thread-910] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@19affe3d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:29,706 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@10854a39{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:29,706 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@15b8b1e1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:29,707 [Thread-910] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34493
2020-04-02 05:05:29,711 [IPC Server listener on 34493] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34493
2020-04-02 05:05:29,714 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:29,714 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:29,715 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1330165299-172.17.0.5-1585803928957 (Datanode Uuid 80417d3d-bf5c-45e1-84d8-7453e47e4f35) service to localhost/127.0.0.1:46638
2020-04-02 05:05:29,815 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1330165299-172.17.0.5-1585803928957 (Datanode Uuid 80417d3d-bf5c-45e1-84d8-7453e47e4f35)
2020-04-02 05:05:29,816 [BP-1330165299-172.17.0.5-1585803928957 heartbeating to localhost/127.0.0.1:46638] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1330165299-172.17.0.5-1585803928957
2020-04-02 05:05:29,825 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1330165299-172.17.0.5-1585803928957] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:29,831 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1330165299-172.17.0.5-1585803928957] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:29,851 [Thread-910] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:29,852 [Thread-910] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:29,855 [Thread-910] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:29,855 [Thread-910] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:29,868 [Thread-910] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:29,868 [Thread-910] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:05:29,868 [Thread-910] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 46638 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:29,868 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:29,868 [Thread[Thread-937,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:05:29,868 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@1403958b] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:05:29,869 [Thread-910] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 3
2020-04-02 05:05:29,869 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3ecc961f] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:05:29,869 [Thread-910] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 4 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 3 7 
2020-04-02 05:05:29,870 [Thread-910] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000004
2020-04-02 05:05:29,871 [Thread-910] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000004
2020-04-02 05:05:29,871 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:05:29,871 [CacheReplicationMonitor(894484145)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:05:29,901 [Thread-910] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46638
2020-04-02 05:05:29,906 [IPC Server listener on 46638] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46638
2020-04-02 05:05:29,906 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:05:29,906 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:05:29,906 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:29,922 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:29,926 [Thread-910] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:05:29,927 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@c627ec{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:05:29,930 [Thread-910] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@74823076{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:05:29,931 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5cb09476{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:29,931 [Thread-910] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@11abc13{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
[msx] test Finished org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testDataNodeStartIfHttpsQopPrivacy
[msx] writeFile testName = org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testDataNodeStartIfHttpsQopPrivacy
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testIntegrity
[msx] perform reset as unitTestCounterInClass 11 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:05:29,992 [Thread-1063] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=3
2020-04-02 05:05:29,998 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803929998,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:30,126 [Thread-1063] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
Formatting using clusterid: testClusterID
2020-04-02 05:05:30,126 [Thread-1063] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:30,127 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:30,127 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:30,127 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:30,127 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:30,127 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:30,127 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:30,127 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:30,128 [Thread-1063] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:30,128 [Thread-1063] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:30,128 [Thread-1063] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:30,128 [Thread-1063] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:30,129 [Thread-1063] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:30
2020-04-02 05:05:30,129 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:30,129 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:30,130 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:05:30,140 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:30,155 [Thread-1063] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:30,155 [Thread-1063] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:30,156 [Thread-1063] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:30,156 [Thread-1063] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:30,156 [Thread-1063] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:30,157 [Thread-1063] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:30,157 [Thread-1063] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:30,157 [Thread-1063] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:30,157 [Thread-1063] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:30,157 [Thread-1063] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:30,157 [Thread-1063] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:30,157 [Thread-1063] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:30,157 [Thread-1063] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:30,158 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:30,158 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:30,158 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:05:30,158 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:30,163 [Thread-1063] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:30,163 [Thread-1063] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:30,163 [Thread-1063] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:30,163 [Thread-1063] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:30,163 [Thread-1063] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:30,163 [Thread-1063] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:30,163 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:30,163 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:30,163 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:05:30,164 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:30,165 [Thread-1063] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:30,165 [Thread-1063] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:30,165 [Thread-1063] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:30,165 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:30,165 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:30,165 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:30,165 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:30,165 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:05:30,165 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:30,167 [Thread-1063] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:30,168 [Thread-1063] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:05:30,174 [Thread-1063] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:05:30,175 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:30,175 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:30,179 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:05:30,186 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:05:30,188 [Thread-1063] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:05:30,190 [Thread-1063] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:30,190 [Thread-1063] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:05:30,190 [Thread-1063] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:30,191 [Thread-1063] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:05:30,196 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803930196,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:30,198 [Thread-1063] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:30,222 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3eeb435c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:30,222 [Thread-1063] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:30,223 [Thread-1063] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:0
2020-04-02 05:05:30,223 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:30,224 [Thread-1063] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:30,225 [Thread-1063] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:30,225 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:30,225 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:30,226 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:30,226 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:30,226 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:30,228 [Thread-1063] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:30,228 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:30,228 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:05:30,228 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:05:30,229 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46196
2020-04-02 05:05:30,229 [Thread-1063] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:30,230 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@49960931{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:30,230 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5d1119ac{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:30,234 [Thread-1063] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:30,234 [Thread-1063] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:30,235 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@13085259{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:30,243 [Thread-1063] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@36d6b614(server,h=[],w=[]) for SslContextFactory@78606679(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/trustKS.jks)
2020-04-02 05:05:30,244 [Thread-1063] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7d01d5b0{SSL,[ssl, http/1.1]}{localhost:46196}
2020-04-02 05:05:30,248 [Thread-1063] INFO  server.Server (Server.java:doStart(419)) - Started @16807ms
2020-04-02 05:05:30,250 [Thread-1063] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:30,250 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:30,251 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:30,251 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:30,251 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:30,251 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:30,251 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:30,251 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:30,252 [Thread-1063] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:30,253 [Thread-1063] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:30,253 [Thread-1063] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:30,254 [Thread-1063] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:30,254 [Thread-1063] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:30
2020-04-02 05:05:30,254 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:30,254 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:30,255 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:05:30,255 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:30,273 [Thread-1063] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:30,274 [Thread-1063] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:30,274 [Thread-1063] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:30,274 [Thread-1063] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:30,274 [Thread-1063] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:30,274 [Thread-1063] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:30,275 [Thread-1063] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:30,275 [Thread-1063] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:30,275 [Thread-1063] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:30,275 [Thread-1063] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:30,275 [Thread-1063] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:30,275 [Thread-1063] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:30,275 [Thread-1063] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:30,275 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:30,275 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:30,275 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:05:30,276 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:30,286 [Thread-1063] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:30,286 [Thread-1063] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:30,286 [Thread-1063] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:30,286 [Thread-1063] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:30,286 [Thread-1063] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:30,287 [Thread-1063] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:30,287 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:30,287 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:30,287 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:05:30,287 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:30,289 [Thread-1063] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:30,289 [Thread-1063] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:30,289 [Thread-1063] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:30,290 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:30,290 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:30,290 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:30,290 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:30,291 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:05:30,291 [Thread-1063] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:30,293 [Thread-1063] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:30,294 [Thread-1063] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:30,295 [Thread-1063] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:05:30,296 [Thread-1063] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:05:30,296 [Thread-1063] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:05:30,296 [Thread-1063] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:30,297 [Thread-1063] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:30,298 [Thread-1063] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:30,298 [Thread-1063] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:30,298 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:30,298 [Thread-1063] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:05:30,312 [Thread-1063] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:30,312 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 20 msecs
2020-04-02 05:05:30,312 [Thread-1063] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:05:30,313 [Thread-1063] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:30,314 [Socket Reader #1 for port 33552] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33552
2020-04-02 05:05:30,320 [Thread-1063] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:33552 to access this namenode/service.
2020-04-02 05:05:30,321 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:30,359 [Thread-1063] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:30,361 [Thread-1063] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:30,361 [Thread-1063] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:05:30,371 [Thread-1063] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:05:30,371 [Thread-1063] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:30,371 [Thread-1063] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:30,364 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@27d8b40f] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:05:30,389 [Thread[Thread-1090,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:05:30,391 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:30,394 [Thread[Thread-1090,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:30,394 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:30,396 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:30,396 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:30,396 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:30,396 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 22 msec
2020-04-02 05:05:30,410 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:30,410 [IPC Server listener on 33552] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33552: starting
2020-04-02 05:05:30,422 [Thread-1063] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:33552
2020-04-02 05:05:30,422 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:30,422 [Thread-1063] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:30,423 [Thread-1063] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:30,427 [Thread-1063] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 33552 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:30,430 [CacheReplicationMonitor(228215942)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:30,435 [Thread-1063] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:30,440 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803930439,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:30,441 [Thread-1063] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:30,442 [Thread-1063] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:30,443 [Thread-1063] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:30,446 [Thread-1063] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:30,449 [Thread-1063] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:30,449 [Thread-1063] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:30,449 [Thread-1063] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:30,449 [Thread-1063] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:30,449 [Thread-1063] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:30,450 [Thread-1063] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:30,450 [Thread-1063] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:35177
2020-04-02 05:05:30,450 [Thread-1063] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:30,450 [Thread-1063] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:30,451 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:30,453 [Thread-1063] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:30,453 [Thread-1063] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:30,453 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:30,454 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:30,455 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:30,455 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:30,455 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:30,455 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41905
2020-04-02 05:05:30,455 [Thread-1063] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:30,457 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@322d1344{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:30,457 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f5b8a81{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:30,462 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@29ad54e3{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:30,463 [Thread-1063] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@277a0811{HTTP/1.1,[http/1.1]}{localhost:41905}
2020-04-02 05:05:30,466 [Thread-1063] INFO  server.Server (Server.java:doStart(419)) - Started @17024ms
2020-04-02 05:05:30,488 [Thread-1063] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:42017
2020-04-02 05:05:30,488 [Thread-1063] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:30,488 [Thread-1063] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:30,488 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@429c1805] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:30,489 [Thread-1063] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:30,490 [Socket Reader #1 for port 37111] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37111
2020-04-02 05:05:30,498 [Thread-1063] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:37111
2020-04-02 05:05:30,519 [Thread-1063] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:30,520 [Thread-1063] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:30,520 [Thread-1119] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33552 starting to offer service
2020-04-02 05:05:30,524 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:30,528 [IPC Server listener on 37111] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37111: starting
2020-04-02 05:05:30,540 [Thread-1063] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 37111 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:30,541 [Thread-1063] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:30,560 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803930559,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:30,562 [Thread-1063] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:30,562 [Thread-1063] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:30,563 [Thread-1063] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:30,564 [Thread-1063] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:30,564 [Thread-1063] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:30,564 [Thread-1063] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:30,564 [Thread-1063] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:30,571 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803930570,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:30,576 [Thread-1063] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:30,577 [Thread-1063] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:30,577 [Thread-1063] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:30,597 [Thread-1063] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:41297
2020-04-02 05:05:30,598 [Thread-1063] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:30,598 [Thread-1063] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:30,599 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:30,600 [Socket Reader #1 for port 33552] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:30,600 [Thread-1063] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:30,604 [Thread-1063] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:30,605 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:30,605 [Thread-1119] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33552
2020-04-02 05:05:30,608 [Thread-1119] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:30,609 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:30,610 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:30,610 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:30,610 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:30,610 [Thread-1119] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:30,611 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39207
2020-04-02 05:05:30,611 [Thread-1119] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1576850949. Formatting...
2020-04-02 05:05:30,611 [Thread-1063] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:30,611 [Thread-1119] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-14d2b0b6-c45b-4691-94f0-76e98f814002 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:05:30,612 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7b345843{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:30,613 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@41a7b36e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:30,615 [Thread-1119] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:30,615 [Thread-1119] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1576850949. Formatting...
2020-04-02 05:05:30,615 [Thread-1119] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b7aa266e-10d6-44df-99be-151d5098bbaa for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:05:30,618 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@183392a3{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:30,623 [Thread-1063] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@39ac8dad{HTTP/1.1,[http/1.1]}{localhost:39207}
2020-04-02 05:05:30,624 [Thread-1063] INFO  server.Server (Server.java:doStart(419)) - Started @17182ms
2020-04-02 05:05:30,632 [Thread-1119] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:30,632 [Thread-1119] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:30,632 [Thread-1119] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-479016599-172.17.0.5-1585803930167 is not formatted. Formatting ...
2020-04-02 05:05:30,632 [Thread-1119] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-479016599-172.17.0.5-1585803930167 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-479016599-172.17.0.5-1585803930167/current
2020-04-02 05:05:30,673 [Thread-1119] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:30,673 [Thread-1119] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:30,688 [Thread-1063] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:39672
2020-04-02 05:05:30,689 [Thread-1119] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-479016599-172.17.0.5-1585803930167 is not formatted. Formatting ...
2020-04-02 05:05:30,689 [Thread-1119] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-479016599-172.17.0.5-1585803930167 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-479016599-172.17.0.5-1585803930167/current
2020-04-02 05:05:30,692 [Thread-1119] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1576850949;bpid=BP-479016599-172.17.0.5-1585803930167;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1576850949;c=1585803930167;bpid=BP-479016599-172.17.0.5-1585803930167;dnuuid=null
2020-04-02 05:05:30,692 [Thread-1063] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:30,701 [Thread-1063] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:30,705 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4d6be34a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:30,705 [Thread-1063] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:30,706 [Thread-1119] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID cbc3f9bc-02b4-402f-abdf-81fd1f7f86a8
2020-04-02 05:05:30,708 [Socket Reader #1 for port 34109] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34109
2020-04-02 05:05:30,712 [Thread-1119] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-14d2b0b6-c45b-4691-94f0-76e98f814002
2020-04-02 05:05:30,715 [Thread-1119] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:05:30,717 [Thread-1063] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:34109
2020-04-02 05:05:30,718 [Thread-1119] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-b7aa266e-10d6-44df-99be-151d5098bbaa
2020-04-02 05:05:30,718 [Thread-1119] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:05:30,722 [Thread-1119] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:30,739 [Thread-1063] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:30,740 [Thread-1063] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:30,740 [Thread-1119] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:30,740 [Thread-1145] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33552 starting to offer service
2020-04-02 05:05:30,741 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:30,751 [Thread-1119] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:30,751 [IPC Server listener on 34109] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34109: starting
2020-04-02 05:05:30,751 [Thread-1119] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:30,760 [Thread-1063] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 34109 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:30,760 [Thread-1119] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:30,763 [Thread-1119] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:30,763 [Thread-1157] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:30,764 [Thread-1063] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:30,765 [Thread-1158] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:30,793 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803930792,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:30,795 [Thread-1063] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:30,795 [Thread-1063] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:30,796 [Thread-1063] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:30,797 [Thread-1063] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:30,797 [Thread-1063] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:30,798 [Thread-1063] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:30,798 [Thread-1063] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:30,798 [Thread-1063] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:30,798 [Thread-1063] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:30,801 [Thread-1063] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:30,802 [Thread-1063] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:39222
2020-04-02 05:05:30,804 [Thread-1063] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:30,804 [Thread-1063] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:30,805 [Thread-1157] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-479016599-172.17.0.5-1585803930167 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 41ms
2020-04-02 05:05:30,806 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:30,807 [Thread-1063] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:30,808 [Thread-1063] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:30,808 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:30,809 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:30,810 [Thread-1158] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-479016599-172.17.0.5-1585803930167 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 45ms
2020-04-02 05:05:30,810 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:30,810 [Thread-1119] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-479016599-172.17.0.5-1585803930167: 47ms
2020-04-02 05:05:30,810 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:30,810 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803930810,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:30,810 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:30,810 [Thread-1164] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:30,810 [Thread-1165] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:30,811 [Thread-1164] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-479016599-172.17.0.5-1585803930167/current/replicas doesn't exist 
2020-04-02 05:05:30,811 [Thread-1165] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-479016599-172.17.0.5-1585803930167/current/replicas doesn't exist 
2020-04-02 05:05:30,811 [Thread-1063] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38601
2020-04-02 05:05:30,811 [Thread-1063] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:30,811 [Thread-1164] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 0ms
2020-04-02 05:05:30,811 [Thread-1165] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 0ms
2020-04-02 05:05:30,811 [Thread-1119] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-479016599-172.17.0.5-1585803930167: 2ms
2020-04-02 05:05:30,812 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:30,812 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:30,812 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-14d2b0b6-c45b-4691-94f0-76e98f814002): finished scanning block pool BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:30,812 [Thread-1119] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:06 AM with interval of 21600000ms
2020-04-02 05:05:30,812 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d4236cc{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:30,812 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-b7aa266e-10d6-44df-99be-151d5098bbaa): finished scanning block pool BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:30,813 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-14d2b0b6-c45b-4691-94f0-76e98f814002): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:05:30,813 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@389bf1c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:30,813 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-b7aa266e-10d6-44df-99be-151d5098bbaa): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:05:30,816 [Socket Reader #1 for port 33552] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:30,819 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-479016599-172.17.0.5-1585803930167 (Datanode Uuid cbc3f9bc-02b4-402f-abdf-81fd1f7f86a8) service to localhost/127.0.0.1:33552 beginning handshake with NN
2020-04-02 05:05:30,816 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2e556c8a{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:30,820 [Thread-1063] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@572a079a{HTTP/1.1,[http/1.1]}{localhost:38601}
2020-04-02 05:05:30,823 [Thread-1063] INFO  server.Server (Server.java:doStart(419)) - Started @17382ms
2020-04-02 05:05:30,824 [IPC Server handler 3 on 33552] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35177, datanodeUuid=cbc3f9bc-02b4-402f-abdf-81fd1f7f86a8, infoPort=0, infoSecurePort=42017, ipcPort=37111, storageInfo=lv=-57;cid=testClusterID;nsid=1576850949;c=1585803930167) storage cbc3f9bc-02b4-402f-abdf-81fd1f7f86a8
2020-04-02 05:05:30,824 [IPC Server handler 3 on 33552] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35177
2020-04-02 05:05:30,824 [IPC Server handler 3 on 33552] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN cbc3f9bc-02b4-402f-abdf-81fd1f7f86a8 (127.0.0.1:35177).
2020-04-02 05:05:30,833 [Thread-1145] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33552
2020-04-02 05:05:30,841 [Thread-1145] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:30,841 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-479016599-172.17.0.5-1585803930167 (Datanode Uuid cbc3f9bc-02b4-402f-abdf-81fd1f7f86a8) service to localhost/127.0.0.1:33552 successfully registered with NN
2020-04-02 05:05:30,841 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-479016599-172.17.0.5-1585803930167 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:30,842 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:30,842 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33552 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:30,846 [Thread-1145] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:30,846 [Thread-1145] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1576850949. Formatting...
2020-04-02 05:05:30,846 [Thread-1145] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7a5dff2e-06f5-4914-a053-e9c9d6374769 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:05:30,850 [IPC Server handler 1 on 33552] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-14d2b0b6-c45b-4691-94f0-76e98f814002 for DN 127.0.0.1:35177
2020-04-02 05:05:30,851 [IPC Server handler 1 on 33552] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b7aa266e-10d6-44df-99be-151d5098bbaa for DN 127.0.0.1:35177
2020-04-02 05:05:30,857 [Thread-1145] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:30,858 [Thread-1145] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1576850949. Formatting...
2020-04-02 05:05:30,858 [Thread-1145] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0beb4497-13c8-4966-a8b4-97c5ccaaca2c for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:05:30,860 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xfc87e8056239d686: Processing first storage report for DS-14d2b0b6-c45b-4691-94f0-76e98f814002 from datanode cbc3f9bc-02b4-402f-abdf-81fd1f7f86a8
2020-04-02 05:05:30,860 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xfc87e8056239d686: from storage DS-14d2b0b6-c45b-4691-94f0-76e98f814002 node DatanodeRegistration(127.0.0.1:35177, datanodeUuid=cbc3f9bc-02b4-402f-abdf-81fd1f7f86a8, infoPort=0, infoSecurePort=42017, ipcPort=37111, storageInfo=lv=-57;cid=testClusterID;nsid=1576850949;c=1585803930167), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:30,861 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xfc87e8056239d686: Processing first storage report for DS-b7aa266e-10d6-44df-99be-151d5098bbaa from datanode cbc3f9bc-02b4-402f-abdf-81fd1f7f86a8
2020-04-02 05:05:30,861 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xfc87e8056239d686: from storage DS-b7aa266e-10d6-44df-99be-151d5098bbaa node DatanodeRegistration(127.0.0.1:35177, datanodeUuid=cbc3f9bc-02b4-402f-abdf-81fd1f7f86a8, infoPort=0, infoSecurePort=42017, ipcPort=37111, storageInfo=lv=-57;cid=testClusterID;nsid=1576850949;c=1585803930167), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:30,861 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xfc87e8056239d686,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:30,862 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:30,870 [Thread-1145] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:30,870 [Thread-1145] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:30,870 [Thread-1145] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-479016599-172.17.0.5-1585803930167 is not formatted. Formatting ...
2020-04-02 05:05:30,870 [Thread-1145] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-479016599-172.17.0.5-1585803930167 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-479016599-172.17.0.5-1585803930167/current
2020-04-02 05:05:30,877 [Thread-1063] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:41798
2020-04-02 05:05:30,877 [Thread-1063] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:30,877 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@18fd41f8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:30,878 [Thread-1063] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:30,878 [Thread-1063] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:30,879 [Socket Reader #1 for port 35379] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35379
2020-04-02 05:05:30,883 [Thread-1063] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:35379
2020-04-02 05:05:30,888 [Thread-1145] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:30,889 [Thread-1145] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:30,889 [Thread-1145] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-479016599-172.17.0.5-1585803930167 is not formatted. Formatting ...
2020-04-02 05:05:30,889 [Thread-1145] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-479016599-172.17.0.5-1585803930167 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-479016599-172.17.0.5-1585803930167/current
2020-04-02 05:05:30,891 [Thread-1063] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:30,891 [Thread-1063] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:30,892 [Thread-1178] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33552 starting to offer service
2020-04-02 05:05:30,894 [Thread-1145] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1576850949;bpid=BP-479016599-172.17.0.5-1585803930167;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1576850949;c=1585803930167;bpid=BP-479016599-172.17.0.5-1585803930167;dnuuid=null
2020-04-02 05:05:30,894 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:30,895 [Thread-1145] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 90a8996d-75f3-4f95-8c05-8214e858bde3
2020-04-02 05:05:30,908 [IPC Server listener on 35379] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35379: starting
2020-04-02 05:05:30,908 [Thread-1145] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-7a5dff2e-06f5-4914-a053-e9c9d6374769
2020-04-02 05:05:30,915 [Thread-1145] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:05:30,920 [Thread-1063] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 35379 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:30,920 [Thread-1145] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-0beb4497-13c8-4966-a8b4-97c5ccaaca2c
2020-04-02 05:05:30,920 [Thread-1145] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:05:30,921 [Thread-1145] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:30,921 [Thread-1145] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:30,921 [Thread-1145] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:30,922 [Thread-1145] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:30,924 [Thread-1145] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:30,924 [Thread-1145] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:30,925 [Thread-1193] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:05:30,925 [Thread-1194] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:05:30,939 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803930939,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:30,943 [Socket Reader #1 for port 33552] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:30,943 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803930943,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:30,946 [Thread-1178] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33552
2020-04-02 05:05:30,948 [Thread-1178] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:30,950 [Thread-1178] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:30,950 [Thread-1178] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1576850949. Formatting...
2020-04-02 05:05:30,951 [Thread-1178] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-dff99c79-2dc1-4779-b6a5-599a88ccea3c for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:05:30,952 [Socket Reader #1 for port 33552] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:30,956 [Thread-1178] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:30,957 [Thread-1178] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1576850949. Formatting...
2020-04-02 05:05:30,957 [Thread-1178] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7fdea2e2-4e93-40ed-9433-11b93aafafa7 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:05:30,957 [Thread-1193] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-479016599-172.17.0.5-1585803930167 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 32ms
2020-04-02 05:05:30,977 [IPC Server handler 6 on 33552] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:30,977 [Thread-1194] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-479016599-172.17.0.5-1585803930167 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 52ms
2020-04-02 05:05:30,978 [Thread-1145] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-479016599-172.17.0.5-1585803930167: 54ms
2020-04-02 05:05:30,978 [Thread-1197] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:05:30,978 [Thread-1198] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:05:30,978 [Thread-1197] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-479016599-172.17.0.5-1585803930167/current/replicas doesn't exist 
2020-04-02 05:05:30,978 [Thread-1198] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-479016599-172.17.0.5-1585803930167/current/replicas doesn't exist 
2020-04-02 05:05:30,978 [Thread-1197] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-04-02 05:05:30,995 [Thread-1198] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 17ms
2020-04-02 05:05:31,002 [Thread-1063] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:31,002 [Thread-1063] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:31,002 [Thread-1145] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-479016599-172.17.0.5-1585803930167: 24ms
2020-04-02 05:05:31,003 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:31,003 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:31,003 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-0beb4497-13c8-4966-a8b4-97c5ccaaca2c): finished scanning block pool BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:31,003 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-7a5dff2e-06f5-4914-a053-e9c9d6374769): finished scanning block pool BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:31,003 [Thread-1145] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:46 AM with interval of 21600000ms
2020-04-02 05:05:31,006 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-479016599-172.17.0.5-1585803930167 (Datanode Uuid 90a8996d-75f3-4f95-8c05-8214e858bde3) service to localhost/127.0.0.1:33552 beginning handshake with NN
2020-04-02 05:05:31,007 [IPC Server handler 7 on 33552] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41297, datanodeUuid=90a8996d-75f3-4f95-8c05-8214e858bde3, infoPort=0, infoSecurePort=39672, ipcPort=34109, storageInfo=lv=-57;cid=testClusterID;nsid=1576850949;c=1585803930167) storage 90a8996d-75f3-4f95-8c05-8214e858bde3
2020-04-02 05:05:31,008 [IPC Server handler 7 on 33552] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41297
2020-04-02 05:05:31,008 [IPC Server handler 7 on 33552] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 90a8996d-75f3-4f95-8c05-8214e858bde3 (127.0.0.1:41297).
2020-04-02 05:05:31,009 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-7a5dff2e-06f5-4914-a053-e9c9d6374769): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-04-02 05:05:31,009 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-0beb4497-13c8-4966-a8b4-97c5ccaaca2c): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-04-02 05:05:31,009 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-479016599-172.17.0.5-1585803930167 (Datanode Uuid 90a8996d-75f3-4f95-8c05-8214e858bde3) service to localhost/127.0.0.1:33552 successfully registered with NN
2020-04-02 05:05:31,009 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-479016599-172.17.0.5-1585803930167 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:31,009 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:31,009 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33552 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:31,020 [IPC Server handler 9 on 33552] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7a5dff2e-06f5-4914-a053-e9c9d6374769 for DN 127.0.0.1:41297
2020-04-02 05:05:31,025 [IPC Server handler 9 on 33552] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0beb4497-13c8-4966-a8b4-97c5ccaaca2c for DN 127.0.0.1:41297
2020-04-02 05:05:31,028 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x550d400b232a90f6: Processing first storage report for DS-0beb4497-13c8-4966-a8b4-97c5ccaaca2c from datanode 90a8996d-75f3-4f95-8c05-8214e858bde3
2020-04-02 05:05:31,028 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x550d400b232a90f6: from storage DS-0beb4497-13c8-4966-a8b4-97c5ccaaca2c node DatanodeRegistration(127.0.0.1:41297, datanodeUuid=90a8996d-75f3-4f95-8c05-8214e858bde3, infoPort=0, infoSecurePort=39672, ipcPort=34109, storageInfo=lv=-57;cid=testClusterID;nsid=1576850949;c=1585803930167), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:31,028 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x550d400b232a90f6: Processing first storage report for DS-7a5dff2e-06f5-4914-a053-e9c9d6374769 from datanode 90a8996d-75f3-4f95-8c05-8214e858bde3
2020-04-02 05:05:31,028 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x550d400b232a90f6: from storage DS-7a5dff2e-06f5-4914-a053-e9c9d6374769 node DatanodeRegistration(127.0.0.1:41297, datanodeUuid=90a8996d-75f3-4f95-8c05-8214e858bde3, infoPort=0, infoSecurePort=39672, ipcPort=34109, storageInfo=lv=-57;cid=testClusterID;nsid=1576850949;c=1585803930167), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:31,028 [Thread-1178] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:31,028 [Thread-1178] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:31,028 [Thread-1178] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-479016599-172.17.0.5-1585803930167 is not formatted. Formatting ...
2020-04-02 05:05:31,028 [Thread-1178] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-479016599-172.17.0.5-1585803930167 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-479016599-172.17.0.5-1585803930167/current
2020-04-02 05:05:31,028 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x550d400b232a90f6,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:31,029 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:31,047 [Thread-1178] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:31,047 [Thread-1178] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:31,047 [Thread-1178] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-479016599-172.17.0.5-1585803930167 is not formatted. Formatting ...
2020-04-02 05:05:31,047 [Thread-1178] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-479016599-172.17.0.5-1585803930167 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-479016599-172.17.0.5-1585803930167/current
2020-04-02 05:05:31,049 [Thread-1178] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1576850949;bpid=BP-479016599-172.17.0.5-1585803930167;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1576850949;c=1585803930167;bpid=BP-479016599-172.17.0.5-1585803930167;dnuuid=null
2020-04-02 05:05:31,050 [Thread-1178] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID f61bcef8-7444-4b2c-9747-a5a3b37f573b
2020-04-02 05:05:31,052 [Thread-1178] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-dff99c79-2dc1-4779-b6a5-599a88ccea3c
2020-04-02 05:05:31,052 [Thread-1178] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:05:31,053 [Thread-1178] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-7fdea2e2-4e93-40ed-9433-11b93aafafa7
2020-04-02 05:05:31,053 [Thread-1178] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:05:31,054 [Thread-1178] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:31,055 [Thread-1178] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:31,055 [Thread-1178] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:31,055 [Thread-1178] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:31,055 [Thread-1178] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:31,057 [Thread-1178] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:31,057 [Thread-1204] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:05:31,057 [Thread-1205] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:05:31,080 [Thread-1204] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-479016599-172.17.0.5-1585803930167 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 22ms
2020-04-02 05:05:31,081 [Thread-1205] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-479016599-172.17.0.5-1585803930167 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 23ms
2020-04-02 05:05:31,081 [Thread-1178] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-479016599-172.17.0.5-1585803930167: 24ms
2020-04-02 05:05:31,081 [Thread-1208] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:05:31,081 [Thread-1209] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:05:31,081 [Thread-1208] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-479016599-172.17.0.5-1585803930167/current/replicas doesn't exist 
2020-04-02 05:05:31,081 [Thread-1209] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-479016599-172.17.0.5-1585803930167/current/replicas doesn't exist 
2020-04-02 05:05:31,082 [Thread-1208] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 1ms
2020-04-02 05:05:31,082 [Thread-1209] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 1ms
2020-04-02 05:05:31,082 [Thread-1178] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-479016599-172.17.0.5-1585803930167: 1ms
2020-04-02 05:05:31,082 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:31,082 [Thread-1178] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:23 AM with interval of 21600000ms
2020-04-02 05:05:31,083 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-7fdea2e2-4e93-40ed-9433-11b93aafafa7): finished scanning block pool BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:31,083 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-479016599-172.17.0.5-1585803930167 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:31,083 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-7fdea2e2-4e93-40ed-9433-11b93aafafa7): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:05:31,083 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-dff99c79-2dc1-4779-b6a5-599a88ccea3c): finished scanning block pool BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:31,084 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-dff99c79-2dc1-4779-b6a5-599a88ccea3c): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:05:31,097 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-479016599-172.17.0.5-1585803930167 (Datanode Uuid f61bcef8-7444-4b2c-9747-a5a3b37f573b) service to localhost/127.0.0.1:33552 beginning handshake with NN
2020-04-02 05:05:31,098 [IPC Server handler 2 on 33552] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39222, datanodeUuid=f61bcef8-7444-4b2c-9747-a5a3b37f573b, infoPort=0, infoSecurePort=41798, ipcPort=35379, storageInfo=lv=-57;cid=testClusterID;nsid=1576850949;c=1585803930167) storage f61bcef8-7444-4b2c-9747-a5a3b37f573b
2020-04-02 05:05:31,099 [IPC Server handler 2 on 33552] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39222
2020-04-02 05:05:31,099 [IPC Server handler 2 on 33552] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f61bcef8-7444-4b2c-9747-a5a3b37f573b (127.0.0.1:39222).
2020-04-02 05:05:31,100 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-479016599-172.17.0.5-1585803930167 (Datanode Uuid f61bcef8-7444-4b2c-9747-a5a3b37f573b) service to localhost/127.0.0.1:33552 successfully registered with NN
2020-04-02 05:05:31,100 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-479016599-172.17.0.5-1585803930167 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:31,100 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:31,100 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33552 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:31,104 [IPC Server handler 0 on 33552] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-dff99c79-2dc1-4779-b6a5-599a88ccea3c for DN 127.0.0.1:39222
2020-04-02 05:05:31,104 [IPC Server handler 0 on 33552] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7fdea2e2-4e93-40ed-9433-11b93aafafa7 for DN 127.0.0.1:39222
2020-04-02 05:05:31,105 [IPC Server handler 3 on 33552] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:31,106 [Thread-1063] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:31,106 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb37cd17359a91fa0: Processing first storage report for DS-7fdea2e2-4e93-40ed-9433-11b93aafafa7 from datanode f61bcef8-7444-4b2c-9747-a5a3b37f573b
2020-04-02 05:05:31,107 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb37cd17359a91fa0: from storage DS-7fdea2e2-4e93-40ed-9433-11b93aafafa7 node DatanodeRegistration(127.0.0.1:39222, datanodeUuid=f61bcef8-7444-4b2c-9747-a5a3b37f573b, infoPort=0, infoSecurePort=41798, ipcPort=35379, storageInfo=lv=-57;cid=testClusterID;nsid=1576850949;c=1585803930167), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:05:31,107 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb37cd17359a91fa0: Processing first storage report for DS-dff99c79-2dc1-4779-b6a5-599a88ccea3c from datanode f61bcef8-7444-4b2c-9747-a5a3b37f573b
2020-04-02 05:05:31,107 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb37cd17359a91fa0: from storage DS-dff99c79-2dc1-4779-b6a5-599a88ccea3c node DatanodeRegistration(127.0.0.1:39222, datanodeUuid=f61bcef8-7444-4b2c-9747-a5a3b37f573b, infoPort=0, infoSecurePort=41798, ipcPort=35379, storageInfo=lv=-57;cid=testClusterID;nsid=1576850949;c=1585803930167), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:31,108 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xb37cd17359a91fa0,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:31,108 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:31,109 [IPC Server handler 4 on 33552] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:31,111 [Thread-1063] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:31,114 [IPC Server handler 5 on 33552] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=create	src=/file1	dst=null	perm=hdfs:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:05:31,138 [IPC Server handler 6 on 33552] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:35177, 127.0.0.1:41297, 127.0.0.1:39222 for /file1
2020-04-02 05:05:31,156 [DataXceiver for client DFSClient_NONMAPREDUCE_1890512123_4337 at /127.0.0.1:53912 [Receiving block BP-479016599-172.17.0.5-1585803930167:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-479016599-172.17.0.5-1585803930167:blk_1073741825_1001 src: /127.0.0.1:53912 dest: /127.0.0.1:35177
2020-04-02 05:05:31,167 [DataXceiver for client DFSClient_NONMAPREDUCE_1890512123_4337 at /127.0.0.1:59490 [Receiving block BP-479016599-172.17.0.5-1585803930167:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-479016599-172.17.0.5-1585803930167:blk_1073741825_1001 src: /127.0.0.1:59490 dest: /127.0.0.1:41297
2020-04-02 05:05:31,177 [DataXceiver for client DFSClient_NONMAPREDUCE_1890512123_4337 at /127.0.0.1:51964 [Receiving block BP-479016599-172.17.0.5-1585803930167:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-479016599-172.17.0.5-1585803930167:blk_1073741825_1001 src: /127.0.0.1:51964 dest: /127.0.0.1:39222
2020-04-02 05:05:31,207 [PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51964, dest: /127.0.0.1:39222, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1890512123_4337, offset: 0, srvID: f61bcef8-7444-4b2c-9747-a5a3b37f573b, blockid: BP-479016599-172.17.0.5-1585803930167:blk_1073741825_1001, duration(ns): 25669669
2020-04-02 05:05:31,208 [PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:31,213 [PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39222]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59490, dest: /127.0.0.1:41297, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1890512123_4337, offset: 0, srvID: 90a8996d-75f3-4f95-8c05-8214e858bde3, blockid: BP-479016599-172.17.0.5-1585803930167:blk_1073741825_1001, duration(ns): 29716810
2020-04-02 05:05:31,213 [PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39222]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39222] terminating
2020-04-02 05:05:31,219 [PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41297, 127.0.0.1:39222]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53912, dest: /127.0.0.1:35177, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1890512123_4337, offset: 0, srvID: cbc3f9bc-02b4-402f-abdf-81fd1f7f86a8, blockid: BP-479016599-172.17.0.5-1585803930167:blk_1073741825_1001, duration(ns): 35256496
2020-04-02 05:05:31,220 [PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41297, 127.0.0.1:39222]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41297, 127.0.0.1:39222] terminating
2020-04-02 05:05:31,248 [IPC Server handler 0 on 33552] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:35177, 127.0.0.1:39222, 127.0.0.1:41297 for /file1
2020-04-02 05:05:31,271 [DataXceiver for client DFSClient_NONMAPREDUCE_1890512123_4337 at /127.0.0.1:53920 [Receiving block BP-479016599-172.17.0.5-1585803930167:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-479016599-172.17.0.5-1585803930167:blk_1073741826_1002 src: /127.0.0.1:53920 dest: /127.0.0.1:35177
2020-04-02 05:05:31,276 [DataXceiver for client DFSClient_NONMAPREDUCE_1890512123_4337 at /127.0.0.1:51970 [Receiving block BP-479016599-172.17.0.5-1585803930167:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-479016599-172.17.0.5-1585803930167:blk_1073741826_1002 src: /127.0.0.1:51970 dest: /127.0.0.1:39222
2020-04-02 05:05:31,281 [DataXceiver for client DFSClient_NONMAPREDUCE_1890512123_4337 at /127.0.0.1:59500 [Receiving block BP-479016599-172.17.0.5-1585803930167:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-479016599-172.17.0.5-1585803930167:blk_1073741826_1002 src: /127.0.0.1:59500 dest: /127.0.0.1:41297
2020-04-02 05:05:31,302 [PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59500, dest: /127.0.0.1:41297, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1890512123_4337, offset: 0, srvID: 90a8996d-75f3-4f95-8c05-8214e858bde3, blockid: BP-479016599-172.17.0.5-1585803930167:blk_1073741826_1002, duration(ns): 16383973
2020-04-02 05:05:31,302 [PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:31,305 [PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41297]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51970, dest: /127.0.0.1:39222, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1890512123_4337, offset: 0, srvID: f61bcef8-7444-4b2c-9747-a5a3b37f573b, blockid: BP-479016599-172.17.0.5-1585803930167:blk_1073741826_1002, duration(ns): 19139656
2020-04-02 05:05:31,305 [PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41297]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41297] terminating
2020-04-02 05:05:31,308 [PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39222, 127.0.0.1:41297]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53920, dest: /127.0.0.1:35177, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1890512123_4337, offset: 0, srvID: cbc3f9bc-02b4-402f-abdf-81fd1f7f86a8, blockid: BP-479016599-172.17.0.5-1585803930167:blk_1073741826_1002, duration(ns): 22552126
2020-04-02 05:05:31,309 [PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39222, 127.0.0.1:41297]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39222, 127.0.0.1:41297] terminating
2020-04-02 05:05:31,311 [IPC Server handler 5 on 33552] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:35177, 127.0.0.1:39222, 127.0.0.1:41297 for /file1
2020-04-02 05:05:31,331 [DataXceiver for client DFSClient_NONMAPREDUCE_1890512123_4337 at /127.0.0.1:53928 [Receiving block BP-479016599-172.17.0.5-1585803930167:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-479016599-172.17.0.5-1585803930167:blk_1073741827_1003 src: /127.0.0.1:53928 dest: /127.0.0.1:35177
2020-04-02 05:05:31,341 [DataXceiver for client DFSClient_NONMAPREDUCE_1890512123_4337 at /127.0.0.1:51980 [Receiving block BP-479016599-172.17.0.5-1585803930167:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-479016599-172.17.0.5-1585803930167:blk_1073741827_1003 src: /127.0.0.1:51980 dest: /127.0.0.1:39222
2020-04-02 05:05:31,359 [DataXceiver for client DFSClient_NONMAPREDUCE_1890512123_4337 at /127.0.0.1:59510 [Receiving block BP-479016599-172.17.0.5-1585803930167:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-479016599-172.17.0.5-1585803930167:blk_1073741827_1003 src: /127.0.0.1:59510 dest: /127.0.0.1:41297
2020-04-02 05:05:31,382 [PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59510, dest: /127.0.0.1:41297, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1890512123_4337, offset: 0, srvID: 90a8996d-75f3-4f95-8c05-8214e858bde3, blockid: BP-479016599-172.17.0.5-1585803930167:blk_1073741827_1003, duration(ns): 14350572
2020-04-02 05:05:31,382 [PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:31,386 [PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41297]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51980, dest: /127.0.0.1:39222, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1890512123_4337, offset: 0, srvID: f61bcef8-7444-4b2c-9747-a5a3b37f573b, blockid: BP-479016599-172.17.0.5-1585803930167:blk_1073741827_1003, duration(ns): 22143492
2020-04-02 05:05:31,387 [PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41297]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41297] terminating
2020-04-02 05:05:31,390 [PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39222, 127.0.0.1:41297]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53928, dest: /127.0.0.1:35177, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1890512123_4337, offset: 0, srvID: cbc3f9bc-02b4-402f-abdf-81fd1f7f86a8, blockid: BP-479016599-172.17.0.5-1585803930167:blk_1073741827_1003, duration(ns): 25555980
2020-04-02 05:05:31,390 [PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39222, 127.0.0.1:41297]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-479016599-172.17.0.5-1585803930167:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39222, 127.0.0.1:41297] terminating
2020-04-02 05:05:31,394 [IPC Server handler 8 on 33552] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /file1 is closed by DFSClient_NONMAPREDUCE_1890512123_4337
2020-04-02 05:05:31,399 [IPC Server handler 2 on 33552] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null	proto=rpc
2020-04-02 05:05:31,422 [IPC Server handler 0 on 33552] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null	proto=rpc
2020-04-02 05:05:31,424 [Thread-1063] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:05:31,425 [Thread-1063] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:05:31,425 [Thread-1063] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 35379 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:31,425 [Thread-1063] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:31,425 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@46bdad12] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:31,430 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-7fdea2e2-4e93-40ed-9433-11b93aafafa7) exiting.
2020-04-02 05:05:31,430 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-dff99c79-2dc1-4779-b6a5-599a88ccea3c) exiting.
2020-04-02 05:05:31,468 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2e556c8a{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:31,469 [Thread-1063] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@572a079a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:31,470 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@389bf1c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:31,470 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6d4236cc{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:31,474 [Thread-1063] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35379
2020-04-02 05:05:31,506 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:31,506 [IPC Server listener on 35379] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35379
2020-04-02 05:05:31,506 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:31,506 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-479016599-172.17.0.5-1585803930167 (Datanode Uuid f61bcef8-7444-4b2c-9747-a5a3b37f573b) service to localhost/127.0.0.1:33552
2020-04-02 05:05:31,516 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-479016599-172.17.0.5-1585803930167 (Datanode Uuid f61bcef8-7444-4b2c-9747-a5a3b37f573b)
2020-04-02 05:05:31,516 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:31,525 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-479016599-172.17.0.5-1585803930167] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:31,533 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-479016599-172.17.0.5-1585803930167] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:31,565 [Thread-1063] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:31,565 [Thread-1063] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:31,568 [Thread-1063] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:31,568 [Thread-1063] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:31,582 [Thread-1063] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:31,582 [Thread-1063] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:05:31,582 [Thread-1063] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 34109 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:31,583 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2d6907a8] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:31,583 [Thread-1063] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:31,594 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-7a5dff2e-06f5-4914-a053-e9c9d6374769) exiting.
2020-04-02 05:05:31,597 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-0beb4497-13c8-4966-a8b4-97c5ccaaca2c) exiting.
2020-04-02 05:05:31,616 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@183392a3{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:31,618 [Thread-1063] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@39ac8dad{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:31,618 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@41a7b36e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:31,619 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7b345843{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:31,628 [Thread-1063] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34109
2020-04-02 05:05:31,652 [IPC Server listener on 34109] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34109
2020-04-02 05:05:31,662 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:31,663 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:31,663 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-479016599-172.17.0.5-1585803930167 (Datanode Uuid 90a8996d-75f3-4f95-8c05-8214e858bde3) service to localhost/127.0.0.1:33552
2020-04-02 05:05:31,663 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-479016599-172.17.0.5-1585803930167 (Datanode Uuid 90a8996d-75f3-4f95-8c05-8214e858bde3)
2020-04-02 05:05:31,666 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:31,674 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-479016599-172.17.0.5-1585803930167] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:31,680 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-479016599-172.17.0.5-1585803930167] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:31,690 [Thread-1063] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:31,690 [Thread-1063] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:31,709 [Thread-1063] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:31,709 [Thread-1063] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:31,710 [Thread-1063] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:31,710 [Thread-1063] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:05:31,710 [Thread-1063] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 37111 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:31,711 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@a660848] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:31,711 [Thread-1063] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:31,713 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-b7aa266e-10d6-44df-99be-151d5098bbaa) exiting.
2020-04-02 05:05:31,715 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-14d2b0b6-c45b-4691-94f0-76e98f814002) exiting.
2020-04-02 05:05:31,733 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@29ad54e3{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:31,734 [Thread-1063] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@277a0811{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:31,734 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f5b8a81{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:31,734 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@322d1344{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:31,735 [Thread-1063] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37111
2020-04-02 05:05:31,742 [IPC Server listener on 37111] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37111
2020-04-02 05:05:31,750 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:31,750 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:31,750 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-479016599-172.17.0.5-1585803930167 (Datanode Uuid cbc3f9bc-02b4-402f-abdf-81fd1f7f86a8) service to localhost/127.0.0.1:33552
2020-04-02 05:05:31,852 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-479016599-172.17.0.5-1585803930167 (Datanode Uuid cbc3f9bc-02b4-402f-abdf-81fd1f7f86a8)
2020-04-02 05:05:31,854 [BP-479016599-172.17.0.5-1585803930167 heartbeating to localhost/127.0.0.1:33552] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-479016599-172.17.0.5-1585803930167
2020-04-02 05:05:31,864 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-479016599-172.17.0.5-1585803930167] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:31,872 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-479016599-172.17.0.5-1585803930167] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:31,872 [Thread-1063] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:31,872 [Thread-1063] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:31,872 [Thread-1063] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:31,872 [Thread-1063] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:31,873 [Thread-1063] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:31,873 [Thread-1063] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:05:31,873 [Thread-1063] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 33552 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:31,873 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:31,874 [Thread[Thread-1090,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:05:31,874 [Thread-1063] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 14
2020-04-02 05:05:31,874 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@75b9fbc6] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:05:31,874 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@5422a7a5] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:05:31,875 [Thread-1063] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 15 Total time for transactions(ms): 30 Number of transactions batched in Syncs: 3 Number of syncs: 13 SyncTimes(ms): 1 1 
2020-04-02 05:05:31,875 [Thread-1063] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000015
2020-04-02 05:05:31,876 [Thread-1063] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000015
2020-04-02 05:05:31,876 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:05:31,879 [CacheReplicationMonitor(228215942)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:05:31,906 [Thread-1063] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33552
2020-04-02 05:05:31,924 [IPC Server listener on 33552] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33552
2020-04-02 05:05:31,924 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:31,924 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:05:31,926 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:05:31,941 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:31,942 [Thread-1063] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:05:31,944 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@13085259{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:05:31,946 [Thread-1063] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7d01d5b0{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:05:31,946 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5d1119ac{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:31,946 [Thread-1063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@49960931{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
[msx] test Finished org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testIntegrity
[msx] writeFile testName = org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testIntegrity
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testDataNodeAbortsIfNoSasl
[msx] perform reset as unitTestCounterInClass 12 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:05:31,998 [Thread-1242] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=3
2020-04-02 05:05:32,003 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803932003,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:32,005 [Thread-1242] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
Formatting using clusterid: testClusterID
2020-04-02 05:05:32,005 [Thread-1242] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:32,006 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:32,006 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:32,006 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:32,006 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:32,006 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:32,006 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:32,006 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:32,007 [Thread-1242] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:32,007 [Thread-1242] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:32,007 [Thread-1242] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:32,007 [Thread-1242] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:32,008 [Thread-1242] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:32
2020-04-02 05:05:32,008 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:32,008 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:32,008 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:05:32,008 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:32,018 [Thread-1242] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:32,018 [Thread-1242] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:32,019 [Thread-1242] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:32,019 [Thread-1242] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:32,019 [Thread-1242] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:32,019 [Thread-1242] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:32,019 [Thread-1242] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:32,019 [Thread-1242] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:32,019 [Thread-1242] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:32,019 [Thread-1242] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:32,019 [Thread-1242] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:32,019 [Thread-1242] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:32,019 [Thread-1242] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:32,020 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:32,020 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:32,020 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:05:32,020 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:32,024 [Thread-1242] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:32,024 [Thread-1242] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:32,024 [Thread-1242] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:32,024 [Thread-1242] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:32,024 [Thread-1242] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:32,024 [Thread-1242] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:32,024 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:32,024 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:32,025 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:05:32,025 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:32,027 [Thread-1242] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:32,027 [Thread-1242] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:32,027 [Thread-1242] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:32,028 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:32,028 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:32,028 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:32,028 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:32,028 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:05:32,028 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:32,030 [Thread-1242] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-476802657-172.17.0.5-1585803932030
2020-04-02 05:05:32,034 [Thread-1242] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:05:32,036 [Thread-1242] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:05:32,037 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:32,037 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:32,043 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 402 bytes saved in 0 seconds .
2020-04-02 05:05:32,045 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 402 bytes saved in 0 seconds .
2020-04-02 05:05:32,047 [Thread-1242] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:05:32,049 [Thread-1242] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:32,050 [Thread-1242] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:05:32,050 [Thread-1242] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:32,050 [Thread-1242] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:05:32,056 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803932056,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:32,058 [Thread-1242] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:32,066 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7a37d19e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:32,066 [Thread-1242] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:32,066 [Thread-1242] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:0
2020-04-02 05:05:32,067 [Thread-1242] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:32,068 [Thread-1242] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:32,069 [Thread-1242] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:32,069 [Thread-1242] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:32,070 [Thread-1242] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:32,071 [Thread-1242] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:32,071 [Thread-1242] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:32,072 [Thread-1242] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:32,074 [Thread-1242] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:32,074 [Thread-1242] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:32,075 [Thread-1242] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:05:32,075 [Thread-1242] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:05:32,075 [Thread-1242] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39571
2020-04-02 05:05:32,075 [Thread-1242] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:32,077 [Thread-1242] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1be06df4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:32,077 [Thread-1242] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@90bd0ef{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:32,082 [Thread-1242] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:32,083 [Thread-1242] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:32,084 [Thread-1242] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@732fbc20{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:32,087 [Thread-1242] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@d3e479d(server,h=[],w=[]) for SslContextFactory@270aff65(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/trustKS.jks)
2020-04-02 05:05:32,088 [Thread-1242] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@11de79c4{SSL,[ssl, http/1.1]}{localhost:39571}
2020-04-02 05:05:32,096 [Thread-1242] INFO  server.Server (Server.java:doStart(419)) - Started @18654ms
2020-04-02 05:05:32,104 [Thread-1242] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:32,105 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:32,105 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:32,105 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:32,105 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:32,106 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:32,106 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:32,106 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:32,106 [Thread-1242] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:32,106 [Thread-1242] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:32,106 [Thread-1242] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:32,107 [Thread-1242] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:32,107 [Thread-1242] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:32
2020-04-02 05:05:32,107 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:32,107 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:32,107 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:05:32,107 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:32,122 [Thread-1242] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:32,123 [Thread-1242] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:32,123 [Thread-1242] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:32,123 [Thread-1242] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:32,123 [Thread-1242] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:32,124 [Thread-1242] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:32,124 [Thread-1242] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:32,124 [Thread-1242] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:32,124 [Thread-1242] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:32,124 [Thread-1242] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:32,124 [Thread-1242] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:32,124 [Thread-1242] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:32,124 [Thread-1242] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:32,124 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:32,125 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:32,125 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:05:32,125 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:32,132 [Thread-1242] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:32,132 [Thread-1242] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:32,132 [Thread-1242] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:32,132 [Thread-1242] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:32,132 [Thread-1242] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:32,132 [Thread-1242] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:32,132 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:32,132 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:32,133 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:05:32,133 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:32,135 [Thread-1242] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:32,136 [Thread-1242] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:32,136 [Thread-1242] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:32,136 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:32,136 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:32,136 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:32,136 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:32,136 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:05:32,136 [Thread-1242] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:32,139 [Thread-1242] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:32,140 [Thread-1242] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 7679@e6c12bc9d8d5
2020-04-02 05:05:32,141 [Thread-1242] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:05:32,142 [Thread-1242] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:05:32,142 [Thread-1242] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:05:32,142 [Thread-1242] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:32,143 [Thread-1242] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:32,144 [Thread-1242] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:32,144 [Thread-1242] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:32,144 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:32,145 [Thread-1242] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:05:32,158 [Thread-1242] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:32,158 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 20 msecs
2020-04-02 05:05:32,158 [Thread-1242] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:05:32,159 [Thread-1242] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:32,159 [Socket Reader #1 for port 39304] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39304
2020-04-02 05:05:32,164 [Thread-1242] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:39304 to access this namenode/service.
2020-04-02 05:05:32,164 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:32,187 [Thread-1242] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:32,189 [Thread-1242] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:32,189 [Thread-1242] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:05:32,189 [Thread-1242] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:05:32,198 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@10e29d1c] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:05:32,199 [Thread-1242] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:32,202 [Thread-1242] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:32,206 [Thread[Thread-1269,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:05:32,206 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:32,208 [Thread[Thread-1269,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:32,208 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:32,209 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:32,209 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:32,209 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:32,209 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 20 msec
2020-04-02 05:05:32,211 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:32,211 [IPC Server listener on 39304] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39304: starting
2020-04-02 05:05:32,370 [Thread-1242] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:39304
2020-04-02 05:05:32,370 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:32,370 [Thread-1242] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:32,371 [Thread-1242] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:32,371 [Thread-1242] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 39304 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:32,379 [Thread-1242] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:32,383 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803932383,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:32,384 [Thread-1242] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:32,387 [Thread-1242] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:32,388 [CacheReplicationMonitor(237104059)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:32,407 [Thread-1242] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:32,411 [Thread-1242] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:32,413 [Thread-1242] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:32,414 [Thread-1242] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:32,414 [Thread-1242] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:32,414 [Thread-1242] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:32,414 [Thread-1242] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:32,414 [Thread-1242] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:05:32,415 [Thread-1242] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:05:32,415 [Thread-1242] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 39304 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:32,415 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:32,415 [Thread[Thread-1269,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:05:32,415 [Thread-1242] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 3
2020-04-02 05:05:32,415 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@2452185a] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:05:32,415 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@2959464] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:05:32,416 [Thread-1242] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 4 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 1 1 
2020-04-02 05:05:32,416 [Thread-1242] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000004
2020-04-02 05:05:32,417 [Thread-1242] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000004
2020-04-02 05:05:32,417 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:05:32,417 [CacheReplicationMonitor(237104059)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:05:32,419 [Thread-1242] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39304
2020-04-02 05:05:32,422 [IPC Server listener on 39304] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39304
2020-04-02 05:05:32,422 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:05:32,422 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:32,422 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:05:32,434 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:32,434 [Thread-1242] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:05:32,435 [Thread-1242] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@732fbc20{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:05:32,436 [Thread-1242] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@11de79c4{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:05:32,436 [Thread-1242] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@90bd0ef{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:32,436 [Thread-1242] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1be06df4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
[msx] test Finished org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testDataNodeAbortsIfNoSasl
[msx] writeFile testName = org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer#testDataNodeAbortsIfNoSasl
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:05:32,442 [main] INFO  impl.DefaultInternalKdcServerImpl (DefaultInternalKdcServerImpl.java:doStop(102)) - Default Internal kdc server stopped.
2020-04-02 05:05:33,442 [main] INFO  minikdc.MiniKdc (MiniKdc.java:stop(359)) - MiniKdc stopped.
[msx] all testRunFinished

[msx] before_class
2020-04-02 05:03:41,266 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=4, numDataNodes=4
2020-04-02 05:03:41,298 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(874)) - MiniDFSCluster disabling checkpointing in the Standby node since no HTTP ports have been specified.
2020-04-02 05:03:41,298 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(880)) - MiniDFSCluster disabling log-roll triggering in the Standby node since no IPC ports have been specified.
Formatting using clusterid: testClusterID
2020-04-02 05:03:42,419 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:42,451 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:42,453 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:42,455 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:42,470 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:42,471 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:42,471 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:42,477 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns0
2020-04-02 05:03:42,477 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:42,555 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:42,563 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:03:42,565 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:42,565 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:42,578 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:42,579 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:42
2020-04-02 05:03:42,582 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:42,583 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:42,585 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:03:42,586 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:42,607 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:42,625 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:42,626 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:42,627 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:42,627 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:42,627 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:42,628 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:42,628 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:42,628 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:42,628 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:42,629 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:42,629 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:42,697 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:03:42,716 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:42,717 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:42,718 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:03:42,718 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:42,724 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:42,724 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:42,725 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:42,726 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:42,732 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:42,736 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:42,743 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:42,743 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:42,744 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:03:42,745 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:42,758 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:42,759 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:42,760 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:42,766 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:42,767 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:42,770 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:42,771 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:42,772 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:03:42,772 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:42,821 [JUnit] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:42,837 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:03:42,840 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:03:42,843 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1 has been successfully formatted.
2020-04-02 05:03:42,858 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:03:42,859 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:03:43,019 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 388 bytes saved in 0 seconds .
2020-04-02 05:03:43,030 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 388 bytes saved in 0 seconds .
2020-04-02 05:03:43,052 [JUnit] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:03:43,178 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1263)) - Copying namedir from primary node dir file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3
2020-04-02 05:03:43,201 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1263)) - Copying namedir from primary node dir file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-4
2020-04-02 05:03:43,212 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:03:43,917 [JUnit] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:03:44,032 [JUnit] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:03:44,149 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:03:44,150 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:03:44,156 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:03:44,159 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-04-02 05:03:44,160 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use ns0 to access this namenode/service.
2020-04-02 05:03:44,272 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5a59ca5e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:44,293 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:03:44,316 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @4759ms
2020-04-02 05:03:44,457 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:44,462 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:03:44,471 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:44,474 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:03:44,475 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:44,475 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:44,508 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:44,508 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:44,519 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43416
2020-04-02 05:03:44,522 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:44,580 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7b7fdc8{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:44,581 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6a57ae10{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:44,712 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@73d983ea{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:03:44,721 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@d771cc9{HTTP/1.1,[http/1.1]}{localhost:43416}
2020-04-02 05:03:44,722 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5165ms
2020-04-02 05:03:44,761 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:44,762 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:44,763 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:44,763 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:44,763 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:44,764 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:44,764 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:44,765 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns0
2020-04-02 05:03:44,765 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:44,766 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:44,766 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:44,767 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:44,768 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:44,768 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:44
2020-04-02 05:03:44,768 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:44,769 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:44,769 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:44,769 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:44,777 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:44,779 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:44,780 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:44,780 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:44,781 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:44,781 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:44,781 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:44,781 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:44,782 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:44,782 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:44,782 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:44,783 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:44,783 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:44,786 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:44,786 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:44,787 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:44,789 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:44,790 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:44,790 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:44,790 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:44,791 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:44,791 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:44,791 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:44,791 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:44,792 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:44,792 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:44,796 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:44,796 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:44,797 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:44,797 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:44,797 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:44,798 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:44,798 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:44,799 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:44,799 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:44,805 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 4700@1d8aaf8ece6d
2020-04-02 05:03:44,808 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 4700@1d8aaf8ece6d
2020-04-02 05:03:44,809 [JUnit] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1
2020-04-02 05:03:44,813 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:03:44,813 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:03:44,859 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:03:44,868 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:03:44,869 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:03:44,876 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-04-02 05:03:44,877 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:03:44,877 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 76 msecs
2020-04-02 05:03:45,110 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to 0.0.0.0:0
2020-04-02 05:03:45,128 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:45,150 [Socket Reader #1 for port 46349] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46349
2020-04-02 05:03:45,567 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:03:45,660 [JUnit] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:03:45,685 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:03:45,685 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:03:45,686 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:03:45,856 [JUnit] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:46349
2020-04-02 05:03:45,862 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1376)) - Starting services required for standby state
2020-04-02 05:03:45,864 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-04-02 05:03:45,864 [JUnit] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(189)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-04-02 05:03:45,866 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 46349 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:45,869 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:03:45,869 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:03:45,869 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:03:45,902 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-04-02 05:03:45,903 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use ns0 to access this namenode/service.
2020-04-02 05:03:45,838 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:45,839 [IPC Server listener on 46349] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46349: starting
2020-04-02 05:03:45,962 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:03:45,963 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1698fc68] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:45,967 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:45,968 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:03:45,970 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:45,972 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:03:45,972 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:45,972 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:45,997 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:45,997 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:46,002 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39034
2020-04-02 05:03:46,003 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:46,020 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2b5825fa{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:46,021 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2cae1042{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:46,039 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1f2f9244{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:03:46,042 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4c4d27c8{HTTP/1.1,[http/1.1]}{localhost:39034}
2020-04-02 05:03:46,050 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @6492ms
2020-04-02 05:03:46,064 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:46,065 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:46,066 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:46,066 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:46,066 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:46,066 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:46,066 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:46,067 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns0
2020-04-02 05:03:46,102 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:46,103 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:46,104 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:46,104 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:46,104 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:46,105 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:46
2020-04-02 05:03:46,105 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:46,119 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:46,138 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:46,139 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:46,169 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:46,171 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:46,172 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:46,172 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:46,173 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:46,173 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:46,173 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:46,174 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:46,174 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:46,174 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:46,174 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:46,175 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:46,175 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:46,175 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:46,176 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:46,176 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:46,182 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:46,183 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:46,183 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:46,184 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:46,184 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:46,184 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:46,185 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:46,185 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:46,186 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:46,187 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:46,189 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:46,189 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:46,189 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:46,190 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:46,190 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:46,191 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:46,191 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:46,192 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:46,192 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:46,198 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/in_use.lock acquired by nodename 4700@1d8aaf8ece6d
2020-04-02 05:03:46,221 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-4/in_use.lock acquired by nodename 4700@1d8aaf8ece6d
2020-04-02 05:03:46,223 [JUnit] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1
2020-04-02 05:03:46,226 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:03:46,227 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:03:46,229 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:03:46,239 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:03:46,241 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000
2020-04-02 05:03:46,241 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-04-02 05:03:46,242 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:03:46,242 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 47 msecs
2020-04-02 05:03:46,243 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to 0.0.0.0:0
2020-04-02 05:03:46,243 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:46,262 [Socket Reader #1 for port 37631] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37631
2020-04-02 05:03:46,273 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:03:46,375 [JUnit] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:03:46,382 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:03:46,383 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:03:46,383 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:03:46,398 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:46,399 [IPC Server listener on 37631] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37631: starting
2020-04-02 05:03:46,404 [JUnit] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:37631
2020-04-02 05:03:46,405 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1376)) - Starting services required for standby state
2020-04-02 05:03:46,405 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-04-02 05:03:46,406 [JUnit] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(189)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-04-02 05:03:46,419 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 37631 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
Formatting using clusterid: testClusterID
2020-04-02 05:03:46,428 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:46,429 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:46,429 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:46,429 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:46,454 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:46,454 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:46,454 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:46,455 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns1
2020-04-02 05:03:46,455 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:46,456 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:46,456 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:46,458 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:46,458 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:46,459 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:46
2020-04-02 05:03:46,462 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:46,463 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:46,463 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:46,463 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:46,489 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:46,523 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:46,524 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:46,524 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:46,538 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:46,539 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:46,539 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:46,539 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:46,539 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:46,540 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:46,540 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:46,540 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:46,540 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:46,541 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:46,541 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:46,541 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:46,556 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:46,556 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:46,557 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:46,557 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:46,560 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:46,561 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:46,561 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:46,561 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:46,562 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:46,562 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:46,573 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:46,573 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:46,574 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:46,574 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:46,574 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:46,575 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:46,579 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:46,580 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:46,580 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:46,583 [JUnit] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:46,591 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 has been successfully formatted.
2020-04-02 05:03:46,598 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 has been successfully formatted.
2020-04-02 05:03:46,609 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3 has been successfully formatted.
2020-04-02 05:03:46,619 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:03:46,622 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:03:46,626 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:03:46,637 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:03:46,652 [JUnit] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:03:46,654 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1263)) - Copying namedir from primary node dir file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 to file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7
2020-04-02 05:03:46,658 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1263)) - Copying namedir from primary node dir file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 to file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-8
2020-04-02 05:03:46,665 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:03:46,665 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:03:46,665 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:03:46,666 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-04-02 05:03:46,666 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use ns1 to access this namenode/service.
2020-04-02 05:03:46,673 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:03:46,676 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:46,677 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:03:46,683 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@fd8294b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:46,684 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:46,685 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:03:46,685 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:46,686 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:46,730 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:46,730 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:46,739 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 36020
2020-04-02 05:03:46,739 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:46,744 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@75c9e76b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:46,745 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5c3b6c6e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:46,775 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6b9ce1bf{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:03:46,777 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@61884cb1{HTTP/1.1,[http/1.1]}{localhost:36020}
2020-04-02 05:03:46,778 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @7220ms
2020-04-02 05:03:46,779 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:46,779 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:46,780 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:46,780 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:46,780 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:46,780 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:46,780 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:46,780 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns1
2020-04-02 05:03:46,781 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:46,781 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:46,781 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:46,782 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:46,785 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:46,785 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:46
2020-04-02 05:03:46,785 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:46,785 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:46,823 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:46,824 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:46,841 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:46,843 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:46,843 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:46,844 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:46,848 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:46,856 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:46,856 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:46,857 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:46,857 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:46,857 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:46,857 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:46,859 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:46,860 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:46,860 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:46,860 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:46,861 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:46,870 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:46,870 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:46,871 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:46,872 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:46,873 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:46,873 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:46,873 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:46,873 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:46,874 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:46,874 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:46,876 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:46,877 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:46,877 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:46,877 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:46,879 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:46,879 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:46,879 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:46,880 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:46,880 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:46,886 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/in_use.lock acquired by nodename 4700@1d8aaf8ece6d
2020-04-02 05:03:46,894 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/in_use.lock acquired by nodename 4700@1d8aaf8ece6d
2020-04-02 05:03:46,895 [JUnit] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3
2020-04-02 05:03:46,902 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:03:46,903 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:03:46,905 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:03:46,909 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:03:46,910 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage_0000000000000000000
2020-04-02 05:03:46,910 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-04-02 05:03:46,911 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:03:46,911 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 27 msecs
2020-04-02 05:03:46,912 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to 0.0.0.0:0
2020-04-02 05:03:46,912 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:46,918 [Socket Reader #1 for port 35176] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35176
2020-04-02 05:03:46,928 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:03:47,041 [JUnit] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:03:47,046 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:03:47,046 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:03:47,047 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:03:47,080 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:47,090 [IPC Server listener on 35176] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35176: starting
2020-04-02 05:03:47,141 [JUnit] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:35176
2020-04-02 05:03:47,142 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1376)) - Starting services required for standby state
2020-04-02 05:03:47,142 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-04-02 05:03:47,143 [JUnit] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(189)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-04-02 05:03:47,143 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 35176 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:47,145 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:03:47,145 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:03:47,168 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:03:47,168 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-04-02 05:03:47,174 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use ns1 to access this namenode/service.
2020-04-02 05:03:47,206 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:03:47,230 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@285c08c8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:47,230 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:47,234 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:03:47,236 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:47,239 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:03:47,239 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:47,241 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:47,244 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:47,244 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:47,245 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38815
2020-04-02 05:03:47,245 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:47,269 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2ece4966{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:47,271 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7894f09b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:47,303 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@30f5a68a{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:03:47,305 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1e1d3956{HTTP/1.1,[http/1.1]}{localhost:38815}
2020-04-02 05:03:47,305 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @7748ms
2020-04-02 05:03:47,323 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:47,350 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:47,351 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:47,351 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:47,351 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:47,351 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:47,352 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:47,353 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns1
2020-04-02 05:03:47,354 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:47,354 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:47,355 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:47,355 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:47,355 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:47,356 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:47
2020-04-02 05:03:47,362 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:47,362 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:47,362 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:47,363 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:47,399 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:47,400 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:47,401 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:47,401 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:47,401 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:47,401 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:47,401 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:47,401 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:47,402 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:47,402 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:47,402 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:47,403 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:47,403 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:47,403 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:47,404 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:47,404 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:47,411 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:47,411 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:47,411 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:47,411 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:47,412 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:47,412 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:47,412 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:47,412 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:47,413 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:47,413 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:47,416 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:47,416 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:47,417 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:47,417 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:47,417 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:47,418 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:47,418 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:47,418 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:47,418 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:47,423 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/in_use.lock acquired by nodename 4700@1d8aaf8ece6d
2020-04-02 05:03:47,430 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-8/in_use.lock acquired by nodename 4700@1d8aaf8ece6d
2020-04-02 05:03:47,431 [JUnit] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3
2020-04-02 05:03:47,433 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:03:47,434 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:03:47,435 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:03:47,436 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:03:47,437 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/current/fsimage_0000000000000000000
2020-04-02 05:03:47,437 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-04-02 05:03:47,437 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:03:47,437 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 17 msecs
2020-04-02 05:03:47,450 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to 0.0.0.0:0
2020-04-02 05:03:47,451 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:47,458 [Socket Reader #1 for port 35597] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35597
2020-04-02 05:03:47,485 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:03:47,930 [JUnit] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:03:47,954 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:03:47,954 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:03:47,954 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:03:47,962 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:47,963 [IPC Server listener on 35597] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35597: starting
2020-04-02 05:03:47,974 [JUnit] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:35597
2020-04-02 05:03:47,975 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1376)) - Starting services required for standby state
2020-04-02 05:03:47,975 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-04-02 05:03:47,975 [JUnit] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(189)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-04-02 05:03:47,976 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 35597 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:48,018 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:48,084 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:48,118 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:48,150 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:48,151 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:48,157 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:48,161 [JUnit] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:48,169 [JUnit] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:48,171 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:48,176 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:48,184 [JUnit] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:33839
2020-04-02 05:03:48,187 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:48,187 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:48,236 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:48,242 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:48,252 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:48,253 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:48,254 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:48,255 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:48,265 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33895
2020-04-02 05:03:48,265 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:48,269 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@38f57b3d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:48,270 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3ce3db41{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:48,295 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1d7f7be7{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:48,304 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@42f3156d{HTTP/1.1,[http/1.1]}{localhost:33895}
2020-04-02 05:03:48,305 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @8748ms
2020-04-02 05:03:49,718 [JUnit] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46757
2020-04-02 05:03:49,727 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:49,727 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:49,742 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6928f576] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:49,759 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:49,760 [Socket Reader #1 for port 38342] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38342
2020-04-02 05:03:49,785 [JUnit] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:38342
2020-04-02 05:03:49,803 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-04-02 05:03:49,806 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-04-02 05:03:49,823 [Thread-153] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46349 starting to offer service
2020-04-02 05:03:49,831 [Thread-154] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37631 starting to offer service
2020-04-02 05:03:49,848 [Thread-155] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35176 starting to offer service
2020-04-02 05:03:49,855 [Thread-156] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35597 starting to offer service
2020-04-02 05:03:49,882 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:49,885 [IPC Server listener on 38342] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38342: starting
2020-04-02 05:03:49,908 [JUnit] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 38342 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:49,910 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:49,914 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:49,918 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:49,920 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:49,936 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:49,937 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:49,937 [JUnit] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:49,937 [JUnit] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:49,938 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:49,938 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:49,939 [JUnit] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:45284
2020-04-02 05:03:49,939 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:49,939 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:49,959 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:49,966 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:49,968 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:49,969 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:49,969 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:49,969 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:49,971 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38218
2020-04-02 05:03:49,971 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:49,973 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@466cf502{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:49,981 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2e185cd7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:50,050 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4b629f13{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:50,051 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@70925b45{HTTP/1.1,[http/1.1]}{localhost:38218}
2020-04-02 05:03:50,052 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @10494ms
2020-04-02 05:03:50,233 [JUnit] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44818
2020-04-02 05:03:50,238 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@aa22f1c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:50,270 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:50,270 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:50,282 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:50,344 [Socket Reader #1 for port 37055] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37055
2020-04-02 05:03:50,362 [JUnit] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:37055
2020-04-02 05:03:50,405 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-04-02 05:03:50,413 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-04-02 05:03:50,437 [JUnit] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 37055 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:50,438 [IPC Server listener on 37055] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37055: starting
2020-04-02 05:03:50,438 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:50,475 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:50,477 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:50,474 [Thread-183] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46349 starting to offer service
2020-04-02 05:03:50,462 [Thread-184] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37631 starting to offer service
2020-04-02 05:03:50,462 [Thread-186] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35597 starting to offer service
2020-04-02 05:03:50,462 [Thread-185] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35176 starting to offer service
2020-04-02 05:03:50,486 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:50,494 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:50,518 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:50,524 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:50,524 [JUnit] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:50,525 [JUnit] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:50,525 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:50,525 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:50,527 [JUnit] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:45081
2020-04-02 05:03:50,527 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:50,527 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:50,532 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:50,534 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:50,536 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:50,537 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:50,537 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:50,537 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:50,543 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38573
2020-04-02 05:03:50,544 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:50,547 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@681aad3b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:50,551 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2427e004{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:50,578 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@486be205{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:50,580 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@f713686{HTTP/1.1,[http/1.1]}{localhost:38573}
2020-04-02 05:03:50,614 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @11056ms
2020-04-02 05:03:50,696 [JUnit] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43769
2020-04-02 05:03:50,696 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:50,697 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:50,697 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:50,698 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4b4dd216] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:50,710 [Socket Reader #1 for port 36669] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36669
2020-04-02 05:03:50,731 [JUnit] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:36669
2020-04-02 05:03:50,776 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-04-02 05:03:50,776 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-04-02 05:03:50,786 [Thread-209] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46349 starting to offer service
2020-04-02 05:03:50,790 [Thread-210] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37631 starting to offer service
2020-04-02 05:03:50,814 [Thread-211] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35176 starting to offer service
2020-04-02 05:03:50,815 [Thread-212] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35597 starting to offer service
2020-04-02 05:03:50,822 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:50,822 [IPC Server listener on 36669] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36669: starting
2020-04-02 05:03:50,824 [JUnit] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 36669 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:50,825 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:50,827 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:50,835 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:50,869 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:50,870 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:50,870 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:50,870 [JUnit] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:50,873 [JUnit] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:50,873 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:50,873 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:50,874 [JUnit] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:41106
2020-04-02 05:03:50,874 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:50,875 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:50,895 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:50,899 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:50,900 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:50,901 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:50,901 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:50,904 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:50,905 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38163
2020-04-02 05:03:50,905 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:50,908 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@21a5fd96{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:50,909 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5c77053b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:50,993 [Thread-209] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:50,998 [Thread-156] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:50,999 [Thread-185] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:50,999 [Thread-156] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 4700@1d8aaf8ece6d
2020-04-02 05:03:51,000 [Thread-156] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 is not formatted for namespace 638608623. Formatting...
2020-04-02 05:03:51,001 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@40f33492{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:51,002 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4fbdc0f0{HTTP/1.1,[http/1.1]}{localhost:38163}
2020-04-02 05:03:51,002 [Thread-156] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-90599705-ceb0-48a2-8083-2c6b6280bd4b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 
2020-04-02 05:03:51,002 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @11445ms
2020-04-02 05:03:51,005 [Thread-209] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 4700@1d8aaf8ece6d
2020-04-02 05:03:51,026 [Thread-209] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 is not formatted for namespace 30846779. Formatting...
2020-04-02 05:03:51,026 [Thread-209] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-22156fcf-6c04-460f-a478-efbd7b0cfc97 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 
2020-04-02 05:03:51,006 [Thread-185] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 4700@1d8aaf8ece6d
2020-04-02 05:03:51,027 [Thread-185] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 is not formatted for namespace 638608623. Formatting...
2020-04-02 05:03:51,027 [Thread-185] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ede8edd0-5de5-4e02-9ddd-7561e4eadf59 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 
2020-04-02 05:03:51,030 [Thread-156] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 4700@1d8aaf8ece6d
2020-04-02 05:03:51,030 [Thread-156] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 is not formatted for namespace 638608623. Formatting...
2020-04-02 05:03:51,031 [Thread-156] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b6cc6c14-c015-45c1-b2b6-a7fbd9456e9e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 
2020-04-02 05:03:51,041 [Thread-185] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 4700@1d8aaf8ece6d
2020-04-02 05:03:51,041 [Thread-185] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 is not formatted for namespace 638608623. Formatting...
2020-04-02 05:03:51,042 [Thread-185] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d2d44c79-d51a-414b-a564-efaee6e2dfb5 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 
2020-04-02 05:03:51,049 [Thread-209] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 4700@1d8aaf8ece6d
2020-04-02 05:03:51,050 [Thread-209] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 is not formatted for namespace 30846779. Formatting...
2020-04-02 05:03:51,050 [Thread-209] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-02748c20-2ca5-4730-a651-f95813f8cec5 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 
2020-04-02 05:03:51,155 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:51,156 [Thread-209] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:51,156 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-2016245141-172.17.0.9-1585803822804 is not formatted. Formatting ...
2020-04-02 05:03:51,157 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2016245141-172.17.0.9-1585803822804 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-2016245141-172.17.0.9-1585803822804/current
2020-04-02 05:03:51,161 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:51,163 [Thread-156] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:51,163 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-1514103897-172.17.0.9-1585803826583 is not formatted. Formatting ...
2020-04-02 05:03:51,163 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1514103897-172.17.0.9-1585803826583 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1514103897-172.17.0.9-1585803826583/current
2020-04-02 05:03:51,187 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:51,188 [Thread-185] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:51,188 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-1514103897-172.17.0.9-1585803826583 is not formatted. Formatting ...
2020-04-02 05:03:51,188 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1514103897-172.17.0.9-1585803826583 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1514103897-172.17.0.9-1585803826583/current
2020-04-02 05:03:51,193 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:51,198 [JUnit] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45936
2020-04-02 05:03:51,200 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:51,200 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:51,201 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:51,198 [Thread-209] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:51,202 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-2016245141-172.17.0.9-1585803822804 is not formatted. Formatting ...
2020-04-02 05:03:51,202 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2016245141-172.17.0.9-1585803822804 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-2016245141-172.17.0.9-1585803822804/current
2020-04-02 05:03:51,200 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:51,203 [Thread-156] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:51,204 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-1514103897-172.17.0.9-1585803826583 is not formatted. Formatting ...
2020-04-02 05:03:51,204 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1514103897-172.17.0.9-1585803826583 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1514103897-172.17.0.9-1585803826583/current
2020-04-02 05:03:51,200 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6bc28a83] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:51,211 [Socket Reader #1 for port 32843] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 32843
2020-04-02 05:03:51,244 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:51,245 [Thread-185] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:51,245 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-1514103897-172.17.0.9-1585803826583 is not formatted. Formatting ...
2020-04-02 05:03:51,245 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1514103897-172.17.0.9-1585803826583 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1514103897-172.17.0.9-1585803826583/current
2020-04-02 05:03:51,259 [JUnit] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:32843
2020-04-02 05:03:51,254 [Thread-153] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:51,260 [Thread-153] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 has already been used.
2020-04-02 05:03:51,260 [Thread-153] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 has already been used.
2020-04-02 05:03:51,250 [Thread-211] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:51,265 [Thread-209] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=30846779;bpid=BP-2016245141-172.17.0.9-1585803822804;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=30846779;c=1585803822804;bpid=BP-2016245141-172.17.0.9-1585803822804;dnuuid=null
2020-04-02 05:03:51,266 [Thread-185] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=638608623;bpid=BP-1514103897-172.17.0.9-1585803826583;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=638608623;c=1585803826583;bpid=BP-1514103897-172.17.0.9-1585803826583;dnuuid=null
2020-04-02 05:03:51,271 [Thread-211] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 has already been used.
2020-04-02 05:03:51,271 [Thread-211] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 has already been used.
2020-04-02 05:03:51,274 [Thread-156] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=638608623;bpid=BP-1514103897-172.17.0.9-1585803826583;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=638608623;c=1585803826583;bpid=BP-1514103897-172.17.0.9-1585803826583;dnuuid=null
2020-04-02 05:03:51,275 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:51,276 [Thread-153] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:51,276 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-2016245141-172.17.0.9-1585803822804 is not formatted. Formatting ...
2020-04-02 05:03:51,276 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2016245141-172.17.0.9-1585803822804 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-2016245141-172.17.0.9-1585803822804/current
2020-04-02 05:03:51,277 [Thread-184] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:51,278 [Thread-184] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 has already been used.
2020-04-02 05:03:51,278 [Thread-184] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 has already been used.
2020-04-02 05:03:51,291 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-04-02 05:03:51,292 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-04-02 05:03:51,296 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:51,296 [Thread-211] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:51,297 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-1514103897-172.17.0.9-1585803826583 is not formatted. Formatting ...
2020-04-02 05:03:51,297 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1514103897-172.17.0.9-1585803826583 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1514103897-172.17.0.9-1585803826583/current
2020-04-02 05:03:51,302 [Thread-235] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46349 starting to offer service
2020-04-02 05:03:51,307 [Thread-236] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37631 starting to offer service
2020-04-02 05:03:51,310 [Thread-237] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35176 starting to offer service
2020-04-02 05:03:51,310 [Thread-238] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35597 starting to offer service
2020-04-02 05:03:51,311 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:51,312 [IPC Server listener on 32843] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 32843: starting
2020-04-02 05:03:51,321 [JUnit] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 32843 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:51,328 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:51,329 [Thread-153] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:51,329 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-2016245141-172.17.0.9-1585803822804 is not formatted. Formatting ...
2020-04-02 05:03:51,329 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2016245141-172.17.0.9-1585803822804 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-2016245141-172.17.0.9-1585803822804/current
2020-04-02 05:03:51,336 [Thread-153] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=30846779;bpid=BP-2016245141-172.17.0.9-1585803822804;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=30846779;c=1585803822804;bpid=BP-2016245141-172.17.0.9-1585803822804;dnuuid=null
2020-04-02 05:03:51,337 [Thread-153] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 37c34b0d-ec3f-4635-b93e-4c5b1348268e
2020-04-02 05:03:51,406 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:51,406 [Thread-211] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:51,407 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-1514103897-172.17.0.9-1585803826583 is not formatted. Formatting ...
2020-04-02 05:03:51,407 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1514103897-172.17.0.9-1585803826583 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1514103897-172.17.0.9-1585803826583/current
2020-04-02 05:03:51,419 [Thread-211] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=638608623;bpid=BP-1514103897-172.17.0.9-1585803826583;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=638608623;c=1585803826583;bpid=BP-1514103897-172.17.0.9-1585803826583;dnuuid=null
2020-04-02 05:03:51,424 [Thread-211] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID be3e34c4-4a49-4457-8d5c-a1340f40b0a6
2020-04-02 05:03:51,433 [Thread-184] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:51,462 [Thread-184] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:51,462 [Thread-184] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-2016245141-172.17.0.9-1585803822804 is not formatted. Formatting ...
2020-04-02 05:03:51,462 [Thread-184] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2016245141-172.17.0.9-1585803822804 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-2016245141-172.17.0.9-1585803822804/current
2020-04-02 05:03:51,482 [Thread-236] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:51,486 [Thread-184] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:51,487 [Thread-184] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:51,487 [Thread-184] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-2016245141-172.17.0.9-1585803822804 is not formatted. Formatting ...
2020-04-02 05:03:51,490 [Thread-236] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 4700@1d8aaf8ece6d
2020-04-02 05:03:51,490 [Thread-236] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 is not formatted for namespace 30846779. Formatting...
2020-04-02 05:03:51,490 [Thread-236] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b04f45b7-2efa-4c1e-bd57-402c44bbd21f for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 
2020-04-02 05:03:51,490 [Thread-184] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2016245141-172.17.0.9-1585803822804 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-2016245141-172.17.0.9-1585803822804/current
2020-04-02 05:03:51,534 [Thread-184] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=30846779;bpid=BP-2016245141-172.17.0.9-1585803822804;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=30846779;c=1585803822804;bpid=BP-2016245141-172.17.0.9-1585803822804;dnuuid=null
2020-04-02 05:03:51,538 [Thread-185] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82
2020-04-02 05:03:51,546 [Thread-236] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 4700@1d8aaf8ece6d
2020-04-02 05:03:51,547 [Thread-236] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 is not formatted for namespace 30846779. Formatting...
2020-04-02 05:03:51,547 [Thread-236] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-009ae7d5-6bbd-4558-89d3-f7832539d9ec for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 
2020-04-02 05:03:51,579 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:51,579 [Thread-236] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:51,579 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-2016245141-172.17.0.9-1585803822804 is not formatted. Formatting ...
2020-04-02 05:03:51,580 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2016245141-172.17.0.9-1585803822804 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-2016245141-172.17.0.9-1585803822804/current
2020-04-02 05:03:51,606 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:51,610 [Thread-236] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:51,610 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-2016245141-172.17.0.9-1585803822804 is not formatted. Formatting ...
2020-04-02 05:03:51,610 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2016245141-172.17.0.9-1585803822804 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-2016245141-172.17.0.9-1585803822804/current
2020-04-02 05:03:51,619 [Thread-237] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:51,619 [Thread-237] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 has already been used.
2020-04-02 05:03:51,619 [Thread-237] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 has already been used.
2020-04-02 05:03:51,619 [Thread-236] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=30846779;bpid=BP-2016245141-172.17.0.9-1585803822804;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=30846779;c=1585803822804;bpid=BP-2016245141-172.17.0.9-1585803822804;dnuuid=null
2020-04-02 05:03:51,636 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:51,636 [Thread-237] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:51,636 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-1514103897-172.17.0.9-1585803826583 is not formatted. Formatting ...
2020-04-02 05:03:51,637 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1514103897-172.17.0.9-1585803826583 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1514103897-172.17.0.9-1585803826583/current
2020-04-02 05:03:51,652 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:51,653 [Thread-237] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:51,654 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-1514103897-172.17.0.9-1585803826583 is not formatted. Formatting ...
2020-04-02 05:03:51,654 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1514103897-172.17.0.9-1585803826583 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1514103897-172.17.0.9-1585803826583/current
2020-04-02 05:03:51,656 [Thread-237] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=638608623;bpid=BP-1514103897-172.17.0.9-1585803826583;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=638608623;c=1585803826583;bpid=BP-1514103897-172.17.0.9-1585803826583;dnuuid=null
2020-04-02 05:03:51,662 [Thread-236] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 1d462b81-d264-4460-97f6-685a3cb75138
2020-04-02 05:03:51,794 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-b04f45b7-2efa-4c1e-bd57-402c44bbd21f
2020-04-02 05:03:51,794 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:03:51,796 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-009ae7d5-6bbd-4558-89d3-f7832539d9ec
2020-04-02 05:03:51,796 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:03:51,871 [Thread-185] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-ede8edd0-5de5-4e02-9ddd-7561e4eadf59
2020-04-02 05:03:51,878 [Thread-185] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:03:51,880 [Thread-185] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-d2d44c79-d51a-414b-a564-efaee6e2dfb5
2020-04-02 05:03:51,881 [Thread-185] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:03:51,883 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-90599705-ceb0-48a2-8083-2c6b6280bd4b
2020-04-02 05:03:51,883 [Thread-153] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:03:51,889 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-22156fcf-6c04-460f-a478-efbd7b0cfc97
2020-04-02 05:03:51,889 [Thread-211] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:03:51,891 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-02748c20-2ca5-4730-a651-f95813f8cec5
2020-04-02 05:03:51,892 [Thread-211] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:03:51,899 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-b6cc6c14-c015-45c1-b2b6-a7fbd9456e9e
2020-04-02 05:03:51,899 [Thread-153] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:03:51,905 [Thread-185] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:51,913 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:51,914 [Thread-184] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:51,913 [Thread-211] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:51,913 [Thread-153] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:51,935 [Thread-258] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-04-02 05:03:51,935 [Thread-257] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-04-02 05:03:51,913 [Thread-185] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:51,944 [Thread-153] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:51,945 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:51,945 [Thread-236] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:51,945 [Thread-156] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:51,959 [Thread-211] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:51,961 [Thread-209] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:51,978 [Thread-261] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-04-02 05:03:51,978 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-04-02 05:03:52,007 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-04-02 05:03:52,010 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-04-02 05:03:52,058 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-04-02 05:03:52,058 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-04-02 05:03:52,084 [Thread-153] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:52,103 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:52,104 [Thread-185] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:52,105 [Thread-185] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:52,105 [Thread-185] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:52,105 [Thread-153] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:52,105 [Thread-153] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:52,106 [Thread-211] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:52,106 [Thread-211] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:52,106 [Thread-211] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:52,105 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:52,107 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:52,290 [Thread-185] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:52,290 [Thread-211] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:52,317 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:52,334 [Thread-153] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:52,370 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2016245141-172.17.0.9-1585803822804 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 356ms
2020-04-02 05:03:52,375 [Thread-261] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2016245141-172.17.0.9-1585803822804 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 398ms
2020-04-02 05:03:52,376 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1514103897-172.17.0.9-1585803826583 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 310ms
2020-04-02 05:03:52,451 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1514103897-172.17.0.9-1585803826583 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 392ms
2020-04-02 05:03:52,453 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1514103897-172.17.0.9-1585803826583: 508ms
2020-04-02 05:03:52,459 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2016245141-172.17.0.9-1585803822804 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 459ms
2020-04-02 05:03:52,459 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2016245141-172.17.0.9-1585803822804: 514ms
2020-04-02 05:03:52,464 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-04-02 05:03:52,465 [Thread-275] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-2016245141-172.17.0.9-1585803822804/current/replicas doesn't exist 
2020-04-02 05:03:52,466 [Thread-258] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2016245141-172.17.0.9-1585803822804 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 530ms
2020-04-02 05:03:52,505 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2016245141-172.17.0.9-1585803822804 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 497ms
2020-04-02 05:03:52,515 [Thread-257] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2016245141-172.17.0.9-1585803822804 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 579ms
2020-04-02 05:03:52,516 [Thread-209] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2016245141-172.17.0.9-1585803822804: 554ms
2020-04-02 05:03:52,526 [Thread-278] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-04-02 05:03:52,535 [Thread-274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-04-02 05:03:52,538 [Thread-273] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-04-02 05:03:52,622 [Thread-273] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1514103897-172.17.0.9-1585803826583/current/replicas doesn't exist 
2020-04-02 05:03:52,625 [Thread-276] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-04-02 05:03:52,626 [Thread-276] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-2016245141-172.17.0.9-1585803822804/current/replicas doesn't exist 
2020-04-02 05:03:52,634 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-04-02 05:03:52,634 [Thread-282] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-2016245141-172.17.0.9-1585803822804/current/replicas doesn't exist 
2020-04-02 05:03:52,606 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-04-02 05:03:52,638 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 4ms
2020-04-02 05:03:52,605 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 140ms
2020-04-02 05:03:52,648 [Thread-279] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-04-02 05:03:52,648 [Thread-279] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-2016245141-172.17.0.9-1585803822804/current/replicas doesn't exist 
2020-04-02 05:03:52,602 [Thread-277] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-04-02 05:03:52,596 [Thread-184] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2016245141-172.17.0.9-1585803822804: 662ms
2020-04-02 05:03:52,674 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-04-02 05:03:52,670 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-04-02 05:03:52,662 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-04-02 05:03:52,680 [Thread-281] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1514103897-172.17.0.9-1585803826583/current/replicas doesn't exist 
2020-04-02 05:03:52,650 [Thread-279] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 2ms
2020-04-02 05:03:52,680 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 0ms
2020-04-02 05:03:52,681 [Thread-273] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 59ms
2020-04-02 05:03:52,683 [Thread-209] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2016245141-172.17.0.9-1585803822804: 168ms
2020-04-02 05:03:52,686 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-04-02 05:03:52,686 [Thread-288] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-2016245141-172.17.0.9-1585803822804/current/replicas doesn't exist 
2020-04-02 05:03:52,687 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 1ms
2020-04-02 05:03:52,687 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-04-02 05:03:52,687 [Thread-290] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-2016245141-172.17.0.9-1585803822804/current/replicas doesn't exist 
2020-04-02 05:03:52,688 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 1ms
2020-04-02 05:03:52,690 [Thread-278] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2016245141-172.17.0.9-1585803822804 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 155ms
2020-04-02 05:03:52,698 [Thread-276] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 72ms
2020-04-02 05:03:52,698 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2016245141-172.17.0.9-1585803822804: 239ms
2020-04-02 05:03:52,710 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-04-02 05:03:52,714 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:52,715 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-02748c20-2ca5-4730-a651-f95813f8cec5): finished scanning block pool BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:52,734 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1514103897-172.17.0.9-1585803826583: 278ms
2020-04-02 05:03:52,734 [Thread-184] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2016245141-172.17.0.9-1585803822804: 60ms
2020-04-02 05:03:52,762 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-04-02 05:03:52,777 [Thread-236] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:01 AM with interval of 21600000ms
2020-04-02 05:03:52,790 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-02748c20-2ca5-4730-a651-f95813f8cec5): no suitable block pools found to scan.  Waiting 1814399922 ms.
2020-04-02 05:03:52,854 [Thread-209] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:38 AM with interval of 21600000ms
2020-04-02 05:03:52,845 [Thread-274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2016245141-172.17.0.9-1585803822804 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 309ms
2020-04-02 05:03:52,838 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:52,867 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-90599705-ceb0-48a2-8083-2c6b6280bd4b): finished scanning block pool BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:52,838 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:52,867 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-d2d44c79-d51a-414b-a564-efaee6e2dfb5): finished scanning block pool BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:52,868 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2016245141-172.17.0.9-1585803822804: 410ms
2020-04-02 05:03:52,834 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:52,870 [Thread-307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-04-02 05:03:52,870 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-ede8edd0-5de5-4e02-9ddd-7561e4eadf59): finished scanning block pool BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:52,870 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-04-02 05:03:52,734 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:52,870 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-b04f45b7-2efa-4c1e-bd57-402c44bbd21f): finished scanning block pool BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:52,734 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:52,871 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-009ae7d5-6bbd-4558-89d3-f7832539d9ec): finished scanning block pool BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:52,807 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:52,874 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-b6cc6c14-c015-45c1-b2b6-a7fbd9456e9e): finished scanning block pool BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:52,717 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:52,875 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-22156fcf-6c04-460f-a478-efbd7b0cfc97): finished scanning block pool BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:52,870 [Thread-308] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-2016245141-172.17.0.9-1585803822804/current/replicas doesn't exist 
2020-04-02 05:03:52,870 [Thread-307] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-2016245141-172.17.0.9-1585803822804/current/replicas doesn't exist 
2020-04-02 05:03:52,878 [Thread-307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 9ms
2020-04-02 05:03:52,879 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 9ms
2020-04-02 05:03:52,879 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2016245141-172.17.0.9-1585803822804: 11ms
2020-04-02 05:03:52,806 [Thread-156] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:54 AM with interval of 21600000ms
2020-04-02 05:03:52,807 [Thread-184] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:40 AM with interval of 21600000ms
2020-04-02 05:03:52,931 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-22156fcf-6c04-460f-a478-efbd7b0cfc97): no suitable block pools found to scan.  Waiting 1814399781 ms.
2020-04-02 05:03:52,931 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-009ae7d5-6bbd-4558-89d3-f7832539d9ec): no suitable block pools found to scan.  Waiting 1814399803 ms.
2020-04-02 05:03:52,931 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-ede8edd0-5de5-4e02-9ddd-7561e4eadf59): no suitable block pools found to scan.  Waiting 1814399875 ms.
2020-04-02 05:03:52,932 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-d2d44c79-d51a-414b-a564-efaee6e2dfb5): no suitable block pools found to scan.  Waiting 1814399874 ms.
2020-04-02 05:03:52,932 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:52,932 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-b6cc6c14-c015-45c1-b2b6-a7fbd9456e9e): finished scanning block pool BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:52,933 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-b6cc6c14-c015-45c1-b2b6-a7fbd9456e9e): no suitable block pools found to scan.  Waiting 1814399873 ms.
2020-04-02 05:03:52,931 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-b04f45b7-2efa-4c1e-bd57-402c44bbd21f): no suitable block pools found to scan.  Waiting 1814399803 ms.
2020-04-02 05:03:52,933 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2016245141-172.17.0.9-1585803822804 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:52,934 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-90599705-ceb0-48a2-8083-2c6b6280bd4b): finished scanning block pool BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:03:52,935 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-90599705-ceb0-48a2-8083-2c6b6280bd4b): no suitable block pools found to scan.  Waiting 1814399871 ms.
2020-04-02 05:03:52,935 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid be3e34c4-4a49-4457-8d5c-a1340f40b0a6) service to localhost/127.0.0.1:46349 beginning handshake with NN
2020-04-02 05:03:52,938 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid be3e34c4-4a49-4457-8d5c-a1340f40b0a6) service to localhost/127.0.0.1:37631 beginning handshake with NN
2020-04-02 05:03:52,946 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 1d462b81-d264-4460-97f6-685a3cb75138) service to localhost/127.0.0.1:46349 beginning handshake with NN
2020-04-02 05:03:52,946 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 1d462b81-d264-4460-97f6-685a3cb75138) service to localhost/127.0.0.1:37631 beginning handshake with NN
2020-04-02 05:03:52,990 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82) service to localhost/127.0.0.1:37631 beginning handshake with NN
2020-04-02 05:03:52,990 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82) service to localhost/127.0.0.1:46349 beginning handshake with NN
2020-04-02 05:03:52,994 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 37c34b0d-ec3f-4635-b93e-4c5b1348268e) service to localhost/127.0.0.1:35597 beginning handshake with NN
2020-04-02 05:03:52,998 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 37c34b0d-ec3f-4635-b93e-4c5b1348268e) service to localhost/127.0.0.1:46349 beginning handshake with NN
2020-04-02 05:03:52,998 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 37c34b0d-ec3f-4635-b93e-4c5b1348268e) service to localhost/127.0.0.1:35176 beginning handshake with NN
2020-04-02 05:03:53,002 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 37c34b0d-ec3f-4635-b93e-4c5b1348268e) service to localhost/127.0.0.1:37631 beginning handshake with NN
2020-04-02 05:03:53,003 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1514103897-172.17.0.9-1585803826583 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 324ms
2020-04-02 05:03:53,011 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1514103897-172.17.0.9-1585803826583 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 333ms
2020-04-02 05:03:53,011 [Thread-277] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1514103897-172.17.0.9-1585803826583 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 339ms
2020-04-02 05:03:53,014 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1514103897-172.17.0.9-1585803826583 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 304ms
2020-04-02 05:03:53,018 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1514103897-172.17.0.9-1585803826583 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 256ms
2020-04-02 05:03:53,034 [Thread-185] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1514103897-172.17.0.9-1585803826583: 360ms
2020-04-02 05:03:53,034 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-04-02 05:03:53,035 [Thread-311] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1514103897-172.17.0.9-1585803826583/current/replicas doesn't exist 
2020-04-02 05:03:53,035 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-04-02 05:03:53,035 [Thread-312] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1514103897-172.17.0.9-1585803826583/current/replicas doesn't exist 
2020-04-02 05:03:53,038 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 3ms
2020-04-02 05:03:53,041 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 7ms
2020-04-02 05:03:53,044 [Thread-185] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1514103897-172.17.0.9-1585803826583: 10ms
2020-04-02 05:03:53,045 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82) service to localhost/127.0.0.1:35176 beginning handshake with NN
2020-04-02 05:03:53,045 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:53,046 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82) service to localhost/127.0.0.1:35597 beginning handshake with NN
2020-04-02 05:03:53,046 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-d2d44c79-d51a-414b-a564-efaee6e2dfb5): finished scanning block pool BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:53,046 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-d2d44c79-d51a-414b-a564-efaee6e2dfb5): no suitable block pools found to scan.  Waiting 1814399760 ms.
2020-04-02 05:03:53,047 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:53,047 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-ede8edd0-5de5-4e02-9ddd-7561e4eadf59): finished scanning block pool BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:53,047 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-ede8edd0-5de5-4e02-9ddd-7561e4eadf59): no suitable block pools found to scan.  Waiting 1814399759 ms.
2020-04-02 05:03:53,044 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1514103897-172.17.0.9-1585803826583 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 406ms
2020-04-02 05:03:53,048 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1514103897-172.17.0.9-1585803826583: 589ms
2020-04-02 05:03:53,050 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-04-02 05:03:53,050 [Thread-313] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1514103897-172.17.0.9-1585803826583/current/replicas doesn't exist 
2020-04-02 05:03:53,050 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-04-02 05:03:53,050 [Thread-314] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1514103897-172.17.0.9-1585803826583/current/replicas doesn't exist 
2020-04-02 05:03:53,053 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 3ms
2020-04-02 05:03:53,074 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 24ms
2020-04-02 05:03:53,070 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1514103897-172.17.0.9-1585803826583: 554ms
2020-04-02 05:03:53,088 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1514103897-172.17.0.9-1585803826583: 41ms
2020-04-02 05:03:53,089 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 1d462b81-d264-4460-97f6-685a3cb75138) service to localhost/127.0.0.1:35176 beginning handshake with NN
2020-04-02 05:03:53,089 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:53,090 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-04-02 05:03:53,090 [Thread-315] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1514103897-172.17.0.9-1585803826583/current/replicas doesn't exist 
2020-04-02 05:03:53,090 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-009ae7d5-6bbd-4558-89d3-f7832539d9ec): finished scanning block pool BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:53,090 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 1ms
2020-04-02 05:03:53,090 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 1d462b81-d264-4460-97f6-685a3cb75138) service to localhost/127.0.0.1:35597 beginning handshake with NN
2020-04-02 05:03:53,092 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-009ae7d5-6bbd-4558-89d3-f7832539d9ec): no suitable block pools found to scan.  Waiting 1814399643 ms.
2020-04-02 05:03:53,090 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-04-02 05:03:53,092 [Thread-316] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1514103897-172.17.0.9-1585803826583/current/replicas doesn't exist 
2020-04-02 05:03:53,093 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 1ms
2020-04-02 05:03:53,093 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1514103897-172.17.0.9-1585803826583: 6ms
2020-04-02 05:03:53,094 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid be3e34c4-4a49-4457-8d5c-a1340f40b0a6) service to localhost/127.0.0.1:35176 beginning handshake with NN
2020-04-02 05:03:53,095 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid be3e34c4-4a49-4457-8d5c-a1340f40b0a6) service to localhost/127.0.0.1:35597 beginning handshake with NN
2020-04-02 05:03:53,093 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:53,095 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-b04f45b7-2efa-4c1e-bd57-402c44bbd21f): finished scanning block pool BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:53,096 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-b04f45b7-2efa-4c1e-bd57-402c44bbd21f): no suitable block pools found to scan.  Waiting 1814399638 ms.
2020-04-02 05:03:53,096 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:53,097 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-02748c20-2ca5-4730-a651-f95813f8cec5): finished scanning block pool BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:53,097 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1514103897-172.17.0.9-1585803826583 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:53,098 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-22156fcf-6c04-460f-a478-efbd7b0cfc97): finished scanning block pool BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:03:53,098 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-02748c20-2ca5-4730-a651-f95813f8cec5): no suitable block pools found to scan.  Waiting 1814399614 ms.
2020-04-02 05:03:53,099 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-22156fcf-6c04-460f-a478-efbd7b0cfc97): no suitable block pools found to scan.  Waiting 1814399613 ms.
2020-04-02 05:03:53,110 [IPC Server handler 6 on 35597] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33839, datanodeUuid=37c34b0d-ec3f-4635-b93e-4c5b1348268e, infoPort=46757, infoSecurePort=0, ipcPort=38342, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583) storage 37c34b0d-ec3f-4635-b93e-4c5b1348268e
2020-04-02 05:03:53,111 [IPC Server handler 3 on 37631] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41106, datanodeUuid=1d462b81-d264-4460-97f6-685a3cb75138, infoPort=45936, infoSecurePort=0, ipcPort=32843, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804) storage 1d462b81-d264-4460-97f6-685a3cb75138
2020-04-02 05:03:53,111 [IPC Server handler 3 on 46349] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41106, datanodeUuid=1d462b81-d264-4460-97f6-685a3cb75138, infoPort=45936, infoSecurePort=0, ipcPort=32843, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804) storage 1d462b81-d264-4460-97f6-685a3cb75138
2020-04-02 05:03:53,113 [IPC Server handler 0 on 35176] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33839, datanodeUuid=37c34b0d-ec3f-4635-b93e-4c5b1348268e, infoPort=46757, infoSecurePort=0, ipcPort=38342, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583) storage 37c34b0d-ec3f-4635-b93e-4c5b1348268e
2020-04-02 05:03:53,125 [IPC Server handler 6 on 35597] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33839
2020-04-02 05:03:53,125 [IPC Server handler 6 on 35597] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 37c34b0d-ec3f-4635-b93e-4c5b1348268e (127.0.0.1:33839).
2020-04-02 05:03:53,150 [IPC Server handler 3 on 37631] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41106
2020-04-02 05:03:53,150 [IPC Server handler 3 on 37631] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1d462b81-d264-4460-97f6-685a3cb75138 (127.0.0.1:41106).
2020-04-02 05:03:53,150 [IPC Server handler 3 on 46349] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41106
2020-04-02 05:03:53,151 [IPC Server handler 3 on 46349] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1d462b81-d264-4460-97f6-685a3cb75138 (127.0.0.1:41106).
2020-04-02 05:03:53,154 [IPC Server handler 0 on 35176] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33839
2020-04-02 05:03:53,154 [IPC Server handler 0 on 35176] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 37c34b0d-ec3f-4635-b93e-4c5b1348268e (127.0.0.1:33839).
2020-04-02 05:03:53,194 [IPC Server handler 0 on 37631] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33839, datanodeUuid=37c34b0d-ec3f-4635-b93e-4c5b1348268e, infoPort=46757, infoSecurePort=0, ipcPort=38342, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804) storage 37c34b0d-ec3f-4635-b93e-4c5b1348268e
2020-04-02 05:03:53,194 [IPC Server handler 0 on 37631] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33839
2020-04-02 05:03:53,200 [IPC Server handler 9 on 35176] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45284, datanodeUuid=5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82, infoPort=44818, infoSecurePort=0, ipcPort=37055, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583) storage 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82
2020-04-02 05:03:53,201 [IPC Server handler 9 on 35176] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45284
2020-04-02 05:03:53,210 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 1d462b81-d264-4460-97f6-685a3cb75138) service to localhost/127.0.0.1:37631 successfully registered with NN
2020-04-02 05:03:53,220 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37631 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:53,222 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 1d462b81-d264-4460-97f6-685a3cb75138) service to localhost/127.0.0.1:46349 successfully registered with NN
2020-04-02 05:03:53,222 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46349 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:53,213 [IPC Server handler 0 on 37631] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 37c34b0d-ec3f-4635-b93e-4c5b1348268e (127.0.0.1:33839).
2020-04-02 05:03:53,220 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 37c34b0d-ec3f-4635-b93e-4c5b1348268e) service to localhost/127.0.0.1:35176 successfully registered with NN
2020-04-02 05:03:53,230 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35176 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:53,220 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 37c34b0d-ec3f-4635-b93e-4c5b1348268e) service to localhost/127.0.0.1:35597 successfully registered with NN
2020-04-02 05:03:53,218 [IPC Server handler 6 on 46349] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45081, datanodeUuid=be3e34c4-4a49-4457-8d5c-a1340f40b0a6, infoPort=43769, infoSecurePort=0, ipcPort=36669, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804) storage be3e34c4-4a49-4457-8d5c-a1340f40b0a6
2020-04-02 05:03:53,231 [IPC Server handler 6 on 46349] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45081
2020-04-02 05:03:53,218 [IPC Server handler 5 on 35597] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45284, datanodeUuid=5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82, infoPort=44818, infoSecurePort=0, ipcPort=37055, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583) storage 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82
2020-04-02 05:03:53,232 [IPC Server handler 5 on 35597] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45284
2020-04-02 05:03:53,214 [IPC Server handler 9 on 35176] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82 (127.0.0.1:45284).
2020-04-02 05:03:53,232 [IPC Server handler 8 on 35176] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41106, datanodeUuid=1d462b81-d264-4460-97f6-685a3cb75138, infoPort=45936, infoSecurePort=0, ipcPort=32843, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583) storage 1d462b81-d264-4460-97f6-685a3cb75138
2020-04-02 05:03:53,233 [IPC Server handler 8 on 35176] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41106
2020-04-02 05:03:53,233 [IPC Server handler 8 on 35176] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1d462b81-d264-4460-97f6-685a3cb75138 (127.0.0.1:41106).
2020-04-02 05:03:53,233 [IPC Server handler 7 on 35176] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45081, datanodeUuid=be3e34c4-4a49-4457-8d5c-a1340f40b0a6, infoPort=43769, infoSecurePort=0, ipcPort=36669, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583) storage be3e34c4-4a49-4457-8d5c-a1340f40b0a6
2020-04-02 05:03:53,233 [IPC Server handler 4 on 37631] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45081, datanodeUuid=be3e34c4-4a49-4457-8d5c-a1340f40b0a6, infoPort=43769, infoSecurePort=0, ipcPort=36669, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804) storage be3e34c4-4a49-4457-8d5c-a1340f40b0a6
2020-04-02 05:03:53,234 [IPC Server handler 4 on 37631] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45081
2020-04-02 05:03:53,234 [IPC Server handler 4 on 37631] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN be3e34c4-4a49-4457-8d5c-a1340f40b0a6 (127.0.0.1:45081).
2020-04-02 05:03:53,234 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82) service to localhost/127.0.0.1:35176 successfully registered with NN
2020-04-02 05:03:53,234 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35176 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:53,235 [IPC Server handler 5 on 37631] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45284, datanodeUuid=5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82, infoPort=44818, infoSecurePort=0, ipcPort=37055, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804) storage 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82
2020-04-02 05:03:53,235 [IPC Server handler 5 on 37631] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45284
2020-04-02 05:03:53,235 [IPC Server handler 5 on 37631] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82 (127.0.0.1:45284).
2020-04-02 05:03:53,231 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 37c34b0d-ec3f-4635-b93e-4c5b1348268e) service to localhost/127.0.0.1:37631 successfully registered with NN
2020-04-02 05:03:53,235 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37631 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:53,231 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35597 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:53,236 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid be3e34c4-4a49-4457-8d5c-a1340f40b0a6) service to localhost/127.0.0.1:37631 successfully registered with NN
2020-04-02 05:03:53,245 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37631 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:53,236 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82) service to localhost/127.0.0.1:37631 successfully registered with NN
2020-04-02 05:03:53,245 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37631 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:53,234 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 1d462b81-d264-4460-97f6-685a3cb75138) service to localhost/127.0.0.1:35176 successfully registered with NN
2020-04-02 05:03:53,255 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35176 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:53,234 [IPC Server handler 7 on 35176] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45081
2020-04-02 05:03:53,256 [IPC Server handler 7 on 35176] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN be3e34c4-4a49-4457-8d5c-a1340f40b0a6 (127.0.0.1:45081).
2020-04-02 05:03:53,258 [IPC Server handler 6 on 46349] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN be3e34c4-4a49-4457-8d5c-a1340f40b0a6 (127.0.0.1:45081).
2020-04-02 05:03:53,259 [IPC Server handler 9 on 46349] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33839, datanodeUuid=37c34b0d-ec3f-4635-b93e-4c5b1348268e, infoPort=46757, infoSecurePort=0, ipcPort=38342, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804) storage 37c34b0d-ec3f-4635-b93e-4c5b1348268e
2020-04-02 05:03:53,259 [IPC Server handler 9 on 46349] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33839
2020-04-02 05:03:53,259 [IPC Server handler 9 on 46349] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 37c34b0d-ec3f-4635-b93e-4c5b1348268e (127.0.0.1:33839).
2020-04-02 05:03:53,260 [IPC Server handler 4 on 46349] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45284, datanodeUuid=5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82, infoPort=44818, infoSecurePort=0, ipcPort=37055, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804) storage 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82
2020-04-02 05:03:53,260 [IPC Server handler 4 on 46349] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45284
2020-04-02 05:03:53,260 [IPC Server handler 4 on 46349] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82 (127.0.0.1:45284).
2020-04-02 05:03:53,261 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82) service to localhost/127.0.0.1:46349 successfully registered with NN
2020-04-02 05:03:53,276 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46349 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:53,276 [IPC Server handler 5 on 35597] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82 (127.0.0.1:45284).
2020-04-02 05:03:53,276 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 37c34b0d-ec3f-4635-b93e-4c5b1348268e) service to localhost/127.0.0.1:46349 successfully registered with NN
2020-04-02 05:03:53,278 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46349 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:53,264 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid be3e34c4-4a49-4457-8d5c-a1340f40b0a6) service to localhost/127.0.0.1:35176 successfully registered with NN
2020-04-02 05:03:53,279 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35176 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:53,281 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82) service to localhost/127.0.0.1:35597 successfully registered with NN
2020-04-02 05:03:53,282 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35597 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:53,282 [IPC Server handler 4 on 35597] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41106, datanodeUuid=1d462b81-d264-4460-97f6-685a3cb75138, infoPort=45936, infoSecurePort=0, ipcPort=32843, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583) storage 1d462b81-d264-4460-97f6-685a3cb75138
2020-04-02 05:03:53,286 [IPC Server handler 4 on 35597] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41106
2020-04-02 05:03:53,286 [IPC Server handler 4 on 35597] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1d462b81-d264-4460-97f6-685a3cb75138 (127.0.0.1:41106).
2020-04-02 05:03:53,287 [IPC Server handler 2 on 35597] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45081, datanodeUuid=be3e34c4-4a49-4457-8d5c-a1340f40b0a6, infoPort=43769, infoSecurePort=0, ipcPort=36669, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583) storage be3e34c4-4a49-4457-8d5c-a1340f40b0a6
2020-04-02 05:03:53,287 [IPC Server handler 2 on 35597] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45081
2020-04-02 05:03:53,287 [IPC Server handler 2 on 35597] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN be3e34c4-4a49-4457-8d5c-a1340f40b0a6 (127.0.0.1:45081).
2020-04-02 05:03:53,288 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 1d462b81-d264-4460-97f6-685a3cb75138) service to localhost/127.0.0.1:35597 successfully registered with NN
2020-04-02 05:03:53,288 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35597 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:53,289 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid be3e34c4-4a49-4457-8d5c-a1340f40b0a6) service to localhost/127.0.0.1:35597 successfully registered with NN
2020-04-02 05:03:53,289 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35597 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:53,296 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid be3e34c4-4a49-4457-8d5c-a1340f40b0a6) service to localhost/127.0.0.1:46349 successfully registered with NN
2020-04-02 05:03:53,296 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46349 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:53,398 [IPC Server handler 6 on 35176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ede8edd0-5de5-4e02-9ddd-7561e4eadf59 for DN 127.0.0.1:45284
2020-04-02 05:03:53,398 [IPC Server handler 6 on 35176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d2d44c79-d51a-414b-a564-efaee6e2dfb5 for DN 127.0.0.1:45284
2020-04-02 05:03:53,436 [IPC Server handler 0 on 35597] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ede8edd0-5de5-4e02-9ddd-7561e4eadf59 for DN 127.0.0.1:45284
2020-04-02 05:03:53,436 [IPC Server handler 0 on 35597] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d2d44c79-d51a-414b-a564-efaee6e2dfb5 for DN 127.0.0.1:45284
2020-04-02 05:03:53,438 [IPC Server handler 6 on 37631] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-90599705-ceb0-48a2-8083-2c6b6280bd4b for DN 127.0.0.1:33839
2020-04-02 05:03:53,438 [IPC Server handler 6 on 37631] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b6cc6c14-c015-45c1-b2b6-a7fbd9456e9e for DN 127.0.0.1:33839
2020-04-02 05:03:53,439 [IPC Server handler 7 on 46349] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-22156fcf-6c04-460f-a478-efbd7b0cfc97 for DN 127.0.0.1:45081
2020-04-02 05:03:53,439 [IPC Server handler 7 on 46349] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-02748c20-2ca5-4730-a651-f95813f8cec5 for DN 127.0.0.1:45081
2020-04-02 05:03:53,422 [IPC Server handler 5 on 35176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-22156fcf-6c04-460f-a478-efbd7b0cfc97 for DN 127.0.0.1:45081
2020-04-02 05:03:53,462 [IPC Server handler 3 on 35597] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-22156fcf-6c04-460f-a478-efbd7b0cfc97 for DN 127.0.0.1:45081
2020-04-02 05:03:53,464 [IPC Server handler 9 on 37631] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-22156fcf-6c04-460f-a478-efbd7b0cfc97 for DN 127.0.0.1:45081
2020-04-02 05:03:53,481 [IPC Server handler 5 on 35176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-02748c20-2ca5-4730-a651-f95813f8cec5 for DN 127.0.0.1:45081
2020-04-02 05:03:53,487 [IPC Server handler 8 on 46349] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b04f45b7-2efa-4c1e-bd57-402c44bbd21f for DN 127.0.0.1:41106
2020-04-02 05:03:53,494 [IPC Server handler 3 on 35597] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-02748c20-2ca5-4730-a651-f95813f8cec5 for DN 127.0.0.1:45081
2020-04-02 05:03:53,517 [IPC Server handler 9 on 37631] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-02748c20-2ca5-4730-a651-f95813f8cec5 for DN 127.0.0.1:45081
2020-04-02 05:03:53,524 [IPC Server handler 4 on 35176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-90599705-ceb0-48a2-8083-2c6b6280bd4b for DN 127.0.0.1:33839
2020-04-02 05:03:53,524 [IPC Server handler 4 on 35176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b6cc6c14-c015-45c1-b2b6-a7fbd9456e9e for DN 127.0.0.1:33839
2020-04-02 05:03:53,526 [IPC Server handler 7 on 35597] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b04f45b7-2efa-4c1e-bd57-402c44bbd21f for DN 127.0.0.1:41106
2020-04-02 05:03:53,526 [IPC Server handler 7 on 35597] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-009ae7d5-6bbd-4558-89d3-f7832539d9ec for DN 127.0.0.1:41106
2020-04-02 05:03:53,531 [IPC Server handler 1 on 35597] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-90599705-ceb0-48a2-8083-2c6b6280bd4b for DN 127.0.0.1:33839
2020-04-02 05:03:53,531 [IPC Server handler 1 on 35597] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b6cc6c14-c015-45c1-b2b6-a7fbd9456e9e for DN 127.0.0.1:33839
2020-04-02 05:03:53,532 [IPC Server handler 2 on 35176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b04f45b7-2efa-4c1e-bd57-402c44bbd21f for DN 127.0.0.1:41106
2020-04-02 05:03:53,532 [IPC Server handler 2 on 35176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-009ae7d5-6bbd-4558-89d3-f7832539d9ec for DN 127.0.0.1:41106
2020-04-02 05:03:53,533 [IPC Server handler 7 on 37631] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ede8edd0-5de5-4e02-9ddd-7561e4eadf59 for DN 127.0.0.1:45284
2020-04-02 05:03:53,533 [IPC Server handler 7 on 37631] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d2d44c79-d51a-414b-a564-efaee6e2dfb5 for DN 127.0.0.1:45284
2020-04-02 05:03:53,533 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf4c621bd58ae634f: Processing first storage report for DS-d2d44c79-d51a-414b-a564-efaee6e2dfb5 from datanode 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82
2020-04-02 05:03:53,533 [IPC Server handler 8 on 46349] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-009ae7d5-6bbd-4558-89d3-f7832539d9ec for DN 127.0.0.1:41106
2020-04-02 05:03:53,534 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x451c093809539273: Processing first storage report for DS-d2d44c79-d51a-414b-a564-efaee6e2dfb5 from datanode 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82
2020-04-02 05:03:53,539 [IPC Server handler 2 on 46349] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ede8edd0-5de5-4e02-9ddd-7561e4eadf59 for DN 127.0.0.1:45284
2020-04-02 05:03:53,539 [IPC Server handler 2 on 46349] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d2d44c79-d51a-414b-a564-efaee6e2dfb5 for DN 127.0.0.1:45284
2020-04-02 05:03:53,540 [IPC Server handler 8 on 37631] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b04f45b7-2efa-4c1e-bd57-402c44bbd21f for DN 127.0.0.1:41106
2020-04-02 05:03:53,540 [IPC Server handler 8 on 37631] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-009ae7d5-6bbd-4558-89d3-f7832539d9ec for DN 127.0.0.1:41106
2020-04-02 05:03:53,553 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf4c621bd58ae634f: from storage DS-d2d44c79-d51a-414b-a564-efaee6e2dfb5 node DatanodeRegistration(127.0.0.1:45284, datanodeUuid=5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82, infoPort=44818, infoSecurePort=0, ipcPort=37055, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583), blocks: 0, hasStaleStorage: true, processing time: 20 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,553 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x117a6277d190f8cf: Processing first storage report for DS-02748c20-2ca5-4730-a651-f95813f8cec5 from datanode be3e34c4-4a49-4457-8d5c-a1340f40b0a6
2020-04-02 05:03:53,553 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x117a6277d190f8cf: from storage DS-02748c20-2ca5-4730-a651-f95813f8cec5 node DatanodeRegistration(127.0.0.1:45081, datanodeUuid=be3e34c4-4a49-4457-8d5c-a1340f40b0a6, infoPort=43769, infoSecurePort=0, ipcPort=36669, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,553 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x1e82076e017a9187: Processing first storage report for DS-b6cc6c14-c015-45c1-b2b6-a7fbd9456e9e from datanode 37c34b0d-ec3f-4635-b93e-4c5b1348268e
2020-04-02 05:03:53,553 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x1e82076e017a9187: from storage DS-b6cc6c14-c015-45c1-b2b6-a7fbd9456e9e node DatanodeRegistration(127.0.0.1:33839, datanodeUuid=37c34b0d-ec3f-4635-b93e-4c5b1348268e, infoPort=46757, infoSecurePort=0, ipcPort=38342, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,554 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2ab71aef8116e2e2: Processing first storage report for DS-b6cc6c14-c015-45c1-b2b6-a7fbd9456e9e from datanode 37c34b0d-ec3f-4635-b93e-4c5b1348268e
2020-04-02 05:03:53,554 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x117a6277d190f8cf: Processing first storage report for DS-22156fcf-6c04-460f-a478-efbd7b0cfc97 from datanode be3e34c4-4a49-4457-8d5c-a1340f40b0a6
2020-04-02 05:03:53,554 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x117a6277d190f8cf: from storage DS-22156fcf-6c04-460f-a478-efbd7b0cfc97 node DatanodeRegistration(127.0.0.1:45081, datanodeUuid=be3e34c4-4a49-4457-8d5c-a1340f40b0a6, infoPort=43769, infoSecurePort=0, ipcPort=36669, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,556 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf4c621bd58ae634f: Processing first storage report for DS-ede8edd0-5de5-4e02-9ddd-7561e4eadf59 from datanode 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82
2020-04-02 05:03:53,556 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf4c621bd58ae634f: from storage DS-ede8edd0-5de5-4e02-9ddd-7561e4eadf59 node DatanodeRegistration(127.0.0.1:45284, datanodeUuid=5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82, infoPort=44818, infoSecurePort=0, ipcPort=37055, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,562 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x1e82076e017a9187: Processing first storage report for DS-90599705-ceb0-48a2-8083-2c6b6280bd4b from datanode 37c34b0d-ec3f-4635-b93e-4c5b1348268e
2020-04-02 05:03:53,563 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x1e82076e017a9187: from storage DS-90599705-ceb0-48a2-8083-2c6b6280bd4b node DatanodeRegistration(127.0.0.1:33839, datanodeUuid=37c34b0d-ec3f-4635-b93e-4c5b1348268e, infoPort=46757, infoSecurePort=0, ipcPort=38342, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,597 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x451c093809539273: from storage DS-d2d44c79-d51a-414b-a564-efaee6e2dfb5 node DatanodeRegistration(127.0.0.1:45284, datanodeUuid=5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82, infoPort=44818, infoSecurePort=0, ipcPort=37055, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583), blocks: 0, hasStaleStorage: true, processing time: 20 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,598 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x451c093809539273: Processing first storage report for DS-ede8edd0-5de5-4e02-9ddd-7561e4eadf59 from datanode 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82
2020-04-02 05:03:53,598 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2ab71aef8116e2e2: from storage DS-b6cc6c14-c015-45c1-b2b6-a7fbd9456e9e node DatanodeRegistration(127.0.0.1:33839, datanodeUuid=37c34b0d-ec3f-4635-b93e-4c5b1348268e, infoPort=46757, infoSecurePort=0, ipcPort=38342, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,598 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x6c0b7d9919af32d6: Processing first storage report for DS-02748c20-2ca5-4730-a651-f95813f8cec5 from datanode be3e34c4-4a49-4457-8d5c-a1340f40b0a6
2020-04-02 05:03:53,598 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x6c0b7d9919af32d6: from storage DS-02748c20-2ca5-4730-a651-f95813f8cec5 node DatanodeRegistration(127.0.0.1:45081, datanodeUuid=be3e34c4-4a49-4457-8d5c-a1340f40b0a6, infoPort=43769, infoSecurePort=0, ipcPort=36669, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,598 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd32a9c828d69c961: Processing first storage report for DS-d2d44c79-d51a-414b-a564-efaee6e2dfb5 from datanode 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82
2020-04-02 05:03:53,598 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd32a9c828d69c961: from storage DS-d2d44c79-d51a-414b-a564-efaee6e2dfb5 node DatanodeRegistration(127.0.0.1:45284, datanodeUuid=5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82, infoPort=44818, infoSecurePort=0, ipcPort=37055, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,599 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x19d99d636de625c8: Processing first storage report for DS-b04f45b7-2efa-4c1e-bd57-402c44bbd21f from datanode 1d462b81-d264-4460-97f6-685a3cb75138
2020-04-02 05:03:53,599 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x19d99d636de625c8: from storage DS-b04f45b7-2efa-4c1e-bd57-402c44bbd21f node DatanodeRegistration(127.0.0.1:41106, datanodeUuid=1d462b81-d264-4460-97f6-685a3cb75138, infoPort=45936, infoSecurePort=0, ipcPort=32843, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,598 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x451c093809539273: from storage DS-ede8edd0-5de5-4e02-9ddd-7561e4eadf59 node DatanodeRegistration(127.0.0.1:45284, datanodeUuid=5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82, infoPort=44818, infoSecurePort=0, ipcPort=37055, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,599 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2ab71aef8116e2e2: Processing first storage report for DS-90599705-ceb0-48a2-8083-2c6b6280bd4b from datanode 37c34b0d-ec3f-4635-b93e-4c5b1348268e
2020-04-02 05:03:53,599 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2ab71aef8116e2e2: from storage DS-90599705-ceb0-48a2-8083-2c6b6280bd4b node DatanodeRegistration(127.0.0.1:33839, datanodeUuid=37c34b0d-ec3f-4635-b93e-4c5b1348268e, infoPort=46757, infoSecurePort=0, ipcPort=38342, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,600 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x6c0b7d9919af32d6: Processing first storage report for DS-22156fcf-6c04-460f-a478-efbd7b0cfc97 from datanode be3e34c4-4a49-4457-8d5c-a1340f40b0a6
2020-04-02 05:03:53,600 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x6c0b7d9919af32d6: from storage DS-22156fcf-6c04-460f-a478-efbd7b0cfc97 node DatanodeRegistration(127.0.0.1:45081, datanodeUuid=be3e34c4-4a49-4457-8d5c-a1340f40b0a6, infoPort=43769, infoSecurePort=0, ipcPort=36669, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,600 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x19d99d636de625c8: Processing first storage report for DS-009ae7d5-6bbd-4558-89d3-f7832539d9ec from datanode 1d462b81-d264-4460-97f6-685a3cb75138
2020-04-02 05:03:53,600 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x19d99d636de625c8: from storage DS-009ae7d5-6bbd-4558-89d3-f7832539d9ec node DatanodeRegistration(127.0.0.1:41106, datanodeUuid=1d462b81-d264-4460-97f6-685a3cb75138, infoPort=45936, infoSecurePort=0, ipcPort=32843, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,600 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd32a9c828d69c961: Processing first storage report for DS-ede8edd0-5de5-4e02-9ddd-7561e4eadf59 from datanode 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82
2020-04-02 05:03:53,601 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd32a9c828d69c961: from storage DS-ede8edd0-5de5-4e02-9ddd-7561e4eadf59 node DatanodeRegistration(127.0.0.1:45284, datanodeUuid=5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82, infoPort=44818, infoSecurePort=0, ipcPort=37055, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,606 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xaa9a225fefb036b5: Processing first storage report for DS-b04f45b7-2efa-4c1e-bd57-402c44bbd21f from datanode 1d462b81-d264-4460-97f6-685a3cb75138
2020-04-02 05:03:53,606 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xaa9a225fefb036b5: from storage DS-b04f45b7-2efa-4c1e-bd57-402c44bbd21f node DatanodeRegistration(127.0.0.1:41106, datanodeUuid=1d462b81-d264-4460-97f6-685a3cb75138, infoPort=45936, infoSecurePort=0, ipcPort=32843, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,607 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xaa9a225fefb036b5: Processing first storage report for DS-009ae7d5-6bbd-4558-89d3-f7832539d9ec from datanode 1d462b81-d264-4460-97f6-685a3cb75138
2020-04-02 05:03:53,607 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xaa9a225fefb036b5: from storage DS-009ae7d5-6bbd-4558-89d3-f7832539d9ec node DatanodeRegistration(127.0.0.1:41106, datanodeUuid=1d462b81-d264-4460-97f6-685a3cb75138, infoPort=45936, infoSecurePort=0, ipcPort=32843, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,627 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x6c0b7d9919af32d6,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 97 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:53,628 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x2ab71aef8116e2e2,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 161 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:53,643 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x451c093809539273,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 162 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:53,644 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd82186dadac09027: Processing first storage report for DS-02748c20-2ca5-4730-a651-f95813f8cec5 from datanode be3e34c4-4a49-4457-8d5c-a1340f40b0a6
2020-04-02 05:03:53,644 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd82186dadac09027: from storage DS-02748c20-2ca5-4730-a651-f95813f8cec5 node DatanodeRegistration(127.0.0.1:45081, datanodeUuid=be3e34c4-4a49-4457-8d5c-a1340f40b0a6, infoPort=43769, infoSecurePort=0, ipcPort=36669, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,644 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x19d99d636de625c8,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 93 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:53,645 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd82186dadac09027: Processing first storage report for DS-22156fcf-6c04-460f-a478-efbd7b0cfc97 from datanode be3e34c4-4a49-4457-8d5c-a1340f40b0a6
2020-04-02 05:03:53,645 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd82186dadac09027: from storage DS-22156fcf-6c04-460f-a478-efbd7b0cfc97 node DatanodeRegistration(127.0.0.1:45081, datanodeUuid=be3e34c4-4a49-4457-8d5c-a1340f40b0a6, infoPort=43769, infoSecurePort=0, ipcPort=36669, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,645 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xaa9a225fefb036b5,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 75 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:53,645 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x117a6277d190f8cf,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 103 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:53,654 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xf4c621bd58ae634f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 210 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:53,654 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x1e82076e017a9187,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 111 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:53,667 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd8da1c00345e89cc: Processing first storage report for DS-b6cc6c14-c015-45c1-b2b6-a7fbd9456e9e from datanode 37c34b0d-ec3f-4635-b93e-4c5b1348268e
2020-04-02 05:03:53,656 [IPC Server handler 5 on 46349] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-90599705-ceb0-48a2-8083-2c6b6280bd4b for DN 127.0.0.1:33839
2020-04-02 05:03:53,674 [IPC Server handler 5 on 46349] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b6cc6c14-c015-45c1-b2b6-a7fbd9456e9e for DN 127.0.0.1:33839
2020-04-02 05:03:53,656 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xd32a9c828d69c961,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 94 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:53,730 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5f0f2db773ae9504: Processing first storage report for DS-02748c20-2ca5-4730-a651-f95813f8cec5 from datanode be3e34c4-4a49-4457-8d5c-a1340f40b0a6
2020-04-02 05:03:53,730 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5f0f2db773ae9504: from storage DS-02748c20-2ca5-4730-a651-f95813f8cec5 node DatanodeRegistration(127.0.0.1:45081, datanodeUuid=be3e34c4-4a49-4457-8d5c-a1340f40b0a6, infoPort=43769, infoSecurePort=0, ipcPort=36669, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,731 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa0188244d2c3e6bf: Processing first storage report for DS-b04f45b7-2efa-4c1e-bd57-402c44bbd21f from datanode 1d462b81-d264-4460-97f6-685a3cb75138
2020-04-02 05:03:53,731 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa0188244d2c3e6bf: from storage DS-b04f45b7-2efa-4c1e-bd57-402c44bbd21f node DatanodeRegistration(127.0.0.1:41106, datanodeUuid=1d462b81-d264-4460-97f6-685a3cb75138, infoPort=45936, infoSecurePort=0, ipcPort=32843, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,733 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd8da1c00345e89cc: from storage DS-b6cc6c14-c015-45c1-b2b6-a7fbd9456e9e node DatanodeRegistration(127.0.0.1:33839, datanodeUuid=37c34b0d-ec3f-4635-b93e-4c5b1348268e, infoPort=46757, infoSecurePort=0, ipcPort=38342, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583), blocks: 0, hasStaleStorage: true, processing time: 7 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,733 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd0fceb8c49bca4: Processing first storage report for DS-b04f45b7-2efa-4c1e-bd57-402c44bbd21f from datanode 1d462b81-d264-4460-97f6-685a3cb75138
2020-04-02 05:03:53,733 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd0fceb8c49bca4: from storage DS-b04f45b7-2efa-4c1e-bd57-402c44bbd21f node DatanodeRegistration(127.0.0.1:41106, datanodeUuid=1d462b81-d264-4460-97f6-685a3cb75138, infoPort=45936, infoSecurePort=0, ipcPort=32843, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,734 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd8da1c00345e89cc: Processing first storage report for DS-90599705-ceb0-48a2-8083-2c6b6280bd4b from datanode 37c34b0d-ec3f-4635-b93e-4c5b1348268e
2020-04-02 05:03:53,734 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd8da1c00345e89cc: from storage DS-90599705-ceb0-48a2-8083-2c6b6280bd4b node DatanodeRegistration(127.0.0.1:33839, datanodeUuid=37c34b0d-ec3f-4635-b93e-4c5b1348268e, infoPort=46757, infoSecurePort=0, ipcPort=38342, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,734 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd0fceb8c49bca4: Processing first storage report for DS-009ae7d5-6bbd-4558-89d3-f7832539d9ec from datanode 1d462b81-d264-4460-97f6-685a3cb75138
2020-04-02 05:03:53,734 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd0fceb8c49bca4: from storage DS-009ae7d5-6bbd-4558-89d3-f7832539d9ec node DatanodeRegistration(127.0.0.1:41106, datanodeUuid=1d462b81-d264-4460-97f6-685a3cb75138, infoPort=45936, infoSecurePort=0, ipcPort=32843, storageInfo=lv=-57;cid=testClusterID;nsid=638608623;c=1585803826583), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,735 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5f0f2db773ae9504: Processing first storage report for DS-22156fcf-6c04-460f-a478-efbd7b0cfc97 from datanode be3e34c4-4a49-4457-8d5c-a1340f40b0a6
2020-04-02 05:03:53,736 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5f0f2db773ae9504: from storage DS-22156fcf-6c04-460f-a478-efbd7b0cfc97 node DatanodeRegistration(127.0.0.1:45081, datanodeUuid=be3e34c4-4a49-4457-8d5c-a1340f40b0a6, infoPort=43769, infoSecurePort=0, ipcPort=36669, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,736 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa0188244d2c3e6bf: Processing first storage report for DS-009ae7d5-6bbd-4558-89d3-f7832539d9ec from datanode 1d462b81-d264-4460-97f6-685a3cb75138
2020-04-02 05:03:53,736 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa0188244d2c3e6bf: from storage DS-009ae7d5-6bbd-4558-89d3-f7832539d9ec node DatanodeRegistration(127.0.0.1:41106, datanodeUuid=1d462b81-d264-4460-97f6-685a3cb75138, infoPort=45936, infoSecurePort=0, ipcPort=32843, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,737 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x5f0f2db773ae9504,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 267 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:53,743 [IPC Server handler 0 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:53,746 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xa0188244d2c3e6bf,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 207 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:53,747 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x7d31829a23eb6297: Processing first storage report for DS-b6cc6c14-c015-45c1-b2b6-a7fbd9456e9e from datanode 37c34b0d-ec3f-4635-b93e-4c5b1348268e
2020-04-02 05:03:53,747 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x7d31829a23eb6297: from storage DS-b6cc6c14-c015-45c1-b2b6-a7fbd9456e9e node DatanodeRegistration(127.0.0.1:33839, datanodeUuid=37c34b0d-ec3f-4635-b93e-4c5b1348268e, infoPort=46757, infoSecurePort=0, ipcPort=38342, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,747 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x7d31829a23eb6297: Processing first storage report for DS-90599705-ceb0-48a2-8083-2c6b6280bd4b from datanode 37c34b0d-ec3f-4635-b93e-4c5b1348268e
2020-04-02 05:03:53,747 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x7d31829a23eb6297: from storage DS-90599705-ceb0-48a2-8083-2c6b6280bd4b node DatanodeRegistration(127.0.0.1:33839, datanodeUuid=37c34b0d-ec3f-4635-b93e-4c5b1348268e, infoPort=46757, infoSecurePort=0, ipcPort=38342, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,748 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x7d31829a23eb6297,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 16 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:53,758 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xd8da1c00345e89cc,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 104 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:53,758 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xd0fceb8c49bca4,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 115 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:53,759 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xd82186dadac09027,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 117 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:53,759 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x28534a062e0d1f92: Processing first storage report for DS-d2d44c79-d51a-414b-a564-efaee6e2dfb5 from datanode 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82
2020-04-02 05:03:53,760 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x28534a062e0d1f92: from storage DS-d2d44c79-d51a-414b-a564-efaee6e2dfb5 node DatanodeRegistration(127.0.0.1:45284, datanodeUuid=5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82, infoPort=44818, infoSecurePort=0, ipcPort=37055, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,760 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x28534a062e0d1f92: Processing first storage report for DS-ede8edd0-5de5-4e02-9ddd-7561e4eadf59 from datanode 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82
2020-04-02 05:03:53,760 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x28534a062e0d1f92: from storage DS-ede8edd0-5de5-4e02-9ddd-7561e4eadf59 node DatanodeRegistration(127.0.0.1:45284, datanodeUuid=5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82, infoPort=44818, infoSecurePort=0, ipcPort=37055, storageInfo=lv=-57;cid=testClusterID;nsid=30846779;c=1585803822804), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:53,761 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x28534a062e0d1f92,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 118 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:53,807 [IPC Server handler 4 on 37631] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:53,819 [IPC Server handler 8 on 35176] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:53,839 [IPC Server handler 4 on 35597] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:53,841 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:03:53,863 [IPC Server handler 4 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:53,875 [IPC Server handler 5 on 37631] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:53,889 [IPC Server handler 7 on 35176] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:53,904 [IPC Server handler 2 on 35597] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:53,908 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:03:53,993 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(250)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-04-02 05:03:54,006 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:54,010 [Socket Reader #1 for port 38843] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38843
2020-04-02 05:03:54,046 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-04-02 05:03:54,046 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-04-02 05:03:54,049 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-04-02 05:03:54,078 [JUnit] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-04-02 05:03:54,078 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:54,109 [Socket Reader #1 for port 34860] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34860
2020-04-02 05:03:54,109 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:54,120 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:54,121 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:54,126 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:54,126 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:54,135 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-04-02 05:03:54,166 [JUnit] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore
2020-04-02 05:03:54,166 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-04-02 05:03:54,179 [JUnit] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC
2020-04-02 05:03:54,191 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:35176
2020-04-02 05:03:54,191 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:35176
2020-04-02 05:03:54,191 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:35176
2020-04-02 05:03:54,191 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:36020
2020-04-02 05:03:54,192 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:46349
2020-04-02 05:03:54,192 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:46349
2020-04-02 05:03:54,192 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:46349
2020-04-02 05:03:54,192 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:43416
2020-04-02 05:03:54,193 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:35597
2020-04-02 05:03:54,193 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:35597
2020-04-02 05:03:54,193 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:35597
2020-04-02 05:03:54,193 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:38815
2020-04-02 05:03:54,194 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:37631
2020-04-02 05:03:54,194 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:37631
2020-04-02 05:03:54,194 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:37631
2020-04-02 05:03:54,194 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:39034
2020-04-02 05:03:54,208 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(250)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-04-02 05:03:54,214 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:54,222 [Socket Reader #1 for port 45777] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45777
2020-04-02 05:03:54,237 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-04-02 05:03:54,238 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-04-02 05:03:54,238 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-04-02 05:03:54,242 [JUnit] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-04-02 05:03:54,242 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:54,254 [Socket Reader #1 for port 33764] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33764
2020-04-02 05:03:54,260 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:54,260 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:54,261 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:54,261 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:54,261 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:54,261 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-04-02 05:03:54,290 [JUnit] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-1
2020-04-02 05:03:54,290 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-04-02 05:03:54,293 [JUnit] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-1
2020-04-02 05:03:54,294 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:35176
2020-04-02 05:03:54,295 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:35176
2020-04-02 05:03:54,295 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:35176
2020-04-02 05:03:54,295 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:36020
2020-04-02 05:03:54,296 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:46349
2020-04-02 05:03:54,296 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:46349
2020-04-02 05:03:54,296 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:46349
2020-04-02 05:03:54,296 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:43416
2020-04-02 05:03:54,296 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:35597
2020-04-02 05:03:54,296 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:35597
2020-04-02 05:03:54,297 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:35597
2020-04-02 05:03:54,297 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:38815
2020-04-02 05:03:54,297 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:37631
2020-04-02 05:03:54,297 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:37631
2020-04-02 05:03:54,297 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:37631
2020-04-02 05:03:54,298 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:39034
2020-04-02 05:03:54,325 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(250)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-04-02 05:03:54,334 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:54,335 [Socket Reader #1 for port 36853] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36853
2020-04-02 05:03:54,339 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-04-02 05:03:54,340 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-04-02 05:03:54,341 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-04-02 05:03:54,346 [JUnit] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-04-02 05:03:54,346 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:54,354 [Socket Reader #1 for port 43313] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43313
2020-04-02 05:03:54,361 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:54,361 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:54,361 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:54,361 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:54,362 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:54,362 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-04-02 05:03:54,363 [JUnit] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-2
2020-04-02 05:03:54,364 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-04-02 05:03:54,365 [JUnit] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-2
2020-04-02 05:03:54,366 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:35176
2020-04-02 05:03:54,366 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:35176
2020-04-02 05:03:54,366 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:35176
2020-04-02 05:03:54,377 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:36020
2020-04-02 05:03:54,383 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:46349
2020-04-02 05:03:54,383 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:46349
2020-04-02 05:03:54,383 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:46349
2020-04-02 05:03:54,383 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:43416
2020-04-02 05:03:54,384 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:35597
2020-04-02 05:03:54,385 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:35597
2020-04-02 05:03:54,386 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:35597
2020-04-02 05:03:54,386 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:38815
2020-04-02 05:03:54,404 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:37631
2020-04-02 05:03:54,406 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:37631
2020-04-02 05:03:54,406 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:37631
2020-04-02 05:03:54,407 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:39034
2020-04-02 05:03:54,439 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(250)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-04-02 05:03:54,454 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:54,463 [Socket Reader #1 for port 43084] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43084
2020-04-02 05:03:54,476 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-04-02 05:03:54,476 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-04-02 05:03:54,481 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-04-02 05:03:54,490 [JUnit] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-04-02 05:03:54,491 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:54,502 [Socket Reader #1 for port 42799] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42799
2020-04-02 05:03:54,530 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:54,531 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:54,532 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:54,533 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:54,535 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:54,535 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-04-02 05:03:54,554 [JUnit] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-3
2020-04-02 05:03:54,555 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-04-02 05:03:54,556 [JUnit] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-3
2020-04-02 05:03:54,557 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:35176
2020-04-02 05:03:54,557 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:35176
2020-04-02 05:03:54,557 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:35176
2020-04-02 05:03:54,557 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:36020
2020-04-02 05:03:54,558 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:35597
2020-04-02 05:03:54,558 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:35597
2020-04-02 05:03:54,558 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:35597
2020-04-02 05:03:54,558 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:38815
2020-04-02 05:03:54,559 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:46349
2020-04-02 05:03:54,559 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:46349
2020-04-02 05:03:54,559 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:46349
2020-04-02 05:03:54,559 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:43416
2020-04-02 05:03:54,559 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:37631
2020-04-02 05:03:54,559 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:37631
2020-04-02 05:03:54,559 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:37631
2020-04-02 05:03:54,559 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:39034
2020-04-02 05:03:54,581 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1d8aaf8ece6d:38843: State Store unavailable
2020-04-02 05:03:54,582 [JUnit] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:54,582 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3f3c966c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:54,595 [JUnit] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir.createCluster(TestRouterWebHDFSContractMkdir.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2020-04-02 05:03:54,598 [JUnit] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:54,598 [JUnit] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:54,598 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:54,602 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-04-02 05:03:54,603 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-04-02 05:03:54,603 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:54,603 [IPC Server listener on 38843] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38843: starting
2020-04-02 05:03:54,605 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(321)) - Router RPC up at: /0.0.0.0:38843
2020-04-02 05:03:54,612 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:54,613 [IPC Server listener on 34860] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34860: starting
2020-04-02 05:03:54,619 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for router at: http://0.0.0.0:0
2020-04-02 05:03:54,619 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:54,621 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:54,603 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:54,622 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:54,622 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-04-02 05:03:54,643 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:54,645 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:54,645 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-04-02 05:03:54,645 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:54,645 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:54,648 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:54,649 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:54,649 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44508
2020-04-02 05:03:54,649 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:54,662 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@467f77a5{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:54,678 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@420bc288{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:54,703 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:03:54,707 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6b5f8707{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-04-02 05:03:54,707 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@772485dd{HTTP/1.1,[http/1.1]}{0.0.0.0:44508}
2020-04-02 05:03:54,708 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @15150ms
2020-04-02 05:03:54,708 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:54,710 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:54,704 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:54,726 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:54,743 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:54,744 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:54,745 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-04-02 05:03:54,818 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-4
2020-04-02 05:03:54,818 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-4
2020-04-02 05:03:54,819 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-4
2020-04-02 05:03:54,820 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-4
2020-04-02 05:03:54,832 [JUnit] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState
2020-04-02 05:03:54,836 [JUnit] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:54,885 [JUnit] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir.createCluster(TestRouterWebHDFSContractMkdir.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2020-04-02 05:03:54,906 [JUnit] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:54,907 [JUnit] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:54,907 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:54,830 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1d8aaf8ece6d:38843: State Store unavailable
2020-04-02 05:03:54,865 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1d8aaf8ece6d:45777: State Store unavailable
2020-04-02 05:03:54,887 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@117632cf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:54,910 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-04-02 05:03:54,911 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:54,911 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:54,912 [IPC Server listener on 45777] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45777: starting
2020-04-02 05:03:54,913 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(321)) - Router RPC up at: /0.0.0.0:45777
2020-04-02 05:03:54,914 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:54,914 [IPC Server listener on 33764] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33764: starting
2020-04-02 05:03:54,923 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for router at: http://0.0.0.0:0
2020-04-02 05:03:54,923 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:54,925 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:54,930 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-04-02 05:03:54,930 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:54,931 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:54,932 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-04-02 05:03:54,932 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:54,932 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:54,933 [IPC Server handler 8 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:54,938 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:54,939 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:54,939 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37721
2020-04-02 05:03:54,939 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:54,943 [IPC Server handler 6 on 35176] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:54,911 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-04-02 05:03:55,018 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@59221b97{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:55,040 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a772895{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:55,042 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:55,050 [IPC Server handler 7 on 35597] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:55,050 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:03:55,056 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:55,056 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:55,063 [IPC Server handler 9 on 37631] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:55,067 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7726e185{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-04-02 05:03:55,069 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@aa5455e{HTTP/1.1,[http/1.1]}{0.0.0.0:37721}
2020-04-02 05:03:55,069 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @15512ms
2020-04-02 05:03:55,070 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:55,119 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:55,126 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:55,127 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:55,128 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-04-02 05:03:55,158 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-5
2020-04-02 05:03:55,158 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-5
2020-04-02 05:03:55,159 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-5
2020-04-02 05:03:55,159 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-5
2020-04-02 05:03:55,159 [JUnit] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-1
2020-04-02 05:03:55,160 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1d8aaf8ece6d:45777: State Store unavailable
2020-04-02 05:03:55,162 [IPC Server handler 5 on 35176] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:55,166 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1d8aaf8ece6d:36853: State Store unavailable
2020-04-02 05:03:55,166 [JUnit] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:55,166 [JUnit] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir.createCluster(TestRouterWebHDFSContractMkdir.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2020-04-02 05:03:55,168 [JUnit] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:55,168 [JUnit] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:55,168 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:55,169 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3b4ef7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:55,169 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-04-02 05:03:55,170 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-04-02 05:03:55,170 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:55,170 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:55,171 [IPC Server listener on 36853] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36853: starting
2020-04-02 05:03:55,172 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(321)) - Router RPC up at: /0.0.0.0:36853
2020-04-02 05:03:55,173 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:55,173 [IPC Server listener on 43313] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43313: starting
2020-04-02 05:03:55,214 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for router at: http://0.0.0.0:0
2020-04-02 05:03:55,214 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:55,226 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:55,249 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:55,254 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-04-02 05:03:55,254 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:55,256 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:55,256 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-04-02 05:03:55,256 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:55,256 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:55,258 [IPC Server handler 1 on 35597] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:55,259 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:03:55,259 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:55,259 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:55,259 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:55,260 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:55,261 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39509
2020-04-02 05:03:55,261 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:55,262 [IPC Server handler 5 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:55,278 [IPC Server handler 8 on 37631] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:55,298 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6979efad{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:55,302 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4a67318f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:55,390 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6e0d4a8{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-04-02 05:03:55,394 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@64d7b720{HTTP/1.1,[http/1.1]}{0.0.0.0:39509}
2020-04-02 05:03:55,394 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @15837ms
2020-04-02 05:03:55,394 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:55,397 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:55,411 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:55,411 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:55,425 [IPC Server handler 9 on 35597] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:55,426 [IPC Server handler 0 on 35176] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:55,430 [IPC Server handler 1 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:55,446 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-04-02 05:03:55,496 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-6
2020-04-02 05:03:55,496 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-6
2020-04-02 05:03:55,497 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-6
2020-04-02 05:03:55,497 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-6
2020-04-02 05:03:55,497 [JUnit] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-2
2020-04-02 05:03:55,498 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1d8aaf8ece6d:36853: State Store unavailable
2020-04-02 05:03:55,498 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1d8aaf8ece6d:43084: State Store unavailable
2020-04-02 05:03:55,498 [JUnit] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:55,498 [JUnit] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir.createCluster(TestRouterWebHDFSContractMkdir.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2020-04-02 05:03:55,508 [JUnit] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:55,509 [JUnit] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:55,509 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:55,509 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-04-02 05:03:55,510 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-04-02 05:03:55,522 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:55,522 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:55,554 [IPC Server listener on 43084] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43084: starting
2020-04-02 05:03:55,564 [IPC Server handler 0 on 37631] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:55,560 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4e7095ac] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:55,559 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(321)) - Router RPC up at: /0.0.0.0:43084
2020-04-02 05:03:55,579 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:55,579 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:03:55,579 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:55,581 [IPC Server listener on 42799] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42799: starting
2020-04-02 05:03:55,581 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:55,581 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for router at: http://0.0.0.0:0
2020-04-02 05:03:55,650 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:55,591 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:55,660 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:55,680 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-04-02 05:03:55,680 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:55,698 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:55,698 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-04-02 05:03:55,699 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:55,699 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:55,700 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:55,701 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:55,701 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33585
2020-04-02 05:03:55,701 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:55,708 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62e8f862{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:55,709 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3c49fab6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:55,758 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@420745d7{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-04-02 05:03:55,760 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7e11ab3d{HTTP/1.1,[http/1.1]}{0.0.0.0:33585}
2020-04-02 05:03:55,760 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @16203ms
2020-04-02 05:03:55,760 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:55,761 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:55,763 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:55,764 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:55,764 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-04-02 05:03:55,768 [IPC Server handler 7 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:55,768 [IPC Server handler 7 on 35176] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:55,771 [IPC Server handler 5 on 37631] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:55,778 [IPC Server handler 2 on 35597] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:55,862 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1d8aaf8ece6d:43084: State Store unavailable
2020-04-02 05:03:56,058 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-7
2020-04-02 05:03:56,074 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-7
2020-04-02 05:03:56,078 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-7
2020-04-02 05:03:56,091 [qtp957923719-171] ERROR jmx.JMXJsonServlet (JMXJsonServlet.java:writeAttribute(345)) - getting attribute CapacityTotal of Hadoop:service=NameNode,name=FSNamesystem-7 threw an exception
javax.management.RuntimeMBeanException: java.lang.NullPointerException
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.rethrow(DefaultMBeanServerInterceptor.java:839)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.rethrowMaybeMBeanException(DefaultMBeanServerInterceptor.java:852)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:651)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678)
	at org.apache.hadoop.jmx.JMXJsonServlet.writeAttribute(JMXJsonServlet.java:338)
	at org.apache.hadoop.jmx.JMXJsonServlet.listBeans(JMXJsonServlet.java:316)
	at org.apache.hadoop.jmx.JMXJsonServlet.doGet(JMXJsonServlet.java:210)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:687)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)
	at org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:110)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1605)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.eclipse.jetty.server.Server.handle(Server.java:539)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
	at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.federation.metrics.NamenodeBeanMetrics.getTotal(NamenodeBeanMetrics.java:215)
	at org.apache.hadoop.hdfs.server.federation.metrics.NamenodeBeanMetrics.getCapacityTotal(NamenodeBeanMetrics.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:72)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:276)
	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:112)
	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:46)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at javax.management.StandardMBean.getAttribute(StandardMBean.java:372)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647)
	... 38 more
2020-04-02 05:03:56,125 [qtp957923719-171] ERROR jmx.JMXJsonServlet (JMXJsonServlet.java:writeAttribute(345)) - getting attribute CapacityUsed of Hadoop:service=NameNode,name=FSNamesystem-7 threw an exception
javax.management.RuntimeMBeanException: java.lang.NullPointerException
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.rethrow(DefaultMBeanServerInterceptor.java:839)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.rethrowMaybeMBeanException(DefaultMBeanServerInterceptor.java:852)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:651)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678)
	at org.apache.hadoop.jmx.JMXJsonServlet.writeAttribute(JMXJsonServlet.java:338)
	at org.apache.hadoop.jmx.JMXJsonServlet.listBeans(JMXJsonServlet.java:316)
	at org.apache.hadoop.jmx.JMXJsonServlet.doGet(JMXJsonServlet.java:210)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:687)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)
	at org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:110)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1605)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.eclipse.jetty.server.Server.handle(Server.java:539)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
	at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.federation.metrics.NamenodeBeanMetrics.getUsed(NamenodeBeanMetrics.java:205)
	at org.apache.hadoop.hdfs.server.federation.metrics.NamenodeBeanMetrics.getCapacityUsed(NamenodeBeanMetrics.java:529)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:72)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:276)
	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:112)
	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:46)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at javax.management.StandardMBean.getAttribute(StandardMBean.java:372)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647)
	... 38 more
2020-04-02 05:03:56,099 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-7
2020-04-02 05:03:56,135 [qtp957923719-171] ERROR jmx.JMXJsonServlet (JMXJsonServlet.java:writeAttribute(345)) - getting attribute CapacityRemaining of Hadoop:service=NameNode,name=FSNamesystem-7 threw an exception
javax.management.RuntimeMBeanException: java.lang.NullPointerException
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.rethrow(DefaultMBeanServerInterceptor.java:839)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.rethrowMaybeMBeanException(DefaultMBeanServerInterceptor.java:852)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:651)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678)
	at org.apache.hadoop.jmx.JMXJsonServlet.writeAttribute(JMXJsonServlet.java:338)
	at org.apache.hadoop.jmx.JMXJsonServlet.listBeans(JMXJsonServlet.java:316)
	at org.apache.hadoop.jmx.JMXJsonServlet.doGet(JMXJsonServlet.java:210)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:687)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)
	at org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:110)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1605)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.eclipse.jetty.server.Server.handle(Server.java:539)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
	at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.federation.metrics.NamenodeBeanMetrics.getFree(NamenodeBeanMetrics.java:210)
	at org.apache.hadoop.hdfs.server.federation.metrics.NamenodeBeanMetrics.getCapacityRemaining(NamenodeBeanMetrics.java:524)
	at sun.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:72)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:276)
	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:112)
	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:46)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at javax.management.StandardMBean.getAttribute(StandardMBean.java:372)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647)
	... 38 more
2020-04-02 05:03:56,136 [JUnit] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-3
2020-04-02 05:03:56,137 [qtp957923719-171] ERROR jmx.JMXJsonServlet (JMXJsonServlet.java:writeAttribute(345)) - getting attribute ProvidedCapacityTotal of Hadoop:service=NameNode,name=FSNamesystem-7 threw an exception
javax.management.RuntimeMBeanException: java.lang.NullPointerException
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.rethrow(DefaultMBeanServerInterceptor.java:839)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.rethrowMaybeMBeanException(DefaultMBeanServerInterceptor.java:852)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:651)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678)
	at org.apache.hadoop.jmx.JMXJsonServlet.writeAttribute(JMXJsonServlet.java:338)
	at org.apache.hadoop.jmx.JMXJsonServlet.listBeans(JMXJsonServlet.java:316)
	at org.apache.hadoop.jmx.JMXJsonServlet.doGet(JMXJsonServlet.java:210)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:687)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)
	at org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:110)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1605)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.eclipse.jetty.server.Server.handle(Server.java:539)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
	at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.federation.metrics.NamenodeBeanMetrics.getProvidedCapacity(NamenodeBeanMetrics.java:220)
	at org.apache.hadoop.hdfs.server.federation.metrics.NamenodeBeanMetrics.getProvidedCapacityTotal(NamenodeBeanMetrics.java:534)
	at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:72)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:276)
	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:112)
	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:46)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at javax.management.StandardMBean.getAttribute(StandardMBean.java:372)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647)
	... 38 more
2020-04-02 05:03:56,234 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:56,238 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(471)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2020-04-02 05:03:56,342 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:03:56,346 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current
2020-04-02 05:03:56,346 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current
2020-04-02 05:03:56,347 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current
2020-04-02 05:03:56,347 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1225)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-04-02 05:03:56,366 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-04-02 05:03:56,412 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1236)) - Reprocessing replication and invalidation queues
2020-04-02 05:03:56,412 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:03:56,413 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1247)) - Will take over writing edit logs at txnid 1
2020-04-02 05:03:56,413 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:03:56,510 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:03:56,511 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:03:56,517 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:56,520 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(471)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2020-04-02 05:03:56,548 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:03:56,558 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current
2020-04-02 05:03:56,558 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current
2020-04-02 05:03:56,558 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current
2020-04-02 05:03:56,559 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1225)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-04-02 05:03:56,559 [CacheReplicationMonitor(1922427887)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:03:56,583 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-04-02 05:03:56,584 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:03:56,586 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 1d462b81-d264-4460-97f6-685a3cb75138) service to localhost/127.0.0.1:46349 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:56,792 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 1d462b81-d264-4460-97f6-685a3cb75138) service to localhost/127.0.0.1:46349
2020-04-02 05:03:56,590 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid be3e34c4-4a49-4457-8d5c-a1340f40b0a6) service to localhost/127.0.0.1:46349 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:56,827 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid be3e34c4-4a49-4457-8d5c-a1340f40b0a6) service to localhost/127.0.0.1:46349
2020-04-02 05:03:56,588 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82) service to localhost/127.0.0.1:46349 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:56,833 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82) service to localhost/127.0.0.1:46349
2020-04-02 05:03:56,586 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:03:56,833 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:03:56,833 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:03:56,833 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:03:56,833 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 420 msec
2020-04-02 05:03:56,838 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1236)) - Reprocessing replication and invalidation queues
2020-04-02 05:03:56,838 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:03:56,841 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1247)) - Will take over writing edit logs at txnid 1
2020-04-02 05:03:56,854 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:03:57,013 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 37c34b0d-ec3f-4635-b93e-4c5b1348268e) service to localhost/127.0.0.1:46349 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:57,013 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 37c34b0d-ec3f-4635-b93e-4c5b1348268e) service to localhost/127.0.0.1:46349
2020-04-02 05:03:57,134 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:03:57,138 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 4 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:03:57,159 [CacheReplicationMonitor(1166608155)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:03:57,208 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 1d462b81-d264-4460-97f6-685a3cb75138) service to localhost/127.0.0.1:35176 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:57,209 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 1d462b81-d264-4460-97f6-685a3cb75138) service to localhost/127.0.0.1:35176
2020-04-02 05:03:57,497 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:03:57,498 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:03:57,498 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:03:57,498 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:03:57,498 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:03:57,498 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 656 msec
2020-04-02 05:03:57,499 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 37c34b0d-ec3f-4635-b93e-4c5b1348268e) service to localhost/127.0.0.1:35176 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:57,499 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 37c34b0d-ec3f-4635-b93e-4c5b1348268e) service to localhost/127.0.0.1:35176
[msx] test Started org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir#testMkdirSlashHandling
[msx] unitTestCounterInClass = 0
2020-04-02 05:03:58,277 [Thread-472] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = webhdfs://0.0.0.0:37721 implemented by org.apache.hadoop.hdfs.web.WebHdfsFileSystem@6fb7987c
Apr 02, 2020 5:03:58 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.federation.router
  org.apache.hadoop.hdfs.web.resources
Apr 02, 2020 5:03:58 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.federation.router.RouterWebHdfsMethods
Apr 02, 2020 5:03:58 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
  class org.apache.hadoop.hdfs.web.resources.UserProvider
Apr 02, 2020 5:03:58 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2020-04-02 05:03:59,262 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82) service to localhost/127.0.0.1:35176 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:59,263 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82) service to localhost/127.0.0.1:35176
2020-04-02 05:03:59,304 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid be3e34c4-4a49-4457-8d5c-a1340f40b0a6) service to localhost/127.0.0.1:35176 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:59,304 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid be3e34c4-4a49-4457-8d5c-a1340f40b0a6) service to localhost/127.0.0.1:35176
2020-04-02 05:03:59,662 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:59,910 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1d8aaf8ece6d:38843: State Store unavailable
2020-04-02 05:03:59,911 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:04:00,160 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1d8aaf8ece6d:45777: State Store unavailable
2020-04-02 05:04:00,172 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:04:00,498 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1d8aaf8ece6d:36853: State Store unavailable
2020-04-02 05:04:00,526 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
Apr 02, 2020 5:04:00 AM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2020-04-02 05:04:00,863 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1d8aaf8ece6d:43084: State Store unavailable
2020-04-02 05:04:00,921 [IPC Server handler 8 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:01,013 [Thread-472] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - verify mkdir slash handling
2020-04-02 05:04:01,060 [IPC Server handler 2 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testMkdirSlashHandling/a	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:01,098 [IPC Server handler 5 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirSlashHandling/a	dst=null	perm=null	proto=rpc
2020-04-02 05:04:01,146 [IPC Server handler 1 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirSlashHandling/a	dst=null	perm=null	proto=rpc
2020-04-02 05:04:01,163 [IPC Server handler 0 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testMkdirSlashHandling/b	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:01,178 [IPC Server handler 3 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirSlashHandling/b	dst=null	perm=null	proto=rpc
2020-04-02 05:04:01,194 [IPC Server handler 7 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirSlashHandling/b	dst=null	perm=null	proto=rpc
2020-04-02 05:04:01,211 [IPC Server handler 4 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testMkdirSlashHandling/c	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:01,224 [IPC Server handler 9 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirSlashHandling/c	dst=null	perm=null	proto=rpc
2020-04-02 05:04:01,246 [IPC Server handler 8 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirSlashHandling/c	dst=null	perm=null	proto=rpc
2020-04-02 05:04:01,270 [IPC Server handler 6 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testMkdirSlashHandling/d	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:01,284 [IPC Server handler 2 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirSlashHandling/d	dst=null	perm=null	proto=rpc
2020-04-02 05:04:01,308 [IPC Server handler 5 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirSlashHandling/d	dst=null	perm=null	proto=rpc
2020-04-02 05:04:01,330 [IPC Server handler 1 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testMkdirSlashHandling/e	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:01,355 [IPC Server handler 0 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirSlashHandling/e	dst=null	perm=null	proto=rpc
2020-04-02 05:04:01,380 [IPC Server handler 3 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirSlashHandling/e	dst=null	perm=null	proto=rpc
2020-04-02 05:04:01,430 [IPC Server handler 7 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirSlashHandling/e	dst=null	perm=null	proto=rpc
2020-04-02 05:04:01,471 [IPC Server handler 4 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:01,515 [IPC Server handler 9 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir#testMkdirSlashHandling
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir#testMkdirSlashHandling
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir#testMkdirsDoesNotRemoveParentDirectories
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:01,572 [Thread-476] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = webhdfs://0.0.0.0:44508 implemented by org.apache.hadoop.hdfs.web.WebHdfsFileSystem@3797c6ff
Apr 02, 2020 5:04:01 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.federation.router
  org.apache.hadoop.hdfs.web.resources
Apr 02, 2020 5:04:01 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.federation.router.RouterWebHdfsMethods
Apr 02, 2020 5:04:01 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
  class org.apache.hadoop.hdfs.web.resources.UserProvider
Apr 02, 2020 5:04:01 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Apr 02, 2020 5:04:01 AM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2020-04-02 05:04:01,960 [IPC Server handler 8 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:01,974 [Thread-476] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Verify mkdir will make its parent existent
2020-04-02 05:04:01,997 [IPC Server handler 6 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testMkdirsDoesNotRemoveParentDirectories	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:02,038 [IPC Server handler 2 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testMkdirsDoesNotRemoveParentDirectories	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:02,055 [IPC Server handler 5 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,067 [IPC Server handler 1 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:02,090 [IPC Server handler 0 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,116 [IPC Server handler 3 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:02,136 [IPC Server handler 7 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,151 [IPC Server handler 4 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:02,198 [IPC Server handler 9 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,214 [IPC Server handler 8 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:02,256 [IPC Server handler 2 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,282 [IPC Server handler 5 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3/dir-4	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:02,290 [IPC Server handler 1 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3/dir-4	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,306 [IPC Server handler 3 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3/dir-4/dir-5	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:02,313 [IPC Server handler 4 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3/dir-4/dir-5	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,343 [IPC Server handler 8 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3/dir-4/dir-5/dir-6	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:02,362 [IPC Server handler 6 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3/dir-4/dir-5/dir-6	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,380 [IPC Server handler 2 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3/dir-4/dir-5/dir-6/dir-7	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:02,390 [IPC Server handler 5 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3/dir-4/dir-5/dir-6/dir-7	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,415 [IPC Server handler 1 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3/dir-4/dir-5/dir-6/dir-7/dir-8	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:02,429 [IPC Server handler 0 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3/dir-4/dir-5/dir-6/dir-7/dir-8	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,442 [IPC Server handler 3 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3/dir-4/dir-5/dir-6/dir-7/dir-8	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,463 [IPC Server handler 7 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3/dir-4/dir-5/dir-6/dir-7/dir-8	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,472 [IPC Server handler 4 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3/dir-4/dir-5/dir-6/dir-7	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,483 [IPC Server handler 9 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3/dir-4/dir-5/dir-6/dir-7	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,495 [IPC Server handler 8 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3/dir-4/dir-5/dir-6	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,507 [IPC Server handler 6 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3/dir-4/dir-5/dir-6	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,534 [IPC Server handler 2 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3/dir-4/dir-5	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,552 [IPC Server handler 5 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3/dir-4/dir-5	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,556 [IPC Server handler 6 on 35597] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,556 [IPC Server handler 9 on 35176] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,559 [IPC Server handler 4 on 35176] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,570 [IPC Server handler 2 on 37631] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,596 [IPC Server handler 6 on 37631] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,597 [IPC Server handler 3 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,598 [IPC Server handler 7 on 37631] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,642 [IPC Server handler 0 on 37631] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,691 [IPC Server handler 0 on 35176] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,691 [IPC Server handler 8 on 35176] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,726 [IPC Server handler 0 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3/dir-4	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,826 [IPC Server handler 7 on 35597] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,826 [IPC Server handler 7 on 35597] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,877 [IPC Server handler 5 on 35597] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,878 [IPC Server handler 9 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,879 [IPC Server handler 2 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,879 [IPC Server handler 2 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,985 [IPC Server handler 1 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3/dir-4	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,006 [IPC Server handler 3 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,017 [IPC Server handler 7 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2/dir-3	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,043 [IPC Server handler 9 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,058 [IPC Server handler 6 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1/dir-2	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,134 [IPC Server handler 2 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,144 [IPC Server handler 5 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0/dir-1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,158 [IPC Server handler 4 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,171 [IPC Server handler 3 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsDoesNotRemoveParentDirectories/dir-0	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,181 [IPC Server handler 7 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,188 [IPC Server handler 0 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir#testMkdirsDoesNotRemoveParentDirectories
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir#testMkdirsDoesNotRemoveParentDirectories
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir#testMkdirOverParentFile
[msx] perform reset as unitTestCounterInClass 2 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:03,215 [Thread-480] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = webhdfs://0.0.0.0:39509 implemented by org.apache.hadoop.hdfs.web.WebHdfsFileSystem@40b0ff49
Apr 02, 2020 5:04:03 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.federation.router
  org.apache.hadoop.hdfs.web.resources
Apr 02, 2020 5:04:03 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.federation.router.RouterWebHdfsMethods
Apr 02, 2020 5:04:03 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
  class org.apache.hadoop.hdfs.web.resources.UserProvider
Apr 02, 2020 5:04:03 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Apr 02, 2020 5:04:03 AM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2020-04-02 05:04:03,626 [IPC Server handler 9 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:03,646 [Thread-480] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - try to mkdir where a parent is a file
Apr 02, 2020 5:04:03 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.namenode.web.resources
  org.apache.hadoop.hdfs.web.resources
Apr 02, 2020 5:04:03 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods
Apr 02, 2020 5:04:03 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
  class org.apache.hadoop.hdfs.web.resources.UserProvider
Apr 02, 2020 5:04:03 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Apr 02, 2020 5:04:03 AM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2020-04-02 05:04:04,663 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:04:04,676 [IPC Server handler 6 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testMkdirOverParentFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:04,716 [nioEventLoopGroup-7-1] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/test/testMkdirOverParentFile?op=CREATE&user.name=root&namenoderpcaddress=1d8aaf8ece6d:36853&blocksize=134217728&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=3&unmaskedpermission=666 201
2020-04-02 05:04:04,774 [IPC Server handler 1 on 46349] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:33839, 127.0.0.1:41106, 127.0.0.1:45284 for /test/testMkdirOverParentFile
2020-04-02 05:04:04,895 [DataXceiver for client DFSClient_NONMAPREDUCE_238458951_694 at /127.0.0.1:42204 [Receiving block BP-2016245141-172.17.0.9-1585803822804:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2016245141-172.17.0.9-1585803822804:blk_1073741825_1001 src: /127.0.0.1:42204 dest: /127.0.0.1:33839
2020-04-02 05:04:04,912 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:04:04,913 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1d8aaf8ece6d:38843: State Store unavailable
2020-04-02 05:04:04,932 [DataXceiver for client DFSClient_NONMAPREDUCE_238458951_694 at /127.0.0.1:51542 [Receiving block BP-2016245141-172.17.0.9-1585803822804:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2016245141-172.17.0.9-1585803822804:blk_1073741825_1001 src: /127.0.0.1:51542 dest: /127.0.0.1:41106
2020-04-02 05:04:04,940 [DataXceiver for client DFSClient_NONMAPREDUCE_238458951_694 at /127.0.0.1:40734 [Receiving block BP-2016245141-172.17.0.9-1585803822804:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2016245141-172.17.0.9-1585803822804:blk_1073741825_1001 src: /127.0.0.1:40734 dest: /127.0.0.1:45284
2020-04-02 05:04:05,058 [PacketResponder: BP-2016245141-172.17.0.9-1585803822804:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40734, dest: /127.0.0.1:45284, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_238458951_694, offset: 0, srvID: 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82, blockid: BP-2016245141-172.17.0.9-1585803822804:blk_1073741825_1001, duration(ns): 71376374
2020-04-02 05:04:05,058 [PacketResponder: BP-2016245141-172.17.0.9-1585803822804:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2016245141-172.17.0.9-1585803822804:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:05,075 [PacketResponder: BP-2016245141-172.17.0.9-1585803822804:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45284]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51542, dest: /127.0.0.1:41106, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_238458951_694, offset: 0, srvID: 1d462b81-d264-4460-97f6-685a3cb75138, blockid: BP-2016245141-172.17.0.9-1585803822804:blk_1073741825_1001, duration(ns): 91587594
2020-04-02 05:04:05,076 [PacketResponder: BP-2016245141-172.17.0.9-1585803822804:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45284]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2016245141-172.17.0.9-1585803822804:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45284] terminating
2020-04-02 05:04:05,112 [PacketResponder: BP-2016245141-172.17.0.9-1585803822804:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41106, 127.0.0.1:45284]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42204, dest: /127.0.0.1:33839, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_238458951_694, offset: 0, srvID: 37c34b0d-ec3f-4635-b93e-4c5b1348268e, blockid: BP-2016245141-172.17.0.9-1585803822804:blk_1073741825_1001, duration(ns): 104292810
2020-04-02 05:04:05,112 [PacketResponder: BP-2016245141-172.17.0.9-1585803822804:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41106, 127.0.0.1:45284]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2016245141-172.17.0.9-1585803822804:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41106, 127.0.0.1:45284] terminating
2020-04-02 05:04:05,135 [IPC Server handler 4 on 46349] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/testMkdirOverParentFile is closed by DFSClient_NONMAPREDUCE_238458951_694
2020-04-02 05:04:05,155 [IPC Server handler 5 on 46349] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 5 on 46349, call Call#292 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 127.0.0.1:47744: org.apache.hadoop.fs.ParentNotDirectoryException: /test/testMkdirOverParentFile (is not a directory)
2020-04-02 05:04:05,162 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1d8aaf8ece6d:45777: State Store unavailable
2020-04-02 05:04:05,172 [IPC Server handler 2 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirOverParentFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,172 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:04:05,180 [IPC Server handler 9 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirOverParentFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,221 [IPC Server handler 6 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,237 [IPC Server handler 5 on 35176] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,246 [IPC Server handler 8 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirOverParentFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,260 [IPC Server handler 0 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testMkdirOverParentFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,295 [IPC Server handler 7 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testMkdirOverParentFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,388 [nioEventLoopGroup-3-1] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 GET /webhdfs/v1/test/testMkdirOverParentFile?op=OPEN&user.name=root&namenoderpcaddress=1d8aaf8ece6d:36853&buffersize=4096&offset=0 200
2020-04-02 05:04:05,419 [IPC Server handler 9 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirOverParentFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,430 [IPC Server handler 6 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirOverParentFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,440 [IPC Server handler 1 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test/testMkdirOverParentFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,452 [IPC Server handler 8 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,465 [IPC Server handler 0 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirOverParentFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,475 [IPC Server handler 7 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,481 [IPC Server handler 3 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir#testMkdirOverParentFile
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir#testMkdirOverParentFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir#testMkdirsPopulatingAllNonexistentAncestors
[msx] perform reset as unitTestCounterInClass 3 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:05,498 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1d8aaf8ece6d:36853: State Store unavailable
2020-04-02 05:04:05,515 [Thread-496] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = webhdfs://0.0.0.0:33585 implemented by org.apache.hadoop.hdfs.web.WebHdfsFileSystem@6d44669
2020-04-02 05:04:05,527 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
Apr 02, 2020 5:04:05 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.federation.router
  org.apache.hadoop.hdfs.web.resources
Apr 02, 2020 5:04:05 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.federation.router.RouterWebHdfsMethods
Apr 02, 2020 5:04:05 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
  class org.apache.hadoop.hdfs.web.resources.UserProvider
Apr 02, 2020 5:04:05 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Apr 02, 2020 5:04:05 AM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2020-04-02 05:04:05,806 [IPC Server handler 4 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:05,814 [Thread-496] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Verify mkdir will populate all its non-existent ancestors
2020-04-02 05:04:05,833 [IPC Server handler 5 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testMkdirsPopulatingAllNonexistentAncestors	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:05,845 [IPC Server handler 2 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsPopulatingAllNonexistentAncestors	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,864 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1d8aaf8ece6d:43084: State Store unavailable
2020-04-02 05:04:05,869 [IPC Server handler 9 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testMkdirsPopulatingAllNonexistentAncestors/a/b/c/d/e/f/g/h/i/j/k/L	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:05,880 [IPC Server handler 6 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsPopulatingAllNonexistentAncestors/a/b/c/d/e/f/g/h/i/j/k/L	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,890 [IPC Server handler 1 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsPopulatingAllNonexistentAncestors/a/b/c/d/e/f/g/h/i/j/k	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,902 [IPC Server handler 8 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsPopulatingAllNonexistentAncestors/a/b/c/d/e/f/g/h/i/j	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,913 [IPC Server handler 0 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsPopulatingAllNonexistentAncestors/a/b/c/d/e/f/g/h/i	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,929 [IPC Server handler 7 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsPopulatingAllNonexistentAncestors/a/b/c/d/e/f/g/h	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,939 [IPC Server handler 3 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsPopulatingAllNonexistentAncestors/a/b/c/d/e/f/g	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,955 [IPC Server handler 4 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsPopulatingAllNonexistentAncestors/a/b/c/d/e/f	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,962 [IPC Server handler 5 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsPopulatingAllNonexistentAncestors/a/b/c/d/e	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,973 [IPC Server handler 2 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsPopulatingAllNonexistentAncestors/a/b/c/d	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,980 [IPC Server handler 9 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsPopulatingAllNonexistentAncestors/a/b/c	dst=null	perm=null	proto=rpc
2020-04-02 05:04:05,994 [IPC Server handler 6 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsPopulatingAllNonexistentAncestors/a/b	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,003 [IPC Server handler 1 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkdirsPopulatingAllNonexistentAncestors/a	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,022 [IPC Server handler 8 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,031 [IPC Server handler 0 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir#testMkdirsPopulatingAllNonexistentAncestors
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir#testMkdirsPopulatingAllNonexistentAncestors
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir#testMkDirRmDir
[msx] perform reset as unitTestCounterInClass 4 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:06,053 [Thread-499] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = webhdfs://0.0.0.0:39509 implemented by org.apache.hadoop.hdfs.web.WebHdfsFileSystem@40b0ff49
2020-04-02 05:04:06,071 [IPC Server handler 7 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:06,083 [IPC Server handler 3 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkDirRmDir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,092 [IPC Server handler 4 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testMkDirRmDir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:06,108 [IPC Server handler 5 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkDirRmDir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,118 [IPC Server handler 2 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkDirRmDir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,125 [IPC Server handler 9 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test/testMkDirRmDir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,139 [IPC Server handler 6 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,149 [IPC Server handler 1 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkDirRmDir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,159 [IPC Server handler 8 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,169 [IPC Server handler 0 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir#testMkDirRmDir
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir#testMkDirRmDir
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir#testNoMkdirOverFile
[msx] perform reset as unitTestCounterInClass 5 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:06,189 [Thread-500] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = webhdfs://0.0.0.0:37721 implemented by org.apache.hadoop.hdfs.web.WebHdfsFileSystem@6fb7987c
2020-04-02 05:04:06,206 [IPC Server handler 7 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:06,212 [Thread-500] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - try to mkdir over a file
2020-04-02 05:04:06,263 [IPC Server handler 4 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testNoMkdirOverFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:06,278 [nioEventLoopGroup-3-2] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/test/testNoMkdirOverFile?op=CREATE&user.name=root&namenoderpcaddress=1d8aaf8ece6d:45777&blocksize=134217728&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=3&unmaskedpermission=666 201
2020-04-02 05:04:06,300 [IPC Server handler 5 on 46349] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:41106, 127.0.0.1:45284, 127.0.0.1:45081 for /test/testNoMkdirOverFile
2020-04-02 05:04:06,325 [DataXceiver for client DFSClient_NONMAPREDUCE_35731971_299 at /127.0.0.1:51698 [Receiving block BP-2016245141-172.17.0.9-1585803822804:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2016245141-172.17.0.9-1585803822804:blk_1073741826_1002 src: /127.0.0.1:51698 dest: /127.0.0.1:41106
2020-04-02 05:04:06,342 [DataXceiver for client DFSClient_NONMAPREDUCE_35731971_299 at /127.0.0.1:40886 [Receiving block BP-2016245141-172.17.0.9-1585803822804:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2016245141-172.17.0.9-1585803822804:blk_1073741826_1002 src: /127.0.0.1:40886 dest: /127.0.0.1:45284
2020-04-02 05:04:06,350 [DataXceiver for client DFSClient_NONMAPREDUCE_35731971_299 at /127.0.0.1:59668 [Receiving block BP-2016245141-172.17.0.9-1585803822804:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2016245141-172.17.0.9-1585803822804:blk_1073741826_1002 src: /127.0.0.1:59668 dest: /127.0.0.1:45081
2020-04-02 05:04:06,431 [PacketResponder: BP-2016245141-172.17.0.9-1585803822804:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59668, dest: /127.0.0.1:45081, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_35731971_299, offset: 0, srvID: be3e34c4-4a49-4457-8d5c-a1340f40b0a6, blockid: BP-2016245141-172.17.0.9-1585803822804:blk_1073741826_1002, duration(ns): 73090896
2020-04-02 05:04:06,431 [PacketResponder: BP-2016245141-172.17.0.9-1585803822804:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2016245141-172.17.0.9-1585803822804:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:06,447 [PacketResponder: BP-2016245141-172.17.0.9-1585803822804:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45081]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40886, dest: /127.0.0.1:45284, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_35731971_299, offset: 0, srvID: 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82, blockid: BP-2016245141-172.17.0.9-1585803822804:blk_1073741826_1002, duration(ns): 72480216
2020-04-02 05:04:06,447 [PacketResponder: BP-2016245141-172.17.0.9-1585803822804:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45081]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2016245141-172.17.0.9-1585803822804:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45081] terminating
2020-04-02 05:04:06,458 [PacketResponder: BP-2016245141-172.17.0.9-1585803822804:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:45284, 127.0.0.1:45081]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51698, dest: /127.0.0.1:41106, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_35731971_299, offset: 0, srvID: 1d462b81-d264-4460-97f6-685a3cb75138, blockid: BP-2016245141-172.17.0.9-1585803822804:blk_1073741826_1002, duration(ns): 86297839
2020-04-02 05:04:06,459 [PacketResponder: BP-2016245141-172.17.0.9-1585803822804:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:45284, 127.0.0.1:45081]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2016245141-172.17.0.9-1585803822804:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:45284, 127.0.0.1:45081] terminating
2020-04-02 05:04:06,479 [IPC Server handler 8 on 46349] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/testNoMkdirOverFile is closed by DFSClient_NONMAPREDUCE_35731971_299
2020-04-02 05:04:06,496 [IPC Server handler 0 on 46349] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 0 on 46349, call Call#369 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 127.0.0.1:47448: org.apache.hadoop.fs.FileAlreadyExistsException: Path is not a directory: /test/testNoMkdirOverFile
2020-04-02 05:04:06,515 [IPC Server handler 7 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testNoMkdirOverFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,522 [IPC Server handler 3 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testNoMkdirOverFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,540 [IPC Server handler 4 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,575 [IPC Server handler 2 on 35176] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,585 [IPC Server handler 5 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testNoMkdirOverFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,589 [IPC Server handler 2 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testNoMkdirOverFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,610 [IPC Server handler 6 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testNoMkdirOverFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,629 [nioEventLoopGroup-5-1] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 GET /webhdfs/v1/test/testNoMkdirOverFile?op=OPEN&user.name=root&namenoderpcaddress=1d8aaf8ece6d:45777&buffersize=4096&offset=0 200
2020-04-02 05:04:06,635 [IPC Server handler 1 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testNoMkdirOverFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,643 [IPC Server handler 8 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testNoMkdirOverFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,655 [IPC Server handler 0 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test/testNoMkdirOverFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,669 [IPC Server handler 7 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,692 [IPC Server handler 3 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testNoMkdirOverFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,706 [IPC Server handler 4 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,726 [IPC Server handler 5 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir#testNoMkdirOverFile
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir#testNoMkdirOverFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir#testMkDirRmRfDir
[msx] perform reset as unitTestCounterInClass 6 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:06,757 [Thread-513] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = webhdfs://0.0.0.0:33585 implemented by org.apache.hadoop.hdfs.web.WebHdfsFileSystem@6d44669
2020-04-02 05:04:06,774 [IPC Server handler 2 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:06,777 [Thread-513] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - create a directory then recursive delete it
2020-04-02 05:04:06,787 [IPC Server handler 6 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkDirRmRfDir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,796 [IPC Server handler 9 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testMkDirRmRfDir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:06,803 [IPC Server handler 1 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkDirRmRfDir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,812 [IPC Server handler 8 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkDirRmRfDir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,822 [IPC Server handler 0 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test/testMkDirRmRfDir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,834 [IPC Server handler 7 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,843 [IPC Server handler 3 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testMkDirRmRfDir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,850 [IPC Server handler 4 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,858 [IPC Server handler 5 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir#testMkDirRmRfDir
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir#testMkDirRmRfDir
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:06,865 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:04:06,866 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 3
2020-04-02 05:04:06,866 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 32843 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:06,866 [JUnit] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:06,867 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4a9419d7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:06,882 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-009ae7d5-6bbd-4558-89d3-f7832539d9ec) exiting.
2020-04-02 05:04:06,885 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-b04f45b7-2efa-4c1e-bd57-402c44bbd21f) exiting.
2020-04-02 05:04:06,990 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@40f33492{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:06,998 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4fbdc0f0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:06,998 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5c77053b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:06,999 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@21a5fd96{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:07,038 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 32843
2020-04-02 05:04:07,075 [IPC Server listener on 32843] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 32843
2020-04-02 05:04:07,080 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:07,080 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 1d462b81-d264-4460-97f6-685a3cb75138) service to localhost/127.0.0.1:46349
2020-04-02 05:04:07,081 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:07,084 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 1d462b81-d264-4460-97f6-685a3cb75138) service to localhost/127.0.0.1:35597
2020-04-02 05:04:07,086 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:07,086 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 1d462b81-d264-4460-97f6-685a3cb75138) service to localhost/127.0.0.1:37631
2020-04-02 05:04:07,087 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 1d462b81-d264-4460-97f6-685a3cb75138)
2020-04-02 05:04:07,087 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:04:07,086 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:07,091 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 1d462b81-d264-4460-97f6-685a3cb75138) service to localhost/127.0.0.1:35176
2020-04-02 05:04:07,091 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 1d462b81-d264-4460-97f6-685a3cb75138)
2020-04-02 05:04:07,102 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:07,102 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-2016245141-172.17.0.9-1585803822804] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:07,125 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:04:07,118 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-2016245141-172.17.0.9-1585803822804] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:07,165 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:07,165 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:07,167 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:07,167 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1514103897-172.17.0.9-1585803826583] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:07,168 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:07,204 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:07,205 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:04:07,205 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 36669 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:07,205 [JUnit] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:07,206 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1df98368] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:07,207 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-22156fcf-6c04-460f-a478-efbd7b0cfc97) exiting.
2020-04-02 05:04:07,207 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-02748c20-2ca5-4730-a651-f95813f8cec5) exiting.
2020-04-02 05:04:07,218 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1514103897-172.17.0.9-1585803826583] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:07,414 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@486be205{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:07,422 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@f713686{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:07,422 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2427e004{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:07,422 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@681aad3b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:07,425 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36669
2020-04-02 05:04:07,458 [IPC Server listener on 36669] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36669
2020-04-02 05:04:07,458 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:07,459 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid be3e34c4-4a49-4457-8d5c-a1340f40b0a6) service to localhost/127.0.0.1:35176
2020-04-02 05:04:07,458 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:07,458 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:07,458 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:07,459 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid be3e34c4-4a49-4457-8d5c-a1340f40b0a6) service to localhost/127.0.0.1:46349
2020-04-02 05:04:07,460 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:07,460 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid be3e34c4-4a49-4457-8d5c-a1340f40b0a6) service to localhost/127.0.0.1:37631
2020-04-02 05:04:07,460 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid be3e34c4-4a49-4457-8d5c-a1340f40b0a6)
2020-04-02 05:04:07,460 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:04:07,459 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid be3e34c4-4a49-4457-8d5c-a1340f40b0a6) service to localhost/127.0.0.1:35597
2020-04-02 05:04:07,471 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid be3e34c4-4a49-4457-8d5c-a1340f40b0a6)
2020-04-02 05:04:07,479 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-2016245141-172.17.0.9-1585803822804] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:07,488 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-2016245141-172.17.0.9-1585803822804] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:07,498 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:04:07,504 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:07,504 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:07,508 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:07,508 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:07,518 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1514103897-172.17.0.9-1585803826583] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:07,537 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1514103897-172.17.0.9-1585803826583] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:07,553 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:07,553 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:04:07,553 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 37055 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:07,554 [JUnit] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:07,557 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-d2d44c79-d51a-414b-a564-efaee6e2dfb5) exiting.
2020-04-02 05:04:07,559 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-ede8edd0-5de5-4e02-9ddd-7561e4eadf59) exiting.
2020-04-02 05:04:07,558 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@514eedd8] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:07,663 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4b629f13{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:07,666 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@70925b45{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:07,667 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2e185cd7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:07,667 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@466cf502{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:07,669 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37055
2020-04-02 05:04:07,692 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:07,693 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:07,693 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82) service to localhost/127.0.0.1:35176
2020-04-02 05:04:07,694 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:07,694 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82) service to localhost/127.0.0.1:46349
2020-04-02 05:04:07,694 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:07,694 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82) service to localhost/127.0.0.1:37631
2020-04-02 05:04:07,695 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82)
2020-04-02 05:04:07,695 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:04:07,705 [IPC Server listener on 37055] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37055
2020-04-02 05:04:07,716 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:07,716 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82) service to localhost/127.0.0.1:35597
2020-04-02 05:04:07,716 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 5d2ec8b3-b3d6-4fb1-9fcb-a295fcd25c82)
2020-04-02 05:04:07,724 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-2016245141-172.17.0.9-1585803822804] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:07,736 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:04:07,742 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-2016245141-172.17.0.9-1585803822804] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:07,758 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:07,758 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:07,777 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1514103897-172.17.0.9-1585803826583] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:07,783 [IPC Server handler 7 on 35176] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:07,791 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:07,798 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:07,810 [IPC Server handler 4 on 37631] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:07,858 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1514103897-172.17.0.9-1585803826583] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:07,864 [IPC Server handler 9 on 35597] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:07,879 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:07,879 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:04:07,879 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 38342 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:07,879 [JUnit] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:07,882 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2e54db99] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:07,892 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-90599705-ceb0-48a2-8083-2c6b6280bd4b) exiting.
2020-04-02 05:04:07,894 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-b6cc6c14-c015-45c1-b2b6-a7fbd9456e9e) exiting.
2020-04-02 05:04:07,903 [IPC Server handler 6 on 35176] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:08,019 [IPC Server handler 6 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:08,061 [IPC Server handler 1 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:08,063 [IPC Server handler 2 on 37631] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:08,063 [IPC Server handler 2 on 35597] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:08,063 [IPC Server handler 8 on 37631] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:08,063 [IPC Server handler 4 on 35597] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:08,064 [IPC Server handler 4 on 35597] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:08,101 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1d7f7be7{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:08,142 [IPC Server handler 3 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:08,142 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@42f3156d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:08,154 [IPC Server handler 2 on 35176] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:08,155 [IPC Server handler 0 on 35176] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:08,181 [IPC Server handler 0 on 46349] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:08,210 [IPC Server handler 7 on 37631] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:08,214 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3ce3db41{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:08,215 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@38f57b3d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:08,237 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38342
2020-04-02 05:04:08,247 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35597] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 37c34b0d-ec3f-4635-b93e-4c5b1348268e) service to localhost/127.0.0.1:35597
2020-04-02 05:04:08,247 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:37631] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 37c34b0d-ec3f-4635-b93e-4c5b1348268e) service to localhost/127.0.0.1:37631
2020-04-02 05:04:08,247 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 37c34b0d-ec3f-4635-b93e-4c5b1348268e) service to localhost/127.0.0.1:35176
2020-04-02 05:04:08,272 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1514103897-172.17.0.9-1585803826583 (Datanode Uuid 37c34b0d-ec3f-4635-b93e-4c5b1348268e)
2020-04-02 05:04:08,272 [BP-1514103897-172.17.0.9-1585803826583 heartbeating to localhost/127.0.0.1:35176] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1514103897-172.17.0.9-1585803826583
2020-04-02 05:04:08,281 [IPC Server listener on 38342] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38342
2020-04-02 05:04:08,282 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:08,282 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:08,283 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 37c34b0d-ec3f-4635-b93e-4c5b1348268e) service to localhost/127.0.0.1:46349
2020-04-02 05:04:08,283 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2016245141-172.17.0.9-1585803822804 (Datanode Uuid 37c34b0d-ec3f-4635-b93e-4c5b1348268e)
2020-04-02 05:04:08,289 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1514103897-172.17.0.9-1585803826583] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:08,326 [BP-2016245141-172.17.0.9-1585803822804 heartbeating to localhost/127.0.0.1:46349] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2016245141-172.17.0.9-1585803822804
2020-04-02 05:04:08,326 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1514103897-172.17.0.9-1585803826583] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:08,353 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-2016245141-172.17.0.9-1585803822804] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:08,368 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-2016245141-172.17.0.9-1585803822804] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:08,401 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:08,401 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:08,405 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:08,406 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:08,418 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:08,418 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:04:08,418 [JUnit] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 46349 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:08,419 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:08,441 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 60
2020-04-02 05:04:08,441 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@76f10035] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:04:08,441 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 61 Total time for transactions(ms): 108 Number of transactions batched in Syncs: 15 Number of syncs: 47 SyncTimes(ms): 22 3 19 
2020-04-02 05:04:08,442 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5ab9b447] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:04:08,443 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current/edits_0000000000000000001-0000000000000000061
2020-04-02 05:04:08,444 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000061
2020-04-02 05:04:08,445 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000061
2020-04-02 05:04:08,445 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:04:08,446 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46349
2020-04-02 05:04:08,452 [CacheReplicationMonitor(1922427887)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:04:08,459 [IPC Server listener on 46349] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46349
2020-04-02 05:04:08,467 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:08,468 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:04:08,477 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:04:08,535 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:08,535 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:04:08,539 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@73d983ea{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:04:08,555 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@d771cc9{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:08,556 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6a57ae10{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:08,557 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7b7fdc8{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:08,576 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:04:08,576 [JUnit] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 37631 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:08,576 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:04:08,582 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(471)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2020-04-02 05:04:08,586 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37631
2020-04-02 05:04:08,594 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:04:08,598 [IPC Server listener on 37631] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37631
2020-04-02 05:04:08,598 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:04:08,598 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:08,612 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:08,612 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:04:08,619 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1f2f9244{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:04:08,642 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4c4d27c8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:08,642 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2cae1042{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:08,643 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2b5825fa{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:08,647 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:04:08,648 [JUnit] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 35176 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:08,648 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:08,648 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 1
2020-04-02 05:04:08,650 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@15b986cd] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:04:08,650 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@6bb7cce7] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:04:08,664 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 154 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 69 22 10 
2020-04-02 05:04:08,664 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current/edits_0000000000000000001-0000000000000000002
2020-04-02 05:04:08,665 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/edits_0000000000000000001-0000000000000000002
2020-04-02 05:04:08,666 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/edits_0000000000000000001-0000000000000000002
2020-04-02 05:04:08,667 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:04:08,667 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35176
2020-04-02 05:04:08,677 [IPC Server listener on 35176] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35176
2020-04-02 05:04:08,681 [CacheReplicationMonitor(1166608155)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:04:08,684 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:08,689 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:04:08,690 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:04:08,712 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:08,712 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:04:08,714 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6b9ce1bf{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:04:08,726 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@61884cb1{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:08,727 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5c3b6c6e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:08,727 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@75c9e76b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:08,763 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:04:08,763 [JUnit] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 35597 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:08,763 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:04:08,764 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(471)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2020-04-02 05:04:08,766 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35597
2020-04-02 05:04:08,766 [IPC Server listener on 35597] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35597
2020-04-02 05:04:08,770 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:04:08,774 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:04:08,773 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:08,812 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:08,813 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:04:08,826 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@30f5a68a{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:04:08,829 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1e1d3956{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:08,830 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7894f09b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:08,830 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2ece4966{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:08,859 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1d8aaf8ece6d:38843: State Store unavailable
2020-04-02 05:04:08,913 [Thread-520] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-04-02 05:04:08,914 [Thread-520] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-04-02 05:04:08,929 [Thread-520] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-04-02 05:04:08,929 [Thread-520] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:04:08,939 [Thread-520] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-04-02 05:04:08,939 [Thread-520] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:04:08,957 [Thread-520] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-04-02 05:04:08,957 [Thread-520] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:04:08,969 [Thread-520] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-04-02 05:04:08,969 [Thread-520] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:04:08,987 [Thread-520] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6b5f8707{/,null,UNAVAILABLE}{/router}
2020-04-02 05:04:08,992 [Thread-520] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@772485dd{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-02 05:04:09,008 [Thread-520] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@420bc288{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:09,013 [Thread-520] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@467f77a5{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:09,035 [Thread-520] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34860
2020-04-02 05:04:09,064 [IPC Server listener on 34860] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34860
2020-04-02 05:04:09,073 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:09,073 [Thread-520] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38843
2020-04-02 05:04:09,084 [IPC Server listener on 38843] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38843
2020-04-02 05:04:09,084 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:09,145 [Thread-520] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-04-02 05:04:09,178 [Thread-520] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-04-02 05:04:09,206 [Thread-520] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-04-02 05:04:09,206 [Thread-520] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-04-02 05:04:09,861 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1d8aaf8ece6d:45777: State Store unavailable
2020-04-02 05:04:09,875 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-04-02 05:04:09,878 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-04-02 05:04:09,884 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-04-02 05:04:09,884 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:04:09,889 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-04-02 05:04:09,890 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:04:09,900 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-04-02 05:04:09,901 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:04:09,905 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-04-02 05:04:09,906 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:04:09,913 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:04:09,920 [Thread-521] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7726e185{/,null,UNAVAILABLE}{/router}
2020-04-02 05:04:09,928 [Thread-521] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@aa5455e{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-02 05:04:09,936 [Thread-521] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5a772895{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:09,944 [Thread-521] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@59221b97{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:09,949 [Thread-521] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33764
2020-04-02 05:04:09,949 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:09,950 [IPC Server listener on 33764] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33764
2020-04-02 05:04:09,954 [Thread-521] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45777
2020-04-02 05:04:09,956 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:09,956 [Thread-521] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping Router metrics system...
2020-04-02 05:04:09,958 [IPC Server listener on 45777] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45777
2020-04-02 05:04:09,983 [Thread-521] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - Router metrics system stopped.
2020-04-02 05:04:09,993 [Thread-521] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - Router metrics system shutdown complete.
2020-04-02 05:04:09,998 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-04-02 05:04:09,998 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-04-02 05:04:10,000 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-04-02 05:04:10,000 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-04-02 05:04:10,173 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:04:10,499 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1d8aaf8ece6d:36853: State Store unavailable
2020-04-02 05:04:10,528 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:04:10,856 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1d8aaf8ece6d:36853: State Store unavailable
2020-04-02 05:04:10,856 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-04-02 05:04:10,857 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-04-02 05:04:10,857 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-04-02 05:04:10,858 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:04:10,858 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-04-02 05:04:10,858 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:04:10,859 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-04-02 05:04:10,859 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:04:10,861 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-04-02 05:04:10,861 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:04:10,863 [Thread-522] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6e0d4a8{/,null,UNAVAILABLE}{/router}
2020-04-02 05:04:10,864 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1d8aaf8ece6d:43084: State Store unavailable
2020-04-02 05:04:10,873 [Thread-522] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@64d7b720{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-02 05:04:10,878 [Thread-522] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4a67318f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:10,879 [Thread-522] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6979efad{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:10,886 [Thread-522] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43313
2020-04-02 05:04:10,890 [IPC Server listener on 43313] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43313
2020-04-02 05:04:10,890 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:10,892 [Thread-522] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36853
2020-04-02 05:04:10,892 [IPC Server listener on 36853] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36853
2020-04-02 05:04:10,892 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:10,895 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-04-02 05:04:10,897 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-04-02 05:04:10,900 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-04-02 05:04:10,900 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-04-02 05:04:11,856 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1d8aaf8ece6d:43084: State Store unavailable
2020-04-02 05:04:11,857 [Thread-527] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-04-02 05:04:11,858 [Thread-527] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-04-02 05:04:11,858 [Thread-527] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-04-02 05:04:11,859 [Thread-527] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:04:11,859 [Thread-527] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-04-02 05:04:11,859 [Thread-527] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:04:11,860 [Thread-527] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-04-02 05:04:11,860 [Thread-527] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:04:11,860 [Thread-527] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-04-02 05:04:11,860 [Thread-527] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:04:11,864 [Thread-527] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@420745d7{/,null,UNAVAILABLE}{/router}
2020-04-02 05:04:11,886 [Thread-527] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7e11ab3d{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-02 05:04:11,888 [Thread-527] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3c49fab6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:11,894 [Thread-527] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62e8f862{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:11,911 [Thread-527] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42799
2020-04-02 05:04:11,911 [IPC Server listener on 42799] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42799
2020-04-02 05:04:11,912 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:11,913 [Thread-527] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43084
2020-04-02 05:04:11,914 [IPC Server listener on 43084] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43084
2020-04-02 05:04:11,915 [Thread-527] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-04-02 05:04:11,916 [Thread-527] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-04-02 05:04:11,916 [Thread-527] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-04-02 05:04:11,916 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:11,916 [Thread-527] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
[msx] all testRunFinished

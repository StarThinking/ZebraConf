[msx] before_class
2020-04-02 05:03:51,349 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=4
Formatting using clusterid: testClusterID
2020-04-02 05:03:52,097 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:52,112 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:52,113 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:52,115 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:52,135 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:52,135 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:52,136 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:52,137 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:03:52,196 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:52,203 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:03:52,204 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:52,204 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:52,210 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:52,211 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:52
2020-04-02 05:03:52,214 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:52,217 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:52,219 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:03:52,220 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:52,241 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:52,249 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:52,249 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:52,250 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:52,251 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:52,251 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:52,251 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:52,252 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:52,252 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:52,253 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:52,253 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:52,253 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:52,289 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:03:52,310 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:52,311 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:52,313 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:03:52,313 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:52,320 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:03:52,321 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:52,321 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:52,322 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:52,328 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:52,333 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:52,340 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:52,340 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:52,341 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:03:52,341 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:52,364 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:52,365 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:52,366 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:52,371 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:52,372 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:52,375 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:52,375 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:52,377 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:03:52,377 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:52,426 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:03:52,450 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:03:52,453 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:03:52,486 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:03:52,489 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:03:52,689 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:03:52,690 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:03:52,726 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:03:52,731 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:03:52,968 [main] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:03:53,062 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:03:53,793 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:03:53,794 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:03:53,805 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:03:53,831 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:03:53,893 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2d710f1a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:53,909 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:03:53,916 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:53,948 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @4631ms
2020-04-02 05:03:54,109 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:54,124 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:03:54,125 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:54,132 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:54,137 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:03:54,137 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:54,137 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:54,170 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:54,171 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:54,180 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33617
2020-04-02 05:03:54,183 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:54,296 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@565f390{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:03:54,315 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f67a4d3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:54,394 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7fc4780b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:03:54,414 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6b58b9e9{HTTP/1.1,[http/1.1]}{localhost:33617}
2020-04-02 05:03:54,415 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5098ms
2020-04-02 05:03:54,484 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:54,490 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:54,491 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:54,491 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:54,492 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:54,492 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:54,492 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:54,493 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:03:54,498 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:54,499 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:54,503 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:54,504 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:54,509 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:54
2020-04-02 05:03:54,509 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:54,512 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:54,512 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:54,513 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:54,556 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:54,557 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:54,557 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:54,557 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:54,557 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:54,557 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:54,557 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:54,557 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:54,557 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:54,558 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:54,558 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:54,558 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:54,559 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:54,559 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:54,560 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:54,560 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:54,563 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:03:54,563 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:54,563 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:54,563 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:54,564 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:54,564 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:54,564 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:54,564 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:54,565 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:54,565 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:54,566 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:54,566 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:54,567 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:54,567 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:54,567 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:54,567 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:54,568 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:54,568 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:54,568 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:54,574 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:03:54,577 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:03:54,618 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:03:54,619 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:03:54,619 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:03:54,620 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:03:54,656 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:03:54,663 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:03:54,664 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:03:54,670 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:03:54,672 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:03:54,717 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:03:54,718 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 147 msecs
2020-04-02 05:03:54,942 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:03:54,953 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:54,973 [Socket Reader #1 for port 37898] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37898
2020-04-02 05:03:55,665 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:37898 to access this namenode/service.
2020-04-02 05:03:55,681 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:03:55,788 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:03:55,811 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:03:55,818 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:03:55,818 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:03:55,818 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:03:55,860 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:03:55,894 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:03:55,894 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:03:55,894 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:03:55,894 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:03:55,895 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 65 msec
2020-04-02 05:03:55,962 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:37898
2020-04-02 05:03:55,959 [IPC Server listener on 37898] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37898: starting
2020-04-02 05:03:55,982 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:03:55,982 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:03:55,962 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:55,993 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 11 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:03:56,000 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 37898 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:56,027 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:03:56,037 [CacheReplicationMonitor(14954711)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:03:56,199 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:03:56,272 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:03:56,314 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:56,315 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:56,352 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:56,360 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:56,375 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:56,390 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:56,406 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:56,448 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:46328
2020-04-02 05:03:56,452 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:56,452 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:56,580 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:56,597 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:56,602 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:56,603 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:56,605 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:56,606 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:56,607 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:56,607 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:56,611 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46625
2020-04-02 05:03:56,612 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:56,617 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5e81e5ac{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:03:56,618 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3fa2213{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:56,626 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6aecbb8d{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:56,634 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3bcc07fa{HTTP/1.1,[http/1.1]}{localhost:46625}
2020-04-02 05:03:56,634 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7318ms
2020-04-02 05:03:57,188 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38711
2020-04-02 05:03:57,201 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:57,201 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:57,212 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@226642a5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:57,227 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:57,238 [Socket Reader #1 for port 32976] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 32976
2020-04-02 05:03:57,274 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:32976
2020-04-02 05:03:57,299 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:03:57,303 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:03:57,954 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:57,955 [IPC Server listener on 32976] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 32976: starting
2020-04-02 05:03:57,957 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 32976 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:57,959 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:03:57,961 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:03:57,946 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37898 starting to offer service
2020-04-02 05:03:57,970 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:03:58,036 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:58,036 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:58,036 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:58,037 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:58,037 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:58,037 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:58,038 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:58,050 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42201
2020-04-02 05:03:58,050 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:58,050 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:58,052 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:58,055 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:58,056 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:58,057 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:58,069 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:58,071 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:58,071 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:58,071 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:58,073 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38428
2020-04-02 05:03:58,077 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:58,117 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@63c5efee{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:03:58,118 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1c98290c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:58,135 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6865c751{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:58,136 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@62679465{HTTP/1.1,[http/1.1]}{localhost:38428}
2020-04-02 05:03:58,136 [main] INFO  server.Server (Server.java:doStart(419)) - Started @8819ms
2020-04-02 05:03:58,344 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43709
2020-04-02 05:03:58,346 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1d71006f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:58,346 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:58,374 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:58,375 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:58,398 [Socket Reader #1 for port 37167] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37167
2020-04-02 05:03:58,419 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:37167
2020-04-02 05:03:58,427 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:03:58,428 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:03:58,430 [Thread-84] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37898 starting to offer service
2020-04-02 05:03:58,458 [IPC Server listener on 37167] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37167: starting
2020-04-02 05:03:58,462 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:58,487 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 37167 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:58,488 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:03:58,534 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:03:58,538 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:03:58,556 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:58,557 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:58,557 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:58,557 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:58,561 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:58,561 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:58,561 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:58,562 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42386
2020-04-02 05:03:58,564 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:58,564 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:58,578 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:58,587 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:58,590 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:58,590 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:58,592 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:58,593 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:58,593 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:58,593 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:58,594 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 36045
2020-04-02 05:03:58,594 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:58,596 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4fcee388{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:03:58,597 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3af17be2{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:58,603 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@63cd604c{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:58,603 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@40dd3977{HTTP/1.1,[http/1.1]}{localhost:36045}
2020-04-02 05:03:58,604 [main] INFO  server.Server (Server.java:doStart(419)) - Started @9287ms
2020-04-02 05:03:58,682 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38679
2020-04-02 05:03:58,695 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:58,695 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:58,695 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:58,696 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6a1d204a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:58,711 [Socket Reader #1 for port 45758] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45758
2020-04-02 05:03:58,718 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:45758
2020-04-02 05:03:58,723 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:03:58,724 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:03:58,725 [Thread-107] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37898 starting to offer service
2020-04-02 05:03:58,749 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:58,761 [IPC Server listener on 45758] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45758: starting
2020-04-02 05:03:58,797 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 45758 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:58,832 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:03:58,878 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:03:58,878 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:03:58,880 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:58,881 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:58,881 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:58,881 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:58,884 [Thread-107] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37898
2020-04-02 05:03:58,893 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:58,893 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:58,894 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:58,894 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:44523
2020-04-02 05:03:58,894 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:58,895 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:58,901 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:58,903 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:58,904 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:58,905 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:58,906 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:58,907 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:58,907 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:58,907 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:58,908 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43669
2020-04-02 05:03:58,908 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:58,927 [Thread-107] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:58,931 [Thread-107] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:03:58,933 [Thread-107] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1950780784. Formatting...
2020-04-02 05:03:58,934 [Thread-107] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6a50e38d-8394-493e-bae9-21cc555d5ff0 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:03:58,955 [Thread-84] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37898
2020-04-02 05:03:58,959 [Thread-84] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:58,962 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37898
2020-04-02 05:03:58,963 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@314b8f2d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:03:58,964 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5118388b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:58,965 [Thread-84] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:03:58,966 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1950780784. Formatting...
2020-04-02 05:03:58,966 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a1bb379d-e304-41de-8d6b-868fc820a567 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:03:58,974 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@290b1b2e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:58,975 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@47874b25{HTTP/1.1,[http/1.1]}{localhost:43669}
2020-04-02 05:03:58,975 [main] INFO  server.Server (Server.java:doStart(419)) - Started @9658ms
2020-04-02 05:03:58,976 [Thread-84] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:03:58,976 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1950780784. Formatting...
2020-04-02 05:03:58,976 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4f1eb05d-12f5-4429-a347-6330e649b422 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:03:59,004 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:59,005 [Thread-107] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:03:59,006 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:03:59,006 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1950780784. Formatting...
2020-04-02 05:03:59,006 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e71e2ffb-339e-4462-8c88-b84e94847941 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:03:59,007 [Thread-107] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1950780784. Formatting...
2020-04-02 05:03:59,007 [Thread-107] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ff45f1b6-7489-4193-a7b7-463383a325e2 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:03:59,014 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:03:59,015 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1950780784. Formatting...
2020-04-02 05:03:59,015 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-17e72323-9be8-4266-96b2-cee02356855e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:03:59,033 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:03:59,034 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:03:59,115 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:03:59,127 [Thread-84] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:03:59,127 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1929959544-172.17.0.14-1585803832412 is not formatted. Formatting ...
2020-04-02 05:03:59,127 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1929959544-172.17.0.14-1585803832412 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1929959544-172.17.0.14-1585803832412/current
2020-04-02 05:03:59,128 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1929959544-172.17.0.14-1585803832412 is not formatted. Formatting ...
2020-04-02 05:03:59,128 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1929959544-172.17.0.14-1585803832412 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1929959544-172.17.0.14-1585803832412/current
2020-04-02 05:03:59,142 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:03:59,142 [Thread-84] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:03:59,143 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1929959544-172.17.0.14-1585803832412 is not formatted. Formatting ...
2020-04-02 05:03:59,143 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1929959544-172.17.0.14-1585803832412 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1929959544-172.17.0.14-1585803832412/current
2020-04-02 05:03:59,146 [Thread-84] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1950780784;bpid=BP-1929959544-172.17.0.14-1585803832412;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1950780784;c=1585803832412;bpid=BP-1929959544-172.17.0.14-1585803832412;dnuuid=null
2020-04-02 05:03:59,148 [Thread-84] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb
2020-04-02 05:03:59,177 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42972
2020-04-02 05:03:59,178 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:59,178 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:59,178 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:59,179 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2c177f9e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:59,182 [Socket Reader #1 for port 40520] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40520
2020-04-02 05:03:59,195 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:03:59,196 [Thread-107] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:03:59,197 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1929959544-172.17.0.14-1585803832412 is not formatted. Formatting ...
2020-04-02 05:03:59,197 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1929959544-172.17.0.14-1585803832412 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1929959544-172.17.0.14-1585803832412/current
2020-04-02 05:03:59,196 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:03:59,198 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:03:59,199 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1929959544-172.17.0.14-1585803832412 is not formatted. Formatting ...
2020-04-02 05:03:59,199 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1929959544-172.17.0.14-1585803832412 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1929959544-172.17.0.14-1585803832412/current
2020-04-02 05:03:59,201 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40520
2020-04-02 05:03:59,204 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:03:59,218 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:03:59,221 [Thread-130] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37898 starting to offer service
2020-04-02 05:03:59,210 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1950780784;bpid=BP-1929959544-172.17.0.14-1585803832412;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1950780784;c=1585803832412;bpid=BP-1929959544-172.17.0.14-1585803832412;dnuuid=null
2020-04-02 05:03:59,245 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40520 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:59,242 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:59,242 [IPC Server listener on 40520] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40520: starting
2020-04-02 05:03:59,313 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID bb837d1a-fd41-4783-ba5c-f312fcccd0ee
2020-04-02 05:03:59,347 [Thread-130] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37898
2020-04-02 05:03:59,354 [Thread-130] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:59,357 [Thread-130] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:03:59,357 [Thread-130] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1950780784. Formatting...
2020-04-02 05:03:59,357 [Thread-130] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3013b8d1-d536-416d-897a-21c98c02f8c3 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-04-02 05:03:59,360 [Thread-130] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:03:59,361 [Thread-130] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1950780784. Formatting...
2020-04-02 05:03:59,361 [Thread-130] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f8a6047a-08e2-4aa0-81dc-441677cee101 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-04-02 05:03:59,366 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:03:59,366 [Thread-107] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:03:59,367 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1929959544-172.17.0.14-1585803832412 is not formatted. Formatting ...
2020-04-02 05:03:59,367 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1929959544-172.17.0.14-1585803832412 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1929959544-172.17.0.14-1585803832412/current
2020-04-02 05:03:59,378 [Thread-107] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1950780784;bpid=BP-1929959544-172.17.0.14-1585803832412;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1950780784;c=1585803832412;bpid=BP-1929959544-172.17.0.14-1585803832412;dnuuid=null
2020-04-02 05:03:59,380 [Thread-107] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID fc5fa929-8ee7-4183-a4b6-ae04670d9642
2020-04-02 05:03:59,395 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:03:59,396 [Thread-130] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:03:59,396 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1929959544-172.17.0.14-1585803832412 is not formatted. Formatting ...
2020-04-02 05:03:59,396 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1929959544-172.17.0.14-1585803832412 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1929959544-172.17.0.14-1585803832412/current
2020-04-02 05:03:59,428 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:03:59,429 [Thread-130] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:03:59,429 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1929959544-172.17.0.14-1585803832412 is not formatted. Formatting ...
2020-04-02 05:03:59,429 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1929959544-172.17.0.14-1585803832412 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1929959544-172.17.0.14-1585803832412/current
2020-04-02 05:03:59,446 [Thread-130] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1950780784;bpid=BP-1929959544-172.17.0.14-1585803832412;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1950780784;c=1585803832412;bpid=BP-1929959544-172.17.0.14-1585803832412;dnuuid=null
2020-04-02 05:03:59,462 [Thread-130] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 0411d447-0b2d-4229-84be-2623f14f0d22
2020-04-02 05:03:59,601 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-e71e2ffb-339e-4462-8c88-b84e94847941
2020-04-02 05:03:59,601 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:03:59,619 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-17e72323-9be8-4266-96b2-cee02356855e
2020-04-02 05:03:59,620 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:03:59,659 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-3013b8d1-d536-416d-897a-21c98c02f8c3
2020-04-02 05:03:59,659 [Thread-130] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:03:59,663 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-a1bb379d-e304-41de-8d6b-868fc820a567
2020-04-02 05:03:59,663 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:03:59,665 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-4f1eb05d-12f5-4429-a347-6330e649b422
2020-04-02 05:03:59,665 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:03:59,606 [Thread-107] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-6a50e38d-8394-493e-bae9-21cc555d5ff0
2020-04-02 05:03:59,666 [Thread-107] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:03:59,669 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-f8a6047a-08e2-4aa0-81dc-441677cee101
2020-04-02 05:03:59,670 [Thread-130] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:03:59,670 [Thread-107] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-ff45f1b6-7489-4193-a7b7-463383a325e2
2020-04-02 05:03:59,670 [Thread-107] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:03:59,737 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:59,738 [Thread-107] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:59,738 [Thread-130] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:59,739 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:59,754 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:03:59,774 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:03:59,775 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:03:59,776 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:03:59,797 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:03:59,800 [Thread-130] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:03:59,802 [Thread-107] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:03:59,807 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:03:59,807 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:03:59,808 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:03:59,820 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:03:59,843 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:03:59,844 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:03:59,868 [Thread-107] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:03:59,869 [Thread-107] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:03:59,869 [Thread-107] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:03:59,869 [Thread-130] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:03:59,869 [Thread-130] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:03:59,869 [Thread-130] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:03:59,903 [Thread-130] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:03:59,904 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:03:59,905 [Thread-151] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:03:59,906 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:03:59,907 [Thread-152] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:03:59,922 [Thread-155] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:03:59,925 [Thread-107] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:03:59,927 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:03:59,927 [Thread-158] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:04:00,192 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 384ms
2020-04-02 05:04:00,203 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 395ms
2020-04-02 05:04:00,206 [Thread-158] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 268ms
2020-04-02 05:04:00,206 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 299ms
2020-04-02 05:04:00,215 [Thread-152] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 301ms
2020-04-02 05:04:00,234 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1929959544-172.17.0.14-1585803832412: 436ms
2020-04-02 05:04:00,238 [Thread-151] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 334ms
2020-04-02 05:04:00,241 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1929959544-172.17.0.14-1585803832412: 339ms
2020-04-02 05:04:00,242 [Thread-155] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 319ms
2020-04-02 05:04:00,243 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1929959544-172.17.0.14-1585803832412: 338ms
2020-04-02 05:04:00,283 [Thread-165] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:04:00,283 [Thread-165] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas doesn't exist 
2020-04-02 05:04:00,284 [Thread-166] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:04:00,284 [Thread-169] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:04:00,285 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 358ms
2020-04-02 05:04:00,288 [Thread-107] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1929959544-172.17.0.14-1585803832412: 362ms
2020-04-02 05:04:00,326 [Thread-168] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:04:00,326 [Thread-168] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas doesn't exist 
2020-04-02 05:04:00,284 [Thread-166] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas doesn't exist 
2020-04-02 05:04:00,284 [Thread-169] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas doesn't exist 
2020-04-02 05:04:00,334 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:04:00,334 [Thread-171] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas doesn't exist 
2020-04-02 05:04:00,338 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:04:00,338 [Thread-172] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas doesn't exist 
2020-04-02 05:04:00,338 [Thread-170] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:04:00,342 [Thread-170] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas doesn't exist 
2020-04-02 05:04:00,350 [Thread-167] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:04:00,351 [Thread-167] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas doesn't exist 
2020-04-02 05:04:00,351 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 13ms
2020-04-02 05:04:00,364 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 30ms
2020-04-02 05:04:00,364 [Thread-165] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 81ms
2020-04-02 05:04:00,364 [Thread-107] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412: 38ms
2020-04-02 05:04:00,365 [Thread-169] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 81ms
2020-04-02 05:04:00,365 [Thread-170] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 23ms
2020-04-02 05:04:00,365 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412: 128ms
2020-04-02 05:04:00,399 [Thread-167] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 48ms
2020-04-02 05:04:00,404 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412: 161ms
2020-04-02 05:04:00,405 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:04:00,406 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-4f1eb05d-12f5-4429-a347-6330e649b422): finished scanning block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:00,409 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:04:00,410 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:04:00,425 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-6a50e38d-8394-493e-bae9-21cc555d5ff0): finished scanning block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:00,426 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-ff45f1b6-7489-4193-a7b7-463383a325e2): finished scanning block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:00,410 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:04:00,426 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-17e72323-9be8-4266-96b2-cee02356855e): finished scanning block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:00,426 [Thread-168] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 100ms
2020-04-02 05:04:00,410 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:04:00,430 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e71e2ffb-339e-4462-8c88-b84e94847941): finished scanning block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:00,438 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:04:00,442 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-a1bb379d-e304-41de-8d6b-868fc820a567): finished scanning block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:00,451 [Thread-166] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 167ms
2020-04-02 05:04:00,455 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412: 213ms
2020-04-02 05:04:00,456 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:04:00,456 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-3013b8d1-d536-416d-897a-21c98c02f8c3): finished scanning block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:00,456 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:04:00,457 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-f8a6047a-08e2-4aa0-81dc-441677cee101): finished scanning block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:00,485 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:19 AM with interval of 21600000ms
2020-04-02 05:04:00,486 [Thread-130] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:57 AM with interval of 21600000ms
2020-04-02 05:04:00,487 [Thread-84] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:43 AM with interval of 21600000ms
2020-04-02 05:04:00,487 [Thread-107] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:50 AM with interval of 21600000ms
2020-04-02 05:04:00,523 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid bb837d1a-fd41-4783-ba5c-f312fcccd0ee) service to localhost/127.0.0.1:37898 beginning handshake with NN
2020-04-02 05:04:00,534 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb) service to localhost/127.0.0.1:37898 beginning handshake with NN
2020-04-02 05:04:00,534 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid fc5fa929-8ee7-4183-a4b6-ae04670d9642) service to localhost/127.0.0.1:37898 beginning handshake with NN
2020-04-02 05:04:00,538 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 0411d447-0b2d-4229-84be-2623f14f0d22) service to localhost/127.0.0.1:37898 beginning handshake with NN
2020-04-02 05:04:00,569 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-3013b8d1-d536-416d-897a-21c98c02f8c3): no suitable block pools found to scan.  Waiting 1814399886 ms.
2020-04-02 05:04:00,579 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-6a50e38d-8394-493e-bae9-21cc555d5ff0): no suitable block pools found to scan.  Waiting 1814399825 ms.
2020-04-02 05:04:00,580 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e71e2ffb-339e-4462-8c88-b84e94847941): no suitable block pools found to scan.  Waiting 1814399830 ms.
2020-04-02 05:04:00,580 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-ff45f1b6-7489-4193-a7b7-463383a325e2): no suitable block pools found to scan.  Waiting 1814399824 ms.
2020-04-02 05:04:00,581 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-f8a6047a-08e2-4aa0-81dc-441677cee101): no suitable block pools found to scan.  Waiting 1814399875 ms.
2020-04-02 05:04:00,581 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-17e72323-9be8-4266-96b2-cee02356855e): no suitable block pools found to scan.  Waiting 1814399829 ms.
2020-04-02 05:04:00,582 [IPC Server handler 0 on 37898] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42201, datanodeUuid=8bebbb2e-b355-4030-af1e-ab7e8b7c53eb, infoPort=43709, infoSecurePort=0, ipcPort=37167, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412) storage 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb
2020-04-02 05:04:00,584 [IPC Server handler 0 on 37898] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42201
2020-04-02 05:04:00,585 [IPC Server handler 0 on 37898] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb (127.0.0.1:42201).
2020-04-02 05:04:00,596 [IPC Server handler 1 on 37898] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46328, datanodeUuid=bb837d1a-fd41-4783-ba5c-f312fcccd0ee, infoPort=38711, infoSecurePort=0, ipcPort=32976, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412) storage bb837d1a-fd41-4783-ba5c-f312fcccd0ee
2020-04-02 05:04:00,597 [IPC Server handler 1 on 37898] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46328
2020-04-02 05:04:00,601 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-4f1eb05d-12f5-4429-a347-6330e649b422): no suitable block pools found to scan.  Waiting 1814399804 ms.
2020-04-02 05:04:00,602 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-a1bb379d-e304-41de-8d6b-868fc820a567): no suitable block pools found to scan.  Waiting 1814399803 ms.
2020-04-02 05:04:00,614 [IPC Server handler 1 on 37898] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN bb837d1a-fd41-4783-ba5c-f312fcccd0ee (127.0.0.1:46328).
2020-04-02 05:04:00,616 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid bb837d1a-fd41-4783-ba5c-f312fcccd0ee) service to localhost/127.0.0.1:37898 successfully registered with NN
2020-04-02 05:04:00,616 [IPC Server handler 4 on 37898] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44523, datanodeUuid=0411d447-0b2d-4229-84be-2623f14f0d22, infoPort=42972, infoSecurePort=0, ipcPort=40520, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412) storage 0411d447-0b2d-4229-84be-2623f14f0d22
2020-04-02 05:04:00,616 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37898 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:04:00,616 [IPC Server handler 4 on 37898] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44523
2020-04-02 05:04:00,616 [IPC Server handler 4 on 37898] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0411d447-0b2d-4229-84be-2623f14f0d22 (127.0.0.1:44523).
2020-04-02 05:04:00,646 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb) service to localhost/127.0.0.1:37898 successfully registered with NN
2020-04-02 05:04:00,646 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 0411d447-0b2d-4229-84be-2623f14f0d22) service to localhost/127.0.0.1:37898 successfully registered with NN
2020-04-02 05:04:00,646 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37898 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:04:00,646 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37898 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:04:00,654 [IPC Server handler 5 on 37898] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42386, datanodeUuid=fc5fa929-8ee7-4183-a4b6-ae04670d9642, infoPort=38679, infoSecurePort=0, ipcPort=45758, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412) storage fc5fa929-8ee7-4183-a4b6-ae04670d9642
2020-04-02 05:04:00,654 [IPC Server handler 5 on 37898] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42386
2020-04-02 05:04:00,654 [IPC Server handler 5 on 37898] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN fc5fa929-8ee7-4183-a4b6-ae04670d9642 (127.0.0.1:42386).
2020-04-02 05:04:00,656 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid fc5fa929-8ee7-4183-a4b6-ae04670d9642) service to localhost/127.0.0.1:37898 successfully registered with NN
2020-04-02 05:04:00,656 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37898 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:04:00,738 [IPC Server handler 6 on 37898] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a1bb379d-e304-41de-8d6b-868fc820a567 for DN 127.0.0.1:42201
2020-04-02 05:04:00,739 [IPC Server handler 6 on 37898] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4f1eb05d-12f5-4429-a347-6330e649b422 for DN 127.0.0.1:42201
2020-04-02 05:04:00,763 [IPC Server handler 7 on 37898] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3013b8d1-d536-416d-897a-21c98c02f8c3 for DN 127.0.0.1:44523
2020-04-02 05:04:00,799 [IPC Server handler 7 on 37898] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f8a6047a-08e2-4aa0-81dc-441677cee101 for DN 127.0.0.1:44523
2020-04-02 05:04:00,819 [IPC Server handler 8 on 37898] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e71e2ffb-339e-4462-8c88-b84e94847941 for DN 127.0.0.1:46328
2020-04-02 05:04:00,819 [IPC Server handler 8 on 37898] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-17e72323-9be8-4266-96b2-cee02356855e for DN 127.0.0.1:46328
2020-04-02 05:04:00,820 [IPC Server handler 8 on 37898] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6a50e38d-8394-493e-bae9-21cc555d5ff0 for DN 127.0.0.1:42386
2020-04-02 05:04:00,821 [IPC Server handler 8 on 37898] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ff45f1b6-7489-4193-a7b7-463383a325e2 for DN 127.0.0.1:42386
2020-04-02 05:04:00,890 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf256c34bca330acb: Processing first storage report for DS-a1bb379d-e304-41de-8d6b-868fc820a567 from datanode 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb
2020-04-02 05:04:00,901 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf256c34bca330acb: from storage DS-a1bb379d-e304-41de-8d6b-868fc820a567 node DatanodeRegistration(127.0.0.1:42201, datanodeUuid=8bebbb2e-b355-4030-af1e-ab7e8b7c53eb, infoPort=43709, infoSecurePort=0, ipcPort=37167, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:04:00,901 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc077a31f6e9d0ae8: Processing first storage report for DS-17e72323-9be8-4266-96b2-cee02356855e from datanode bb837d1a-fd41-4783-ba5c-f312fcccd0ee
2020-04-02 05:04:00,901 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc077a31f6e9d0ae8: from storage DS-17e72323-9be8-4266-96b2-cee02356855e node DatanodeRegistration(127.0.0.1:46328, datanodeUuid=bb837d1a-fd41-4783-ba5c-f312fcccd0ee, infoPort=38711, infoSecurePort=0, ipcPort=32976, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:00,901 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xcec7d31dccc468b4: Processing first storage report for DS-6a50e38d-8394-493e-bae9-21cc555d5ff0 from datanode fc5fa929-8ee7-4183-a4b6-ae04670d9642
2020-04-02 05:04:00,901 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xcec7d31dccc468b4: from storage DS-6a50e38d-8394-493e-bae9-21cc555d5ff0 node DatanodeRegistration(127.0.0.1:42386, datanodeUuid=fc5fa929-8ee7-4183-a4b6-ae04670d9642, infoPort=38679, infoSecurePort=0, ipcPort=45758, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:00,902 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf256c34bca330acb: Processing first storage report for DS-4f1eb05d-12f5-4429-a347-6330e649b422 from datanode 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb
2020-04-02 05:04:00,902 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf256c34bca330acb: from storage DS-4f1eb05d-12f5-4429-a347-6330e649b422 node DatanodeRegistration(127.0.0.1:42201, datanodeUuid=8bebbb2e-b355-4030-af1e-ab7e8b7c53eb, infoPort=43709, infoSecurePort=0, ipcPort=37167, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:00,902 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc077a31f6e9d0ae8: Processing first storage report for DS-e71e2ffb-339e-4462-8c88-b84e94847941 from datanode bb837d1a-fd41-4783-ba5c-f312fcccd0ee
2020-04-02 05:04:00,902 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc077a31f6e9d0ae8: from storage DS-e71e2ffb-339e-4462-8c88-b84e94847941 node DatanodeRegistration(127.0.0.1:46328, datanodeUuid=bb837d1a-fd41-4783-ba5c-f312fcccd0ee, infoPort=38711, infoSecurePort=0, ipcPort=32976, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:00,918 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xcec7d31dccc468b4: Processing first storage report for DS-ff45f1b6-7489-4193-a7b7-463383a325e2 from datanode fc5fa929-8ee7-4183-a4b6-ae04670d9642
2020-04-02 05:04:00,918 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xcec7d31dccc468b4: from storage DS-ff45f1b6-7489-4193-a7b7-463383a325e2 node DatanodeRegistration(127.0.0.1:42386, datanodeUuid=fc5fa929-8ee7-4183-a4b6-ae04670d9642, infoPort=38679, infoSecurePort=0, ipcPort=45758, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:00,919 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x8f2e085b277eb137: Processing first storage report for DS-3013b8d1-d536-416d-897a-21c98c02f8c3 from datanode 0411d447-0b2d-4229-84be-2623f14f0d22
2020-04-02 05:04:00,919 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x8f2e085b277eb137: from storage DS-3013b8d1-d536-416d-897a-21c98c02f8c3 node DatanodeRegistration(127.0.0.1:44523, datanodeUuid=0411d447-0b2d-4229-84be-2623f14f0d22, infoPort=42972, infoSecurePort=0, ipcPort=40520, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:00,919 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x8f2e085b277eb137: Processing first storage report for DS-f8a6047a-08e2-4aa0-81dc-441677cee101 from datanode 0411d447-0b2d-4229-84be-2623f14f0d22
2020-04-02 05:04:00,919 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x8f2e085b277eb137: from storage DS-f8a6047a-08e2-4aa0-81dc-441677cee101 node DatanodeRegistration(127.0.0.1:44523, datanodeUuid=0411d447-0b2d-4229-84be-2623f14f0d22, infoPort=42972, infoSecurePort=0, ipcPort=40520, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:00,956 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xf256c34bca330acb,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 25 msec to generate and 129 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:04:00,956 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:00,975 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xc077a31f6e9d0ae8,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 125 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:04:00,975 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:00,979 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xcec7d31dccc468b4,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 129 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:04:00,979 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:00,979 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x8f2e085b277eb137,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 27 msec to generate and 129 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:04:00,979 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:01,064 [IPC Server handler 4 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:01,095 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
[msx] test Started org.apache.hadoop.fs.permission.TestStickyBit#testMovingFiles
[msx] unitTestCounterInClass = 0
2020-04-02 05:04:01,144 [IPC Server handler 5 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:04:01,161 [IPC Server handler 6 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:01,183 [IPC Server handler 7 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:01,190 [IPC Server handler 8 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/tmp	dst=null	perm=root:supergroup:rwxrwxrwt	proto=rpc
2020-04-02 05:04:01,195 [IPC Server handler 9 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/tmp2	dst=null	perm=root:supergroup:rwxrwxrwt	proto=rpc
2020-04-02 05:04:01,268 [IPC Server handler 2 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=theDoctor (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/foo	dst=null	perm=theDoctor:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:01,328 [IPC Server handler 0 on 37898] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:46328, 127.0.0.1:44523, 127.0.0.1:42386 for /tmp/foo
2020-04-02 05:04:01,421 [DataXceiver for client DFSClient_NONMAPREDUCE_-962709692_1 at /127.0.0.1:44120 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741825_1001 src: /127.0.0.1:44120 dest: /127.0.0.1:46328
2020-04-02 05:04:01,454 [DataXceiver for client DFSClient_NONMAPREDUCE_-962709692_1 at /127.0.0.1:38584 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741825_1001 src: /127.0.0.1:38584 dest: /127.0.0.1:44523
2020-04-02 05:04:01,462 [DataXceiver for client DFSClient_NONMAPREDUCE_-962709692_1 at /127.0.0.1:40732 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741825_1001 src: /127.0.0.1:40732 dest: /127.0.0.1:42386
2020-04-02 05:04:01,554 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40732, dest: /127.0.0.1:42386, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-962709692_1, offset: 0, srvID: fc5fa929-8ee7-4183-a4b6-ae04670d9642, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741825_1001, duration(ns): 58435325
2020-04-02 05:04:01,554 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:01,560 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42386]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38584, dest: /127.0.0.1:44523, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-962709692_1, offset: 0, srvID: 0411d447-0b2d-4229-84be-2623f14f0d22, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741825_1001, duration(ns): 66740154
2020-04-02 05:04:01,564 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42386]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42386] terminating
2020-04-02 05:04:01,578 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44523, 127.0.0.1:42386]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44120, dest: /127.0.0.1:46328, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-962709692_1, offset: 0, srvID: bb837d1a-fd41-4783-ba5c-f312fcccd0ee, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741825_1001, duration(ns): 66338560
2020-04-02 05:04:01,578 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44523, 127.0.0.1:42386]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44523, 127.0.0.1:42386] terminating
2020-04-02 05:04:01,590 [IPC Server handler 3 on 37898] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/foo
2020-04-02 05:04:02,005 [IPC Server handler 7 on 37898] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/foo is closed by DFSClient_NONMAPREDUCE_-962709692_1
2020-04-02 05:04:02,019 [IPC Server handler 8 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=rose (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/tmp/foo	dst=/tmp2/renamed	perm=null	proto=rpc
2020-04-02 05:04:02,020 [IPC Server handler 8 on 37898] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 8 on 37898, call Call#30 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename from 127.0.0.1:59658: org.apache.hadoop.security.AccessControlException: Permission denied by sticky bit: user=rose, path="/tmp/foo":theDoctor:supergroup:-rw-r--r--, parent="/tmp":root:supergroup:drwxrwxrwt
[msx] test Finished org.apache.hadoop.fs.permission.TestStickyBit#testMovingFiles
[msx] writeFile testName = org.apache.hadoop.fs.permission.TestStickyBit#testMovingFiles
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.permission.TestStickyBit#testAclGeneralSBBehavior
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:02,034 [IPC Server handler 9 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,044 [IPC Server handler 2 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,051 [IPC Server handler 0 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp2	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,058 [IPC Server handler 1 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/mcgann	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:02,065 [IPC Server handler 3 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/mcgann/tmp	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:02,068 [IPC Server handler 4 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/mcgann/tmp	dst=null	perm=root:supergroup:rwxrwxrwt	proto=rpc
2020-04-02 05:04:02,098 [IPC Server handler 5 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=modifyAclEntries	src=/mcgann/tmp	dst=null	perm=root:supergroup:rwxrwxrwt	proto=rpc
2020-04-02 05:04:02,122 [IPC Server handler 6 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=theDoctor (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/mcgann/tmp/foo	dst=null	perm=theDoctor:supergroup:rw-rw-rw-	proto=rpc
2020-04-02 05:04:02,146 [IPC Server handler 7 on 37898] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:46328, 127.0.0.1:42386, 127.0.0.1:44523 for /mcgann/tmp/foo
2020-04-02 05:04:02,169 [DataXceiver for client DFSClient_NONMAPREDUCE_-962709692_1 at /127.0.0.1:44190 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002 src: /127.0.0.1:44190 dest: /127.0.0.1:46328
2020-04-02 05:04:02,181 [DataXceiver for client DFSClient_NONMAPREDUCE_-962709692_1 at /127.0.0.1:40782 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002 src: /127.0.0.1:40782 dest: /127.0.0.1:42386
2020-04-02 05:04:02,199 [DataXceiver for client DFSClient_NONMAPREDUCE_-962709692_1 at /127.0.0.1:38640 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002 src: /127.0.0.1:38640 dest: /127.0.0.1:44523
2020-04-02 05:04:02,290 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38640, dest: /127.0.0.1:44523, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-962709692_1, offset: 0, srvID: 0411d447-0b2d-4229-84be-2623f14f0d22, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002, duration(ns): 82061689
2020-04-02 05:04:02,290 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:02,307 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44523]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40782, dest: /127.0.0.1:42386, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-962709692_1, offset: 0, srvID: fc5fa929-8ee7-4183-a4b6-ae04670d9642, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002, duration(ns): 103737059
2020-04-02 05:04:02,307 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44523]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44523] terminating
2020-04-02 05:04:02,329 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42386, 127.0.0.1:44523]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44190, dest: /127.0.0.1:46328, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-962709692_1, offset: 0, srvID: bb837d1a-fd41-4783-ba5c-f312fcccd0ee, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002, duration(ns): 118366130
2020-04-02 05:04:02,329 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42386, 127.0.0.1:44523]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42386, 127.0.0.1:44523] terminating
2020-04-02 05:04:02,356 [IPC Server handler 0 on 37898] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /mcgann/tmp/foo is closed by DFSClient_NONMAPREDUCE_-962709692_1
2020-04-02 05:04:02,374 [IPC Server handler 1 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=theDoctor (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/mcgann/tmp/foo	dst=null	perm=theDoctor:supergroup:rwxrwxrwx	proto=rpc
2020-04-02 05:04:02,409 [IPC Server handler 3 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rose (auth:SIMPLE)	ip=/127.0.0.1	cmd=append	src=/mcgann/tmp/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,447 [DataXceiver for client DFSClient_NONMAPREDUCE_1181568498_1 at /127.0.0.1:38652 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002 src: /127.0.0.1:38652 dest: /127.0.0.1:44523
2020-04-02 05:04:02,447 [DataXceiver for client DFSClient_NONMAPREDUCE_1181568498_1 at /127.0.0.1:38652 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:append(1187)) - Appending to FinalizedReplica, blk_1073741826_1002, FINALIZED
  getNumBytes()     = 18
  getBytesOnDisk()  = 18
  getVisibleLength()= 18
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1929959544-172.17.0.14-1585803832412/current/finalized/subdir0/subdir0/blk_1073741826
2020-04-02 05:04:02,511 [DataXceiver for client DFSClient_NONMAPREDUCE_1181568498_1 at /127.0.0.1:40804 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002 src: /127.0.0.1:40804 dest: /127.0.0.1:42386
2020-04-02 05:04:02,512 [DataXceiver for client DFSClient_NONMAPREDUCE_1181568498_1 at /127.0.0.1:40804 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:append(1187)) - Appending to FinalizedReplica, blk_1073741826_1002, FINALIZED
  getNumBytes()     = 18
  getBytesOnDisk()  = 18
  getVisibleLength()= 18
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1929959544-172.17.0.14-1585803832412/current/finalized/subdir0/subdir0/blk_1073741826
2020-04-02 05:04:02,558 [DataXceiver for client DFSClient_NONMAPREDUCE_1181568498_1 at /127.0.0.1:44218 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002 src: /127.0.0.1:44218 dest: /127.0.0.1:46328
2020-04-02 05:04:02,559 [DataXceiver for client DFSClient_NONMAPREDUCE_1181568498_1 at /127.0.0.1:44218 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1002]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:append(1187)) - Appending to FinalizedReplica, blk_1073741826_1002, FINALIZED
  getNumBytes()     = 18
  getBytesOnDisk()  = 18
  getVisibleLength()= 18
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1929959544-172.17.0.14-1585803832412/current/finalized/subdir0/subdir0/blk_1073741826
2020-04-02 05:04:02,608 [IPC Server handler 6 on 37898] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5340)) - updatePipeline(blk_1073741826_1002, newGS=1003, newLength=18, newNodes=[127.0.0.1:44523, 127.0.0.1:42386, 127.0.0.1:46328], client=DFSClient_NONMAPREDUCE_1181568498_1)
2020-04-02 05:04:02,612 [IPC Server handler 6 on 37898] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5358)) - updatePipeline(blk_1073741826_1002 => blk_1073741826_1003) success
2020-04-02 05:04:02,678 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44218, dest: /127.0.0.1:46328, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1181568498_1, offset: 0, srvID: bb837d1a-fd41-4783-ba5c-f312fcccd0ee, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1003, duration(ns): 76506828
2020-04-02 05:04:02,679 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:02,703 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46328]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40804, dest: /127.0.0.1:42386, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1181568498_1, offset: 0, srvID: fc5fa929-8ee7-4183-a4b6-ae04670d9642, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1003, duration(ns): 78921065
2020-04-02 05:04:02,703 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46328]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46328] terminating
2020-04-02 05:04:02,743 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42386, 127.0.0.1:46328]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38652, dest: /127.0.0.1:44523, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1181568498_1, offset: 0, srvID: 0411d447-0b2d-4229-84be-2623f14f0d22, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1003, duration(ns): 124401884
2020-04-02 05:04:02,743 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42386, 127.0.0.1:46328]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741826_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42386, 127.0.0.1:46328] terminating
2020-04-02 05:04:02,755 [IPC Server handler 9 on 37898] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /mcgann/tmp/foo is closed by DFSClient_NONMAPREDUCE_1181568498_1
2020-04-02 05:04:02,763 [IPC Server handler 0 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/eccleston	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:02,766 [IPC Server handler 1 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/eccleston/roguetraders	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:02,774 [IPC Server handler 3 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=modifyAclEntries	src=/eccleston/roguetraders	dst=null	perm=root:supergroup:rwxrwxr-x	proto=rpc
2020-04-02 05:04:02,780 [IPC Server handler 4 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/eccleston/roguetraders	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,786 [IPC Server handler 5 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/eccleston/roguetraders	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,789 [IPC Server handler 6 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/eccleston/roguetraders	dst=null	perm=root:supergroup:rwxrwxr-t	proto=rpc
2020-04-02 05:04:02,794 [IPC Server handler 7 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/eccleston/roguetraders	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,797 [IPC Server handler 8 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/eccleston/somefile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:02,831 [IPC Server handler 2 on 37898] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1004, replicas=127.0.0.1:44523, 127.0.0.1:46328, 127.0.0.1:42201 for /eccleston/somefile
2020-04-02 05:04:02,852 [DataXceiver for client DFSClient_NONMAPREDUCE_-1205192209_1 at /127.0.0.1:38698 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741827_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741827_1004 src: /127.0.0.1:38698 dest: /127.0.0.1:44523
2020-04-02 05:04:02,859 [DataXceiver for client DFSClient_NONMAPREDUCE_-1205192209_1 at /127.0.0.1:44258 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741827_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741827_1004 src: /127.0.0.1:44258 dest: /127.0.0.1:46328
2020-04-02 05:04:02,862 [DataXceiver for client DFSClient_NONMAPREDUCE_-1205192209_1 at /127.0.0.1:59582 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741827_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741827_1004 src: /127.0.0.1:59582 dest: /127.0.0.1:42201
2020-04-02 05:04:02,896 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741827_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59582, dest: /127.0.0.1:42201, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1205192209_1, offset: 0, srvID: 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741827_1004, duration(ns): 31448045
2020-04-02 05:04:02,896 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741827_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741827_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:02,913 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741827_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42201]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44258, dest: /127.0.0.1:46328, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1205192209_1, offset: 0, srvID: bb837d1a-fd41-4783-ba5c-f312fcccd0ee, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741827_1004, duration(ns): 34423776
2020-04-02 05:04:02,914 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741827_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42201]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741827_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42201] terminating
2020-04-02 05:04:02,927 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741827_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46328, 127.0.0.1:42201]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38698, dest: /127.0.0.1:44523, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1205192209_1, offset: 0, srvID: 0411d447-0b2d-4229-84be-2623f14f0d22, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741827_1004, duration(ns): 47091141
2020-04-02 05:04:02,928 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741827_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46328, 127.0.0.1:42201]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741827_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46328, 127.0.0.1:42201] terminating
2020-04-02 05:04:02,946 [IPC Server handler 4 on 37898] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /eccleston/somefile is closed by DFSClient_NONMAPREDUCE_-1205192209_1
2020-04-02 05:04:02,950 [IPC Server handler 5 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/eccleston/somefile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,958 [IPC Server handler 6 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/eccleston/somefile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,966 [IPC Server handler 7 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/eccleston/somefile	dst=null	perm=root:supergroup:rw-r--r-T	proto=rpc
2020-04-02 05:04:02,974 [IPC Server handler 8 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/eccleston/somefile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:02,978 [IPC Server handler 2 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tennant	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:02,981 [IPC Server handler 9 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tennant/contemporary	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:02,984 [IPC Server handler 0 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/tennant/contemporary	dst=null	perm=root:supergroup:rwxrwxrwt	proto=rpc
2020-04-02 05:04:02,989 [IPC Server handler 1 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=modifyAclEntries	src=/tennant/contemporary	dst=null	perm=root:supergroup:rwxrwxrwt	proto=rpc
2020-04-02 05:04:03,002 [IPC Server handler 3 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=theDoctor (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tennant/contemporary/foo	dst=null	perm=theDoctor:supergroup:rw-rw-rw-	proto=rpc
2020-04-02 05:04:03,020 [IPC Server handler 4 on 37898] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1005, replicas=127.0.0.1:44523, 127.0.0.1:42386, 127.0.0.1:42201 for /tennant/contemporary/foo
2020-04-02 05:04:03,043 [DataXceiver for client DFSClient_NONMAPREDUCE_-962709692_1 at /127.0.0.1:38720 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741828_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741828_1005 src: /127.0.0.1:38720 dest: /127.0.0.1:44523
2020-04-02 05:04:03,052 [DataXceiver for client DFSClient_NONMAPREDUCE_-962709692_1 at /127.0.0.1:40866 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741828_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741828_1005 src: /127.0.0.1:40866 dest: /127.0.0.1:42386
2020-04-02 05:04:03,058 [DataXceiver for client DFSClient_NONMAPREDUCE_-962709692_1 at /127.0.0.1:59602 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741828_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741828_1005 src: /127.0.0.1:59602 dest: /127.0.0.1:42201
2020-04-02 05:04:03,150 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741828_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59602, dest: /127.0.0.1:42201, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-962709692_1, offset: 0, srvID: 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741828_1005, duration(ns): 48115172
2020-04-02 05:04:03,152 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741828_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741828_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:03,158 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741828_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42201]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40866, dest: /127.0.0.1:42386, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-962709692_1, offset: 0, srvID: fc5fa929-8ee7-4183-a4b6-ae04670d9642, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741828_1005, duration(ns): 96446160
2020-04-02 05:04:03,160 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741828_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42201]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741828_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42201] terminating
2020-04-02 05:04:03,161 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741828_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42386, 127.0.0.1:42201]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38720, dest: /127.0.0.1:44523, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-962709692_1, offset: 0, srvID: 0411d447-0b2d-4229-84be-2623f14f0d22, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741828_1005, duration(ns): 63584924
2020-04-02 05:04:03,162 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741828_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42386, 127.0.0.1:42201]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741828_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42386, 127.0.0.1:42201] terminating
2020-04-02 05:04:03,164 [IPC Server handler 6 on 37898] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tennant/contemporary/foo is closed by DFSClient_NONMAPREDUCE_-962709692_1
2020-04-02 05:04:03,168 [IPC Server handler 8 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=theDoctor (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tennant/contemporary/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,180 [IPC Server handler 2 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=rose (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tennant/contemporary/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,180 [IPC Server handler 2 on 37898] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 2 on 37898, call Call#82 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 127.0.0.1:59658: org.apache.hadoop.security.AccessControlException: Permission denied by sticky bit: user=rose, path="/tennant/contemporary/foo":theDoctor:supergroup:-rw-rw-rw-, parent="/tennant/contemporary":root:supergroup:drwxrwxrwt
2020-04-02 05:04:03,192 [IPC Server handler 9 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/smith	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:03,199 [IPC Server handler 1 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/smith/scissorsisters	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:03,203 [IPC Server handler 3 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=modifyAclEntries	src=/smith/scissorsisters	dst=null	perm=root:supergroup:rw-rwxr--	proto=rpc
2020-04-02 05:04:03,211 [IPC Server handler 4 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/smith/scissorsisters/bar	dst=null	perm=root:supergroup:rw-rwxr--	proto=rpc
2020-04-02 05:04:03,225 [IPC Server handler 5 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/smith/scissorsisters/bar	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.permission.TestStickyBit#testAclGeneralSBBehavior
[msx] writeFile testName = org.apache.hadoop.fs.permission.TestStickyBit#testAclGeneralSBBehavior
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.permission.TestStickyBit#testAclMovingFiles
[msx] perform reset as unitTestCounterInClass 2 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:03,228 [IPC Server handler 7 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,230 [IPC Server handler 6 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/eccleston	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,233 [IPC Server handler 8 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/mcgann	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,238 [IPC Server handler 2 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/smith	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,241 [IPC Server handler 9 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tennant	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,250 [IPC Server handler 0 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:03,251 [IPC Server handler 1 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:03,253 [IPC Server handler 3 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/tmp	dst=null	perm=root:supergroup:rwxrwxrwt	proto=rpc
2020-04-02 05:04:03,257 [IPC Server handler 4 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=modifyAclEntries	src=/tmp	dst=null	perm=root:supergroup:rwxrwxrwt	proto=rpc
2020-04-02 05:04:03,268 [IPC Server handler 5 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/tmp2	dst=null	perm=root:supergroup:rwxrwxrwt	proto=rpc
2020-04-02 05:04:03,272 [IPC Server handler 7 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=modifyAclEntries	src=/tmp2	dst=null	perm=root:supergroup:rwxrwxrwt	proto=rpc
2020-04-02 05:04:03,276 [IPC Server handler 6 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=theDoctor (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/foo	dst=null	perm=theDoctor:supergroup:rw-rw-rw-	proto=rpc
2020-04-02 05:04:03,289 [IPC Server handler 8 on 37898] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741829_1006, replicas=127.0.0.1:46328, 127.0.0.1:42386, 127.0.0.1:44523 for /tmp/foo
2020-04-02 05:04:03,301 [DataXceiver for client DFSClient_NONMAPREDUCE_-962709692_1 at /127.0.0.1:44316 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741829_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741829_1006 src: /127.0.0.1:44316 dest: /127.0.0.1:46328
2020-04-02 05:04:03,308 [DataXceiver for client DFSClient_NONMAPREDUCE_-962709692_1 at /127.0.0.1:40910 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741829_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741829_1006 src: /127.0.0.1:40910 dest: /127.0.0.1:42386
2020-04-02 05:04:03,319 [DataXceiver for client DFSClient_NONMAPREDUCE_-962709692_1 at /127.0.0.1:38768 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741829_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741829_1006 src: /127.0.0.1:38768 dest: /127.0.0.1:44523
2020-04-02 05:04:03,384 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741829_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38768, dest: /127.0.0.1:44523, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-962709692_1, offset: 0, srvID: 0411d447-0b2d-4229-84be-2623f14f0d22, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741829_1006, duration(ns): 25686497
2020-04-02 05:04:03,384 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741829_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741829_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:03,393 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741829_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44523]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40910, dest: /127.0.0.1:42386, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-962709692_1, offset: 0, srvID: fc5fa929-8ee7-4183-a4b6-ae04670d9642, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741829_1006, duration(ns): 35451981
2020-04-02 05:04:03,396 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741829_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44523]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741829_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44523] terminating
2020-04-02 05:04:03,411 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741829_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42386, 127.0.0.1:44523]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44316, dest: /127.0.0.1:46328, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-962709692_1, offset: 0, srvID: bb837d1a-fd41-4783-ba5c-f312fcccd0ee, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741829_1006, duration(ns): 52694735
2020-04-02 05:04:03,411 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741829_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42386, 127.0.0.1:44523]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741829_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42386, 127.0.0.1:44523] terminating
2020-04-02 05:04:03,439 [IPC Server handler 1 on 37898] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/foo is closed by DFSClient_NONMAPREDUCE_-962709692_1
2020-04-02 05:04:03,452 [IPC Server handler 3 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=rose (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/tmp/foo	dst=/tmp2/renamed	perm=null	proto=rpc
2020-04-02 05:04:03,452 [IPC Server handler 3 on 37898] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 3 on 37898, call Call#105 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename from 127.0.0.1:59658: org.apache.hadoop.security.AccessControlException: Permission denied by sticky bit: user=rose, path="/tmp/foo":theDoctor:supergroup:-rw-rw-rw-, parent="/tmp":root:supergroup:drwxrwxrwt
[msx] test Finished org.apache.hadoop.fs.permission.TestStickyBit#testAclMovingFiles
[msx] writeFile testName = org.apache.hadoop.fs.permission.TestStickyBit#testAclMovingFiles
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.permission.TestStickyBit#testStickyBitRecursiveDeleteDir
[msx] perform reset as unitTestCounterInClass 3 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:03,458 [IPC Server handler 4 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,461 [IPC Server handler 5 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,463 [IPC Server handler 7 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp2	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,466 [IPC Server handler 6 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/testStickyBitRecursiveDeleteDir/tmp	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:03,468 [IPC Server handler 8 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/testStickyBitRecursiveDeleteDir	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
2020-04-02 05:04:03,469 [IPC Server handler 2 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/testStickyBitRecursiveDeleteDir/tmp	dst=null	perm=root:supergroup:rwxrwxrwt	proto=rpc
2020-04-02 05:04:03,473 [IPC Server handler 9 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=theDoctor (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/testStickyBitRecursiveDeleteDir/tmp/dir	dst=null	perm=theDoctor:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:03,481 [IPC Server handler 0 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=theDoctor (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/testStickyBitRecursiveDeleteDir/tmp/dir	dst=null	perm=theDoctor:supergroup:rwxrwxrwx	proto=rpc
2020-04-02 05:04:03,487 [IPC Server handler 1 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=theDoctor (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/testStickyBitRecursiveDeleteDir/tmp/dir/file	dst=null	perm=theDoctor:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:03,507 [IPC Server handler 3 on 37898] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741830_1007, replicas=127.0.0.1:44523, 127.0.0.1:46328, 127.0.0.1:42386 for /testStickyBitRecursiveDeleteDir/tmp/dir/file
2020-04-02 05:04:03,513 [DataXceiver for client DFSClient_NONMAPREDUCE_-962709692_1 at /127.0.0.1:38778 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741830_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741830_1007 src: /127.0.0.1:38778 dest: /127.0.0.1:44523
2020-04-02 05:04:03,515 [DataXceiver for client DFSClient_NONMAPREDUCE_-962709692_1 at /127.0.0.1:44334 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741830_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741830_1007 src: /127.0.0.1:44334 dest: /127.0.0.1:46328
2020-04-02 05:04:03,518 [DataXceiver for client DFSClient_NONMAPREDUCE_-962709692_1 at /127.0.0.1:40926 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741830_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741830_1007 src: /127.0.0.1:40926 dest: /127.0.0.1:42386
2020-04-02 05:04:03,589 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741830_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40926, dest: /127.0.0.1:42386, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-962709692_1, offset: 0, srvID: fc5fa929-8ee7-4183-a4b6-ae04670d9642, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741830_1007, duration(ns): 56875232
2020-04-02 05:04:03,589 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741830_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741830_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:03,597 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741830_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42386]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44334, dest: /127.0.0.1:46328, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-962709692_1, offset: 0, srvID: bb837d1a-fd41-4783-ba5c-f312fcccd0ee, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741830_1007, duration(ns): 48384958
2020-04-02 05:04:03,597 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741830_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42386]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741830_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42386] terminating
2020-04-02 05:04:03,599 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741830_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46328, 127.0.0.1:42386]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38778, dest: /127.0.0.1:44523, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-962709692_1, offset: 0, srvID: 0411d447-0b2d-4229-84be-2623f14f0d22, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741830_1007, duration(ns): 56889115
2020-04-02 05:04:03,599 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741830_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46328, 127.0.0.1:42386]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741830_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46328, 127.0.0.1:42386] terminating
2020-04-02 05:04:03,601 [IPC Server handler 6 on 37898] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /testStickyBitRecursiveDeleteDir/tmp/dir/file is closed by DFSClient_NONMAPREDUCE_-962709692_1
2020-04-02 05:04:03,605 [IPC Server handler 8 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/testStickyBitRecursiveDeleteDir/tmp/dir/file	dst=null	perm=theDoctor:supergroup:rw-rw-rw-	proto=rpc
2020-04-02 05:04:03,614 [IPC Server handler 2 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=rose (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/testStickyBitRecursiveDeleteDir/tmp	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,615 [IPC Server handler 2 on 37898] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 2 on 37898, call Call#121 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 127.0.0.1:59658: org.apache.hadoop.security.AccessControlException: Permission denied by sticky bit: user=rose, path="/testStickyBitRecursiveDeleteDir/tmp/dir":theDoctor:supergroup:drwxrwxrwx, parent="/testStickyBitRecursiveDeleteDir/tmp":root:supergroup:drwxrwxrwt
2020-04-02 05:04:03,618 [IPC Server handler 9 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=theDoctor (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/testStickyBitRecursiveDeleteDir/tmp	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.permission.TestStickyBit#testStickyBitRecursiveDeleteDir
[msx] writeFile testName = org.apache.hadoop.fs.permission.TestStickyBit#testStickyBitRecursiveDeleteDir
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.permission.TestStickyBit#testAclStickyBitPersistence
[msx] perform reset as unitTestCounterInClass 4 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:03,631 [IPC Server handler 1 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,633 [IPC Server handler 3 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/testStickyBitRecursiveDeleteDir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:03,637 [IPC Server handler 4 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/Housemartins	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:03,642 [IPC Server handler 5 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/INXS	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:03,666 [IPC Server handler 2 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/Easyworld	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:03,674 [IPC Server handler 9 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/Housemartins	dst=null	perm=root:supergroup:rwxrwxrwt	proto=rpc
2020-04-02 05:04:03,682 [IPC Server handler 0 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=modifyAclEntries	src=/Housemartins	dst=null	perm=root:supergroup:rwxrwxrwt	proto=rpc
2020-04-02 05:04:03,690 [IPC Server handler 1 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/Easyworld	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
2020-04-02 05:04:03,694 [IPC Server handler 3 on 37898] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=modifyAclEntries	src=/Easyworld	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
2020-04-02 05:04:03,697 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:04:03,697 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 3
2020-04-02 05:04:03,698 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40520 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:03,698 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:03,702 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2f7a7219] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:03,707 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-3013b8d1-d536-416d-897a-21c98c02f8c3) exiting.
2020-04-02 05:04:03,713 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-f8a6047a-08e2-4aa0-81dc-441677cee101) exiting.
2020-04-02 05:04:03,868 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@290b1b2e{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:03,886 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@47874b25{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:03,887 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5118388b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:03,887 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@314b8f2d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:04:03,922 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40520
2020-04-02 05:04:03,941 [IPC Server listener on 40520] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40520
2020-04-02 05:04:03,941 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:03,943 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:03,943 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 0411d447-0b2d-4229-84be-2623f14f0d22) service to localhost/127.0.0.1:37898
2020-04-02 05:04:03,944 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 0411d447-0b2d-4229-84be-2623f14f0d22)
2020-04-02 05:04:03,944 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:03,957 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:03,979 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:03,989 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:03,989 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:03,991 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:03,991 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:04,004 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:04,004 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:04:04,004 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 45758 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:04,004 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:04,006 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-6a50e38d-8394-493e-bae9-21cc555d5ff0) exiting.
2020-04-02 05:04:04,006 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-ff45f1b6-7489-4193-a7b7-463383a325e2) exiting.
2020-04-02 05:04:04,026 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@66629f63] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:04,306 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@63cd604c{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:04,307 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@40dd3977{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:04,308 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3af17be2{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:04,308 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4fcee388{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:04:04,319 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45758
2020-04-02 05:04:04,335 [IPC Server listener on 45758] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45758
2020-04-02 05:04:04,336 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:04,336 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:04,365 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid fc5fa929-8ee7-4183-a4b6-ae04670d9642) service to localhost/127.0.0.1:37898
2020-04-02 05:04:04,365 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid fc5fa929-8ee7-4183-a4b6-ae04670d9642)
2020-04-02 05:04:04,365 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:04,386 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:04,397 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:04,412 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:04,412 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:04,413 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:04,414 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:04,420 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:04,421 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:04:04,421 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 37167 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:04,421 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:04,426 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@41fe9859] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:04,429 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-4f1eb05d-12f5-4429-a347-6330e649b422) exiting.
2020-04-02 05:04:04,430 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-a1bb379d-e304-41de-8d6b-868fc820a567) exiting.
2020-04-02 05:04:04,491 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6865c751{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:04,493 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@62679465{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:04,498 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1c98290c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:04,499 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@63c5efee{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:04:04,526 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37167
2020-04-02 05:04:04,531 [IPC Server listener on 37167] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37167
2020-04-02 05:04:04,532 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:04,535 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb) service to localhost/127.0.0.1:37898
2020-04-02 05:04:04,536 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb)
2020-04-02 05:04:04,536 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:04,544 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:04,535 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:04,553 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:04,569 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:04,569 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:04,578 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:04,578 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:04,598 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:04,598 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:04:04,598 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 32976 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:04,598 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:04,605 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-17e72323-9be8-4266-96b2-cee02356855e) exiting.
2020-04-02 05:04:04,605 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e71e2ffb-339e-4462-8c88-b84e94847941) exiting.
2020-04-02 05:04:04,638 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2ccca26f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:04,676 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6aecbb8d{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:04,678 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3bcc07fa{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:04,678 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3fa2213{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:04,680 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5e81e5ac{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:04:04,696 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 32976
2020-04-02 05:04:04,710 [IPC Server listener on 32976] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 32976
2020-04-02 05:04:04,720 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:04,726 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:04,726 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid bb837d1a-fd41-4783-ba5c-f312fcccd0ee) service to localhost/127.0.0.1:37898
2020-04-02 05:04:04,830 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid bb837d1a-fd41-4783-ba5c-f312fcccd0ee)
2020-04-02 05:04:04,830 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:37898] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:04,847 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:04,859 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:04,881 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:04,882 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:04,885 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:04,885 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:04,892 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:04,893 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:04:04,893 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 37898 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:04,893 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:04,899 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 87
2020-04-02 05:04:04,900 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 88 Total time for transactions(ms): 41 Number of transactions batched in Syncs: 13 Number of syncs: 76 SyncTimes(ms): 20 3 
2020-04-02 05:04:04,901 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000088
2020-04-02 05:04:04,902 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@25e2ab5a] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:04:04,902 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000088
2020-04-02 05:04:04,905 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:04:04,905 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@35e5d0e5] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:04:04,913 [CacheReplicationMonitor(14954711)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:04:04,918 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37898
2020-04-02 05:04:04,934 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:04,934 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:04:04,934 [IPC Server listener on 37898] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37898
2020-04-02 05:04:04,957 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:04:05,031 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:05,031 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:04:05,035 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7fc4780b{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:04:05,054 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6b58b9e9{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:05,055 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f67a4d3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:05,056 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@565f390{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:04:05,077 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:04:05,096 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:04:05,097 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:04:05,106 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=4
2020-04-02 05:04:05,108 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:04:05,117 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:04:05,120 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:04:05,120 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:04:05,120 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:04:05,121 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:04:05,133 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1b822fcc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:04:05,134 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:04:05,134 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:05,136 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:04:05,137 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:04:05,137 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:05,138 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:04:05,139 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:04:05,140 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:04:05,140 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:04:05,141 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:04:05,142 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:04:05,142 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34961
2020-04-02 05:04:05,142 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:04:05,148 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@410954b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:04:05,149 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3b366632{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:04:05,155 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@687a762c{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:04:05,156 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1a2e2935{HTTP/1.1,[http/1.1]}{localhost:34961}
2020-04-02 05:04:05,156 [main] INFO  server.Server (Server.java:doStart(419)) - Started @15839ms
2020-04-02 05:04:05,190 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:04:05,191 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:04:05,191 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:04:05,191 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:04:05,191 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:04:05,191 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:04:05,191 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:04:05,192 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:04:05,196 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:05,197 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:04:05,197 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:04:05,197 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:04:05,207 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:04:05
2020-04-02 05:04:05,207 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:04:05,207 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:05,208 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:04:05,208 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:04:05,213 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:04:05,214 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:04:05,214 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:04:05,214 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:04:05,214 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:04:05,214 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:04:05,214 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:04:05,214 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:04:05,214 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:04:05,214 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:04:05,214 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:04:05,215 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:04:05,215 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:04:05,215 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:05,215 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:04:05,215 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:04:05,219 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:04:05,220 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:04:05,220 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:04:05,220 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:04:05,220 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:04:05,220 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:04:05,220 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:04:05,220 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:05,221 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:04:05,221 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:04:05,222 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:04:05,222 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:04:05,222 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:04:05,223 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:04:05,223 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:04:05,223 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:04:05,224 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:05,224 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:04:05,224 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:04:05,230 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:04:05,237 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:04:05,239 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:04:05,241 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:04:05,254 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:04:05,256 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:04:05,261 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:04:05,261 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:04:05,262 [main] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@71f67a79 expecting start txid #1
2020-04-02 05:04:05,262 [main] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000088, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000088 maxTxnsToRead = 9223372036854775807
2020-04-02 05:04:05,263 [main] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000088' to transaction ID 1
2020-04-02 05:04:05,310 [main] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000088, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000088 of size 6620 edits # 88 loaded in 0 seconds
2020-04-02 05:04:05,310 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:04:05,339 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 89
2020-04-02 05:04:05,386 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:04:05,386 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 161 msecs
2020-04-02 05:04:05,387 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:04:05,387 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:04:05,388 [Socket Reader #1 for port 33297] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33297
2020-04-02 05:04:05,404 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:33297 to access this namenode/service.
2020-04-02 05:04:05,404 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:04:05,487 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:04:05,501 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:04:05,501 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:04:05,501 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:04:05,502 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:04:05,521 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:04:05,522 [IPC Server listener on 33297] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33297: starting
2020-04-02 05:04:05,524 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:33297
2020-04-02 05:04:05,550 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:04:05,550 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:04:05,550 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:04:05,550 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:04:05,550 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:04:05,551 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 33 msec
2020-04-02 05:04:05,553 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:04:05,554 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:04:05,586 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 32 milliseconds
name space=4
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:04:05,588 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 33297 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:05,589 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:04:05,591 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:04:05,591 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:04:05,593 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:04:05,593 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:04:05,593 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:05,594 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:04:05,594 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:04:05,594 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:05,594 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:04:05,595 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:45934
2020-04-02 05:04:05,595 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:04:05,595 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:04:05,600 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:05,626 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:04:05,627 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:04:05,627 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:05,623 [CacheReplicationMonitor(1214682859)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:04:05,646 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:04:05,647 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:04:05,647 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:04:05,647 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:04:05,648 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46058
2020-04-02 05:04:05,648 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:04:05,650 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1b58ff9e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:04:05,651 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@56b78e55{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:04:05,658 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1051817b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:04:05,659 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@35293c05{HTTP/1.1,[http/1.1]}{localhost:46058}
2020-04-02 05:04:05,667 [main] INFO  server.Server (Server.java:doStart(419)) - Started @16350ms
2020-04-02 05:04:05,721 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34934
2020-04-02 05:04:05,721 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:04:05,722 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2db2dd9d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:04:05,722 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:04:05,722 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:04:05,724 [Socket Reader #1 for port 41808] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41808
2020-04-02 05:04:05,732 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:41808
2020-04-02 05:04:05,755 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:04:05,756 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:04:05,756 [Thread-310] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33297 starting to offer service
2020-04-02 05:04:05,791 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 41808 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:05,792 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:04:05,793 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:04:05,797 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:04:05,828 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:04:05,829 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:04:05,829 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:04:05,830 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:05,793 [IPC Server listener on 41808] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41808: starting
2020-04-02 05:04:05,833 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:04:05,834 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:04:05,835 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:05,835 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:04:05,835 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:45138
2020-04-02 05:04:05,836 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:04:05,836 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:04:05,838 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:05,840 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:04:05,841 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:04:05,842 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:05,843 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:04:05,843 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:04:05,843 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:04:05,844 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:04:05,844 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42085
2020-04-02 05:04:05,844 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:04:05,852 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5149f008{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:04:05,853 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@158d255c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:04:05,888 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@120f38e6{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:04:05,891 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7a0e1b5e{HTTP/1.1,[http/1.1]}{localhost:42085}
2020-04-02 05:04:05,892 [main] INFO  server.Server (Server.java:doStart(419)) - Started @16575ms
2020-04-02 05:04:05,906 [Thread-310] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33297
2020-04-02 05:04:05,918 [Thread-310] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:04:05,920 [Thread-310] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:04:05,956 [Thread-310] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:04:05,956 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41566
2020-04-02 05:04:05,957 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@173b9122] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:04:06,006 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:04:06,006 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:04:06,007 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:04:06,108 [Socket Reader #1 for port 43430] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43430
2020-04-02 05:04:06,139 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43430
2020-04-02 05:04:06,147 [Thread-310] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,148 [Thread-310] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,151 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:04:06,152 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:04:06,152 [Thread-334] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33297 starting to offer service
2020-04-02 05:04:06,153 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:04:06,153 [IPC Server listener on 43430] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43430: starting
2020-04-02 05:04:06,154 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43430 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:06,155 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:04:06,156 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:04:06,156 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:04:06,157 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:04:06,157 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:04:06,157 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:06,157 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:04:06,165 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:04:06,165 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:06,165 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:04:06,166 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:45355
2020-04-02 05:04:06,166 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:04:06,166 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:04:06,174 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:06,175 [Thread-310] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,176 [Thread-310] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,177 [Thread-310] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1950780784;bpid=BP-1929959544-172.17.0.14-1585803832412;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1950780784;c=1585803832412;bpid=BP-1929959544-172.17.0.14-1585803832412;dnuuid=bb837d1a-fd41-4783-ba5c-f312fcccd0ee
2020-04-02 05:04:06,180 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-e71e2ffb-339e-4462-8c88-b84e94847941
2020-04-02 05:04:06,180 [Thread-310] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:04:06,181 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:04:06,181 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:04:06,181 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-17e72323-9be8-4266-96b2-cee02356855e
2020-04-02 05:04:06,182 [Thread-310] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:04:06,182 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:06,183 [Thread-310] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:04:06,184 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:04:06,185 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:04:06,185 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:04:06,185 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:04:06,184 [Thread-310] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:04:06,186 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34105
2020-04-02 05:04:06,186 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:04:06,186 [Thread-310] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:04:06,186 [Thread-310] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:04:06,186 [Thread-310] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:04:06,190 [Thread-334] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33297
2020-04-02 05:04:06,193 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@c1fca1e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:04:06,198 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@344344fa{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:04:06,202 [Thread-334] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:04:06,202 [Thread-310] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,203 [Thread-353] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:04:06,205 [Thread-353] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1929959544-172.17.0.14-1585803832412/current: 24663
2020-04-02 05:04:06,206 [Thread-354] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:04:06,208 [Thread-354] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1929959544-172.17.0.14-1585803832412/current: 24677
2020-04-02 05:04:06,208 [Thread-334] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:04:06,216 [Thread-353] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 13ms
2020-04-02 05:04:06,220 [Thread-334] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:04:06,218 [Thread-354] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 12ms
2020-04-02 05:04:06,228 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1929959544-172.17.0.14-1585803832412: 25ms
2020-04-02 05:04:06,231 [Thread-356] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:04:06,232 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7957dc72{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:04:06,236 [Thread-355] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:04:06,246 [Thread-355] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas
2020-04-02 05:04:06,246 [Thread-355] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 0ms
2020-04-02 05:04:06,237 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6ab72419{HTTP/1.1,[http/1.1]}{localhost:34105}
2020-04-02 05:04:06,247 [Thread-356] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas
2020-04-02 05:04:06,247 [Thread-356] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 15ms
2020-04-02 05:04:06,247 [main] INFO  server.Server (Server.java:doStart(419)) - Started @16930ms
2020-04-02 05:04:06,247 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412: 19ms
2020-04-02 05:04:06,277 [Thread-334] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,277 [Thread-334] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,287 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46702
2020-04-02 05:04:06,288 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:04:06,288 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4fdfa676] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:04:06,288 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:04:06,289 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:04:06,289 [Socket Reader #1 for port 41367] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41367
2020-04-02 05:04:06,289 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-17e72323-9be8-4266-96b2-cee02356855e): no suitable block pools found to scan.  Waiting 1814394121 ms.
2020-04-02 05:04:06,297 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e71e2ffb-339e-4462-8c88-b84e94847941): no suitable block pools found to scan.  Waiting 1814394113 ms.
2020-04-02 05:04:06,296 [Thread-310] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:23 AM with interval of 21600000ms
2020-04-02 05:04:06,302 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid bb837d1a-fd41-4783-ba5c-f312fcccd0ee) service to localhost/127.0.0.1:33297 beginning handshake with NN
2020-04-02 05:04:06,305 [IPC Server handler 2 on 33297] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45934, datanodeUuid=bb837d1a-fd41-4783-ba5c-f312fcccd0ee, infoPort=34934, infoSecurePort=0, ipcPort=41808, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412) storage bb837d1a-fd41-4783-ba5c-f312fcccd0ee
2020-04-02 05:04:06,305 [IPC Server handler 2 on 33297] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45934
2020-04-02 05:04:06,305 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:41367
2020-04-02 05:04:06,308 [Thread-334] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,322 [Thread-334] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,323 [Thread-334] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1950780784;bpid=BP-1929959544-172.17.0.14-1585803832412;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1950780784;c=1585803832412;bpid=BP-1929959544-172.17.0.14-1585803832412;dnuuid=8bebbb2e-b355-4030-af1e-ab7e8b7c53eb
2020-04-02 05:04:06,305 [IPC Server handler 2 on 33297] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN bb837d1a-fd41-4783-ba5c-f312fcccd0ee (127.0.0.1:45934).
2020-04-02 05:04:06,404 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:04:06,412 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:04:06,413 [Thread-334] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-a1bb379d-e304-41de-8d6b-868fc820a567
2020-04-02 05:04:06,422 [Thread-334] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:04:06,426 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:04:06,431 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid bb837d1a-fd41-4783-ba5c-f312fcccd0ee) service to localhost/127.0.0.1:33297 successfully registered with NN
2020-04-02 05:04:06,432 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33297 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:04:06,434 [IPC Server listener on 41367] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41367: starting
2020-04-02 05:04:06,443 [Thread-334] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-4f1eb05d-12f5-4429-a347-6330e649b422
2020-04-02 05:04:06,493 [Thread-334] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:04:06,493 [Thread-334] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:04:06,455 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 41367 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:06,494 [Thread-367] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33297 starting to offer service
2020-04-02 05:04:06,495 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:04:06,495 [Thread-334] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:04:06,496 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:04:06,496 [Thread-334] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:04:06,496 [Thread-334] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:04:06,496 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:04:06,496 [Thread-334] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:04:06,496 [Thread-334] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,497 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:04:06,497 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:04:06,497 [Thread-379] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:04:06,497 [Thread-380] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:04:06,497 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:06,497 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:04:06,498 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:04:06,498 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:06,498 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:04:06,499 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40466
2020-04-02 05:04:06,499 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:04:06,499 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:04:06,508 [Thread-380] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1929959544-172.17.0.14-1585803832412/current: 24605
2020-04-02 05:04:06,508 [Thread-379] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1929959544-172.17.0.14-1585803832412/current: 24605
2020-04-02 05:04:06,526 [IPC Server handler 3 on 33297] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e71e2ffb-339e-4462-8c88-b84e94847941 for DN 127.0.0.1:45934
2020-04-02 05:04:06,526 [IPC Server handler 3 on 33297] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-17e72323-9be8-4266-96b2-cee02356855e for DN 127.0.0.1:45934
2020-04-02 05:04:06,526 [Thread-367] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33297
2020-04-02 05:04:06,526 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:06,529 [Thread-367] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:04:06,535 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x312dd88f82665796: Processing first storage report for DS-17e72323-9be8-4266-96b2-cee02356855e from datanode bb837d1a-fd41-4783-ba5c-f312fcccd0ee
2020-04-02 05:04:06,538 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x312dd88f82665796: from storage DS-17e72323-9be8-4266-96b2-cee02356855e node DatanodeRegistration(127.0.0.1:45934, datanodeUuid=bb837d1a-fd41-4783-ba5c-f312fcccd0ee, infoPort=34934, infoSecurePort=0, ipcPort=41808, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 2, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:06,538 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x312dd88f82665796: Processing first storage report for DS-e71e2ffb-339e-4462-8c88-b84e94847941 from datanode bb837d1a-fd41-4783-ba5c-f312fcccd0ee
2020-04-02 05:04:06,538 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x312dd88f82665796: from storage DS-e71e2ffb-339e-4462-8c88-b84e94847941 node DatanodeRegistration(127.0.0.1:45934, datanodeUuid=bb837d1a-fd41-4783-ba5c-f312fcccd0ee, infoPort=34934, infoSecurePort=0, ipcPort=41808, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 3, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:06,542 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:04:06,544 [Thread-367] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:04:06,545 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:04:06,545 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:06,551 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x312dd88f82665796,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:04:06,562 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,547 [Thread-367] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:04:06,585 [Thread-380] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 88ms
2020-04-02 05:04:06,585 [Thread-379] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 88ms
2020-04-02 05:04:06,582 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:04:06,586 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:04:06,587 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:04:06,587 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:04:06,588 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37341
2020-04-02 05:04:06,588 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:04:06,593 [Thread-367] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,594 [Thread-367] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,595 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7db0565c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:04:06,595 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@52eacb4b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:04:06,604 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@52d10fb8{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:04:06,609 [Thread-334] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1929959544-172.17.0.14-1585803832412: 113ms
2020-04-02 05:04:06,614 [Thread-387] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:04:06,614 [Thread-388] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:04:06,618 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@41c07648{HTTP/1.1,[http/1.1]}{localhost:37341}
2020-04-02 05:04:06,618 [main] INFO  server.Server (Server.java:doStart(419)) - Started @17301ms
2020-04-02 05:04:06,618 [Thread-387] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas
2020-04-02 05:04:06,619 [Thread-387] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 5ms
2020-04-02 05:04:06,619 [Thread-388] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas
2020-04-02 05:04:06,620 [Thread-388] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 6ms
2020-04-02 05:04:06,625 [Thread-367] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,626 [Thread-367] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,626 [Thread-334] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412: 16ms
2020-04-02 05:04:06,629 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-4f1eb05d-12f5-4429-a347-6330e649b422): no suitable block pools found to scan.  Waiting 1814393776 ms.
2020-04-02 05:04:06,629 [Thread-367] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1950780784;bpid=BP-1929959544-172.17.0.14-1585803832412;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1950780784;c=1585803832412;bpid=BP-1929959544-172.17.0.14-1585803832412;dnuuid=fc5fa929-8ee7-4183-a4b6-ae04670d9642
2020-04-02 05:04:06,630 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-a1bb379d-e304-41de-8d6b-868fc820a567): no suitable block pools found to scan.  Waiting 1814393775 ms.
2020-04-02 05:04:06,629 [Thread-334] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:22 AM with interval of 21600000ms
2020-04-02 05:04:06,634 [Thread-367] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-6a50e38d-8394-493e-bae9-21cc555d5ff0
2020-04-02 05:04:06,637 [Thread-367] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:04:06,637 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb) service to localhost/127.0.0.1:33297 beginning handshake with NN
2020-04-02 05:04:06,640 [Thread-367] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-ff45f1b6-7489-4193-a7b7-463383a325e2
2020-04-02 05:04:06,643 [Thread-367] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:04:06,644 [Thread-367] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:04:06,645 [Thread-367] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:04:06,646 [Thread-367] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:04:06,646 [Thread-367] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:04:06,646 [Thread-367] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:04:06,647 [Thread-367] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,648 [Thread-394] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:04:06,641 [IPC Server handler 1 on 33297] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45138, datanodeUuid=8bebbb2e-b355-4030-af1e-ab7e8b7c53eb, infoPort=41566, infoSecurePort=0, ipcPort=43430, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412) storage 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb
2020-04-02 05:04:06,650 [IPC Server handler 1 on 33297] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45138
2020-04-02 05:04:06,650 [IPC Server handler 1 on 33297] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb (127.0.0.1:45138).
2020-04-02 05:04:06,651 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb) service to localhost/127.0.0.1:33297 successfully registered with NN
2020-04-02 05:04:06,651 [Thread-395] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:04:06,651 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33297 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:04:06,658 [Thread-394] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1929959544-172.17.0.14-1585803832412/current: 24663
2020-04-02 05:04:06,673 [IPC Server handler 2 on 33297] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a1bb379d-e304-41de-8d6b-868fc820a567 for DN 127.0.0.1:45138
2020-04-02 05:04:06,682 [IPC Server handler 2 on 33297] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4f1eb05d-12f5-4429-a347-6330e649b422 for DN 127.0.0.1:45138
2020-04-02 05:04:06,700 [Thread-395] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1929959544-172.17.0.14-1585803832412/current: 24677
2020-04-02 05:04:06,721 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2c770181a7cef5f0: Processing first storage report for DS-a1bb379d-e304-41de-8d6b-868fc820a567 from datanode 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb
2020-04-02 05:04:06,721 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2c770181a7cef5f0: from storage DS-a1bb379d-e304-41de-8d6b-868fc820a567 node DatanodeRegistration(127.0.0.1:45138, datanodeUuid=8bebbb2e-b355-4030-af1e-ab7e8b7c53eb, infoPort=41566, infoSecurePort=0, ipcPort=43430, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 1, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:06,721 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2c770181a7cef5f0: Processing first storage report for DS-4f1eb05d-12f5-4429-a347-6330e649b422 from datanode 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb
2020-04-02 05:04:06,721 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2c770181a7cef5f0: from storage DS-4f1eb05d-12f5-4429-a347-6330e649b422 node DatanodeRegistration(127.0.0.1:45138, datanodeUuid=8bebbb2e-b355-4030-af1e-ab7e8b7c53eb, infoPort=41566, infoSecurePort=0, ipcPort=43430, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:06,739 [Thread-394] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 91ms
2020-04-02 05:04:06,753 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x2c770181a7cef5f0,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 1 msec to generate and 33 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:04:06,761 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,768 [Thread-395] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 117ms
2020-04-02 05:04:06,780 [Thread-367] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1929959544-172.17.0.14-1585803832412: 132ms
2020-04-02 05:04:06,784 [Thread-396] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:04:06,786 [Thread-396] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas
2020-04-02 05:04:06,786 [Thread-396] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 2ms
2020-04-02 05:04:06,788 [Thread-397] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:04:06,789 [Thread-397] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas
2020-04-02 05:04:06,789 [Thread-397] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 1ms
2020-04-02 05:04:06,789 [Thread-367] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412: 9ms
2020-04-02 05:04:06,792 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-ff45f1b6-7489-4193-a7b7-463383a325e2): no suitable block pools found to scan.  Waiting 1814393612 ms.
2020-04-02 05:04:06,792 [Thread-367] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:13 AM with interval of 21600000ms
2020-04-02 05:04:06,797 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-6a50e38d-8394-493e-bae9-21cc555d5ff0): no suitable block pools found to scan.  Waiting 1814393607 ms.
2020-04-02 05:04:06,799 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid fc5fa929-8ee7-4183-a4b6-ae04670d9642) service to localhost/127.0.0.1:33297 beginning handshake with NN
2020-04-02 05:04:06,799 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42598
2020-04-02 05:04:06,799 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:04:06,799 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@781e7326] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:04:06,799 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:04:06,800 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:04:06,801 [Socket Reader #1 for port 37713] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37713
2020-04-02 05:04:06,803 [IPC Server handler 9 on 33297] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45355, datanodeUuid=fc5fa929-8ee7-4183-a4b6-ae04670d9642, infoPort=46702, infoSecurePort=0, ipcPort=41367, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412) storage fc5fa929-8ee7-4183-a4b6-ae04670d9642
2020-04-02 05:04:06,803 [IPC Server handler 9 on 33297] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45355
2020-04-02 05:04:06,803 [IPC Server handler 9 on 33297] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN fc5fa929-8ee7-4183-a4b6-ae04670d9642 (127.0.0.1:45355).
2020-04-02 05:04:06,804 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid fc5fa929-8ee7-4183-a4b6-ae04670d9642) service to localhost/127.0.0.1:33297 successfully registered with NN
2020-04-02 05:04:06,805 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33297 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:04:06,811 [IPC Server handler 3 on 33297] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6a50e38d-8394-493e-bae9-21cc555d5ff0 for DN 127.0.0.1:45355
2020-04-02 05:04:06,812 [IPC Server handler 3 on 33297] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ff45f1b6-7489-4193-a7b7-463383a325e2 for DN 127.0.0.1:45355
2020-04-02 05:04:06,818 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd1197b5cae3c88f3: Processing first storage report for DS-6a50e38d-8394-493e-bae9-21cc555d5ff0 from datanode fc5fa929-8ee7-4183-a4b6-ae04670d9642
2020-04-02 05:04:06,818 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd1197b5cae3c88f3: from storage DS-6a50e38d-8394-493e-bae9-21cc555d5ff0 node DatanodeRegistration(127.0.0.1:45355, datanodeUuid=fc5fa929-8ee7-4183-a4b6-ae04670d9642, infoPort=46702, infoSecurePort=0, ipcPort=41367, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 3, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:06,819 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd1197b5cae3c88f3: Processing first storage report for DS-ff45f1b6-7489-4193-a7b7-463383a325e2 from datanode fc5fa929-8ee7-4183-a4b6-ae04670d9642
2020-04-02 05:04:06,819 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd1197b5cae3c88f3: from storage DS-ff45f1b6-7489-4193-a7b7-463383a325e2 node DatanodeRegistration(127.0.0.1:45355, datanodeUuid=fc5fa929-8ee7-4183-a4b6-ae04670d9642, infoPort=46702, infoSecurePort=0, ipcPort=41367, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:06,820 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xd1197b5cae3c88f3,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 0 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:04:06,820 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,828 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:37713
2020-04-02 05:04:06,841 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:04:06,842 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:04:06,843 [Thread-407] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33297 starting to offer service
2020-04-02 05:04:06,844 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:04:06,844 [IPC Server listener on 37713] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37713: starting
2020-04-02 05:04:06,845 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 37713 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:06,883 [IPC Server handler 7 on 33297] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,885 [Thread-407] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33297
2020-04-02 05:04:06,886 [Thread-407] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:04:06,887 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:04:06,887 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:04:06,888 [Thread-407] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:04:06,897 [Thread-407] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:04:06,912 [Thread-407] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,915 [Thread-407] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,936 [Thread-407] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,936 [Thread-407] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,938 [Thread-407] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1950780784;bpid=BP-1929959544-172.17.0.14-1585803832412;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1950780784;c=1585803832412;bpid=BP-1929959544-172.17.0.14-1585803832412;dnuuid=0411d447-0b2d-4229-84be-2623f14f0d22
2020-04-02 05:04:06,940 [Thread-407] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-3013b8d1-d536-416d-897a-21c98c02f8c3
2020-04-02 05:04:06,941 [Thread-407] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:04:06,944 [Thread-407] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-f8a6047a-08e2-4aa0-81dc-441677cee101
2020-04-02 05:04:06,944 [Thread-407] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:04:06,944 [Thread-407] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:04:06,947 [Thread-407] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:04:06,958 [Thread-407] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:04:06,958 [Thread-407] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:04:06,958 [Thread-407] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:04:06,961 [Thread-407] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:06,964 [Thread-422] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:04:06,964 [Thread-421] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:04:06,965 [Thread-422] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1929959544-172.17.0.14-1585803832412/current: 24706
2020-04-02 05:04:06,965 [Thread-421] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1929959544-172.17.0.14-1585803832412/current: 24663
2020-04-02 05:04:06,974 [Thread-422] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 10ms
2020-04-02 05:04:06,981 [Thread-421] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 17ms
2020-04-02 05:04:06,982 [Thread-407] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1929959544-172.17.0.14-1585803832412: 20ms
2020-04-02 05:04:06,986 [Thread-423] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:04:06,986 [Thread-424] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:04:06,987 [Thread-423] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas
2020-04-02 05:04:06,988 [Thread-423] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 2ms
2020-04-02 05:04:06,988 [Thread-424] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas
2020-04-02 05:04:06,988 [Thread-424] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 1ms
2020-04-02 05:04:06,988 [Thread-407] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412: 6ms
2020-04-02 05:04:06,989 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-3013b8d1-d536-416d-897a-21c98c02f8c3): no suitable block pools found to scan.  Waiting 1814393466 ms.
2020-04-02 05:04:06,989 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-f8a6047a-08e2-4aa0-81dc-441677cee101): no suitable block pools found to scan.  Waiting 1814393467 ms.
2020-04-02 05:04:06,989 [Thread-407] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:15 AM with interval of 21600000ms
2020-04-02 05:04:06,993 [IPC Server handler 5 on 33297] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:06,993 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 0411d447-0b2d-4229-84be-2623f14f0d22) service to localhost/127.0.0.1:33297 beginning handshake with NN
2020-04-02 05:04:06,995 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:04:06,995 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:04:06,997 [IPC Server handler 0 on 33297] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40466, datanodeUuid=0411d447-0b2d-4229-84be-2623f14f0d22, infoPort=42598, infoSecurePort=0, ipcPort=37713, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412) storage 0411d447-0b2d-4229-84be-2623f14f0d22
2020-04-02 05:04:06,997 [IPC Server handler 0 on 33297] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40466
2020-04-02 05:04:06,997 [IPC Server handler 0 on 33297] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0411d447-0b2d-4229-84be-2623f14f0d22 (127.0.0.1:40466).
2020-04-02 05:04:06,998 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 0411d447-0b2d-4229-84be-2623f14f0d22) service to localhost/127.0.0.1:33297 successfully registered with NN
2020-04-02 05:04:06,998 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33297 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:04:07,000 [IPC Server handler 1 on 33297] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3013b8d1-d536-416d-897a-21c98c02f8c3 for DN 127.0.0.1:40466
2020-04-02 05:04:07,001 [IPC Server handler 1 on 33297] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f8a6047a-08e2-4aa0-81dc-441677cee101 for DN 127.0.0.1:40466
2020-04-02 05:04:07,003 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xfe8381170e805513: Processing first storage report for DS-3013b8d1-d536-416d-897a-21c98c02f8c3 from datanode 0411d447-0b2d-4229-84be-2623f14f0d22
2020-04-02 05:04:07,003 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xfe8381170e805513: from storage DS-3013b8d1-d536-416d-897a-21c98c02f8c3 node DatanodeRegistration(127.0.0.1:40466, datanodeUuid=0411d447-0b2d-4229-84be-2623f14f0d22, infoPort=42598, infoSecurePort=0, ipcPort=37713, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 3, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:07,003 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xfe8381170e805513: Processing first storage report for DS-f8a6047a-08e2-4aa0-81dc-441677cee101 from datanode 0411d447-0b2d-4229-84be-2623f14f0d22
2020-04-02 05:04:07,003 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xfe8381170e805513: from storage DS-f8a6047a-08e2-4aa0-81dc-441677cee101 node DatanodeRegistration(127.0.0.1:40466, datanodeUuid=0411d447-0b2d-4229-84be-2623f14f0d22, infoPort=42598, infoSecurePort=0, ipcPort=37713, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 3, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:07,004 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xfe8381170e805513,  containing 2 storage report(s), of which we sent 2. The reports had 6 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:04:07,004 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:07,098 [IPC Server handler 4 on 33297] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:07,100 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:04:07,105 [IPC Server handler 9 on 33297] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/Housemartins	dst=null	perm=null	proto=rpc
2020-04-02 05:04:07,109 [IPC Server handler 3 on 33297] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/Housemartins	dst=null	perm=null	proto=rpc
2020-04-02 05:04:07,112 [IPC Server handler 8 on 33297] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/INXS	dst=null	perm=null	proto=rpc
2020-04-02 05:04:07,114 [IPC Server handler 7 on 33297] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/INXS	dst=null	perm=null	proto=rpc
2020-04-02 05:04:07,116 [IPC Server handler 6 on 33297] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/Easyworld	dst=null	perm=null	proto=rpc
2020-04-02 05:04:07,118 [IPC Server handler 5 on 33297] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/Easyworld	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.permission.TestStickyBit#testAclStickyBitPersistence
[msx] writeFile testName = org.apache.hadoop.fs.permission.TestStickyBit#testAclStickyBitPersistence
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.permission.TestStickyBit#testStickyBitPersistence
[msx] perform reset as unitTestCounterInClass 5 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:07,120 [IPC Server handler 0 on 33297] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:04:07,125 [IPC Server handler 1 on 33297] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/Easyworld	dst=null	perm=null	proto=rpc
2020-04-02 05:04:07,127 [IPC Server handler 2 on 33297] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/Housemartins	dst=null	perm=null	proto=rpc
2020-04-02 05:04:07,129 [IPC Server handler 4 on 33297] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/INXS	dst=null	perm=null	proto=rpc
2020-04-02 05:04:07,132 [IPC Server handler 9 on 33297] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/Housemartins	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:07,133 [IPC Server handler 3 on 33297] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/INXS	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:07,138 [IPC Server handler 8 on 33297] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/Easyworld	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:07,142 [IPC Server handler 7 on 33297] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/Housemartins	dst=null	perm=root:supergroup:rwxrwxrwt	proto=rpc
2020-04-02 05:04:07,154 [IPC Server handler 6 on 33297] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/Easyworld	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
2020-04-02 05:04:07,155 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:04:07,155 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 3
2020-04-02 05:04:07,155 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 37713 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:07,155 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:07,156 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3113a37] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:07,157 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-3013b8d1-d536-416d-897a-21c98c02f8c3) exiting.
2020-04-02 05:04:07,158 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-f8a6047a-08e2-4aa0-81dc-441677cee101) exiting.
2020-04-02 05:04:07,189 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@52d10fb8{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:07,190 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@41c07648{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:07,191 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@52eacb4b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:07,192 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7db0565c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:04:07,215 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37713
2020-04-02 05:04:07,237 [IPC Server listener on 37713] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37713
2020-04-02 05:04:07,238 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:07,241 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:07,242 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 0411d447-0b2d-4229-84be-2623f14f0d22) service to localhost/127.0.0.1:33297
2020-04-02 05:04:07,242 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 0411d447-0b2d-4229-84be-2623f14f0d22)
2020-04-02 05:04:07,242 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:07,258 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:07,267 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:07,275 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:07,276 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:07,277 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:07,277 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:07,283 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:07,283 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:04:07,284 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 41367 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:07,284 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:07,284 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@57f791c6] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:07,314 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-6a50e38d-8394-493e-bae9-21cc555d5ff0) exiting.
2020-04-02 05:04:07,321 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-ff45f1b6-7489-4193-a7b7-463383a325e2) exiting.
2020-04-02 05:04:07,420 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7957dc72{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:07,421 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6ab72419{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:07,421 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@344344fa{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:07,421 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@c1fca1e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:04:07,424 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41367
2020-04-02 05:04:07,430 [IPC Server listener on 41367] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41367
2020-04-02 05:04:07,439 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:07,439 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:07,440 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid fc5fa929-8ee7-4183-a4b6-ae04670d9642) service to localhost/127.0.0.1:33297
2020-04-02 05:04:07,442 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid fc5fa929-8ee7-4183-a4b6-ae04670d9642)
2020-04-02 05:04:07,442 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:07,453 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:07,462 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:07,465 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:07,465 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:07,466 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:07,466 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:07,469 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:07,469 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:04:07,469 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43430 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:07,474 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:07,474 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@287f94b1] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:07,480 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-4f1eb05d-12f5-4429-a347-6330e649b422) exiting.
2020-04-02 05:04:07,481 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-a1bb379d-e304-41de-8d6b-868fc820a567) exiting.
2020-04-02 05:04:07,571 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@120f38e6{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:07,576 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7a0e1b5e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:07,589 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@158d255c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:07,590 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5149f008{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:04:07,599 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43430
2020-04-02 05:04:07,604 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:07,605 [IPC Server listener on 43430] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43430
2020-04-02 05:04:07,605 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:07,614 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb) service to localhost/127.0.0.1:33297
2020-04-02 05:04:07,614 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb)
2020-04-02 05:04:07,614 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:07,628 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:07,638 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:07,640 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:07,641 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:07,644 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:07,644 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:07,656 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:07,657 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:04:07,657 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 41808 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:07,657 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:07,657 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@52350abb] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:07,674 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-17e72323-9be8-4266-96b2-cee02356855e) exiting.
2020-04-02 05:04:07,675 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e71e2ffb-339e-4462-8c88-b84e94847941) exiting.
2020-04-02 05:04:07,717 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1051817b{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:07,726 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@35293c05{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:07,735 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@56b78e55{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:07,736 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1b58ff9e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:04:07,743 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41808
2020-04-02 05:04:07,762 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:07,762 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:07,763 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid bb837d1a-fd41-4783-ba5c-f312fcccd0ee) service to localhost/127.0.0.1:33297
2020-04-02 05:04:07,765 [IPC Server listener on 41808] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41808
2020-04-02 05:04:07,864 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid bb837d1a-fd41-4783-ba5c-f312fcccd0ee)
2020-04-02 05:04:07,864 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:33297] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:07,874 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:07,894 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:07,898 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:07,899 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:07,901 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:07,901 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:07,922 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:07,922 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:04:07,922 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 33297 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:07,923 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:07,923 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 89, 97
2020-04-02 05:04:07,923 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@71a9b4c7] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:04:07,923 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4628b1d3] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:04:07,924 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 10 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 88 Number of syncs: 11 SyncTimes(ms): 12 4 
2020-04-02 05:04:07,925 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000089 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000089-0000000000000000098
2020-04-02 05:04:07,925 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000089 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000089-0000000000000000098
2020-04-02 05:04:07,926 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:04:07,933 [CacheReplicationMonitor(1214682859)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:04:07,986 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33297
2020-04-02 05:04:07,993 [IPC Server listener on 33297] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33297
2020-04-02 05:04:07,993 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:07,993 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:04:08,013 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:04:08,033 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:08,034 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:04:08,035 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@687a762c{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:04:08,038 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1a2e2935{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:08,039 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3b366632{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:08,040 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@410954b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:04:08,041 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:04:08,046 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:04:08,047 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:04:08,064 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=4
2020-04-02 05:04:08,066 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:04:08,071 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:04:08,075 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:04:08,075 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:04:08,076 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:04:08,076 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:04:08,088 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4cc61eb1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:04:08,088 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:04:08,088 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:08,089 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:04:08,090 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:04:08,090 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:08,091 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:04:08,092 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:04:08,092 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:04:08,092 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:04:08,094 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:04:08,094 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:04:08,094 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35959
2020-04-02 05:04:08,095 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:04:08,097 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5949eba8{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:04:08,099 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@58dea0a5{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:04:08,105 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@88d6f9b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:04:08,106 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@47d93e0d{HTTP/1.1,[http/1.1]}{localhost:35959}
2020-04-02 05:04:08,110 [main] INFO  server.Server (Server.java:doStart(419)) - Started @18793ms
2020-04-02 05:04:08,111 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:04:08,112 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:04:08,112 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:04:08,112 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:04:08,112 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:04:08,112 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:04:08,113 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:04:08,113 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:04:08,113 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:08,114 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:04:08,114 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:04:08,114 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:04:08,115 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:04:08
2020-04-02 05:04:08,115 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:04:08,115 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:08,116 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:04:08,116 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:04:08,135 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:04:08,136 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:04:08,136 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:04:08,137 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:04:08,137 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:04:08,137 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:04:08,137 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:04:08,138 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:04:08,138 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:04:08,138 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:04:08,139 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:04:08,139 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:04:08,139 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:04:08,139 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:08,140 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:04:08,140 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:04:08,146 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:04:08,147 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:04:08,147 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:04:08,147 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:04:08,148 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:04:08,150 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:04:08,150 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:04:08,150 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:08,150 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:04:08,151 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:04:08,153 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:04:08,153 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:04:08,153 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:04:08,154 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:04:08,155 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:04:08,155 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:04:08,155 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:08,159 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:04:08,159 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:04:08,163 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:04:08,165 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:04:08,167 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:04:08,167 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:04:08,168 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:04:08,170 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:04:08,170 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:04:08,171 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:04:08,171 [main] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7577b641 expecting start txid #1
2020-04-02 05:04:08,171 [main] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000088, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000088 maxTxnsToRead = 9223372036854775807
2020-04-02 05:04:08,171 [main] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000088' to transaction ID 1
2020-04-02 05:04:08,194 [main] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000088, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000088 of size 6620 edits # 88 loaded in 0 seconds
2020-04-02 05:04:08,195 [main] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3704122f expecting start txid #89
2020-04-02 05:04:08,195 [main] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000089-0000000000000000098, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000089-0000000000000000098 maxTxnsToRead = 9223372036854775807
2020-04-02 05:04:08,195 [main] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000089-0000000000000000098' to transaction ID 1
2020-04-02 05:04:08,196 [main] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000089-0000000000000000098, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000089-0000000000000000098 of size 508 edits # 10 loaded in 0 seconds
2020-04-02 05:04:08,197 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:04:08,197 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 99
2020-04-02 05:04:08,245 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:04:08,245 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 84 msecs
2020-04-02 05:04:08,246 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:04:08,246 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:04:08,250 [Socket Reader #1 for port 40012] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40012
2020-04-02 05:04:08,252 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:40012 to access this namenode/service.
2020-04-02 05:04:08,253 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:04:08,346 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:04:08,354 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:04:08,354 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:04:08,354 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:04:08,355 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:04:08,396 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:04:08,396 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:04:08,396 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:04:08,396 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:04:08,396 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:04:08,397 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 43 msec
2020-04-02 05:04:08,424 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:04:08,425 [IPC Server listener on 40012] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40012: starting
2020-04-02 05:04:08,426 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:40012
2020-04-02 05:04:08,426 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:04:08,426 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:04:08,509 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 82 milliseconds
name space=4
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:04:08,510 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 40012 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:08,511 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:04:08,513 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:04:08,513 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:04:08,529 [CacheReplicationMonitor(1027343815)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:04:08,533 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:04:08,543 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:04:08,543 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:08,544 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:04:08,544 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:04:08,544 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:08,545 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:04:08,545 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42101
2020-04-02 05:04:08,546 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:04:08,546 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:04:08,547 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:08,549 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:04:08,549 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:04:08,550 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:08,551 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:04:08,557 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:04:08,557 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:04:08,560 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:04:08,561 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35741
2020-04-02 05:04:08,561 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:04:08,563 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6058e535{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:04:08,564 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1deb2c43{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:04:08,570 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5af5def9{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:04:08,571 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3a4c11be{HTTP/1.1,[http/1.1]}{localhost:35741}
2020-04-02 05:04:08,571 [main] INFO  server.Server (Server.java:doStart(419)) - Started @19254ms
2020-04-02 05:04:08,633 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40288
2020-04-02 05:04:08,638 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:04:08,638 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:04:08,638 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:04:08,639 [Socket Reader #1 for port 36740] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36740
2020-04-02 05:04:08,648 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@36dce7ed] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:04:08,657 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:36740
2020-04-02 05:04:08,671 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:04:08,671 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:04:08,672 [Thread-479] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40012 starting to offer service
2020-04-02 05:04:08,673 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:04:08,673 [IPC Server listener on 36740] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36740: starting
2020-04-02 05:04:08,718 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 36740 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:08,719 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:04:08,740 [Thread-479] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40012
2020-04-02 05:04:08,744 [Thread-479] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:04:08,745 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:04:08,745 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:04:08,746 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:04:08,747 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:04:08,747 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:08,747 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:04:08,747 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:04:08,748 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:08,748 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:04:08,749 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:44821
2020-04-02 05:04:08,749 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:04:08,749 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:04:08,750 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:08,751 [Thread-479] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:04:08,751 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:04:08,752 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:04:08,753 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:08,754 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:04:08,754 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:04:08,754 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:04:08,755 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:04:08,755 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37035
2020-04-02 05:04:08,756 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:04:08,761 [Thread-479] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:04:08,770 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3a71c100{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:04:08,771 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@f325091{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:04:08,774 [Thread-479] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:08,774 [Thread-479] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:08,776 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@df5f5c0{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:04:08,777 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@308a6984{HTTP/1.1,[http/1.1]}{localhost:37035}
2020-04-02 05:04:08,777 [main] INFO  server.Server (Server.java:doStart(419)) - Started @19460ms
2020-04-02 05:04:08,802 [Thread-479] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:08,803 [Thread-479] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:08,806 [Thread-479] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1950780784;bpid=BP-1929959544-172.17.0.14-1585803832412;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1950780784;c=1585803832412;bpid=BP-1929959544-172.17.0.14-1585803832412;dnuuid=bb837d1a-fd41-4783-ba5c-f312fcccd0ee
2020-04-02 05:04:08,807 [Thread-479] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-e71e2ffb-339e-4462-8c88-b84e94847941
2020-04-02 05:04:08,808 [Thread-479] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:04:08,818 [Thread-479] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-17e72323-9be8-4266-96b2-cee02356855e
2020-04-02 05:04:08,822 [Thread-479] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:04:08,830 [Thread-479] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:04:08,831 [Thread-479] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:04:08,832 [Thread-479] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:04:08,832 [Thread-479] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:04:08,836 [Thread-479] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:04:08,842 [Thread-479] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:08,842 [Thread-499] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:04:08,865 [Thread-500] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:04:08,871 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35606
2020-04-02 05:04:08,873 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:04:08,874 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:04:08,872 [Thread-499] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1929959544-172.17.0.14-1585803832412/current: 24663
2020-04-02 05:04:08,873 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7a34b7b8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:04:08,874 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:04:08,873 [Thread-500] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1929959544-172.17.0.14-1585803832412/current: 24677
2020-04-02 05:04:08,882 [Socket Reader #1 for port 39246] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39246
2020-04-02 05:04:08,886 [Thread-500] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 15ms
2020-04-02 05:04:08,888 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:39246
2020-04-02 05:04:08,912 [Thread-499] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 48ms
2020-04-02 05:04:08,922 [Thread-479] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1929959544-172.17.0.14-1585803832412: 80ms
2020-04-02 05:04:08,924 [Thread-506] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:04:08,933 [Thread-505] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:04:08,933 [Thread-505] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas
2020-04-02 05:04:08,933 [Thread-505] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:04:08,947 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:04:08,948 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:04:08,948 [Thread-506] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas
2020-04-02 05:04:08,949 [Thread-506] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 24ms
2020-04-02 05:04:08,949 [Thread-509] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40012 starting to offer service
2020-04-02 05:04:08,949 [Thread-479] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412: 27ms
2020-04-02 05:04:08,950 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e71e2ffb-339e-4462-8c88-b84e94847941): no suitable block pools found to scan.  Waiting 1814391460 ms.
2020-04-02 05:04:08,950 [Thread-479] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:32 AM with interval of 21600000ms
2020-04-02 05:04:08,951 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-17e72323-9be8-4266-96b2-cee02356855e): no suitable block pools found to scan.  Waiting 1814391459 ms.
2020-04-02 05:04:08,951 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:04:08,953 [IPC Server listener on 39246] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39246: starting
2020-04-02 05:04:09,021 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid bb837d1a-fd41-4783-ba5c-f312fcccd0ee) service to localhost/127.0.0.1:40012 beginning handshake with NN
2020-04-02 05:04:09,032 [IPC Server handler 2 on 40012] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42101, datanodeUuid=bb837d1a-fd41-4783-ba5c-f312fcccd0ee, infoPort=40288, infoSecurePort=0, ipcPort=36740, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412) storage bb837d1a-fd41-4783-ba5c-f312fcccd0ee
2020-04-02 05:04:09,032 [IPC Server handler 2 on 40012] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42101
2020-04-02 05:04:09,033 [IPC Server handler 2 on 40012] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN bb837d1a-fd41-4783-ba5c-f312fcccd0ee (127.0.0.1:42101).
2020-04-02 05:04:09,033 [Thread-509] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40012
2020-04-02 05:04:09,046 [Thread-509] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:04:09,047 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid bb837d1a-fd41-4783-ba5c-f312fcccd0ee) service to localhost/127.0.0.1:40012 successfully registered with NN
2020-04-02 05:04:09,048 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40012 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:04:09,048 [Thread-509] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:04:09,055 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 39246 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:09,056 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:04:09,057 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:04:09,058 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:04:09,059 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:04:09,059 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:04:09,060 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:09,060 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:04:09,060 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:04:09,060 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:09,061 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:04:09,097 [IPC Server handler 3 on 40012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e71e2ffb-339e-4462-8c88-b84e94847941 for DN 127.0.0.1:42101
2020-04-02 05:04:09,098 [IPC Server handler 3 on 40012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-17e72323-9be8-4266-96b2-cee02356855e for DN 127.0.0.1:42101
2020-04-02 05:04:09,098 [Thread-509] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:04:09,100 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:38969
2020-04-02 05:04:09,101 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:04:09,101 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:04:09,125 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:09,130 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc35bbd75240122a2: Processing first storage report for DS-17e72323-9be8-4266-96b2-cee02356855e from datanode bb837d1a-fd41-4783-ba5c-f312fcccd0ee
2020-04-02 05:04:09,130 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc35bbd75240122a2: from storage DS-17e72323-9be8-4266-96b2-cee02356855e node DatanodeRegistration(127.0.0.1:42101, datanodeUuid=bb837d1a-fd41-4783-ba5c-f312fcccd0ee, infoPort=40288, infoSecurePort=0, ipcPort=36740, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 2, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:09,130 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc35bbd75240122a2: Processing first storage report for DS-e71e2ffb-339e-4462-8c88-b84e94847941 from datanode bb837d1a-fd41-4783-ba5c-f312fcccd0ee
2020-04-02 05:04:09,131 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc35bbd75240122a2: from storage DS-e71e2ffb-339e-4462-8c88-b84e94847941 node DatanodeRegistration(127.0.0.1:42101, datanodeUuid=bb837d1a-fd41-4783-ba5c-f312fcccd0ee, infoPort=40288, infoSecurePort=0, ipcPort=36740, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 3, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:09,132 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:04:09,133 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:04:09,133 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:09,134 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:04:09,135 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:04:09,135 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:04:09,135 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:04:09,137 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43328
2020-04-02 05:04:09,137 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:04:09,139 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3add81c4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:04:09,140 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1c65121{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:04:09,141 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xc35bbd75240122a2,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 0 msec to generate and 18 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:04:09,141 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:09,145 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7668d560{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:04:09,146 [Thread-509] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:09,149 [Thread-509] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:09,149 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@46292372{HTTP/1.1,[http/1.1]}{localhost:43328}
2020-04-02 05:04:09,153 [main] INFO  server.Server (Server.java:doStart(419)) - Started @19836ms
2020-04-02 05:04:09,172 [Thread-509] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:09,172 [Thread-509] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:09,180 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36020
2020-04-02 05:04:09,181 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:04:09,181 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6c44052e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:04:09,182 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:04:09,182 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:04:09,186 [Thread-509] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1950780784;bpid=BP-1929959544-172.17.0.14-1585803832412;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1950780784;c=1585803832412;bpid=BP-1929959544-172.17.0.14-1585803832412;dnuuid=8bebbb2e-b355-4030-af1e-ab7e8b7c53eb
2020-04-02 05:04:09,198 [Socket Reader #1 for port 45189] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45189
2020-04-02 05:04:09,202 [Thread-509] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-a1bb379d-e304-41de-8d6b-868fc820a567
2020-04-02 05:04:09,203 [Thread-509] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:04:09,205 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:45189
2020-04-02 05:04:09,208 [Thread-509] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-4f1eb05d-12f5-4429-a347-6330e649b422
2020-04-02 05:04:09,208 [Thread-509] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:04:09,209 [Thread-509] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:04:09,555 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:04:09,555 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:04:09,556 [Thread-509] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:04:09,573 [Thread-537] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40012 starting to offer service
2020-04-02 05:04:09,574 [IPC Server listener on 45189] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45189: starting
2020-04-02 05:04:09,574 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:04:09,576 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 45189 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:09,577 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:04:09,582 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:04:09,587 [Thread-509] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:04:09,588 [Thread-509] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:04:09,588 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:04:09,594 [Thread-509] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:04:09,650 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:04:09,651 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:04:09,651 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:09,651 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:04:09,666 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:04:09,666 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:09,667 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:04:09,667 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:38566
2020-04-02 05:04:09,668 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:04:09,668 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:04:09,710 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:09,733 [Thread-537] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40012
2020-04-02 05:04:09,735 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:04:09,735 [Thread-509] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:09,755 [Thread-537] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:04:09,761 [Thread-537] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:04:09,780 [Thread-537] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:04:09,804 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:04:09,804 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:09,806 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:04:09,807 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:04:09,807 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:04:09,807 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:04:09,808 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34939
2020-04-02 05:04:09,809 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:04:09,812 [Thread-551] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:04:09,814 [Thread-551] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1929959544-172.17.0.14-1585803832412/current: 24605
2020-04-02 05:04:09,815 [Thread-553] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:04:09,815 [Thread-537] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:09,816 [Thread-537] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:09,816 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6650813a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:04:09,816 [Thread-553] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1929959544-172.17.0.14-1585803832412/current: 24605
2020-04-02 05:04:09,817 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@50cf5a23{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:04:09,822 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5bb3d42d{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:04:09,823 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5bf61e67{HTTP/1.1,[http/1.1]}{localhost:34939}
2020-04-02 05:04:09,826 [main] INFO  server.Server (Server.java:doStart(419)) - Started @20509ms
2020-04-02 05:04:09,828 [Thread-551] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 15ms
2020-04-02 05:04:09,830 [Thread-537] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:09,830 [Thread-553] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 15ms
2020-04-02 05:04:09,830 [Thread-509] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1929959544-172.17.0.14-1585803832412: 94ms
2020-04-02 05:04:09,830 [Thread-537] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:09,831 [Thread-557] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:04:09,839 [Thread-556] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:04:09,839 [Thread-557] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas
2020-04-02 05:04:09,840 [Thread-557] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 9ms
2020-04-02 05:04:09,850 [Thread-537] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1950780784;bpid=BP-1929959544-172.17.0.14-1585803832412;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1950780784;c=1585803832412;bpid=BP-1929959544-172.17.0.14-1585803832412;dnuuid=fc5fa929-8ee7-4183-a4b6-ae04670d9642
2020-04-02 05:04:09,840 [Thread-556] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas
2020-04-02 05:04:09,852 [Thread-556] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 12ms
2020-04-02 05:04:09,852 [Thread-537] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-6a50e38d-8394-493e-bae9-21cc555d5ff0
2020-04-02 05:04:09,853 [Thread-537] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:04:09,857 [Thread-509] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412: 27ms
2020-04-02 05:04:09,858 [Thread-537] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-ff45f1b6-7489-4193-a7b7-463383a325e2
2020-04-02 05:04:09,859 [Thread-537] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:04:09,859 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-4f1eb05d-12f5-4429-a347-6330e649b422): no suitable block pools found to scan.  Waiting 1814390546 ms.
2020-04-02 05:04:09,859 [Thread-537] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:04:09,860 [Thread-509] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:26 AM with interval of 21600000ms
2020-04-02 05:04:09,860 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-a1bb379d-e304-41de-8d6b-868fc820a567): no suitable block pools found to scan.  Waiting 1814390545 ms.
2020-04-02 05:04:09,865 [Thread-537] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:04:09,867 [Thread-537] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:04:09,867 [Thread-537] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:04:09,867 [Thread-537] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:04:09,867 [Thread-537] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:09,868 [Thread-563] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:04:09,868 [Thread-564] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:04:09,870 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb) service to localhost/127.0.0.1:40012 beginning handshake with NN
2020-04-02 05:04:09,872 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46404
2020-04-02 05:04:09,872 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4e7095ac] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:04:09,873 [Thread-564] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1929959544-172.17.0.14-1585803832412/current: 24677
2020-04-02 05:04:09,873 [Thread-563] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1929959544-172.17.0.14-1585803832412/current: 24663
2020-04-02 05:04:09,873 [IPC Server handler 1 on 40012] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44821, datanodeUuid=8bebbb2e-b355-4030-af1e-ab7e8b7c53eb, infoPort=35606, infoSecurePort=0, ipcPort=39246, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412) storage 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb
2020-04-02 05:04:09,873 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:04:09,873 [IPC Server handler 1 on 40012] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44821
2020-04-02 05:04:09,873 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:04:09,873 [IPC Server handler 1 on 40012] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb (127.0.0.1:44821).
2020-04-02 05:04:09,873 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:04:09,874 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb) service to localhost/127.0.0.1:40012 successfully registered with NN
2020-04-02 05:04:09,874 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40012 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:04:09,874 [Socket Reader #1 for port 44185] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44185
2020-04-02 05:04:09,892 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:44185
2020-04-02 05:04:09,901 [IPC Server handler 2 on 40012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a1bb379d-e304-41de-8d6b-868fc820a567 for DN 127.0.0.1:44821
2020-04-02 05:04:09,904 [IPC Server handler 2 on 40012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4f1eb05d-12f5-4429-a347-6330e649b422 for DN 127.0.0.1:44821
2020-04-02 05:04:09,906 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:04:09,906 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:04:09,908 [Thread-571] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40012 starting to offer service
2020-04-02 05:04:09,932 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 44185 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:09,989 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:04:10,002 [IPC Server listener on 44185] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44185: starting
2020-04-02 05:04:10,005 [Thread-564] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 137ms
2020-04-02 05:04:10,011 [IPC Server handler 3 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,012 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:04:10,012 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:04:10,014 [Thread-571] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40012
2020-04-02 05:04:10,025 [Thread-563] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 157ms
2020-04-02 05:04:10,026 [Thread-571] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:04:10,033 [Thread-537] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1929959544-172.17.0.14-1585803832412: 167ms
2020-04-02 05:04:10,035 [Thread-571] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:04:10,038 [Thread-583] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:04:10,038 [Thread-584] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:04:10,039 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb35c71a1bcb3a0cc: Processing first storage report for DS-a1bb379d-e304-41de-8d6b-868fc820a567 from datanode 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb
2020-04-02 05:04:10,040 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb35c71a1bcb3a0cc: from storage DS-a1bb379d-e304-41de-8d6b-868fc820a567 node DatanodeRegistration(127.0.0.1:44821, datanodeUuid=8bebbb2e-b355-4030-af1e-ab7e8b7c53eb, infoPort=35606, infoSecurePort=0, ipcPort=39246, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 1, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:04:10,040 [Thread-583] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas
2020-04-02 05:04:10,040 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb35c71a1bcb3a0cc: Processing first storage report for DS-4f1eb05d-12f5-4429-a347-6330e649b422 from datanode 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb
2020-04-02 05:04:10,040 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb35c71a1bcb3a0cc: from storage DS-4f1eb05d-12f5-4429-a347-6330e649b422 node DatanodeRegistration(127.0.0.1:44821, datanodeUuid=8bebbb2e-b355-4030-af1e-ab7e8b7c53eb, infoPort=35606, infoSecurePort=0, ipcPort=39246, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:10,040 [Thread-583] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 2ms
2020-04-02 05:04:10,041 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xb35c71a1bcb3a0cc,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 136 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:04:10,041 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:10,042 [Thread-584] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas
2020-04-02 05:04:10,042 [Thread-584] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 4ms
2020-04-02 05:04:10,042 [Thread-537] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412: 8ms
2020-04-02 05:04:10,043 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-6a50e38d-8394-493e-bae9-21cc555d5ff0): no suitable block pools found to scan.  Waiting 1814390361 ms.
2020-04-02 05:04:10,043 [Thread-571] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 4596@8480ff0b2e43
2020-04-02 05:04:10,043 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-ff45f1b6-7489-4193-a7b7-463383a325e2): no suitable block pools found to scan.  Waiting 1814390361 ms.
2020-04-02 05:04:10,043 [Thread-537] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:29 AM with interval of 21600000ms
2020-04-02 05:04:10,046 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid fc5fa929-8ee7-4183-a4b6-ae04670d9642) service to localhost/127.0.0.1:40012 beginning handshake with NN
2020-04-02 05:04:10,047 [IPC Server handler 8 on 40012] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38969, datanodeUuid=fc5fa929-8ee7-4183-a4b6-ae04670d9642, infoPort=36020, infoSecurePort=0, ipcPort=45189, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412) storage fc5fa929-8ee7-4183-a4b6-ae04670d9642
2020-04-02 05:04:10,048 [IPC Server handler 8 on 40012] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38969
2020-04-02 05:04:10,048 [IPC Server handler 8 on 40012] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN fc5fa929-8ee7-4183-a4b6-ae04670d9642 (127.0.0.1:38969).
2020-04-02 05:04:10,048 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid fc5fa929-8ee7-4183-a4b6-ae04670d9642) service to localhost/127.0.0.1:40012 successfully registered with NN
2020-04-02 05:04:10,049 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40012 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:04:10,051 [IPC Server handler 7 on 40012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6a50e38d-8394-493e-bae9-21cc555d5ff0 for DN 127.0.0.1:38969
2020-04-02 05:04:10,052 [IPC Server handler 7 on 40012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ff45f1b6-7489-4193-a7b7-463383a325e2 for DN 127.0.0.1:38969
2020-04-02 05:04:10,053 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5681a57a51f7bf9a: Processing first storage report for DS-6a50e38d-8394-493e-bae9-21cc555d5ff0 from datanode fc5fa929-8ee7-4183-a4b6-ae04670d9642
2020-04-02 05:04:10,053 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5681a57a51f7bf9a: from storage DS-6a50e38d-8394-493e-bae9-21cc555d5ff0 node DatanodeRegistration(127.0.0.1:38969, datanodeUuid=fc5fa929-8ee7-4183-a4b6-ae04670d9642, infoPort=36020, infoSecurePort=0, ipcPort=45189, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 3, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:10,054 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5681a57a51f7bf9a: Processing first storage report for DS-ff45f1b6-7489-4193-a7b7-463383a325e2 from datanode fc5fa929-8ee7-4183-a4b6-ae04670d9642
2020-04-02 05:04:10,054 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5681a57a51f7bf9a: from storage DS-ff45f1b6-7489-4193-a7b7-463383a325e2 node DatanodeRegistration(127.0.0.1:38969, datanodeUuid=fc5fa929-8ee7-4183-a4b6-ae04670d9642, infoPort=36020, infoSecurePort=0, ipcPort=45189, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:10,055 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x5681a57a51f7bf9a,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:04:10,055 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:10,056 [Thread-571] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:10,057 [Thread-571] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:10,065 [Thread-571] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:10,066 [Thread-571] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:10,067 [Thread-571] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1950780784;bpid=BP-1929959544-172.17.0.14-1585803832412;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1950780784;c=1585803832412;bpid=BP-1929959544-172.17.0.14-1585803832412;dnuuid=0411d447-0b2d-4229-84be-2623f14f0d22
2020-04-02 05:04:10,069 [Thread-571] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-3013b8d1-d536-416d-897a-21c98c02f8c3
2020-04-02 05:04:10,069 [Thread-571] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:04:10,071 [Thread-571] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-f8a6047a-08e2-4aa0-81dc-441677cee101
2020-04-02 05:04:10,071 [Thread-571] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:04:10,072 [Thread-571] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:04:10,074 [Thread-571] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:04:10,074 [Thread-571] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:04:10,074 [Thread-571] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:04:10,074 [Thread-571] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:04:10,074 [Thread-571] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:10,075 [Thread-590] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:04:10,076 [Thread-590] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1929959544-172.17.0.14-1585803832412/current: 24663
2020-04-02 05:04:10,078 [Thread-591] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:04:10,079 [Thread-591] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1929959544-172.17.0.14-1585803832412/current: 24706
2020-04-02 05:04:10,086 [Thread-590] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 12ms
2020-04-02 05:04:10,089 [Thread-591] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1929959544-172.17.0.14-1585803832412 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 11ms
2020-04-02 05:04:10,089 [Thread-571] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1929959544-172.17.0.14-1585803832412: 14ms
2020-04-02 05:04:10,089 [Thread-592] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:04:10,089 [Thread-593] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:04:10,091 [Thread-593] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas
2020-04-02 05:04:10,091 [Thread-593] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 1ms
2020-04-02 05:04:10,091 [Thread-592] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1929959544-172.17.0.14-1585803832412/current/replicas
2020-04-02 05:04:10,092 [Thread-592] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 2ms
2020-04-02 05:04:10,092 [Thread-571] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1929959544-172.17.0.14-1585803832412: 3ms
2020-04-02 05:04:10,093 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-3013b8d1-d536-416d-897a-21c98c02f8c3): no suitable block pools found to scan.  Waiting 1814390362 ms.
2020-04-02 05:04:10,093 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-f8a6047a-08e2-4aa0-81dc-441677cee101): no suitable block pools found to scan.  Waiting 1814390363 ms.
2020-04-02 05:04:10,094 [Thread-571] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:44 AM with interval of 21600000ms
2020-04-02 05:04:10,098 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 0411d447-0b2d-4229-84be-2623f14f0d22) service to localhost/127.0.0.1:40012 beginning handshake with NN
2020-04-02 05:04:10,102 [IPC Server handler 5 on 40012] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38566, datanodeUuid=0411d447-0b2d-4229-84be-2623f14f0d22, infoPort=46404, infoSecurePort=0, ipcPort=44185, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412) storage 0411d447-0b2d-4229-84be-2623f14f0d22
2020-04-02 05:04:10,103 [IPC Server handler 5 on 40012] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38566
2020-04-02 05:04:10,103 [IPC Server handler 5 on 40012] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0411d447-0b2d-4229-84be-2623f14f0d22 (127.0.0.1:38566).
2020-04-02 05:04:10,104 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 0411d447-0b2d-4229-84be-2623f14f0d22) service to localhost/127.0.0.1:40012 successfully registered with NN
2020-04-02 05:04:10,104 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40012 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:04:10,109 [IPC Server handler 0 on 40012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3013b8d1-d536-416d-897a-21c98c02f8c3 for DN 127.0.0.1:38566
2020-04-02 05:04:10,109 [IPC Server handler 0 on 40012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f8a6047a-08e2-4aa0-81dc-441677cee101 for DN 127.0.0.1:38566
2020-04-02 05:04:10,113 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa4c04b1870b19eb7: Processing first storage report for DS-3013b8d1-d536-416d-897a-21c98c02f8c3 from datanode 0411d447-0b2d-4229-84be-2623f14f0d22
2020-04-02 05:04:10,114 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa4c04b1870b19eb7: from storage DS-3013b8d1-d536-416d-897a-21c98c02f8c3 node DatanodeRegistration(127.0.0.1:38566, datanodeUuid=0411d447-0b2d-4229-84be-2623f14f0d22, infoPort=46404, infoSecurePort=0, ipcPort=44185, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 3, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:04:10,114 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa4c04b1870b19eb7: Processing first storage report for DS-f8a6047a-08e2-4aa0-81dc-441677cee101 from datanode 0411d447-0b2d-4229-84be-2623f14f0d22
2020-04-02 05:04:10,115 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa4c04b1870b19eb7: from storage DS-f8a6047a-08e2-4aa0-81dc-441677cee101 node DatanodeRegistration(127.0.0.1:38566, datanodeUuid=0411d447-0b2d-4229-84be-2623f14f0d22, infoPort=46404, infoSecurePort=0, ipcPort=44185, storageInfo=lv=-57;cid=testClusterID;nsid=1950780784;c=1585803832412), blocks: 3, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:04:10,116 [IPC Server handler 2 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,116 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xa4c04b1870b19eb7,  containing 2 storage report(s), of which we sent 2. The reports had 6 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:04:10,116 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:10,117 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:04:10,124 [IPC Server handler 3 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/Housemartins	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,126 [IPC Server handler 4 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/Housemartins	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,129 [IPC Server handler 9 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/INXS	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,131 [IPC Server handler 8 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/INXS	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,132 [IPC Server handler 7 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/Easyworld	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,133 [IPC Server handler 6 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/Easyworld	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.permission.TestStickyBit#testStickyBitPersistence
[msx] writeFile testName = org.apache.hadoop.fs.permission.TestStickyBit#testStickyBitPersistence
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.permission.TestStickyBit#testStickyBitRecursiveDeleteFile
[msx] perform reset as unitTestCounterInClass 6 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:10,136 [IPC Server handler 5 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,142 [IPC Server handler 0 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/Easyworld	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,146 [IPC Server handler 1 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/Housemartins	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,150 [IPC Server handler 2 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/INXS	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,153 [IPC Server handler 3 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/testStickyBitRecursiveDeleteFile/tmp	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:10,155 [IPC Server handler 4 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/testStickyBitRecursiveDeleteFile	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
2020-04-02 05:04:10,157 [IPC Server handler 9 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/testStickyBitRecursiveDeleteFile/tmp	dst=null	perm=root:supergroup:rwxrwxrwt	proto=rpc
2020-04-02 05:04:10,162 [IPC Server handler 8 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=theDoctor (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/testStickyBitRecursiveDeleteFile/tmp/file	dst=null	perm=theDoctor:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:10,167 [IPC Server handler 7 on 40012] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741831_1008, replicas=127.0.0.1:42101, 127.0.0.1:44821, 127.0.0.1:38969 for /testStickyBitRecursiveDeleteFile/tmp/file
2020-04-02 05:04:10,172 [DataXceiver for client DFSClient_NONMAPREDUCE_-470420205_1 at /127.0.0.1:44730 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741831_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741831_1008 src: /127.0.0.1:44730 dest: /127.0.0.1:42101
2020-04-02 05:04:10,178 [DataXceiver for client DFSClient_NONMAPREDUCE_-470420205_1 at /127.0.0.1:59558 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741831_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741831_1008 src: /127.0.0.1:59558 dest: /127.0.0.1:44821
2020-04-02 05:04:10,179 [DataXceiver for client DFSClient_NONMAPREDUCE_-470420205_1 at /127.0.0.1:58848 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741831_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741831_1008 src: /127.0.0.1:58848 dest: /127.0.0.1:38969
2020-04-02 05:04:10,193 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741831_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58848, dest: /127.0.0.1:38969, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-470420205_1, offset: 0, srvID: fc5fa929-8ee7-4183-a4b6-ae04670d9642, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741831_1008, duration(ns): 11626830
2020-04-02 05:04:10,194 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741831_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741831_1008, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:10,195 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741831_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38969]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59558, dest: /127.0.0.1:44821, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-470420205_1, offset: 0, srvID: 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741831_1008, duration(ns): 10808183
2020-04-02 05:04:10,195 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741831_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38969]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741831_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38969] terminating
2020-04-02 05:04:10,197 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741831_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44821, 127.0.0.1:38969]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44730, dest: /127.0.0.1:42101, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-470420205_1, offset: 0, srvID: bb837d1a-fd41-4783-ba5c-f312fcccd0ee, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741831_1008, duration(ns): 11300061
2020-04-02 05:04:10,197 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741831_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44821, 127.0.0.1:38969]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741831_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44821, 127.0.0.1:38969] terminating
2020-04-02 05:04:10,199 [IPC Server handler 2 on 40012] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /testStickyBitRecursiveDeleteFile/tmp/file is closed by DFSClient_NONMAPREDUCE_-470420205_1
2020-04-02 05:04:10,201 [IPC Server handler 3 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/testStickyBitRecursiveDeleteFile/tmp/file	dst=null	perm=theDoctor:supergroup:rw-rw-rw-	proto=rpc
2020-04-02 05:04:10,204 [IPC Server handler 4 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=rose (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/testStickyBitRecursiveDeleteFile/tmp	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,205 [IPC Server handler 4 on 40012] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 4 on 40012, call Call#209 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 127.0.0.1:49052: org.apache.hadoop.security.AccessControlException: Permission denied by sticky bit: user=rose, path="/testStickyBitRecursiveDeleteFile/tmp/file":theDoctor:supergroup:-rw-rw-rw-, parent="/testStickyBitRecursiveDeleteFile/tmp":root:supergroup:drwxrwxrwt
2020-04-02 05:04:10,208 [IPC Server handler 9 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=theDoctor (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/testStickyBitRecursiveDeleteFile/tmp	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.permission.TestStickyBit#testStickyBitRecursiveDeleteFile
[msx] writeFile testName = org.apache.hadoop.fs.permission.TestStickyBit#testStickyBitRecursiveDeleteFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.permission.TestStickyBit#testGeneralSBBehavior
[msx] perform reset as unitTestCounterInClass 7 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:10,210 [IPC Server handler 8 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,212 [IPC Server handler 7 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/testStickyBitRecursiveDeleteFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,214 [IPC Server handler 6 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/mcgann	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:10,215 [IPC Server handler 5 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/mcgann/tmp	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:10,220 [IPC Server handler 0 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/mcgann/tmp	dst=null	perm=root:supergroup:rwxrwxrwt	proto=rpc
2020-04-02 05:04:10,222 [IPC Server handler 1 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=theDoctor (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/mcgann/tmp/foo	dst=null	perm=theDoctor:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:10,228 [IPC Server handler 2 on 40012] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741832_1009, replicas=127.0.0.1:38969, 127.0.0.1:42101, 127.0.0.1:38566 for /mcgann/tmp/foo
2020-04-02 05:04:10,231 [DataXceiver for client DFSClient_NONMAPREDUCE_-470420205_1 at /127.0.0.1:58856 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009 src: /127.0.0.1:58856 dest: /127.0.0.1:38969
2020-04-02 05:04:10,233 [DataXceiver for client DFSClient_NONMAPREDUCE_-470420205_1 at /127.0.0.1:44744 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009 src: /127.0.0.1:44744 dest: /127.0.0.1:42101
2020-04-02 05:04:10,234 [DataXceiver for client DFSClient_NONMAPREDUCE_-470420205_1 at /127.0.0.1:58588 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009 src: /127.0.0.1:58588 dest: /127.0.0.1:38566
2020-04-02 05:04:10,242 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58588, dest: /127.0.0.1:38566, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-470420205_1, offset: 0, srvID: 0411d447-0b2d-4229-84be-2623f14f0d22, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009, duration(ns): 6522265
2020-04-02 05:04:10,242 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:10,244 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38566]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44744, dest: /127.0.0.1:42101, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-470420205_1, offset: 0, srvID: bb837d1a-fd41-4783-ba5c-f312fcccd0ee, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009, duration(ns): 7795882
2020-04-02 05:04:10,245 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38566]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38566] terminating
2020-04-02 05:04:10,246 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42101, 127.0.0.1:38566]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58856, dest: /127.0.0.1:38969, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-470420205_1, offset: 0, srvID: fc5fa929-8ee7-4183-a4b6-ae04670d9642, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009, duration(ns): 9805553
2020-04-02 05:04:10,246 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42101, 127.0.0.1:38566]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42101, 127.0.0.1:38566] terminating
2020-04-02 05:04:10,257 [IPC Server handler 8 on 40012] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /mcgann/tmp/foo is closed by DFSClient_NONMAPREDUCE_-470420205_1
2020-04-02 05:04:10,259 [IPC Server handler 7 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=theDoctor (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/mcgann/tmp/foo	dst=null	perm=theDoctor:supergroup:rwxrwxrwx	proto=rpc
2020-04-02 05:04:10,262 [IPC Server handler 6 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rose (auth:SIMPLE)	ip=/127.0.0.1	cmd=append	src=/mcgann/tmp/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,268 [DataXceiver for client DFSClient_NONMAPREDUCE_514168894_1 at /127.0.0.1:58590 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009 src: /127.0.0.1:58590 dest: /127.0.0.1:38566
2020-04-02 05:04:10,268 [DataXceiver for client DFSClient_NONMAPREDUCE_514168894_1 at /127.0.0.1:58590 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:append(1187)) - Appending to FinalizedReplica, blk_1073741832_1009, FINALIZED
  getNumBytes()     = 18
  getBytesOnDisk()  = 18
  getVisibleLength()= 18
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1929959544-172.17.0.14-1585803832412/current/finalized/subdir0/subdir0/blk_1073741832
2020-04-02 05:04:10,297 [DataXceiver for client DFSClient_NONMAPREDUCE_514168894_1 at /127.0.0.1:44752 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009 src: /127.0.0.1:44752 dest: /127.0.0.1:42101
2020-04-02 05:04:10,302 [DataXceiver for client DFSClient_NONMAPREDUCE_514168894_1 at /127.0.0.1:44752 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:append(1187)) - Appending to FinalizedReplica, blk_1073741832_1009, FINALIZED
  getNumBytes()     = 18
  getBytesOnDisk()  = 18
  getVisibleLength()= 18
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1929959544-172.17.0.14-1585803832412/current/finalized/subdir0/subdir0/blk_1073741832
2020-04-02 05:04:10,341 [DataXceiver for client DFSClient_NONMAPREDUCE_514168894_1 at /127.0.0.1:58868 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009 src: /127.0.0.1:58868 dest: /127.0.0.1:38969
2020-04-02 05:04:10,342 [DataXceiver for client DFSClient_NONMAPREDUCE_514168894_1 at /127.0.0.1:58868 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1009]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:append(1187)) - Appending to FinalizedReplica, blk_1073741832_1009, FINALIZED
  getNumBytes()     = 18
  getBytesOnDisk()  = 18
  getVisibleLength()= 18
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1929959544-172.17.0.14-1585803832412/current/finalized/subdir0/subdir0/blk_1073741832
2020-04-02 05:04:10,367 [IPC Server handler 1 on 40012] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5340)) - updatePipeline(blk_1073741832_1009, newGS=1010, newLength=18, newNodes=[127.0.0.1:38566, 127.0.0.1:42101, 127.0.0.1:38969], client=DFSClient_NONMAPREDUCE_514168894_1)
2020-04-02 05:04:10,368 [IPC Server handler 1 on 40012] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5358)) - updatePipeline(blk_1073741832_1009 => blk_1073741832_1010) success
2020-04-02 05:04:10,399 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58868, dest: /127.0.0.1:38969, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_514168894_1, offset: 0, srvID: fc5fa929-8ee7-4183-a4b6-ae04670d9642, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1010, duration(ns): 31741280
2020-04-02 05:04:10,400 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1010, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:10,403 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38969]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44752, dest: /127.0.0.1:42101, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_514168894_1, offset: 0, srvID: bb837d1a-fd41-4783-ba5c-f312fcccd0ee, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1010, duration(ns): 35130375
2020-04-02 05:04:10,403 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38969]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38969] terminating
2020-04-02 05:04:10,405 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42101, 127.0.0.1:38969]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58590, dest: /127.0.0.1:38566, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_514168894_1, offset: 0, srvID: 0411d447-0b2d-4229-84be-2623f14f0d22, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1010, duration(ns): 37773170
2020-04-02 05:04:10,406 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42101, 127.0.0.1:38969]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741832_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42101, 127.0.0.1:38969] terminating
2020-04-02 05:04:10,411 [IPC Server handler 3 on 40012] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /mcgann/tmp/foo is closed by DFSClient_NONMAPREDUCE_514168894_1
2020-04-02 05:04:10,413 [IPC Server handler 9 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/eccleston	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:10,415 [IPC Server handler 7 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/eccleston/roguetraders	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:10,416 [IPC Server handler 6 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/eccleston/roguetraders	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,417 [IPC Server handler 5 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/eccleston/roguetraders	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,420 [IPC Server handler 0 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/eccleston/roguetraders	dst=null	perm=root:supergroup:rwxr-xr-t	proto=rpc
2020-04-02 05:04:10,422 [IPC Server handler 1 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/eccleston/roguetraders	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,424 [IPC Server handler 2 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/eccleston/somefile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:10,433 [IPC Server handler 4 on 40012] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741833_1011, replicas=127.0.0.1:38566, 127.0.0.1:42101, 127.0.0.1:44821 for /eccleston/somefile
2020-04-02 05:04:10,440 [DataXceiver for client DFSClient_NONMAPREDUCE_-1432518069_1 at /127.0.0.1:58602 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741833_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741833_1011 src: /127.0.0.1:58602 dest: /127.0.0.1:38566
2020-04-02 05:04:10,441 [DataXceiver for client DFSClient_NONMAPREDUCE_-1432518069_1 at /127.0.0.1:44762 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741833_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741833_1011 src: /127.0.0.1:44762 dest: /127.0.0.1:42101
2020-04-02 05:04:10,443 [DataXceiver for client DFSClient_NONMAPREDUCE_-1432518069_1 at /127.0.0.1:59590 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741833_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741833_1011 src: /127.0.0.1:59590 dest: /127.0.0.1:44821
2020-04-02 05:04:10,455 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741833_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59590, dest: /127.0.0.1:44821, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1432518069_1, offset: 0, srvID: 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741833_1011, duration(ns): 10876981
2020-04-02 05:04:10,456 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741833_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741833_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:10,459 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741833_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44821]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44762, dest: /127.0.0.1:42101, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1432518069_1, offset: 0, srvID: bb837d1a-fd41-4783-ba5c-f312fcccd0ee, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741833_1011, duration(ns): 12898342
2020-04-02 05:04:10,459 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741833_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44821]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741833_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44821] terminating
2020-04-02 05:04:10,461 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741833_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42101, 127.0.0.1:44821]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58602, dest: /127.0.0.1:38566, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1432518069_1, offset: 0, srvID: 0411d447-0b2d-4229-84be-2623f14f0d22, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741833_1011, duration(ns): 15359546
2020-04-02 05:04:10,461 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741833_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42101, 127.0.0.1:44821]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741833_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42101, 127.0.0.1:44821] terminating
2020-04-02 05:04:10,467 [IPC Server handler 6 on 40012] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /eccleston/somefile is closed by DFSClient_NONMAPREDUCE_-1432518069_1
2020-04-02 05:04:10,470 [IPC Server handler 5 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/eccleston/somefile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,472 [IPC Server handler 0 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/eccleston/somefile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,474 [IPC Server handler 1 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/eccleston/somefile	dst=null	perm=root:supergroup:rw-r--r-T	proto=rpc
2020-04-02 05:04:10,477 [IPC Server handler 2 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/eccleston/somefile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,478 [IPC Server handler 4 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tennant	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:10,481 [IPC Server handler 3 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tennant/contemporary	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:10,483 [IPC Server handler 8 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/tennant/contemporary	dst=null	perm=root:supergroup:rwxrwxrwt	proto=rpc
2020-04-02 05:04:10,485 [IPC Server handler 9 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=theDoctor (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tennant/contemporary/foo	dst=null	perm=theDoctor:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:10,490 [IPC Server handler 7 on 40012] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741834_1012, replicas=127.0.0.1:38969, 127.0.0.1:44821, 127.0.0.1:42101 for /tennant/contemporary/foo
2020-04-02 05:04:10,493 [DataXceiver for client DFSClient_NONMAPREDUCE_-470420205_1 at /127.0.0.1:58890 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741834_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741834_1012 src: /127.0.0.1:58890 dest: /127.0.0.1:38969
2020-04-02 05:04:10,495 [DataXceiver for client DFSClient_NONMAPREDUCE_-470420205_1 at /127.0.0.1:59604 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741834_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741834_1012 src: /127.0.0.1:59604 dest: /127.0.0.1:44821
2020-04-02 05:04:10,496 [DataXceiver for client DFSClient_NONMAPREDUCE_-470420205_1 at /127.0.0.1:44782 [Receiving block BP-1929959544-172.17.0.14-1585803832412:blk_1073741834_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1929959544-172.17.0.14-1585803832412:blk_1073741834_1012 src: /127.0.0.1:44782 dest: /127.0.0.1:42101
2020-04-02 05:04:10,515 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741834_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44782, dest: /127.0.0.1:42101, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-470420205_1, offset: 0, srvID: bb837d1a-fd41-4783-ba5c-f312fcccd0ee, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741834_1012, duration(ns): 16480043
2020-04-02 05:04:10,515 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741834_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741834_1012, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:10,517 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741834_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42101]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59604, dest: /127.0.0.1:44821, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-470420205_1, offset: 0, srvID: 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741834_1012, duration(ns): 18610750
2020-04-02 05:04:10,517 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741834_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42101]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741834_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42101] terminating
2020-04-02 05:04:10,530 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741834_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44821, 127.0.0.1:42101]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58890, dest: /127.0.0.1:38969, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-470420205_1, offset: 0, srvID: fc5fa929-8ee7-4183-a4b6-ae04670d9642, blockid: BP-1929959544-172.17.0.14-1585803832412:blk_1073741834_1012, duration(ns): 19898761
2020-04-02 05:04:10,531 [PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741834_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44821, 127.0.0.1:42101]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929959544-172.17.0.14-1585803832412:blk_1073741834_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44821, 127.0.0.1:42101] terminating
2020-04-02 05:04:10,532 [IPC Server handler 1 on 40012] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tennant/contemporary/foo is closed by DFSClient_NONMAPREDUCE_-470420205_1
2020-04-02 05:04:10,535 [IPC Server handler 2 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=theDoctor (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tennant/contemporary/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,537 [IPC Server handler 4 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=rose (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tennant/contemporary/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,537 [IPC Server handler 4 on 40012] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 4 on 40012, call Call#258 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 127.0.0.1:49052: org.apache.hadoop.security.AccessControlException: Permission denied by sticky bit: user=rose, path="/tennant/contemporary/foo":theDoctor:supergroup:-rw-r--r--, parent="/tennant/contemporary":root:supergroup:drwxrwxrwt
2020-04-02 05:04:10,541 [IPC Server handler 3 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/smith	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:10,543 [IPC Server handler 8 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/smith/scissorsisters	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:10,544 [IPC Server handler 9 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/smith/bar	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:10,545 [IPC Server handler 7 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/smith/bar	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.permission.TestStickyBit#testGeneralSBBehavior
[msx] writeFile testName = org.apache.hadoop.fs.permission.TestStickyBit#testGeneralSBBehavior
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.permission.TestStickyBit#testStickyBitReset
[msx] perform reset as unitTestCounterInClass 8 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:10,547 [IPC Server handler 5 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,548 [IPC Server handler 6 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/eccleston	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,550 [IPC Server handler 0 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/mcgann	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,551 [IPC Server handler 1 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/smith	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,555 [IPC Server handler 2 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tennant	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,557 [IPC Server handler 4 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/DirToTestExplicitStickyBit	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:10,562 [IPC Server handler 3 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/DirToTestOmittedStickyBit	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:10,564 [IPC Server handler 8 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/DirToTestExplicitStickyBit	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,565 [IPC Server handler 9 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/DirToTestOmittedStickyBit	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,568 [IPC Server handler 7 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/DirToTestExplicitStickyBit	dst=null	perm=root:supergroup:rwxrwxrwt	proto=rpc
2020-04-02 05:04:10,570 [IPC Server handler 5 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/DirToTestExplicitStickyBit	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,570 [main] INFO  permission.TestStickyBit (TestStickyBit.java:testStickyBitReset(372)) - Dir: DirToTestExplicitStickyBit, permission: rwxrwxrwt
2020-04-02 05:04:10,571 [IPC Server handler 6 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/DirToTestExplicitStickyBit	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,574 [IPC Server handler 0 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/DirToTestOmittedStickyBit	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
2020-04-02 05:04:10,575 [IPC Server handler 1 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/DirToTestOmittedStickyBit	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,575 [main] INFO  permission.TestStickyBit (TestStickyBit.java:testStickyBitReset(379)) - Dir: DirToTestOmittedStickyBit, permission: rwxrwxrwx
2020-04-02 05:04:10,576 [IPC Server handler 2 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/DirToTestOmittedStickyBit	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,577 [IPC Server handler 4 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/DirToTestExplicitStickyBit	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
2020-04-02 05:04:10,578 [IPC Server handler 3 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/DirToTestExplicitStickyBit	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,579 [main] INFO  permission.TestStickyBit (TestStickyBit.java:testStickyBitReset(386)) - Dir: DirToTestExplicitStickyBit, permission: rwxrwxrwx
2020-04-02 05:04:10,581 [IPC Server handler 8 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/DirToTestExplicitStickyBit	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,583 [IPC Server handler 9 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/DirToTestOmittedStickyBit	dst=null	perm=root:supergroup:rwxrwxrwt	proto=rpc
2020-04-02 05:04:10,584 [IPC Server handler 7 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/DirToTestOmittedStickyBit	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
2020-04-02 05:04:10,588 [IPC Server handler 5 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/DirToTestOmittedStickyBit	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,589 [main] INFO  permission.TestStickyBit (TestStickyBit.java:testStickyBitReset(394)) - Dir: DirToTestOmittedStickyBit, permission: rwxrwxrwx
2020-04-02 05:04:10,589 [IPC Server handler 6 on 40012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/DirToTestOmittedStickyBit	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.permission.TestStickyBit#testStickyBitReset
[msx] writeFile testName = org.apache.hadoop.fs.permission.TestStickyBit#testStickyBitReset
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:10,591 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:04:10,591 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 3
2020-04-02 05:04:10,591 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 44185 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:10,591 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:10,591 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5a6d5a8f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:10,595 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-f8a6047a-08e2-4aa0-81dc-441677cee101) exiting.
2020-04-02 05:04:10,595 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-3013b8d1-d536-416d-897a-21c98c02f8c3) exiting.
2020-04-02 05:04:10,625 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5bb3d42d{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:10,626 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5bf61e67{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:10,627 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@50cf5a23{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:10,628 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6650813a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:04:10,629 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44185
2020-04-02 05:04:10,632 [IPC Server listener on 44185] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44185
2020-04-02 05:04:10,633 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:10,633 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:10,633 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 0411d447-0b2d-4229-84be-2623f14f0d22) service to localhost/127.0.0.1:40012
2020-04-02 05:04:10,633 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 0411d447-0b2d-4229-84be-2623f14f0d22)
2020-04-02 05:04:10,633 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:10,639 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:10,640 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:10,640 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:10,640 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:10,658 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:10,688 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:10,690 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:10,690 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:04:10,690 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 45189 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:10,690 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:10,690 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@71652c98] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:10,691 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-6a50e38d-8394-493e-bae9-21cc555d5ff0) exiting.
2020-04-02 05:04:10,691 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-ff45f1b6-7489-4193-a7b7-463383a325e2) exiting.
2020-04-02 05:04:10,704 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7668d560{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:10,704 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@46292372{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:10,705 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1c65121{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:10,705 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3add81c4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:04:10,706 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45189
2020-04-02 05:04:10,708 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:10,710 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:10,710 [IPC Server listener on 45189] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45189
2020-04-02 05:04:10,711 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid fc5fa929-8ee7-4183-a4b6-ae04670d9642) service to localhost/127.0.0.1:40012
2020-04-02 05:04:10,713 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid fc5fa929-8ee7-4183-a4b6-ae04670d9642)
2020-04-02 05:04:10,713 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:10,723 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:10,730 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:10,735 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:10,736 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:10,737 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:10,737 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:10,741 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:10,741 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:04:10,741 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 39246 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:10,741 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:10,741 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@e041f0c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:10,742 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-4f1eb05d-12f5-4429-a347-6330e649b422) exiting.
2020-04-02 05:04:10,742 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-a1bb379d-e304-41de-8d6b-868fc820a567) exiting.
2020-04-02 05:04:10,766 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@df5f5c0{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:10,766 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@308a6984{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:10,767 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@f325091{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:10,767 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3a71c100{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:04:10,769 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39246
2020-04-02 05:04:10,774 [IPC Server listener on 39246] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39246
2020-04-02 05:04:10,774 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:10,782 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:10,782 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb) service to localhost/127.0.0.1:40012
2020-04-02 05:04:10,782 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid 8bebbb2e-b355-4030-af1e-ab7e8b7c53eb)
2020-04-02 05:04:10,782 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:10,799 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:10,807 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:10,814 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:10,814 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:10,815 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:10,815 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:10,817 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:10,817 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:04:10,817 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 36740 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:10,818 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:10,818 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6b85300e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:10,821 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-17e72323-9be8-4266-96b2-cee02356855e) exiting.
2020-04-02 05:04:10,822 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e71e2ffb-339e-4462-8c88-b84e94847941) exiting.
2020-04-02 05:04:10,881 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5af5def9{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:10,885 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3a4c11be{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:10,885 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1deb2c43{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:10,885 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6058e535{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:04:10,888 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36740
2020-04-02 05:04:10,902 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:10,903 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:10,903 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid bb837d1a-fd41-4783-ba5c-f312fcccd0ee) service to localhost/127.0.0.1:40012
2020-04-02 05:04:10,905 [IPC Server listener on 36740] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36740
2020-04-02 05:04:11,006 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1929959544-172.17.0.14-1585803832412 (Datanode Uuid bb837d1a-fd41-4783-ba5c-f312fcccd0ee)
2020-04-02 05:04:11,006 [BP-1929959544-172.17.0.14-1585803832412 heartbeating to localhost/127.0.0.1:40012] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1929959544-172.17.0.14-1585803832412
2020-04-02 05:04:11,015 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:11,024 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1929959544-172.17.0.14-1585803832412] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:11,036 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:11,036 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:11,039 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:11,039 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:11,047 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:11,048 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:04:11,048 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 40012 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:11,048 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:11,050 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 99, 158
2020-04-02 05:04:11,050 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@12f3afb5] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:04:11,050 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@1e392345] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:04:11,051 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 61 Total time for transactions(ms): 27 Number of transactions batched in Syncs: 104 Number of syncs: 56 SyncTimes(ms): 9 4 
2020-04-02 05:04:11,052 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000099 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000099-0000000000000000159
2020-04-02 05:04:11,053 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000099 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000099-0000000000000000159
2020-04-02 05:04:11,053 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:04:11,053 [CacheReplicationMonitor(1027343815)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:04:11,084 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40012
2020-04-02 05:04:11,084 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:11,087 [IPC Server listener on 40012] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40012
2020-04-02 05:04:11,087 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:04:11,087 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:04:11,098 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:11,099 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:04:11,100 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@88d6f9b{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:04:11,106 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@47d93e0d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:11,106 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@58dea0a5{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:11,107 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5949eba8{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:04:11,111 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:04:11,125 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:04:11,126 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] all testRunFinished

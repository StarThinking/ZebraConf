[msx] before_class
2020-04-02 05:05:19,480 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(225)) - Configuration:
2020-04-02 05:05:19,484 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(226)) - ---------------------------------------------------------------
2020-04-02 05:05:19,486 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   debug: false
2020-04-02 05:05:19,486 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   transport: TCP
2020-04-02 05:05:19,486 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   max.ticket.lifetime: 86400000
2020-04-02 05:05:19,486 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   org.name: EXAMPLE
2020-04-02 05:05:19,486 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   kdc.port: 0
2020-04-02 05:05:19,486 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   org.domain: COM
2020-04-02 05:05:19,487 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   max.renewable.lifetime: 604800000
2020-04-02 05:05:19,487 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   instance: DefaultKrbServer
2020-04-02 05:05:19,487 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   kdc.bind.address: localhost
2020-04-02 05:05:19,487 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(230)) - ---------------------------------------------------------------
2020-04-02 05:05:19,598 [main] INFO  minikdc.MiniKdc (MiniKdc.java:start(285)) - MiniKdc started.
[msx] test Started org.apache.hadoop.hdfs.qjournal.TestSecureNNWithQJM#testSecureMode
[msx] unitTestCounterInClass = 0
2020-04-02 05:05:20,324 [Thread-3] INFO  qjournal.MiniJournalCluster (MiniJournalCluster.java:<init>(100)) - Starting MiniJournalCluster with 3 journal nodes
2020-04-02 05:05:20,335 [Thread-3] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] JournalNode init, vvmode is none, do nothing
2020-04-02 05:05:20,481 [Thread-3] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:05:20,524 [Thread-3] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:05:20,589 [Thread-3] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:05:20,589 [Thread-3] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - JournalNode metrics system started
2020-04-02 05:05:20,709 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803920652,root/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:20,720 [Thread-3] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user root/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab
2020-04-02 05:05:20,744 [Thread-3] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:20,751 [Thread-3] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for journal at: https://localhost:0
2020-04-02 05:05:20,765 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:20,778 [Thread-3] INFO  util.log (Log.java:initialized(192)) - Logging initialized @1940ms
2020-04-02 05:05:21,085 [Thread-3] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:21,088 [Thread-3] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-04-02 05:05:21,089 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:21,095 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:21,098 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-04-02 05:05:21,098 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:21,099 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:21,131 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to getJournal
2020-04-02 05:05:21,136 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42831
2020-04-02 05:05:21,138 [Thread-3] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:21,175 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2adfa90{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:21,176 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1aeaefab{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:21,206 [Thread-3] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:21,219 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5d17ee0c{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-04-02 05:05:21,230 [Thread-3] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@44aab7fd(server,h=[],w=[]) for SslContextFactory@d49ba3(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/trustKS.jks)
2020-04-02 05:05:21,261 [Thread-3] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5a4b59e5{SSL,[ssl, http/1.1]}{localhost:42831}
2020-04-02 05:05:21,261 [Thread-3] INFO  server.Server (Server.java:doStart(419)) - Started @2424ms
2020-04-02 05:05:21,263 [Thread-3] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(84)) - RPC server is binding to localhost:0
2020-04-02 05:05:21,296 [Thread-3] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 500 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:21,311 [Socket Reader #1 for port 42171] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42171
2020-04-02 05:05:21,506 [IPC Server listener on 42171] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42171: starting
2020-04-02 05:05:21,506 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:21,507 [Thread-3] INFO  server.JournalNode (JournalNode.java:start(251)) - [msx-restart] JournalNode 42171 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:21,508 [Thread-3] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] JournalNode init, vvmode is none, do nothing
2020-04-02 05:05:21,508 [Thread-3] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JournalNode metrics system started (again)
2020-04-02 05:05:21,519 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803921517,root/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:21,528 [Thread-3] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user root/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab
2020-04-02 05:05:21,529 [Thread-3] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:21,530 [Thread-3] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for journal at: https://localhost:0
2020-04-02 05:05:21,531 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:21,533 [Thread-3] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:21,533 [Thread-3] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-04-02 05:05:21,534 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:21,536 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:21,537 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-04-02 05:05:21,537 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:21,538 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:21,540 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to getJournal
2020-04-02 05:05:21,541 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41810
2020-04-02 05:05:21,541 [Thread-3] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:21,544 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@352f6cad{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:21,545 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@73580cca{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:21,554 [Thread-3] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:21,556 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4a98d7ed{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-04-02 05:05:21,558 [Thread-3] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@6b4a5883(server,h=[],w=[]) for SslContextFactory@4e11bf4a(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/trustKS.jks)
2020-04-02 05:05:21,561 [Thread-3] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@28b76761{SSL,[ssl, http/1.1]}{localhost:41810}
2020-04-02 05:05:21,561 [Thread-3] INFO  server.Server (Server.java:doStart(419)) - Started @2724ms
2020-04-02 05:05:21,563 [Thread-3] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(84)) - RPC server is binding to localhost:0
2020-04-02 05:05:21,563 [Thread-3] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 500 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:21,564 [Socket Reader #1 for port 46100] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46100
2020-04-02 05:05:21,569 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:21,569 [IPC Server listener on 46100] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46100: starting
2020-04-02 05:05:21,570 [Thread-3] INFO  server.JournalNode (JournalNode.java:start(251)) - [msx-restart] JournalNode 46100 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:21,571 [Thread-3] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] JournalNode init, vvmode is none, do nothing
2020-04-02 05:05:21,572 [Thread-3] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JournalNode metrics system started (again)
2020-04-02 05:05:21,587 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803921585,root/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:21,591 [Thread-3] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user root/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab
2020-04-02 05:05:21,592 [Thread-3] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:21,594 [Thread-3] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for journal at: https://localhost:0
2020-04-02 05:05:21,594 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:21,596 [Thread-3] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:21,598 [Thread-3] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-04-02 05:05:21,598 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:21,601 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:21,603 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-04-02 05:05:21,603 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:21,603 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:21,606 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to getJournal
2020-04-02 05:05:21,606 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46134
2020-04-02 05:05:21,607 [Thread-3] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:21,610 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@63dd18e3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:21,611 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1e39b054{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:21,621 [Thread-3] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:21,622 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6287622c{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-04-02 05:05:21,625 [Thread-3] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@57852fa2(server,h=[],w=[]) for SslContextFactory@72e75c66(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/trustKS.jks)
2020-04-02 05:05:21,627 [Thread-3] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@55383290{SSL,[ssl, http/1.1]}{localhost:46134}
2020-04-02 05:05:21,628 [Thread-3] INFO  server.Server (Server.java:doStart(419)) - Started @2791ms
2020-04-02 05:05:21,629 [Thread-3] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(84)) - RPC server is binding to localhost:0
2020-04-02 05:05:21,629 [Thread-3] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 500 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:21,630 [Socket Reader #1 for port 36263] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36263
2020-04-02 05:05:21,634 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:21,634 [IPC Server listener on 36263] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36263: starting
2020-04-02 05:05:21,635 [Thread-3] INFO  server.JournalNode (JournalNode.java:start(251)) - [msx-restart] JournalNode 36263 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:21,884 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803921882,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:21,885 [pool-1-thread-3] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803921882,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:21,887 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803921884,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:21,910 [Socket Reader #1 for port 46100] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:21,910 [Socket Reader #1 for port 42171] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:21,910 [Socket Reader #1 for port 36263] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:22,013 [IPC Server handler 0 on 46100] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(104)) - Initializing journal in directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/waitactive
2020-04-02 05:05:22,013 [IPC Server handler 0 on 42171] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(104)) - Initializing journal in directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/waitactive
2020-04-02 05:05:22,013 [IPC Server handler 0 on 36263] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(104)) - Initializing journal in directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/waitactive
2020-04-02 05:05:22,025 [IPC Server handler 0 on 46100] WARN  common.Storage (Storage.java:analyzeStorage(654)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/waitactive does not exist
2020-04-02 05:05:22,025 [IPC Server handler 0 on 42171] WARN  common.Storage (Storage.java:analyzeStorage(654)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/waitactive does not exist
2020-04-02 05:05:22,025 [IPC Server handler 0 on 36263] WARN  common.Storage (Storage.java:analyzeStorage(654)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/waitactive does not exist
2020-04-02 05:05:22,049 [IPC Server handler 0 on 42171] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(297)) - Could not construct Shared Edits Uri
2020-04-02 05:05:22,049 [IPC Server handler 0 on 36263] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(297)) - Could not construct Shared Edits Uri
2020-04-02 05:05:22,050 [IPC Server handler 0 on 36263] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(144)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-04-02 05:05:22,049 [IPC Server handler 0 on 42171] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(144)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-04-02 05:05:22,055 [IPC Server handler 0 on 46100] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(297)) - Could not construct Shared Edits Uri
2020-04-02 05:05:22,055 [IPC Server handler 0 on 46100] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(144)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-04-02 05:05:22,183 [Socket Reader #1 for port 42171] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:22,189 [Socket Reader #1 for port 46100] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:22,190 [Socket Reader #1 for port 36263] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:22,347 [Socket Reader #1 for port 46100] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:22,363 [Socket Reader #1 for port 42171] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:22,371 [Socket Reader #1 for port 36263] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:22,486 [Thread-3] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:05:22,725 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803922724,root/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:22,734 [Thread-3] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user root/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab
Formatting using clusterid: testClusterID
2020-04-02 05:05:22,747 [Thread-3] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:22,756 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:22,758 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:22,759 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:22,759 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:22,759 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:22,759 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:22,759 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:22,794 [Thread-3] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:22,798 [Thread-3] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:05:22,798 [Thread-3] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:22,798 [Thread-3] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:22,801 [Thread-3] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:22,802 [Thread-3] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:22
2020-04-02 05:05:22,804 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:22,804 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:22,805 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:05:22,806 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:22,823 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:22,823 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:22,839 [Thread-3] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:22,839 [Thread-3] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:22,839 [Thread-3] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:22,839 [Thread-3] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:22,840 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:05:22,840 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:22,840 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:22,840 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:22,840 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:22,840 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:22,840 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:22,865 [Thread-3] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:05:22,881 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:22,882 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:22,882 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:05:22,882 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:22,889 [Thread-3] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:22,889 [Thread-3] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:22,890 [Thread-3] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:22,890 [Thread-3] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:22,897 [Thread-3] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:23,081 [Thread-3] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:23,089 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:23,090 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:23,090 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:05:23,090 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:23,098 [Thread-3] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:23,098 [Thread-3] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:23,098 [Thread-3] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:23,101 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:23,101 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:23,104 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:23,104 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:23,104 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:05:23,104 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:23,139 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803923137,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:23,142 [pool-1-thread-3] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803923140,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:23,144 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803923143,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:23,153 [Socket Reader #1 for port 42171] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:23,159 [IPC Server handler 1 on 42171] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(104)) - Initializing journal in directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal
2020-04-02 05:05:23,159 [IPC Server handler 1 on 42171] WARN  common.Storage (Storage.java:analyzeStorage(654)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal does not exist
2020-04-02 05:05:23,159 [Socket Reader #1 for port 36263] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:23,162 [Socket Reader #1 for port 46100] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:23,164 [IPC Server handler 1 on 42171] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(297)) - Could not construct Shared Edits Uri
2020-04-02 05:05:23,164 [IPC Server handler 1 on 42171] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(144)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-04-02 05:05:23,165 [IPC Server handler 1 on 36263] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(104)) - Initializing journal in directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal
2020-04-02 05:05:23,167 [IPC Server handler 1 on 36263] WARN  common.Storage (Storage.java:analyzeStorage(654)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal does not exist
2020-04-02 05:05:23,168 [IPC Server handler 1 on 46100] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(104)) - Initializing journal in directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal
2020-04-02 05:05:23,168 [IPC Server handler 1 on 46100] WARN  common.Storage (Storage.java:analyzeStorage(654)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal does not exist
2020-04-02 05:05:23,170 [IPC Server handler 1 on 36263] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(297)) - Could not construct Shared Edits Uri
2020-04-02 05:05:23,170 [IPC Server handler 1 on 36263] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(144)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-04-02 05:05:23,171 [IPC Server handler 1 on 46100] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(297)) - Could not construct Shared Edits Uri
2020-04-02 05:05:23,172 [IPC Server handler 1 on 46100] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(144)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-04-02 05:05:23,175 [Thread-3] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1190329926-172.17.0.11-1585803923175
2020-04-02 05:05:23,186 [Thread-3] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:05:23,188 [Thread-3] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:05:23,216 [IPC Server handler 2 on 42171] INFO  server.Journal (Journal.java:format(234)) - Formatting journal id : myjournal with namespace info: lv=-64;cid=testClusterID;nsid=1279554039;c=1585803923175;bpid=BP-1190329926-172.17.0.11-1585803923175
2020-04-02 05:05:23,216 [IPC Server handler 2 on 36263] INFO  server.Journal (Journal.java:format(234)) - Formatting journal id : myjournal with namespace info: lv=-64;cid=testClusterID;nsid=1279554039;c=1585803923175;bpid=BP-1190329926-172.17.0.11-1585803923175
2020-04-02 05:05:23,217 [IPC Server handler 2 on 42171] INFO  common.Storage (Storage.java:analyzeStorage(657)) - /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal does not exist. Creating ...
2020-04-02 05:05:23,217 [IPC Server handler 2 on 36263] INFO  common.Storage (Storage.java:analyzeStorage(657)) - /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal does not exist. Creating ...
2020-04-02 05:05:23,216 [IPC Server handler 2 on 46100] INFO  server.Journal (Journal.java:format(234)) - Formatting journal id : myjournal with namespace info: lv=-64;cid=testClusterID;nsid=1279554039;c=1585803923175;bpid=BP-1190329926-172.17.0.11-1585803923175
2020-04-02 05:05:23,218 [IPC Server handler 2 on 46100] INFO  common.Storage (Storage.java:analyzeStorage(657)) - /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal does not exist. Creating ...
2020-04-02 05:05:23,219 [IPC Server handler 2 on 46100] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:23,219 [IPC Server handler 2 on 42171] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:23,220 [IPC Server handler 2 on 46100] INFO  common.Storage (JNStorage.java:format(216)) - Formatting journal Storage Directory root= /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal; location= null with nsid: 1279554039
2020-04-02 05:05:23,219 [IPC Server handler 2 on 36263] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:23,220 [IPC Server handler 2 on 42171] INFO  common.Storage (JNStorage.java:format(216)) - Formatting journal Storage Directory root= /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal; location= null with nsid: 1279554039
2020-04-02 05:05:23,221 [IPC Server handler 2 on 36263] INFO  common.Storage (JNStorage.java:format(216)) - Formatting journal Storage Directory root= /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal; location= null with nsid: 1279554039
2020-04-02 05:05:23,222 [IPC Server handler 2 on 46100] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:23,223 [IPC Server handler 2 on 36263] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:23,224 [IPC Server handler 2 on 42171] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:23,238 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:23,238 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:23,335 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:05:23,335 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:05:23,341 [Thread-3] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:05:23,360 [Thread-3] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:23,368 [Thread-3] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:05:23,369 [Thread-3] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:23,371 [Thread-3] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:05:23,385 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803923383,root/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:23,388 [Thread-3] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user root/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab
2020-04-02 05:05:23,410 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@bb3f2f9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:23,411 [Thread-3] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:23,412 [Thread-3] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:0
2020-04-02 05:05:23,412 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:23,414 [Thread-3] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:23,414 [Thread-3] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:23,415 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:23,416 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:23,417 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:23,417 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:23,417 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:23,427 [Thread-3] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:23,427 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:23,431 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:05:23,432 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:05:23,432 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41720
2020-04-02 05:05:23,432 [Thread-3] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:23,435 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@715a5e22{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:23,436 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@28530ec5{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:23,442 [Thread-3] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:23,444 [Thread-3] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:23,447 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1437cba0{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:23,449 [Thread-3] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@4b50d57f(server,h=[],w=[]) for SslContextFactory@182ac0e8(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/trustKS.jks)
2020-04-02 05:05:23,452 [Thread-3] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@41f085bd{SSL,[ssl, http/1.1]}{localhost:41720}
2020-04-02 05:05:23,452 [Thread-3] INFO  server.Server (Server.java:doStart(419)) - Started @4615ms
2020-04-02 05:05:23,454 [Thread-3] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(685)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-04-02 05:05:23,467 [Thread-3] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:23,467 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:23,468 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:23,468 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:23,468 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:23,468 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:23,469 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:23,469 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:23,470 [Thread-3] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:23,470 [Thread-3] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:23,470 [Thread-3] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:23,471 [Thread-3] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:23,471 [Thread-3] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:23
2020-04-02 05:05:23,471 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:23,471 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:23,472 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:05:23,472 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:23,476 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:23,476 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:23,477 [Thread-3] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:23,477 [Thread-3] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:23,477 [Thread-3] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:23,477 [Thread-3] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:23,477 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:05:23,477 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:23,478 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:23,478 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:23,478 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:23,478 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:23,478 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:23,478 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:23,478 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:23,479 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:05:23,479 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:23,484 [Thread-3] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:23,484 [Thread-3] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:23,485 [Thread-3] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:23,485 [Thread-3] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:23,485 [Thread-3] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:23,485 [Thread-3] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:23,485 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:23,485 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:23,486 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:05:23,486 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:23,487 [Thread-3] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:23,487 [Thread-3] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:23,487 [Thread-3] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:23,487 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:23,487 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:23,487 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:23,488 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:23,488 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:05:23,488 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:23,492 [Thread-3] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:23,494 [Thread-3] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:23,499 [Thread-3] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(442)) - Starting recovery process for unclosed journal segments...
2020-04-02 05:05:23,579 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803923578,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:23,585 [pool-1-thread-3] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803923584,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:23,587 [Socket Reader #1 for port 42171] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:23,595 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803923594,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:23,596 [Socket Reader #1 for port 46100] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:23,609 [Socket Reader #1 for port 36263] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:23,617 [IPC Server handler 1 on 42171] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(346)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:23,617 [IPC Server handler 0 on 36263] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(346)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:23,617 [IPC Server handler 1 on 46100] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(346)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:23,621 [IPC Server handler 0 on 36263] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(205)) - Scanning storage FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal)
2020-04-02 05:05:23,621 [IPC Server handler 1 on 42171] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(205)) - Scanning storage FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal)
2020-04-02 05:05:23,622 [IPC Server handler 1 on 46100] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(205)) - Scanning storage FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal)
2020-04-02 05:05:23,623 [IPC Server handler 0 on 36263] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(223)) - No files in FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal)
2020-04-02 05:05:23,623 [IPC Server handler 1 on 42171] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(223)) - No files in FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal)
2020-04-02 05:05:23,627 [IPC Server handler 1 on 46100] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(223)) - No files in FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal)
2020-04-02 05:05:23,628 [Thread-3] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(444)) - Successfully started new epoch 1
2020-04-02 05:05:23,636 [Thread-3] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:05:23,637 [Thread-3] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:23,660 [Thread-3] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:23,666 [Thread-3] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:23,666 [Thread-3] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:23,670 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:23,675 [Thread-3] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:05:23,683 [IPC Server handler 4 on 46100] INFO  server.Journal (Journal.java:startLogSegment(582)) - Updating lastWriterEpoch from 0 to 1 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:23,683 [IPC Server handler 3 on 36263] INFO  server.Journal (Journal.java:startLogSegment(582)) - Updating lastWriterEpoch from 0 to 1 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:23,684 [IPC Server handler 4 on 42171] INFO  server.Journal (Journal.java:startLogSegment(582)) - Updating lastWriterEpoch from 0 to 1 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:23,714 [Thread-3] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:23,714 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 225 msecs
2020-04-02 05:05:23,879 [Thread-3] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:05:23,880 [Thread-3] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:23,881 [Socket Reader #1 for port 36732] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36732
2020-04-02 05:05:23,888 [Thread-3] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:36732 to access this namenode/service.
2020-04-02 05:05:23,891 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:23,895 [Thread-3] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:23,903 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@6c4bc4e2] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:05:23,906 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:23,907 [Thread-3] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:05:23,907 [Thread-3] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:05:23,907 [Thread-3] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:23,913 [Thread-3] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:23,928 [Thread[Thread-98,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:05:23,928 [Thread[Thread-98,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:23,932 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:23,932 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:23,932 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:23,932 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:23,932 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:23,932 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 25 msec
2020-04-02 05:05:23,974 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:23,976 [IPC Server listener on 36732] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36732: starting
2020-04-02 05:05:23,978 [Thread-3] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:36732
2020-04-02 05:05:23,981 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:23,982 [Thread-3] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:23,985 [Thread-3] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 3 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:23,991 [Thread-3] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 36732 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:23,992 [CacheReplicationMonitor(1612647929)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:24,002 [Thread-3] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:24,030 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803924029,root/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:24,035 [Thread-3] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user root/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab
2020-04-02 05:05:24,097 [Thread-3] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:24,101 [Thread-3] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:24,120 [Thread-3] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:24,121 [Thread-3] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:24,124 [Thread-3] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:24,128 [Thread-3] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:24,130 [Thread-3] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:24,131 [Thread-3] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:24,146 [Thread-3] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:24,153 [Thread-3] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37809
2020-04-02 05:05:24,154 [Thread-3] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:24,155 [Thread-3] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:24,172 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:24,174 [Thread-3] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:24,175 [Thread-3] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:24,175 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:24,177 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:24,177 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:24,177 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:24,177 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:24,180 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34334
2020-04-02 05:05:24,180 [Thread-3] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:24,183 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@56ada5dc{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:24,185 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@41035a02{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:24,193 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@12b91779{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:24,193 [Thread-3] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1220f919{HTTP/1.1,[http/1.1]}{localhost:34334}
2020-04-02 05:05:24,193 [Thread-3] INFO  server.Server (Server.java:doStart(419)) - Started @5356ms
2020-04-02 05:05:24,461 [Thread-3] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:46618
2020-04-02 05:05:24,462 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6829222c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:24,462 [Thread-3] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root/localhost@EXAMPLE.COM
2020-04-02 05:05:24,463 [Thread-3] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:24,478 [Thread-3] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:24,479 [Socket Reader #1 for port 43376] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43376
2020-04-02 05:05:24,487 [Thread-3] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43376
2020-04-02 05:05:24,502 [Thread-3] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:24,505 [Thread-3] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:24,512 [Thread-130] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36732 starting to offer service
2020-04-02 05:05:24,517 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:24,517 [IPC Server listener on 43376] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43376: starting
2020-04-02 05:05:24,524 [Thread-3] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43376 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:24,601 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803924600,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:24,615 [Socket Reader #1 for port 36732] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:24,642 [Thread-130] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36732
2020-04-02 05:05:24,644 [Thread-130] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:24,645 [Thread-130] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:24,646 [Thread-130] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1279554039. Formatting...
2020-04-02 05:05:24,647 [Thread-130] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8fe8e01c-3b84-441d-b227-8784609f6f6f for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:05:24,650 [Thread-130] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:24,651 [Thread-130] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1279554039. Formatting...
2020-04-02 05:05:24,651 [Thread-130] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-94f230a6-f230-47db-8bbe-ffd4f0c3a78b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:05:24,663 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1190329926-172.17.0.11-1585803923175
2020-04-02 05:05:24,664 [Thread-130] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1190329926-172.17.0.11-1585803923175
2020-04-02 05:05:24,664 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1190329926-172.17.0.11-1585803923175 is not formatted. Formatting ...
2020-04-02 05:05:24,664 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1190329926-172.17.0.11-1585803923175 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1190329926-172.17.0.11-1585803923175/current
2020-04-02 05:05:24,674 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1190329926-172.17.0.11-1585803923175
2020-04-02 05:05:24,675 [Thread-130] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1190329926-172.17.0.11-1585803923175
2020-04-02 05:05:24,675 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1190329926-172.17.0.11-1585803923175 is not formatted. Formatting ...
2020-04-02 05:05:24,675 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1190329926-172.17.0.11-1585803923175 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1190329926-172.17.0.11-1585803923175/current
2020-04-02 05:05:24,677 [Thread-130] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1279554039;bpid=BP-1190329926-172.17.0.11-1585803923175;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1279554039;c=1585803923175;bpid=BP-1190329926-172.17.0.11-1585803923175;dnuuid=null
2020-04-02 05:05:24,678 [Thread-130] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID f1ce352c-0cd1-4bfb-933b-9a874a2a2bee
2020-04-02 05:05:24,814 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8fe8e01c-3b84-441d-b227-8784609f6f6f
2020-04-02 05:05:24,815 [Thread-130] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:05:24,817 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-94f230a6-f230-47db-8bbe-ffd4f0c3a78b
2020-04-02 05:05:24,818 [Thread-130] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:05:24,824 [Thread-130] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:24,830 [Thread-130] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:24,841 [Thread-130] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:24,843 [Thread-130] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:24,843 [Thread-130] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:24,845 [Thread-130] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1190329926-172.17.0.11-1585803923175
2020-04-02 05:05:24,846 [Thread-146] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1190329926-172.17.0.11-1585803923175 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:24,846 [Thread-145] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1190329926-172.17.0.11-1585803923175 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:24,871 [Thread-146] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1190329926-172.17.0.11-1585803923175 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 25ms
2020-04-02 05:05:24,874 [Thread-145] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1190329926-172.17.0.11-1585803923175 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 28ms
2020-04-02 05:05:24,877 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1190329926-172.17.0.11-1585803923175: 33ms
2020-04-02 05:05:24,880 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1190329926-172.17.0.11-1585803923175 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:24,881 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1190329926-172.17.0.11-1585803923175 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:24,881 [Thread-149] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1190329926-172.17.0.11-1585803923175/current/replicas doesn't exist 
2020-04-02 05:05:24,881 [Thread-150] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1190329926-172.17.0.11-1585803923175/current/replicas doesn't exist 
2020-04-02 05:05:24,885 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1190329926-172.17.0.11-1585803923175 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 4ms
2020-04-02 05:05:24,889 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1190329926-172.17.0.11-1585803923175 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 9ms
2020-04-02 05:05:24,890 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1190329926-172.17.0.11-1585803923175: 10ms
2020-04-02 05:05:24,892 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1190329926-172.17.0.11-1585803923175 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:24,892 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1190329926-172.17.0.11-1585803923175 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:24,894 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8fe8e01c-3b84-441d-b227-8784609f6f6f): finished scanning block pool BP-1190329926-172.17.0.11-1585803923175
2020-04-02 05:05:24,894 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-94f230a6-f230-47db-8bbe-ffd4f0c3a78b): finished scanning block pool BP-1190329926-172.17.0.11-1585803923175
2020-04-02 05:05:24,903 [Thread-130] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:26 AM with interval of 21600000ms
2020-04-02 05:05:24,909 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1190329926-172.17.0.11-1585803923175 (Datanode Uuid f1ce352c-0cd1-4bfb-933b-9a874a2a2bee) service to localhost/127.0.0.1:36732 beginning handshake with NN
2020-04-02 05:05:24,934 [IPC Server handler 1 on 36732] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37809, datanodeUuid=f1ce352c-0cd1-4bfb-933b-9a874a2a2bee, infoPort=0, infoSecurePort=46618, ipcPort=43376, storageInfo=lv=-57;cid=testClusterID;nsid=1279554039;c=1585803923175) storage f1ce352c-0cd1-4bfb-933b-9a874a2a2bee
2020-04-02 05:05:24,936 [IPC Server handler 1 on 36732] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37809
2020-04-02 05:05:24,937 [IPC Server handler 1 on 36732] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f1ce352c-0cd1-4bfb-933b-9a874a2a2bee (127.0.0.1:37809).
2020-04-02 05:05:24,944 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8fe8e01c-3b84-441d-b227-8784609f6f6f): no suitable block pools found to scan.  Waiting 1814399948 ms.
2020-04-02 05:05:24,944 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-94f230a6-f230-47db-8bbe-ffd4f0c3a78b): no suitable block pools found to scan.  Waiting 1814399948 ms.
2020-04-02 05:05:24,945 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1190329926-172.17.0.11-1585803923175 (Datanode Uuid f1ce352c-0cd1-4bfb-933b-9a874a2a2bee) service to localhost/127.0.0.1:36732 successfully registered with NN
2020-04-02 05:05:24,945 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1190329926-172.17.0.11-1585803923175 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:24,945 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:24,945 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:36732 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:24,962 [Socket Reader #1 for port 36732] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:24,975 [IPC Server handler 3 on 36732] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8fe8e01c-3b84-441d-b227-8784609f6f6f for DN 127.0.0.1:37809
2020-04-02 05:05:24,976 [IPC Server handler 3 on 36732] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-94f230a6-f230-47db-8bbe-ffd4f0c3a78b for DN 127.0.0.1:37809
2020-04-02 05:05:25,010 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x449cd047fad9eafd: Processing first storage report for DS-94f230a6-f230-47db-8bbe-ffd4f0c3a78b from datanode f1ce352c-0cd1-4bfb-933b-9a874a2a2bee
2020-04-02 05:05:25,014 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x449cd047fad9eafd: from storage DS-94f230a6-f230-47db-8bbe-ffd4f0c3a78b node DatanodeRegistration(127.0.0.1:37809, datanodeUuid=f1ce352c-0cd1-4bfb-933b-9a874a2a2bee, infoPort=0, infoSecurePort=46618, ipcPort=43376, storageInfo=lv=-57;cid=testClusterID;nsid=1279554039;c=1585803923175), blocks: 0, hasStaleStorage: true, processing time: 3 msecs, invalidatedBlocks: 0
2020-04-02 05:05:25,014 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x449cd047fad9eafd: Processing first storage report for DS-8fe8e01c-3b84-441d-b227-8784609f6f6f from datanode f1ce352c-0cd1-4bfb-933b-9a874a2a2bee
2020-04-02 05:05:25,014 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x449cd047fad9eafd: from storage DS-8fe8e01c-3b84-441d-b227-8784609f6f6f node DatanodeRegistration(127.0.0.1:37809, datanodeUuid=f1ce352c-0cd1-4bfb-933b-9a874a2a2bee, infoPort=0, infoSecurePort=46618, ipcPort=43376, storageInfo=lv=-57;cid=testClusterID;nsid=1279554039;c=1585803923175), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:25,020 [IPC Server handler 2 on 36732] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:25,042 [Thread-3] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:25,047 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x449cd047fad9eafd,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 48 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:25,048 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1190329926-172.17.0.11-1585803923175
2020-04-02 05:05:25,054 [IPC Server handler 1 on 36732] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:25,055 [Thread-3] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:25,075 [IPC Server handler 9 on 36732] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=mkdirs	src=/test-dir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:05:25,105 [Thread-3] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:05:25,105 [Thread-3] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 36732 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:25,105 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:25,106 [Thread[Thread-98,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:05:25,107 [Thread-3] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 4
2020-04-02 05:05:25,108 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@226f4dad] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:05:25,109 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5b8ec7f1] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:05:25,118 [Thread-3] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 5 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 33 
2020-04-02 05:05:25,136 [IPC Server handler 0 on 46100] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_0000000000000000001-0000000000000000005
2020-04-02 05:05:25,138 [IPC Server handler 0 on 42171] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_0000000000000000001-0000000000000000005
2020-04-02 05:05:25,139 [IPC Server handler 4 on 36263] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_0000000000000000001-0000000000000000005
2020-04-02 05:05:25,147 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:05:25,153 [CacheReplicationMonitor(1612647929)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:05:25,155 [Thread-3] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36732
2020-04-02 05:05:25,171 [IPC Server listener on 36732] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36732
2020-04-02 05:05:25,172 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:05:25,175 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:25,176 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:05:25,215 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:25,215 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:05:25,219 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1437cba0{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:05:25,225 [Thread-3] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@41f085bd{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:05:25,226 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@28530ec5{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:25,226 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@715a5e22{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:25,236 [Thread-3] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:25,237 [Thread-3] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:05:25,237 [Thread-3] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:25,237 [Thread-3] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://localhost:36732
2020-04-02 05:05:25,237 [Thread-3] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use localhost:36732 to access this namenode/service.
2020-04-02 05:05:25,244 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803925244,root/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:25,247 [Thread-3] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user root/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab
2020-04-02 05:05:25,252 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@77d33fce] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:25,252 [Thread-3] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:25,253 [Thread-3] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:41720
2020-04-02 05:05:25,253 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:25,254 [Thread-3] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:25,255 [Thread-3] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:25,255 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:25,256 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:25,257 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:25,257 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:25,257 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:25,260 [Thread-3] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:25,260 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:25,260 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:05:25,260 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:05:25,260 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41720
2020-04-02 05:05:25,260 [Thread-3] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:25,263 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@149b922c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:25,263 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2e05677c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:25,267 [Thread-3] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:25,268 [Thread-3] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:25,268 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6f34a17b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:25,271 [Thread-3] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@70599beb(server,h=[],w=[]) for SslContextFactory@54232dfc(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/trustKS.jks)
2020-04-02 05:05:25,273 [Thread-3] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2e823cc4{SSL,[ssl, http/1.1]}{localhost:41720}
2020-04-02 05:05:25,274 [Thread-3] INFO  server.Server (Server.java:doStart(419)) - Started @6436ms
2020-04-02 05:05:25,286 [Thread-3] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(685)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-04-02 05:05:25,288 [Thread-3] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:25,289 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:25,289 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:25,289 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:25,290 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:25,290 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:25,290 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:25,290 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:25,291 [Thread-3] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:25,291 [Thread-3] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:25,291 [Thread-3] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:25,292 [Thread-3] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:25,292 [Thread-3] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:25
2020-04-02 05:05:25,293 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:25,293 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:25,293 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:05:25,294 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:25,308 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:25,308 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:25,309 [Thread-3] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:25,309 [Thread-3] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:25,309 [Thread-3] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:25,309 [Thread-3] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:25,309 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:05:25,310 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:25,310 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:25,310 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:25,310 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:25,310 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:25,310 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:25,310 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:25,311 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:25,311 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:05:25,311 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:25,318 [Thread-3] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:25,319 [Thread-3] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:25,319 [Thread-3] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:25,319 [Thread-3] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:25,319 [Thread-3] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:25,319 [Thread-3] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:25,320 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:25,320 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:25,320 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:05:25,321 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:25,323 [Thread-3] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:25,323 [Thread-3] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:25,323 [Thread-3] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:25,324 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:25,324 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:25,324 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:25,324 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:25,325 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:05:25,325 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:25,328 [Thread-3] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:25,329 [Thread-3] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:25,334 [Thread-3] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(442)) - Starting recovery process for unclosed journal segments...
2020-04-02 05:05:25,353 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803925352,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:25,372 [Socket Reader #1 for port 42171] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:25,374 [pool-1-thread-3] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803925373,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:25,376 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803925375,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:25,384 [Socket Reader #1 for port 36263] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:25,393 [IPC Server handler 1 on 36263] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(346)) - Updating lastPromisedEpoch from 1 to 2 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:25,395 [IPC Server handler 1 on 36263] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(205)) - Scanning storage FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal)
2020-04-02 05:05:25,400 [Socket Reader #1 for port 46100] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:25,403 [IPC Server handler 2 on 42171] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(346)) - Updating lastPromisedEpoch from 1 to 2 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:25,404 [IPC Server handler 2 on 42171] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(205)) - Scanning storage FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal)
2020-04-02 05:05:25,405 [IPC Server handler 2 on 46100] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(346)) - Updating lastPromisedEpoch from 1 to 2 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:25,406 [IPC Server handler 2 on 46100] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(205)) - Scanning storage FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal)
2020-04-02 05:05:25,406 [IPC Server handler 2 on 42171] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(211)) - Latest log is EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_0000000000000000001-0000000000000000005,first=0000000000000000001,last=0000000000000000005,inProgress=false,hasCorruptHeader=false) ; journal id: myjournal
2020-04-02 05:05:25,406 [IPC Server handler 1 on 36263] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(211)) - Latest log is EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_0000000000000000001-0000000000000000005,first=0000000000000000001,last=0000000000000000005,inProgress=false,hasCorruptHeader=false) ; journal id: myjournal
2020-04-02 05:05:25,406 [IPC Server handler 2 on 46100] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(211)) - Latest log is EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_0000000000000000001-0000000000000000005,first=0000000000000000001,last=0000000000000000005,inProgress=false,hasCorruptHeader=false) ; journal id: myjournal
2020-04-02 05:05:25,407 [Thread-3] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(444)) - Successfully started new epoch 2
2020-04-02 05:05:25,407 [Thread-3] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(284)) - Beginning recovery of unclosed segment starting at txid 1
2020-04-02 05:05:25,418 [IPC Server handler 3 on 42171] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_0000000000000000001-0000000000000000005,first=0000000000000000001,last=0000000000000000005,inProgress=false,hasCorruptHeader=false) -> startTxId: 1 endTxId: 5 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:25,418 [IPC Server handler 3 on 46100] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_0000000000000000001-0000000000000000005,first=0000000000000000001,last=0000000000000000005,inProgress=false,hasCorruptHeader=false) -> startTxId: 1 endTxId: 5 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:25,418 [IPC Server handler 2 on 36263] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_0000000000000000001-0000000000000000005,first=0000000000000000001,last=0000000000000000005,inProgress=false,hasCorruptHeader=false) -> startTxId: 1 endTxId: 5 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:25,420 [IPC Server handler 3 on 42171] INFO  server.Journal (Journal.java:prepareRecovery(784)) - Prepared recovery for segment 1: segmentState { startTxId: 1 endTxId: 5 isInProgress: false } lastWriterEpoch: 1 lastCommittedTxId: 5 ; journal id: myjournal
2020-04-02 05:05:25,420 [IPC Server handler 2 on 36263] INFO  server.Journal (Journal.java:prepareRecovery(784)) - Prepared recovery for segment 1: segmentState { startTxId: 1 endTxId: 5 isInProgress: false } lastWriterEpoch: 1 lastCommittedTxId: 5 ; journal id: myjournal
2020-04-02 05:05:25,420 [IPC Server handler 3 on 46100] INFO  server.Journal (Journal.java:prepareRecovery(784)) - Prepared recovery for segment 1: segmentState { startTxId: 1 endTxId: 5 isInProgress: false } lastWriterEpoch: 1 lastCommittedTxId: 5 ; journal id: myjournal
2020-04-02 05:05:25,421 [Thread-3] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(293)) - Recovery prepare phase complete. Responses:
127.0.0.1:46100: segmentState { startTxId: 1 endTxId: 5 isInProgress: false } lastWriterEpoch: 1 lastCommittedTxId: 5
127.0.0.1:36263: segmentState { startTxId: 1 endTxId: 5 isInProgress: false } lastWriterEpoch: 1 lastCommittedTxId: 5
2020-04-02 05:05:25,422 [Thread-3] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(317)) - Using longest log: 127.0.0.1:46100=segmentState {
  startTxId: 1
  endTxId: 5
  isInProgress: false
}
lastWriterEpoch: 1
lastCommittedTxId: 5

2020-04-02 05:05:25,437 [IPC Server handler 3 on 36263] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_0000000000000000001-0000000000000000005,first=0000000000000000001,last=0000000000000000005,inProgress=false,hasCorruptHeader=false) -> startTxId: 1 endTxId: 5 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:25,437 [IPC Server handler 4 on 46100] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_0000000000000000001-0000000000000000005,first=0000000000000000001,last=0000000000000000005,inProgress=false,hasCorruptHeader=false) -> startTxId: 1 endTxId: 5 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:25,438 [IPC Server handler 4 on 42171] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_0000000000000000001-0000000000000000005,first=0000000000000000001,last=0000000000000000005,inProgress=false,hasCorruptHeader=false) -> startTxId: 1 endTxId: 5 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:25,438 [IPC Server handler 4 on 42171] INFO  server.Journal (Journal.java:acceptRecovery(872)) - Skipping download of log startTxId: 1 endTxId: 5 isInProgress: false: already have up-to-date logs ; journal id: myjournal
2020-04-02 05:05:25,439 [IPC Server handler 3 on 36263] INFO  server.Journal (Journal.java:acceptRecovery(872)) - Skipping download of log startTxId: 1 endTxId: 5 isInProgress: false: already have up-to-date logs ; journal id: myjournal
2020-04-02 05:05:25,439 [IPC Server handler 4 on 46100] INFO  server.Journal (Journal.java:acceptRecovery(872)) - Skipping download of log startTxId: 1 endTxId: 5 isInProgress: false: already have up-to-date logs ; journal id: myjournal
2020-04-02 05:05:25,441 [IPC Server handler 4 on 42171] INFO  server.Journal (Journal.java:acceptRecovery(905)) - Accepted recovery for segment 1: segmentState { startTxId: 1 endTxId: 5 isInProgress: false } acceptedInEpoch: 2 ; journal id: myjournal
2020-04-02 05:05:25,441 [IPC Server handler 3 on 36263] INFO  server.Journal (Journal.java:acceptRecovery(905)) - Accepted recovery for segment 1: segmentState { startTxId: 1 endTxId: 5 isInProgress: false } acceptedInEpoch: 2 ; journal id: myjournal
2020-04-02 05:05:25,441 [IPC Server handler 4 on 46100] INFO  server.Journal (Journal.java:acceptRecovery(905)) - Accepted recovery for segment 1: segmentState { startTxId: 1 endTxId: 5 isInProgress: false } acceptedInEpoch: 2 ; journal id: myjournal
2020-04-02 05:05:25,460 [Thread-3] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:25,461 [Thread-3] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:25,463 [Thread-3] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:25,463 [Thread-3] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:25,463 [Thread-3] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4d82d800 expecting start txid #1
2020-04-02 05:05:25,463 [Thread-3] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file https://localhost:41810/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1279554039%3A1585803923175%3AtestClusterID&inProgressOk=true, https://localhost:46134/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1279554039%3A1585803923175%3AtestClusterID&inProgressOk=true maxTxnsToRead = 9223372036854775807
2020-04-02 05:05:25,464 [Thread-3] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream 'https://localhost:41810/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1279554039%3A1585803923175%3AtestClusterID&inProgressOk=true, https://localhost:46134/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1279554039%3A1585803923175%3AtestClusterID&inProgressOk=true' to transaction ID 1
2020-04-02 05:05:25,464 [Thread-3] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream 'https://localhost:41810/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1279554039%3A1585803923175%3AtestClusterID&inProgressOk=true' to transaction ID 1
2020-04-02 05:05:25,855 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803925848,root/localhost for HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:25,926 [qtp1818267346-54] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(396)) - Sending fileName: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_0000000000000000001-0000000000000000005, fileSize: 185. Sent total: 185 bytes. Size of last segment intended to send: -1 bytes.
2020-04-02 05:05:25,942 [Thread-3] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file https://localhost:41810/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1279554039%3A1585803923175%3AtestClusterID&inProgressOk=true, https://localhost:46134/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1279554039%3A1585803923175%3AtestClusterID&inProgressOk=true of size 185 edits # 5 loaded in 0 seconds
2020-04-02 05:05:25,942 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:25,944 [Thread-3] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 6
2020-04-02 05:05:25,945 [IPC Server handler 3 on 42171] INFO  server.Journal (Journal.java:startLogSegment(582)) - Updating lastWriterEpoch from 1 to 2 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:25,945 [IPC Server handler 3 on 46100] INFO  server.Journal (Journal.java:startLogSegment(582)) - Updating lastWriterEpoch from 1 to 2 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:25,951 [IPC Server handler 2 on 36263] INFO  server.Journal (Journal.java:startLogSegment(582)) - Updating lastWriterEpoch from 1 to 2 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:25,986 [Thread-3] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:25,987 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 660 msecs
2020-04-02 05:05:25,987 [Thread-3] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:36732
2020-04-02 05:05:25,987 [Thread-3] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:25,990 [Socket Reader #1 for port 36732] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36732
2020-04-02 05:05:26,001 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:26,001 [Thread-3] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:26,015 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@75c79362] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:05:26,018 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:26,021 [Thread-3] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:05:26,022 [Thread-3] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:05:26,022 [Thread-3] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:26,025 [Thread-3] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:26,030 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:26,030 [Thread[Thread-182,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:05:26,030 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:26,031 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:26,031 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:26,031 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:26,031 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2020-04-02 05:05:26,031 [Thread[Thread-182,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:26,036 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:26,036 [IPC Server listener on 36732] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36732: starting
2020-04-02 05:05:26,039 [Thread-3] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:36732
2020-04-02 05:05:26,040 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:26,040 [Thread-3] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:26,042 [Thread-3] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 2 milliseconds
name space=2
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:26,042 [Thread-3] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 36732 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:26,043 [Thread-3] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1409)) - Waiting for the Mini HDFS Cluster to start...
2020-04-02 05:05:26,050 [CacheReplicationMonitor(138111922)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:27,044 [Thread-3] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1409)) - Waiting for the Mini HDFS Cluster to start...
2020-04-02 05:05:27,949 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] WARN  datanode.DataNode (BPServiceActor.java:offerService(728)) - IOException in offerService
java.io.EOFException: End of File Exception between local host is: "f8287aaf0779/172.17.0.11"; destination host is: "localhost":36732; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:789)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy27.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:514)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:645)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:842)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2020-04-02 05:05:28,044 [Thread-3] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1409)) - Waiting for the Mini HDFS Cluster to start...
2020-04-02 05:05:29,045 [Thread-3] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1409)) - Waiting for the Mini HDFS Cluster to start...
2020-04-02 05:05:30,045 [Thread-3] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1409)) - Waiting for the Mini HDFS Cluster to start...
2020-04-02 05:05:30,956 [Socket Reader #1 for port 36732] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:30,962 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:36732 with active state
2020-04-02 05:05:30,964 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1190329926-172.17.0.11-1585803923175 (Datanode Uuid f1ce352c-0cd1-4bfb-933b-9a874a2a2bee) service to localhost/127.0.0.1:36732 beginning handshake with NN
2020-04-02 05:05:30,966 [IPC Server handler 2 on 36732] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37809, datanodeUuid=f1ce352c-0cd1-4bfb-933b-9a874a2a2bee, infoPort=0, infoSecurePort=46618, ipcPort=43376, storageInfo=lv=-57;cid=testClusterID;nsid=1279554039;c=1585803923175) storage f1ce352c-0cd1-4bfb-933b-9a874a2a2bee
2020-04-02 05:05:30,966 [IPC Server handler 2 on 36732] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37809
2020-04-02 05:05:30,966 [IPC Server handler 2 on 36732] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f1ce352c-0cd1-4bfb-933b-9a874a2a2bee (127.0.0.1:37809).
2020-04-02 05:05:30,968 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1190329926-172.17.0.11-1585803923175 (Datanode Uuid f1ce352c-0cd1-4bfb-933b-9a874a2a2bee) service to localhost/127.0.0.1:36732 successfully registered with NN
2020-04-02 05:05:30,968 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:30,972 [IPC Server handler 4 on 36732] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8fe8e01c-3b84-441d-b227-8784609f6f6f for DN 127.0.0.1:37809
2020-04-02 05:05:30,973 [IPC Server handler 4 on 36732] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-94f230a6-f230-47db-8bbe-ffd4f0c3a78b for DN 127.0.0.1:37809
2020-04-02 05:05:30,980 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x449cd047fad9eafe: Processing first storage report for DS-94f230a6-f230-47db-8bbe-ffd4f0c3a78b from datanode f1ce352c-0cd1-4bfb-933b-9a874a2a2bee
2020-04-02 05:05:30,981 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x449cd047fad9eafe: from storage DS-94f230a6-f230-47db-8bbe-ffd4f0c3a78b node DatanodeRegistration(127.0.0.1:37809, datanodeUuid=f1ce352c-0cd1-4bfb-933b-9a874a2a2bee, infoPort=0, infoSecurePort=46618, ipcPort=43376, storageInfo=lv=-57;cid=testClusterID;nsid=1279554039;c=1585803923175), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:05:30,981 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x449cd047fad9eafe: Processing first storage report for DS-8fe8e01c-3b84-441d-b227-8784609f6f6f from datanode f1ce352c-0cd1-4bfb-933b-9a874a2a2bee
2020-04-02 05:05:30,982 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x449cd047fad9eafe: from storage DS-8fe8e01c-3b84-441d-b227-8784609f6f6f node DatanodeRegistration(127.0.0.1:37809, datanodeUuid=f1ce352c-0cd1-4bfb-933b-9a874a2a2bee, infoPort=0, infoSecurePort=46618, ipcPort=43376, storageInfo=lv=-57;cid=testClusterID;nsid=1279554039;c=1585803923175), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:05:30,986 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x449cd047fad9eafe,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:30,986 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1190329926-172.17.0.11-1585803923175
2020-04-02 05:05:31,046 [Thread-3] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartNameNode(2140)) - Restarted the namenode
2020-04-02 05:05:31,057 [Socket Reader #1 for port 36732] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:31,076 [IPC Server handler 0 on 36732] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:31,077 [Thread-3] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:31,090 [IPC Server handler 1 on 36732] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/test-dir	dst=null	perm=null	proto=rpc
2020-04-02 05:05:31,098 [IPC Server handler 2 on 36732] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=mkdirs	src=/test-dir-2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:05:31,104 [Thread-3] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:05:31,104 [Thread-3] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 36732 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:31,105 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:31,105 [Thread[Thread-182,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:05:31,105 [Thread-3] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 6, 9
2020-04-02 05:05:31,105 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@65573e0e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:05:31,106 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@2a576852] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:05:31,111 [Thread-3] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 5 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 5 Number of syncs: 5 SyncTimes(ms): 25 
2020-04-02 05:05:31,116 [IPC Server handler 4 on 42171] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_inprogress_0000000000000000006 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_0000000000000000006-0000000000000000010
2020-04-02 05:05:31,117 [IPC Server handler 3 on 36263] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_inprogress_0000000000000000006 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_0000000000000000006-0000000000000000010
2020-04-02 05:05:31,118 [IPC Server handler 4 on 46100] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_inprogress_0000000000000000006 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_0000000000000000006-0000000000000000010
2020-04-02 05:05:31,119 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:05:31,120 [CacheReplicationMonitor(138111922)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:05:31,127 [Thread-3] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36732
2020-04-02 05:05:31,129 [IPC Server listener on 36732] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36732
2020-04-02 05:05:31,129 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:31,129 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:05:31,129 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:05:31,151 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:31,151 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:05:31,153 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6f34a17b{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:05:31,156 [Thread-3] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2e823cc4{SSL,[ssl, http/1.1]}{localhost:41720}
2020-04-02 05:05:31,156 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2e05677c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:31,157 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@149b922c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:31,163 [Thread-3] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:31,164 [Thread-3] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:05:31,164 [Thread-3] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:31,165 [Thread-3] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://localhost:36732
2020-04-02 05:05:31,166 [Thread-3] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use localhost:36732 to access this namenode/service.
2020-04-02 05:05:31,175 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803931174,root/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:31,178 [Thread-3] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user root/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab
2020-04-02 05:05:31,184 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@546fbe95] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:31,184 [Thread-3] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:31,185 [Thread-3] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:41720
2020-04-02 05:05:31,186 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:31,187 [Thread-3] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:31,188 [Thread-3] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:31,188 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:31,190 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:31,190 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:31,191 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:31,191 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:31,193 [Thread-3] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:31,193 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:31,194 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:05:31,194 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:05:31,194 [Thread-3] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41720
2020-04-02 05:05:31,194 [Thread-3] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:31,323 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@208b0eb4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:31,324 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@66491a99{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:31,332 [Thread-3] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:31,336 [Thread-3] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:31,337 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2b68cb8a{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:31,339 [Thread-3] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@505b558e(server,h=[],w=[]) for SslContextFactory@6afe1ac3(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/trustKS.jks)
2020-04-02 05:05:31,340 [Thread-3] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@63e4293c{SSL,[ssl, http/1.1]}{localhost:41720}
2020-04-02 05:05:31,342 [Thread-3] INFO  server.Server (Server.java:doStart(419)) - Started @12505ms
2020-04-02 05:05:31,343 [Thread-3] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(685)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-04-02 05:05:31,351 [Thread-3] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:31,351 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:31,351 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:31,352 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:31,352 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:31,352 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:31,352 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:31,352 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:31,353 [Thread-3] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:31,353 [Thread-3] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:31,353 [Thread-3] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:31,353 [Thread-3] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:31,354 [Thread-3] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:31
2020-04-02 05:05:31,354 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:31,354 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:31,354 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:05:31,354 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:31,366 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:31,367 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:31,367 [Thread-3] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:31,368 [Thread-3] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:31,368 [Thread-3] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:31,368 [Thread-3] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:31,368 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:05:31,368 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:31,368 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:31,368 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:31,369 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:31,369 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:31,369 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:31,369 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:31,369 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:31,370 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:05:31,370 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:31,374 [Thread-3] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:31,378 [Thread-3] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:31,378 [Thread-3] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:31,378 [Thread-3] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:31,378 [Thread-3] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:31,378 [Thread-3] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:31,378 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:31,378 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:31,379 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:05:31,379 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:31,380 [Thread-3] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:31,380 [Thread-3] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:31,380 [Thread-3] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:31,380 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:31,380 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:31,380 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:31,380 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:31,380 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:05:31,381 [Thread-3] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:31,384 [Thread-3] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:31,385 [Thread-3] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:31,388 [Thread-3] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(442)) - Starting recovery process for unclosed journal segments...
2020-04-02 05:05:31,417 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803931416,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:31,417 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803931417,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:31,417 [pool-1-thread-3] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803931417,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:31,438 [Socket Reader #1 for port 36263] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:31,443 [Socket Reader #1 for port 46100] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:31,446 [Socket Reader #1 for port 42171] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:31,450 [IPC Server handler 1 on 46100] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(346)) - Updating lastPromisedEpoch from 2 to 3 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:31,451 [IPC Server handler 1 on 42171] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(346)) - Updating lastPromisedEpoch from 2 to 3 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:31,451 [IPC Server handler 1 on 46100] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(205)) - Scanning storage FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal)
2020-04-02 05:05:31,451 [IPC Server handler 0 on 36263] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(346)) - Updating lastPromisedEpoch from 2 to 3 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:31,452 [IPC Server handler 1 on 42171] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(205)) - Scanning storage FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal)
2020-04-02 05:05:31,452 [IPC Server handler 0 on 36263] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(205)) - Scanning storage FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal)
2020-04-02 05:05:31,454 [IPC Server handler 1 on 46100] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(211)) - Latest log is EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_0000000000000000006-0000000000000000010,first=0000000000000000006,last=0000000000000000010,inProgress=false,hasCorruptHeader=false) ; journal id: myjournal
2020-04-02 05:05:31,454 [IPC Server handler 0 on 36263] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(211)) - Latest log is EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_0000000000000000006-0000000000000000010,first=0000000000000000006,last=0000000000000000010,inProgress=false,hasCorruptHeader=false) ; journal id: myjournal
2020-04-02 05:05:31,458 [Thread-3] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(444)) - Successfully started new epoch 3
2020-04-02 05:05:31,458 [Thread-3] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(284)) - Beginning recovery of unclosed segment starting at txid 6
2020-04-02 05:05:31,461 [IPC Server handler 1 on 42171] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(211)) - Latest log is EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_0000000000000000006-0000000000000000010,first=0000000000000000006,last=0000000000000000010,inProgress=false,hasCorruptHeader=false) ; journal id: myjournal
2020-04-02 05:05:31,463 [IPC Server handler 1 on 36263] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(6): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_0000000000000000006-0000000000000000010,first=0000000000000000006,last=0000000000000000010,inProgress=false,hasCorruptHeader=false) -> startTxId: 6 endTxId: 10 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:31,464 [IPC Server handler 1 on 36263] INFO  server.Journal (Journal.java:prepareRecovery(784)) - Prepared recovery for segment 6: segmentState { startTxId: 6 endTxId: 10 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 10 ; journal id: myjournal
2020-04-02 05:05:31,464 [IPC Server handler 2 on 46100] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(6): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_0000000000000000006-0000000000000000010,first=0000000000000000006,last=0000000000000000010,inProgress=false,hasCorruptHeader=false) -> startTxId: 6 endTxId: 10 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:31,464 [IPC Server handler 2 on 46100] INFO  server.Journal (Journal.java:prepareRecovery(784)) - Prepared recovery for segment 6: segmentState { startTxId: 6 endTxId: 10 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 10 ; journal id: myjournal
2020-04-02 05:05:31,467 [IPC Server handler 2 on 42171] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(6): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_0000000000000000006-0000000000000000010,first=0000000000000000006,last=0000000000000000010,inProgress=false,hasCorruptHeader=false) -> startTxId: 6 endTxId: 10 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:31,467 [Thread-3] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(293)) - Recovery prepare phase complete. Responses:
127.0.0.1:36263: segmentState { startTxId: 6 endTxId: 10 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 10
127.0.0.1:46100: segmentState { startTxId: 6 endTxId: 10 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 10
2020-04-02 05:05:31,467 [IPC Server handler 2 on 42171] INFO  server.Journal (Journal.java:prepareRecovery(784)) - Prepared recovery for segment 6: segmentState { startTxId: 6 endTxId: 10 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 10 ; journal id: myjournal
2020-04-02 05:05:31,468 [Thread-3] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(317)) - Using longest log: 127.0.0.1:36263=segmentState {
  startTxId: 6
  endTxId: 10
  isInProgress: false
}
lastWriterEpoch: 2
lastCommittedTxId: 10

2020-04-02 05:05:31,470 [IPC Server handler 2 on 36263] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(6): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_0000000000000000006-0000000000000000010,first=0000000000000000006,last=0000000000000000010,inProgress=false,hasCorruptHeader=false) -> startTxId: 6 endTxId: 10 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:31,470 [IPC Server handler 2 on 36263] INFO  server.Journal (Journal.java:acceptRecovery(872)) - Skipping download of log startTxId: 6 endTxId: 10 isInProgress: false: already have up-to-date logs ; journal id: myjournal
2020-04-02 05:05:31,470 [IPC Server handler 3 on 46100] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(6): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_0000000000000000006-0000000000000000010,first=0000000000000000006,last=0000000000000000010,inProgress=false,hasCorruptHeader=false) -> startTxId: 6 endTxId: 10 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:31,471 [IPC Server handler 3 on 46100] INFO  server.Journal (Journal.java:acceptRecovery(872)) - Skipping download of log startTxId: 6 endTxId: 10 isInProgress: false: already have up-to-date logs ; journal id: myjournal
2020-04-02 05:05:31,471 [IPC Server handler 3 on 42171] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(6): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_0000000000000000006-0000000000000000010,first=0000000000000000006,last=0000000000000000010,inProgress=false,hasCorruptHeader=false) -> startTxId: 6 endTxId: 10 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:31,471 [IPC Server handler 3 on 42171] INFO  server.Journal (Journal.java:acceptRecovery(872)) - Skipping download of log startTxId: 6 endTxId: 10 isInProgress: false: already have up-to-date logs ; journal id: myjournal
2020-04-02 05:05:31,473 [IPC Server handler 3 on 42171] INFO  server.Journal (Journal.java:acceptRecovery(905)) - Accepted recovery for segment 6: segmentState { startTxId: 6 endTxId: 10 isInProgress: false } acceptedInEpoch: 3 ; journal id: myjournal
2020-04-02 05:05:31,474 [IPC Server handler 3 on 46100] INFO  server.Journal (Journal.java:acceptRecovery(905)) - Accepted recovery for segment 6: segmentState { startTxId: 6 endTxId: 10 isInProgress: false } acceptedInEpoch: 3 ; journal id: myjournal
2020-04-02 05:05:31,480 [Thread-3] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:31,481 [Thread-3] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:31,481 [Thread-3] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:31,482 [Thread-3] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:31,482 [IPC Server handler 2 on 36263] INFO  server.Journal (Journal.java:acceptRecovery(905)) - Accepted recovery for segment 6: segmentState { startTxId: 6 endTxId: 10 isInProgress: false } acceptedInEpoch: 3 ; journal id: myjournal
2020-04-02 05:05:31,482 [Thread-3] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2eefb7e8 expecting start txid #1
2020-04-02 05:05:31,482 [Thread-3] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file https://localhost:42831/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1279554039%3A1585803923175%3AtestClusterID&inProgressOk=true, https://localhost:41810/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1279554039%3A1585803923175%3AtestClusterID&inProgressOk=true maxTxnsToRead = 9223372036854775807
2020-04-02 05:05:31,483 [Thread-3] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream 'https://localhost:42831/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1279554039%3A1585803923175%3AtestClusterID&inProgressOk=true, https://localhost:41810/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1279554039%3A1585803923175%3AtestClusterID&inProgressOk=true' to transaction ID 1
2020-04-02 05:05:31,483 [Thread-3] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream 'https://localhost:42831/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1279554039%3A1585803923175%3AtestClusterID&inProgressOk=true' to transaction ID 1
2020-04-02 05:05:31,540 [pool-1-thread-3] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803931540,root/localhost for HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:31,588 [qtp128274280-522] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(396)) - Sending fileName: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_0000000000000000001-0000000000000000005, fileSize: 185. Sent total: 185 bytes. Size of last segment intended to send: -1 bytes.
2020-04-02 05:05:31,591 [Thread-3] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file https://localhost:42831/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1279554039%3A1585803923175%3AtestClusterID&inProgressOk=true, https://localhost:41810/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1279554039%3A1585803923175%3AtestClusterID&inProgressOk=true of size 185 edits # 5 loaded in 0 seconds
2020-04-02 05:05:31,591 [Thread-3] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2f7fcd8b expecting start txid #6
2020-04-02 05:05:31,591 [Thread-3] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file https://localhost:41810/getJournal?jid=myjournal&segmentTxId=6&storageInfo=-64%3A1279554039%3A1585803923175%3AtestClusterID&inProgressOk=true, https://localhost:42831/getJournal?jid=myjournal&segmentTxId=6&storageInfo=-64%3A1279554039%3A1585803923175%3AtestClusterID&inProgressOk=true maxTxnsToRead = 9223372036854775807
2020-04-02 05:05:31,591 [Thread-3] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream 'https://localhost:41810/getJournal?jid=myjournal&segmentTxId=6&storageInfo=-64%3A1279554039%3A1585803923175%3AtestClusterID&inProgressOk=true, https://localhost:42831/getJournal?jid=myjournal&segmentTxId=6&storageInfo=-64%3A1279554039%3A1585803923175%3AtestClusterID&inProgressOk=true' to transaction ID 1
2020-04-02 05:05:31,591 [Thread-3] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream 'https://localhost:41810/getJournal?jid=myjournal&segmentTxId=6&storageInfo=-64%3A1279554039%3A1585803923175%3AtestClusterID&inProgressOk=true' to transaction ID 1
2020-04-02 05:05:31,659 [pool-1-thread-3] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803931658,root/localhost for HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:31,694 [qtp1818267346-57] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(396)) - Sending fileName: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_0000000000000000006-0000000000000000010, fileSize: 187. Sent total: 187 bytes. Size of last segment intended to send: -1 bytes.
2020-04-02 05:05:31,696 [Thread-3] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file https://localhost:41810/getJournal?jid=myjournal&segmentTxId=6&storageInfo=-64%3A1279554039%3A1585803923175%3AtestClusterID&inProgressOk=true, https://localhost:42831/getJournal?jid=myjournal&segmentTxId=6&storageInfo=-64%3A1279554039%3A1585803923175%3AtestClusterID&inProgressOk=true of size 187 edits # 5 loaded in 0 seconds
2020-04-02 05:05:31,696 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:31,700 [Thread-3] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 11
2020-04-02 05:05:31,702 [IPC Server handler 2 on 42171] INFO  server.Journal (Journal.java:startLogSegment(582)) - Updating lastWriterEpoch from 2 to 3 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:31,702 [IPC Server handler 2 on 46100] INFO  server.Journal (Journal.java:startLogSegment(582)) - Updating lastWriterEpoch from 2 to 3 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:31,718 [IPC Server handler 1 on 36263] INFO  server.Journal (Journal.java:startLogSegment(582)) - Updating lastWriterEpoch from 2 to 3 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:31,735 [Thread-3] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:31,735 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 353 msecs
2020-04-02 05:05:31,736 [Thread-3] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:36732
2020-04-02 05:05:31,736 [Thread-3] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:31,737 [Socket Reader #1 for port 36732] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36732
2020-04-02 05:05:31,743 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:31,743 [Thread-3] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:31,759 [Thread-3] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:31,760 [Thread-3] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:05:31,760 [Thread-3] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:05:31,760 [Thread-3] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:31,760 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@1e726374] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:05:31,773 [Thread-3] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:31,778 [Thread[Thread-226,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:05:31,790 [Thread[Thread-226,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:31,791 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:31,792 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:31,792 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:31,792 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:31,792 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:31,792 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 19 msec
2020-04-02 05:05:31,794 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:31,794 [IPC Server listener on 36732] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36732: starting
2020-04-02 05:05:31,795 [Thread-3] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:36732
2020-04-02 05:05:31,800 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:31,800 [Thread-3] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:31,801 [Thread-3] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=3
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:31,802 [Thread-3] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 36732 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:31,806 [CacheReplicationMonitor(290257981)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:31,806 [Thread-3] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1409)) - Waiting for the Mini HDFS Cluster to start...
2020-04-02 05:05:32,807 [Thread-3] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1409)) - Waiting for the Mini HDFS Cluster to start...
2020-04-02 05:05:33,814 [Thread-3] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1409)) - Waiting for the Mini HDFS Cluster to start...
2020-04-02 05:05:33,969 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] WARN  datanode.DataNode (BPServiceActor.java:offerService(728)) - IOException in offerService
java.io.EOFException: End of File Exception between local host is: "f8287aaf0779/172.17.0.11"; destination host is: "localhost":36732; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:789)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy27.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:514)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:645)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:842)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2020-04-02 05:05:34,816 [Thread-3] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1409)) - Waiting for the Mini HDFS Cluster to start...
2020-04-02 05:05:35,817 [Thread-3] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1409)) - Waiting for the Mini HDFS Cluster to start...
2020-04-02 05:05:36,817 [Thread-3] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1409)) - Waiting for the Mini HDFS Cluster to start...
2020-04-02 05:05:36,975 [Socket Reader #1 for port 36732] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:36,996 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:36732 with active state
2020-04-02 05:05:36,999 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1190329926-172.17.0.11-1585803923175 (Datanode Uuid f1ce352c-0cd1-4bfb-933b-9a874a2a2bee) service to localhost/127.0.0.1:36732 beginning handshake with NN
2020-04-02 05:05:37,003 [IPC Server handler 1 on 36732] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37809, datanodeUuid=f1ce352c-0cd1-4bfb-933b-9a874a2a2bee, infoPort=0, infoSecurePort=46618, ipcPort=43376, storageInfo=lv=-57;cid=testClusterID;nsid=1279554039;c=1585803923175) storage f1ce352c-0cd1-4bfb-933b-9a874a2a2bee
2020-04-02 05:05:37,003 [IPC Server handler 1 on 36732] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37809
2020-04-02 05:05:37,003 [IPC Server handler 1 on 36732] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f1ce352c-0cd1-4bfb-933b-9a874a2a2bee (127.0.0.1:37809).
2020-04-02 05:05:37,012 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1190329926-172.17.0.11-1585803923175 (Datanode Uuid f1ce352c-0cd1-4bfb-933b-9a874a2a2bee) service to localhost/127.0.0.1:36732 successfully registered with NN
2020-04-02 05:05:37,012 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:37,015 [IPC Server handler 3 on 36732] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8fe8e01c-3b84-441d-b227-8784609f6f6f for DN 127.0.0.1:37809
2020-04-02 05:05:37,015 [IPC Server handler 3 on 36732] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-94f230a6-f230-47db-8bbe-ffd4f0c3a78b for DN 127.0.0.1:37809
2020-04-02 05:05:37,022 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x449cd047fad9eaff: Processing first storage report for DS-94f230a6-f230-47db-8bbe-ffd4f0c3a78b from datanode f1ce352c-0cd1-4bfb-933b-9a874a2a2bee
2020-04-02 05:05:37,023 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x449cd047fad9eaff: from storage DS-94f230a6-f230-47db-8bbe-ffd4f0c3a78b node DatanodeRegistration(127.0.0.1:37809, datanodeUuid=f1ce352c-0cd1-4bfb-933b-9a874a2a2bee, infoPort=0, infoSecurePort=46618, ipcPort=43376, storageInfo=lv=-57;cid=testClusterID;nsid=1279554039;c=1585803923175), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:05:37,024 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x449cd047fad9eaff: Processing first storage report for DS-8fe8e01c-3b84-441d-b227-8784609f6f6f from datanode f1ce352c-0cd1-4bfb-933b-9a874a2a2bee
2020-04-02 05:05:37,024 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x449cd047fad9eaff: from storage DS-8fe8e01c-3b84-441d-b227-8784609f6f6f node DatanodeRegistration(127.0.0.1:37809, datanodeUuid=f1ce352c-0cd1-4bfb-933b-9a874a2a2bee, infoPort=0, infoSecurePort=46618, ipcPort=43376, storageInfo=lv=-57;cid=testClusterID;nsid=1279554039;c=1585803923175), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:37,030 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x449cd047fad9eaff,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 14 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:37,030 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1190329926-172.17.0.11-1585803923175
2020-04-02 05:05:37,818 [Thread-3] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartNameNode(2140)) - Restarted the namenode
2020-04-02 05:05:37,826 [Socket Reader #1 for port 36732] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:37,831 [IPC Server handler 0 on 36732] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:37,832 [Thread-3] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:37,835 [IPC Server handler 2 on 36732] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/test-dir	dst=null	perm=null	proto=rpc
2020-04-02 05:05:37,838 [IPC Server handler 1 on 36732] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/test-dir-2	dst=null	perm=null	proto=rpc
2020-04-02 05:05:37,854 [Thread-3] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:05:37,854 [Thread-3] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:05:37,854 [Thread-3] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43376 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:37,855 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@678cfd6f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:37,855 [Thread-3] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:37,862 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-94f230a6-f230-47db-8bbe-ffd4f0c3a78b) exiting.
2020-04-02 05:05:37,865 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8fe8e01c-3b84-441d-b227-8784609f6f6f) exiting.
2020-04-02 05:05:38,009 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@12b91779{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:38,015 [Thread-3] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1220f919{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:38,039 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@41035a02{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:38,039 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@56ada5dc{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:38,059 [Thread-3] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43376
2020-04-02 05:05:38,065 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:38,065 [IPC Server listener on 43376] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43376
2020-04-02 05:05:38,065 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:38,066 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1190329926-172.17.0.11-1585803923175 (Datanode Uuid f1ce352c-0cd1-4bfb-933b-9a874a2a2bee) service to localhost/127.0.0.1:36732
2020-04-02 05:05:38,066 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1190329926-172.17.0.11-1585803923175 (Datanode Uuid f1ce352c-0cd1-4bfb-933b-9a874a2a2bee)
2020-04-02 05:05:38,066 [BP-1190329926-172.17.0.11-1585803923175 heartbeating to localhost/127.0.0.1:36732] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1190329926-172.17.0.11-1585803923175
2020-04-02 05:05:38,090 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1190329926-172.17.0.11-1585803923175] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:38,108 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1190329926-172.17.0.11-1585803923175] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:38,114 [Thread-3] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:38,114 [Thread-3] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:38,118 [Thread-3] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:38,118 [Thread-3] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:38,130 [Thread-3] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:38,131 [Thread-3] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:05:38,131 [Thread-3] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 36732 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:38,131 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:38,131 [Thread[Thread-226,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:05:38,131 [Thread-3] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 11, 13
2020-04-02 05:05:38,131 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@189c1519] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:05:38,137 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@32b09915] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:05:38,147 [Thread-3] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 4 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 10 Number of syncs: 4 SyncTimes(ms): 36 
2020-04-02 05:05:38,149 [IPC Server handler 2 on 42171] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_inprogress_0000000000000000011 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_0000000000000000011-0000000000000000014
2020-04-02 05:05:38,149 [IPC Server handler 1 on 36263] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_inprogress_0000000000000000011 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_0000000000000000011-0000000000000000014
2020-04-02 05:05:38,150 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:05:38,162 [Thread-3] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36732
2020-04-02 05:05:38,171 [CacheReplicationMonitor(290257981)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:05:38,173 [IPC Server handler 2 on 46100] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_inprogress_0000000000000000011 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_0000000000000000011-0000000000000000014
2020-04-02 05:05:38,178 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:05:38,179 [IPC Server listener on 36732] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36732
2020-04-02 05:05:38,181 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:05:38,182 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:38,201 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:38,206 [Thread-3] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:05:38,209 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2b68cb8a{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:05:38,217 [Thread-3] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@63e4293c{SSL,[ssl, http/1.1]}{localhost:41720}
2020-04-02 05:05:38,217 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@66491a99{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:38,218 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@208b0eb4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:38,228 [Thread-3] INFO  server.JournalNode (JournalNode.java:stop(286)) - [msx-restart] JournalNode 42171 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:38,229 [Thread-3] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42171
2020-04-02 05:05:38,230 [IPC Server listener on 42171] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42171
2020-04-02 05:05:38,230 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5d17ee0c{/,null,UNAVAILABLE}{/journal}
2020-04-02 05:05:38,232 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:38,244 [Thread-3] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5a4b59e5{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:05:38,244 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1aeaefab{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:38,245 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2adfa90{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:38,254 [Thread-3] INFO  common.Storage (JNStorage.java:close(280)) - Closing journal storage for Storage Directory root= /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/waitactive; location= null
2020-04-02 05:05:38,254 [Thread-3] INFO  common.Storage (JNStorage.java:close(280)) - Closing journal storage for Storage Directory root= /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal; location= null
2020-04-02 05:05:38,275 [Thread-3] INFO  server.JournalNode (JournalNode.java:stop(286)) - [msx-restart] JournalNode 46100 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:38,275 [Thread-3] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46100
2020-04-02 05:05:38,282 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:38,282 [IPC Server listener on 46100] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46100
2020-04-02 05:05:38,282 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4a98d7ed{/,null,UNAVAILABLE}{/journal}
2020-04-02 05:05:38,303 [Thread-3] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@28b76761{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:05:38,304 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@73580cca{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:38,304 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@352f6cad{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:38,314 [Thread-3] INFO  common.Storage (JNStorage.java:close(280)) - Closing journal storage for Storage Directory root= /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/waitactive; location= null
2020-04-02 05:05:38,314 [Thread-3] INFO  common.Storage (JNStorage.java:close(280)) - Closing journal storage for Storage Directory root= /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal; location= null
2020-04-02 05:05:38,329 [Thread-3] INFO  server.JournalNode (JournalNode.java:stop(286)) - [msx-restart] JournalNode 36263 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:38,329 [Thread-3] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36263
2020-04-02 05:05:38,335 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6287622c{/,null,UNAVAILABLE}{/journal}
2020-04-02 05:05:38,337 [IPC Server listener on 36263] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36263
2020-04-02 05:05:38,338 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:38,370 [Thread-3] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@55383290{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:05:38,371 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1e39b054{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:38,372 [Thread-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@63dd18e3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:38,380 [Thread-3] INFO  common.Storage (JNStorage.java:close(280)) - Closing journal storage for Storage Directory root= /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/waitactive; location= null
2020-04-02 05:05:38,380 [Thread-3] INFO  common.Storage (JNStorage.java:close(280)) - Closing journal storage for Storage Directory root= /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal; location= null
2020-04-02 05:05:38,387 [Thread-3] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping NameNode metrics system...
2020-04-02 05:05:38,396 [Thread-3] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - NameNode metrics system stopped.
2020-04-02 05:05:38,397 [Thread-3] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - NameNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.qjournal.TestSecureNNWithQJM#testSecureMode
[msx] writeFile testName = org.apache.hadoop.hdfs.qjournal.TestSecureNNWithQJM#testSecureMode
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.qjournal.TestSecureNNWithQJM#testSecondaryNameNodeHttpAddressNotNeeded
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:05:38,409 [Thread-259] INFO  qjournal.MiniJournalCluster (MiniJournalCluster.java:<init>(100)) - Starting MiniJournalCluster with 3 journal nodes
2020-04-02 05:05:38,411 [Thread-259] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] JournalNode init, vvmode is none, do nothing
2020-04-02 05:05:38,415 [Thread-259] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:05:38,418 [Thread-259] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:05:38,419 [Thread-259] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - JournalNode metrics system started
2020-04-02 05:05:38,425 [pool-1-thread-3] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803938424,root/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:38,430 [Thread-259] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user root/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab
2020-04-02 05:05:38,431 [Thread-259] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:38,431 [Thread-259] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for journal at: https://localhost:0
2020-04-02 05:05:38,432 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:38,433 [Thread-259] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:38,434 [Thread-259] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-04-02 05:05:38,434 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:38,435 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:38,436 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-04-02 05:05:38,436 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:38,436 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:38,437 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to getJournal
2020-04-02 05:05:38,437 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44718
2020-04-02 05:05:38,438 [Thread-259] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:38,439 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@171d3a9d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:38,441 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d08717b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:38,464 [Thread-259] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:38,465 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@26c596d{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-04-02 05:05:38,470 [Thread-259] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@7b7e1de4(server,h=[],w=[]) for SslContextFactory@72915d7d(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/trustKS.jks)
2020-04-02 05:05:38,473 [Thread-259] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@51eedb35{SSL,[ssl, http/1.1]}{localhost:44718}
2020-04-02 05:05:38,473 [Thread-259] INFO  server.Server (Server.java:doStart(419)) - Started @19636ms
2020-04-02 05:05:38,504 [Thread-259] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(84)) - RPC server is binding to localhost:0
2020-04-02 05:05:38,505 [Thread-259] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 500 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:38,506 [Socket Reader #1 for port 45921] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45921
2020-04-02 05:05:38,515 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:38,515 [IPC Server listener on 45921] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45921: starting
2020-04-02 05:05:38,534 [Thread-259] INFO  server.JournalNode (JournalNode.java:start(251)) - [msx-restart] JournalNode 45921 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:38,535 [Thread-259] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] JournalNode init, vvmode is none, do nothing
2020-04-02 05:05:38,536 [Thread-259] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JournalNode metrics system started (again)
2020-04-02 05:05:38,559 [pool-1-thread-3] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803938559,root/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:38,561 [Thread-259] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user root/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab
2020-04-02 05:05:38,562 [Thread-259] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:38,562 [Thread-259] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for journal at: https://localhost:0
2020-04-02 05:05:38,563 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:38,564 [Thread-259] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:38,567 [Thread-259] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-04-02 05:05:38,567 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:38,568 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:38,569 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-04-02 05:05:38,569 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:38,569 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:38,571 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to getJournal
2020-04-02 05:05:38,571 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39988
2020-04-02 05:05:38,571 [Thread-259] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:38,582 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6ed6b7e3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:38,582 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@27ea2a2e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:38,587 [Thread-259] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:38,591 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@208016b0{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-04-02 05:05:38,592 [Thread-259] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@9843a63(server,h=[],w=[]) for SslContextFactory@74544c7c(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/trustKS.jks)
2020-04-02 05:05:38,594 [Thread-259] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6b40a74d{SSL,[ssl, http/1.1]}{localhost:39988}
2020-04-02 05:05:38,594 [Thread-259] INFO  server.Server (Server.java:doStart(419)) - Started @19757ms
2020-04-02 05:05:38,595 [Thread-259] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(84)) - RPC server is binding to localhost:0
2020-04-02 05:05:38,595 [Thread-259] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 500 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:38,596 [Socket Reader #1 for port 37640] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37640
2020-04-02 05:05:38,605 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:38,605 [IPC Server listener on 37640] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37640: starting
2020-04-02 05:05:38,612 [Thread-259] INFO  server.JournalNode (JournalNode.java:start(251)) - [msx-restart] JournalNode 37640 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:38,614 [Thread-259] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] JournalNode init, vvmode is none, do nothing
2020-04-02 05:05:38,614 [Thread-259] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JournalNode metrics system started (again)
2020-04-02 05:05:38,623 [pool-1-thread-3] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803938622,root/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:38,626 [Thread-259] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user root/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab
2020-04-02 05:05:38,636 [Thread-259] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:38,637 [Thread-259] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for journal at: https://localhost:0
2020-04-02 05:05:38,637 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:38,650 [Thread-259] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:38,651 [Thread-259] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-04-02 05:05:38,651 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:38,652 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:38,653 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-04-02 05:05:38,653 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:38,653 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:38,655 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to getJournal
2020-04-02 05:05:38,655 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41129
2020-04-02 05:05:38,655 [Thread-259] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:38,659 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2bf75669{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:38,660 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@628d11cb{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:38,665 [Thread-259] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:38,666 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6edab47c{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-04-02 05:05:38,667 [Thread-259] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@214f3791(server,h=[],w=[]) for SslContextFactory@50423c75(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/trustKS.jks)
2020-04-02 05:05:38,668 [Thread-259] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@65fd2c24{SSL,[ssl, http/1.1]}{localhost:41129}
2020-04-02 05:05:38,668 [Thread-259] INFO  server.Server (Server.java:doStart(419)) - Started @19831ms
2020-04-02 05:05:38,669 [Thread-259] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(84)) - RPC server is binding to localhost:0
2020-04-02 05:05:38,669 [Thread-259] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 500 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:38,674 [Socket Reader #1 for port 42462] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42462
2020-04-02 05:05:38,681 [IPC Server listener on 42462] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42462: starting
2020-04-02 05:05:38,681 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:38,686 [Thread-259] INFO  server.JournalNode (JournalNode.java:start(251)) - [msx-restart] JournalNode 42462 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:38,796 [pool-1-thread-3] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803938795,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:38,804 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803938803,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:38,804 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803938803,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:38,810 [Socket Reader #1 for port 45921] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:38,813 [Socket Reader #1 for port 37640] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:38,818 [Socket Reader #1 for port 42462] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:38,862 [IPC Server handler 1 on 37640] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(104)) - Initializing journal in directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/waitactive
2020-04-02 05:05:38,863 [IPC Server handler 1 on 37640] WARN  common.Storage (Storage.java:analyzeStorage(654)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/waitactive does not exist
2020-04-02 05:05:38,864 [IPC Server handler 1 on 45921] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(104)) - Initializing journal in directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/waitactive
2020-04-02 05:05:38,864 [IPC Server handler 1 on 45921] WARN  common.Storage (Storage.java:analyzeStorage(654)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/waitactive does not exist
2020-04-02 05:05:38,864 [IPC Server handler 1 on 37640] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(297)) - Could not construct Shared Edits Uri
2020-04-02 05:05:38,864 [IPC Server handler 1 on 37640] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(144)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-04-02 05:05:38,869 [IPC Server handler 0 on 42462] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(104)) - Initializing journal in directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/waitactive
2020-04-02 05:05:38,869 [IPC Server handler 0 on 42462] WARN  common.Storage (Storage.java:analyzeStorage(654)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/waitactive does not exist
2020-04-02 05:05:38,871 [IPC Server handler 0 on 42462] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(297)) - Could not construct Shared Edits Uri
2020-04-02 05:05:38,871 [IPC Server handler 0 on 42462] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(144)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-04-02 05:05:38,874 [IPC Server handler 1 on 45921] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(297)) - Could not construct Shared Edits Uri
2020-04-02 05:05:38,875 [IPC Server handler 1 on 45921] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(144)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-04-02 05:05:38,925 [Thread-259] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:05:38,943 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803938942,root/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:38,946 [Thread-259] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user root/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab
Formatting using clusterid: testClusterID
2020-04-02 05:05:38,947 [Thread-259] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:38,948 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:38,948 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:38,948 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:38,948 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:38,948 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:38,948 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:38,949 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:38,949 [Thread-259] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:38,949 [Thread-259] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:38,949 [Thread-259] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:38,950 [Thread-259] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:38,950 [Thread-259] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:38
2020-04-02 05:05:38,950 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:38,950 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:38,951 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:05:38,951 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:38,960 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:38,960 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:38,961 [Thread-259] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:38,961 [Thread-259] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:38,961 [Thread-259] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:38,961 [Thread-259] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:38,961 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:05:38,961 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:38,961 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:38,962 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:38,962 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:38,962 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:38,962 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:38,962 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:38,962 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:38,962 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:05:38,963 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:38,965 [Thread-259] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:38,965 [Thread-259] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:38,965 [Thread-259] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:38,965 [Thread-259] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:38,965 [Thread-259] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:38,965 [Thread-259] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:38,965 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:38,965 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:38,966 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:05:38,966 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:38,966 [Thread-259] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:38,968 [Thread-259] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:38,968 [Thread-259] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:38,968 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:38,969 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:38,969 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:38,969 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:38,969 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:05:38,969 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:38,996 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803938996,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:38,996 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803938996,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:39,000 [pool-1-thread-3] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803939000,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:39,007 [Socket Reader #1 for port 45921] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:39,014 [Socket Reader #1 for port 37640] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:39,048 [IPC Server handler 4 on 37640] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(104)) - Initializing journal in directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal
2020-04-02 05:05:39,048 [IPC Server handler 3 on 45921] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(104)) - Initializing journal in directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal
2020-04-02 05:05:39,049 [IPC Server handler 3 on 45921] WARN  common.Storage (Storage.java:analyzeStorage(654)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal does not exist
2020-04-02 05:05:39,050 [IPC Server handler 4 on 37640] WARN  common.Storage (Storage.java:analyzeStorage(654)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal does not exist
2020-04-02 05:05:39,073 [IPC Server handler 3 on 45921] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(297)) - Could not construct Shared Edits Uri
2020-04-02 05:05:39,074 [IPC Server handler 3 on 45921] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(144)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-04-02 05:05:39,076 [Socket Reader #1 for port 42462] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:39,082 [IPC Server handler 4 on 37640] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(297)) - Could not construct Shared Edits Uri
2020-04-02 05:05:39,083 [IPC Server handler 4 on 37640] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(144)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-04-02 05:05:39,088 [IPC Server handler 3 on 42462] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(104)) - Initializing journal in directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal
2020-04-02 05:05:39,089 [IPC Server handler 3 on 42462] WARN  common.Storage (Storage.java:analyzeStorage(654)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal does not exist
2020-04-02 05:05:39,090 [IPC Server handler 3 on 42462] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(297)) - Could not construct Shared Edits Uri
2020-04-02 05:05:39,090 [IPC Server handler 3 on 42462] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(144)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-04-02 05:05:39,097 [Thread-259] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-51517513-172.17.0.11-1585803939097
2020-04-02 05:05:39,099 [Thread-259] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:05:39,102 [Thread-259] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:05:39,103 [IPC Server handler 3 on 37640] INFO  server.Journal (Journal.java:format(234)) - Formatting journal id : myjournal with namespace info: lv=-64;cid=testClusterID;nsid=1090066364;c=1585803939097;bpid=BP-51517513-172.17.0.11-1585803939097
2020-04-02 05:05:39,104 [IPC Server handler 3 on 37640] INFO  common.Storage (Storage.java:analyzeStorage(657)) - /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal does not exist. Creating ...
2020-04-02 05:05:39,105 [IPC Server handler 3 on 37640] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:39,105 [IPC Server handler 3 on 37640] INFO  common.Storage (JNStorage.java:format(216)) - Formatting journal Storage Directory root= /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal; location= null with nsid: 1090066364
2020-04-02 05:05:39,106 [IPC Server handler 4 on 45921] INFO  server.Journal (Journal.java:format(234)) - Formatting journal id : myjournal with namespace info: lv=-64;cid=testClusterID;nsid=1090066364;c=1585803939097;bpid=BP-51517513-172.17.0.11-1585803939097
2020-04-02 05:05:39,106 [IPC Server handler 4 on 45921] INFO  common.Storage (Storage.java:analyzeStorage(657)) - /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal does not exist. Creating ...
2020-04-02 05:05:39,106 [IPC Server handler 4 on 42462] INFO  server.Journal (Journal.java:format(234)) - Formatting journal id : myjournal with namespace info: lv=-64;cid=testClusterID;nsid=1090066364;c=1585803939097;bpid=BP-51517513-172.17.0.11-1585803939097
2020-04-02 05:05:39,106 [IPC Server handler 4 on 42462] INFO  common.Storage (Storage.java:analyzeStorage(657)) - /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal does not exist. Creating ...
2020-04-02 05:05:39,107 [IPC Server handler 3 on 37640] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:39,108 [IPC Server handler 4 on 42462] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:39,108 [IPC Server handler 4 on 42462] INFO  common.Storage (JNStorage.java:format(216)) - Formatting journal Storage Directory root= /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal; location= null with nsid: 1090066364
2020-04-02 05:05:39,120 [IPC Server handler 4 on 45921] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:39,120 [IPC Server handler 4 on 45921] INFO  common.Storage (JNStorage.java:format(216)) - Formatting journal Storage Directory root= /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal; location= null with nsid: 1090066364
2020-04-02 05:05:39,123 [IPC Server handler 4 on 42462] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:39,134 [IPC Server handler 4 on 45921] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:39,143 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:39,143 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:39,150 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:05:39,151 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:05:39,155 [Thread-259] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:05:39,163 [Thread-259] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:39,168 [Thread-259] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:05:39,168 [Thread-259] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:39,169 [Thread-259] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:05:39,179 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803939179,root/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:39,191 [Thread-259] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user root/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab
2020-04-02 05:05:39,200 [Thread-259] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:39,201 [Thread-259] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:0
2020-04-02 05:05:39,201 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:39,203 [Thread-259] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:39,203 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@47ce0f22] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:39,210 [Thread-259] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:39,211 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:39,212 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:39,212 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:39,213 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:39,213 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:39,215 [Thread-259] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:39,215 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:39,215 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:05:39,215 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:05:39,216 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40876
2020-04-02 05:05:39,216 [Thread-259] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:39,221 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3337b0ee{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:39,222 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d59a2e9{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:39,230 [Thread-259] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:39,231 [Thread-259] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:39,231 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2c79b8ac{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:39,233 [Thread-259] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@407273f9(server,h=[],w=[]) for SslContextFactory@784a3b1c(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/trustKS.jks)
2020-04-02 05:05:39,234 [Thread-259] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2fe6546e{SSL,[ssl, http/1.1]}{localhost:40876}
2020-04-02 05:05:39,234 [Thread-259] INFO  server.Server (Server.java:doStart(419)) - Started @20397ms
2020-04-02 05:05:39,234 [Thread-259] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(685)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-04-02 05:05:39,235 [Thread-259] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:39,236 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:39,236 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:39,236 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:39,236 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:39,236 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:39,236 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:39,237 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:39,237 [Thread-259] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:39,237 [Thread-259] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:39,237 [Thread-259] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:39,238 [Thread-259] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:39,238 [Thread-259] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:39
2020-04-02 05:05:39,238 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:39,238 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:39,238 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:05:39,238 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:39,263 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:39,264 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:39,264 [Thread-259] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:39,265 [Thread-259] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:39,265 [Thread-259] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:39,265 [Thread-259] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:39,268 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:05:39,268 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:39,268 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:39,268 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:39,268 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:39,268 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:39,268 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:39,269 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:39,269 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:39,269 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:05:39,269 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:39,274 [Thread-259] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:39,274 [Thread-259] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:39,274 [Thread-259] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:39,274 [Thread-259] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:39,274 [Thread-259] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:39,275 [Thread-259] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:39,275 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:39,275 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:39,275 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:05:39,275 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:39,276 [Thread-259] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:39,277 [Thread-259] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:39,277 [Thread-259] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:39,277 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:39,277 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:39,277 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:39,278 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:39,278 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:05:39,278 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:39,281 [Thread-259] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:39,282 [Thread-259] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:39,286 [Thread-259] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(442)) - Starting recovery process for unclosed journal segments...
2020-04-02 05:05:39,343 [pool-1-thread-3] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803939343,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:39,344 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803939343,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:39,351 [Socket Reader #1 for port 42462] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:39,351 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803939351,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:39,358 [Socket Reader #1 for port 45921] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:39,377 [Socket Reader #1 for port 37640] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:39,378 [IPC Server handler 0 on 45921] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(346)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:39,380 [IPC Server handler 2 on 42462] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(346)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:39,380 [IPC Server handler 0 on 45921] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(205)) - Scanning storage FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal)
2020-04-02 05:05:39,380 [IPC Server handler 0 on 45921] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(223)) - No files in FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal)
2020-04-02 05:05:39,381 [IPC Server handler 2 on 42462] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(205)) - Scanning storage FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal)
2020-04-02 05:05:39,381 [IPC Server handler 2 on 42462] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(223)) - No files in FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal)
2020-04-02 05:05:39,382 [Thread-259] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(444)) - Successfully started new epoch 1
2020-04-02 05:05:39,410 [Thread-259] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:05:39,411 [Thread-259] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:39,414 [Thread-259] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:39,415 [Thread-259] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:39,415 [Thread-259] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:39,416 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:39,425 [IPC Server handler 2 on 37640] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(346)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:39,430 [IPC Server handler 2 on 37640] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(205)) - Scanning storage FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal)
2020-04-02 05:05:39,430 [IPC Server handler 2 on 37640] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(223)) - No files in FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal)
2020-04-02 05:05:39,438 [Thread-259] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:05:39,439 [IPC Server handler 4 on 42462] INFO  server.Journal (Journal.java:startLogSegment(582)) - Updating lastWriterEpoch from 0 to 1 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:39,444 [IPC Server handler 1 on 37640] INFO  server.Journal (Journal.java:startLogSegment(582)) - Updating lastWriterEpoch from 0 to 1 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:39,474 [IPC Server handler 1 on 45921] INFO  server.Journal (Journal.java:startLogSegment(582)) - Updating lastWriterEpoch from 0 to 1 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:39,528 [Thread-259] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:39,528 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 248 msecs
2020-04-02 05:05:39,529 [Thread-259] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:05:39,529 [Thread-259] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:39,534 [Thread-259] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:46553 to access this namenode/service.
2020-04-02 05:05:39,535 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:39,535 [Thread-259] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:39,536 [Socket Reader #1 for port 46553] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46553
2020-04-02 05:05:39,562 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:39,563 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@343e2004] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:05:39,563 [Thread-259] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:05:39,564 [Thread-259] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:05:39,565 [Thread-259] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:39,566 [Thread-259] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:39,623 [Thread[Thread-348,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:05:39,632 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:39,632 [Thread[Thread-348,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:39,633 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:39,633 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:39,633 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:39,633 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:39,633 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 67 msec
2020-04-02 05:05:39,641 [IPC Server listener on 46553] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46553: starting
2020-04-02 05:05:39,641 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:39,660 [Thread-259] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:46553
2020-04-02 05:05:39,689 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:39,690 [Thread-259] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:39,691 [Thread-259] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:39,693 [Thread-259] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 46553 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:39,702 [Thread-259] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:39,695 [CacheReplicationMonitor(1445929723)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:39,708 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803939707,root/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:39,716 [Thread-259] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user root/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab
2020-04-02 05:05:39,728 [Thread-259] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:39,734 [Thread-259] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:39,760 [Thread-259] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:39,760 [Thread-259] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:39,760 [Thread-259] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:39,760 [Thread-259] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:39,762 [Thread-259] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:39,762 [Thread-259] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:39,763 [Thread-259] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:39,764 [Thread-259] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42965
2020-04-02 05:05:39,764 [Thread-259] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:39,764 [Thread-259] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:39,765 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:39,766 [Thread-259] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:39,768 [Thread-259] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:39,769 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:39,770 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:39,770 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:39,771 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:39,771 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:39,773 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34023
2020-04-02 05:05:39,773 [Thread-259] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:39,789 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@45ed7005{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:39,790 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@35f4d709{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:39,802 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@42329a28{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:39,803 [Thread-259] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7b0f339b{HTTP/1.1,[http/1.1]}{localhost:34023}
2020-04-02 05:05:39,803 [Thread-259] INFO  server.Server (Server.java:doStart(419)) - Started @20966ms
2020-04-02 05:05:39,957 [Thread-259] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:43625
2020-04-02 05:05:39,962 [Thread-259] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root/localhost@EXAMPLE.COM
2020-04-02 05:05:39,962 [Thread-259] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:39,962 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2b2b698f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:39,962 [Thread-259] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:39,963 [Socket Reader #1 for port 35916] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35916
2020-04-02 05:05:39,968 [Thread-259] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:35916
2020-04-02 05:05:39,972 [Thread-259] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:39,973 [Thread-259] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:39,994 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:39,998 [IPC Server listener on 35916] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35916: starting
2020-04-02 05:05:40,003 [Thread-259] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 35916 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:40,007 [Thread-377] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46553 starting to offer service
2020-04-02 05:05:40,061 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803940061,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:40,084 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803940084,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:40,141 [Socket Reader #1 for port 46553] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:40,161 [Socket Reader #1 for port 46553] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:40,282 [IPC Server handler 0 on 46553] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:40,282 [Thread-377] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46553
2020-04-02 05:05:40,283 [Thread-377] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:40,285 [Thread-377] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:40,286 [Thread-377] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1090066364. Formatting...
2020-04-02 05:05:40,286 [Thread-259] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:40,286 [Thread-259] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:40,286 [Thread-377] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-36fd048c-d797-46f6-86f0-c7d903c90294 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:05:40,290 [Thread-377] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:40,290 [Thread-377] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1090066364. Formatting...
2020-04-02 05:05:40,291 [Thread-377] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-95951cee-9278-441c-8509-16ddf718694c for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:05:40,303 [Thread-377] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-51517513-172.17.0.11-1585803939097
2020-04-02 05:05:40,303 [Thread-377] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-51517513-172.17.0.11-1585803939097
2020-04-02 05:05:40,303 [Thread-377] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-51517513-172.17.0.11-1585803939097 is not formatted. Formatting ...
2020-04-02 05:05:40,303 [Thread-377] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-51517513-172.17.0.11-1585803939097 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-51517513-172.17.0.11-1585803939097/current
2020-04-02 05:05:40,312 [Thread-377] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-51517513-172.17.0.11-1585803939097
2020-04-02 05:05:40,313 [Thread-377] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-51517513-172.17.0.11-1585803939097
2020-04-02 05:05:40,313 [Thread-377] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-51517513-172.17.0.11-1585803939097 is not formatted. Formatting ...
2020-04-02 05:05:40,313 [Thread-377] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-51517513-172.17.0.11-1585803939097 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-51517513-172.17.0.11-1585803939097/current
2020-04-02 05:05:40,315 [Thread-377] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1090066364;bpid=BP-51517513-172.17.0.11-1585803939097;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1090066364;c=1585803939097;bpid=BP-51517513-172.17.0.11-1585803939097;dnuuid=null
2020-04-02 05:05:40,317 [Thread-377] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 72900ae7-24a8-4a6d-bc4a-69046a9f3d2f
2020-04-02 05:05:40,319 [Thread-377] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-36fd048c-d797-46f6-86f0-c7d903c90294
2020-04-02 05:05:40,321 [Thread-377] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:05:40,322 [Thread-377] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-95951cee-9278-441c-8509-16ddf718694c
2020-04-02 05:05:40,323 [Thread-377] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:05:40,323 [Thread-377] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:40,327 [Thread-377] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:40,328 [Thread-377] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:40,328 [Thread-377] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:40,328 [Thread-377] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:40,328 [Thread-377] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-51517513-172.17.0.11-1585803939097
2020-04-02 05:05:40,328 [Thread-392] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-51517513-172.17.0.11-1585803939097 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:40,328 [Thread-393] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-51517513-172.17.0.11-1585803939097 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:40,383 [Thread-393] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-51517513-172.17.0.11-1585803939097 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 54ms
2020-04-02 05:05:40,398 [IPC Server handler 1 on 46553] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:40,402 [Thread-259] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:40,402 [Thread-259] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:40,404 [Thread-392] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-51517513-172.17.0.11-1585803939097 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 76ms
2020-04-02 05:05:40,404 [Thread-377] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-51517513-172.17.0.11-1585803939097: 76ms
2020-04-02 05:05:40,407 [Thread-397] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-51517513-172.17.0.11-1585803939097 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:40,408 [Thread-397] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-51517513-172.17.0.11-1585803939097/current/replicas doesn't exist 
2020-04-02 05:05:40,409 [Thread-397] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-51517513-172.17.0.11-1585803939097 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:05:40,414 [Thread-396] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-51517513-172.17.0.11-1585803939097 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:40,415 [Thread-396] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-51517513-172.17.0.11-1585803939097/current/replicas doesn't exist 
2020-04-02 05:05:40,415 [Thread-396] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-51517513-172.17.0.11-1585803939097 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 0ms
2020-04-02 05:05:40,417 [Thread-377] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-51517513-172.17.0.11-1585803939097: 14ms
2020-04-02 05:05:40,419 [Thread-377] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:17 AM with interval of 21600000ms
2020-04-02 05:05:40,419 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-51517513-172.17.0.11-1585803939097 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:40,420 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-36fd048c-d797-46f6-86f0-c7d903c90294): finished scanning block pool BP-51517513-172.17.0.11-1585803939097
2020-04-02 05:05:40,420 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-36fd048c-d797-46f6-86f0-c7d903c90294): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:05:40,421 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-51517513-172.17.0.11-1585803939097 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:40,422 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-95951cee-9278-441c-8509-16ddf718694c): finished scanning block pool BP-51517513-172.17.0.11-1585803939097
2020-04-02 05:05:40,422 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-95951cee-9278-441c-8509-16ddf718694c): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:05:40,428 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-51517513-172.17.0.11-1585803939097 (Datanode Uuid 72900ae7-24a8-4a6d-bc4a-69046a9f3d2f) service to localhost/127.0.0.1:46553 beginning handshake with NN
2020-04-02 05:05:40,434 [IPC Server handler 3 on 46553] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42965, datanodeUuid=72900ae7-24a8-4a6d-bc4a-69046a9f3d2f, infoPort=0, infoSecurePort=43625, ipcPort=35916, storageInfo=lv=-57;cid=testClusterID;nsid=1090066364;c=1585803939097) storage 72900ae7-24a8-4a6d-bc4a-69046a9f3d2f
2020-04-02 05:05:40,434 [IPC Server handler 3 on 46553] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42965
2020-04-02 05:05:40,435 [IPC Server handler 3 on 46553] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 72900ae7-24a8-4a6d-bc4a-69046a9f3d2f (127.0.0.1:42965).
2020-04-02 05:05:40,442 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-51517513-172.17.0.11-1585803939097 (Datanode Uuid 72900ae7-24a8-4a6d-bc4a-69046a9f3d2f) service to localhost/127.0.0.1:46553 successfully registered with NN
2020-04-02 05:05:40,442 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-51517513-172.17.0.11-1585803939097 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:40,443 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:40,443 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46553 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:40,448 [IPC Server handler 5 on 46553] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-36fd048c-d797-46f6-86f0-c7d903c90294 for DN 127.0.0.1:42965
2020-04-02 05:05:40,448 [IPC Server handler 5 on 46553] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-95951cee-9278-441c-8509-16ddf718694c for DN 127.0.0.1:42965
2020-04-02 05:05:40,456 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x61d9a531e9e5d43f: Processing first storage report for DS-95951cee-9278-441c-8509-16ddf718694c from datanode 72900ae7-24a8-4a6d-bc4a-69046a9f3d2f
2020-04-02 05:05:40,458 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x61d9a531e9e5d43f: from storage DS-95951cee-9278-441c-8509-16ddf718694c node DatanodeRegistration(127.0.0.1:42965, datanodeUuid=72900ae7-24a8-4a6d-bc4a-69046a9f3d2f, infoPort=0, infoSecurePort=43625, ipcPort=35916, storageInfo=lv=-57;cid=testClusterID;nsid=1090066364;c=1585803939097), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:40,462 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x61d9a531e9e5d43f: Processing first storage report for DS-36fd048c-d797-46f6-86f0-c7d903c90294 from datanode 72900ae7-24a8-4a6d-bc4a-69046a9f3d2f
2020-04-02 05:05:40,462 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x61d9a531e9e5d43f: from storage DS-36fd048c-d797-46f6-86f0-c7d903c90294 node DatanodeRegistration(127.0.0.1:42965, datanodeUuid=72900ae7-24a8-4a6d-bc4a-69046a9f3d2f, infoPort=0, infoSecurePort=43625, ipcPort=35916, storageInfo=lv=-57;cid=testClusterID;nsid=1090066364;c=1585803939097), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:40,478 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x61d9a531e9e5d43f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 22 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:40,479 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-51517513-172.17.0.11-1585803939097
2020-04-02 05:05:40,506 [IPC Server handler 7 on 46553] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:40,510 [Thread-259] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:40,514 [IPC Server handler 6 on 46553] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:40,515 [Thread-259] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:40,526 [IPC Server handler 9 on 46553] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=mkdirs	src=/test-dir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:05:40,542 [Thread-259] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:05:40,542 [Thread-259] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 46553 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:40,543 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:40,543 [Thread[Thread-348,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:05:40,561 [Thread-259] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 4
2020-04-02 05:05:40,562 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@17104705] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:05:40,562 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@2ecee646] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:05:40,577 [Thread-259] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 5 Total time for transactions(ms): 25 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 134 
2020-04-02 05:05:40,579 [IPC Server handler 4 on 42462] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_0000000000000000001-0000000000000000005
2020-04-02 05:05:40,592 [IPC Server handler 4 on 45921] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_0000000000000000001-0000000000000000005
2020-04-02 05:05:40,592 [IPC Server handler 4 on 37640] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_0000000000000000001-0000000000000000005
2020-04-02 05:05:40,595 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:05:40,597 [CacheReplicationMonitor(1445929723)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:05:40,598 [Thread-259] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46553
2020-04-02 05:05:40,610 [IPC Server listener on 46553] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46553
2020-04-02 05:05:40,612 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:05:40,613 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:05:40,613 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:40,641 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:40,641 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:05:40,643 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2c79b8ac{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:05:40,652 [Thread-259] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2fe6546e{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:05:40,653 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6d59a2e9{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:40,654 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3337b0ee{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:40,670 [Thread-259] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:40,671 [Thread-259] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:05:40,671 [Thread-259] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:40,671 [Thread-259] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://localhost:46553
2020-04-02 05:05:40,672 [Thread-259] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use localhost:46553 to access this namenode/service.
2020-04-02 05:05:40,681 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803940681,root/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:40,688 [Thread-259] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user root/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab
2020-04-02 05:05:40,693 [Thread-259] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:40,693 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@71015107] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:40,693 [Thread-259] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:40876
2020-04-02 05:05:40,694 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:40,695 [Thread-259] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:40,696 [Thread-259] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:40,696 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:40,697 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:40,698 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:40,698 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:40,698 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:40,700 [Thread-259] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:40,700 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:40,701 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:05:40,701 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:05:40,701 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40876
2020-04-02 05:05:40,701 [Thread-259] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:40,705 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5fb9b18a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:40,705 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3b5f4ef2{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:40,708 [Thread-259] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:40,724 [Thread-259] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:40,725 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@9afe0d9{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:40,731 [Thread-259] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@60bced2b(server,h=[],w=[]) for SslContextFactory@6fa69fc0(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/trustKS.jks)
2020-04-02 05:05:40,739 [Thread-259] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@76f3eb68{SSL,[ssl, http/1.1]}{localhost:40876}
2020-04-02 05:05:40,739 [Thread-259] INFO  server.Server (Server.java:doStart(419)) - Started @21902ms
2020-04-02 05:05:40,740 [Thread-259] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(685)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-04-02 05:05:40,741 [Thread-259] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:40,741 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:40,741 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:40,741 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:40,756 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:40,757 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:40,757 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:40,757 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:40,757 [Thread-259] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:40,758 [Thread-259] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:40,758 [Thread-259] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:40,758 [Thread-259] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:40,758 [Thread-259] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:40
2020-04-02 05:05:40,758 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:40,758 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:40,759 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:05:40,759 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:40,799 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:40,812 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:40,813 [Thread-259] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:40,842 [Thread-259] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:40,843 [Thread-259] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:40,843 [Thread-259] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:40,843 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:05:40,843 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:40,843 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:40,843 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:40,843 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:40,843 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:40,843 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:40,844 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:40,846 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:40,846 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:05:40,846 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:40,849 [Thread-259] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:40,850 [Thread-259] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:40,850 [Thread-259] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:40,851 [Thread-259] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:40,851 [Thread-259] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:40,851 [Thread-259] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:40,851 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:40,851 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:40,852 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:05:40,852 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:40,854 [Thread-259] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:40,854 [Thread-259] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:40,854 [Thread-259] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:40,854 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:40,855 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:40,855 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:40,855 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:40,857 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:05:40,857 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:40,860 [Thread-259] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:40,861 [Thread-259] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:40,870 [Thread-259] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(442)) - Starting recovery process for unclosed journal segments...
2020-04-02 05:05:40,894 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803940893,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:40,929 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803940929,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:40,930 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803940930,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:40,937 [Socket Reader #1 for port 42462] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:40,939 [Socket Reader #1 for port 45921] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:40,996 [IPC Server handler 2 on 45921] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(346)) - Updating lastPromisedEpoch from 1 to 2 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:40,997 [IPC Server handler 2 on 45921] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(205)) - Scanning storage FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal)
2020-04-02 05:05:40,998 [IPC Server handler 2 on 45921] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(211)) - Latest log is EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_0000000000000000001-0000000000000000005,first=0000000000000000001,last=0000000000000000005,inProgress=false,hasCorruptHeader=false) ; journal id: myjournal
2020-04-02 05:05:40,998 [IPC Server handler 1 on 42462] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(346)) - Updating lastPromisedEpoch from 1 to 2 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:41,002 [IPC Server handler 1 on 42462] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(205)) - Scanning storage FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal)
2020-04-02 05:05:41,002 [IPC Server handler 1 on 42462] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(211)) - Latest log is EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_0000000000000000001-0000000000000000005,first=0000000000000000001,last=0000000000000000005,inProgress=false,hasCorruptHeader=false) ; journal id: myjournal
2020-04-02 05:05:41,006 [Thread-259] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(444)) - Successfully started new epoch 2
2020-04-02 05:05:41,006 [Thread-259] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(284)) - Beginning recovery of unclosed segment starting at txid 1
2020-04-02 05:05:41,007 [IPC Server handler 0 on 45921] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_0000000000000000001-0000000000000000005,first=0000000000000000001,last=0000000000000000005,inProgress=false,hasCorruptHeader=false) -> startTxId: 1 endTxId: 5 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:41,008 [IPC Server handler 0 on 45921] INFO  server.Journal (Journal.java:prepareRecovery(784)) - Prepared recovery for segment 1: segmentState { startTxId: 1 endTxId: 5 isInProgress: false } lastWriterEpoch: 1 lastCommittedTxId: 5 ; journal id: myjournal
2020-04-02 05:05:41,010 [IPC Server handler 2 on 42462] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_0000000000000000001-0000000000000000005,first=0000000000000000001,last=0000000000000000005,inProgress=false,hasCorruptHeader=false) -> startTxId: 1 endTxId: 5 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:41,011 [IPC Server handler 2 on 42462] INFO  server.Journal (Journal.java:prepareRecovery(784)) - Prepared recovery for segment 1: segmentState { startTxId: 1 endTxId: 5 isInProgress: false } lastWriterEpoch: 1 lastCommittedTxId: 5 ; journal id: myjournal
2020-04-02 05:05:41,011 [Socket Reader #1 for port 37640] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:41,032 [Thread-259] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(293)) - Recovery prepare phase complete. Responses:
127.0.0.1:42462: segmentState { startTxId: 1 endTxId: 5 isInProgress: false } lastWriterEpoch: 1 lastCommittedTxId: 5
127.0.0.1:45921: segmentState { startTxId: 1 endTxId: 5 isInProgress: false } lastWriterEpoch: 1 lastCommittedTxId: 5
2020-04-02 05:05:41,032 [Thread-259] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(317)) - Using longest log: 127.0.0.1:42462=segmentState {
  startTxId: 1
  endTxId: 5
  isInProgress: false
}
lastWriterEpoch: 1
lastCommittedTxId: 5

2020-04-02 05:05:41,040 [IPC Server handler 3 on 42462] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_0000000000000000001-0000000000000000005,first=0000000000000000001,last=0000000000000000005,inProgress=false,hasCorruptHeader=false) -> startTxId: 1 endTxId: 5 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:41,041 [IPC Server handler 3 on 42462] INFO  server.Journal (Journal.java:acceptRecovery(872)) - Skipping download of log startTxId: 1 endTxId: 5 isInProgress: false: already have up-to-date logs ; journal id: myjournal
2020-04-02 05:05:41,043 [IPC Server handler 3 on 42462] INFO  server.Journal (Journal.java:acceptRecovery(905)) - Accepted recovery for segment 1: segmentState { startTxId: 1 endTxId: 5 isInProgress: false } acceptedInEpoch: 2 ; journal id: myjournal
2020-04-02 05:05:41,046 [IPC Server handler 3 on 45921] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_0000000000000000001-0000000000000000005,first=0000000000000000001,last=0000000000000000005,inProgress=false,hasCorruptHeader=false) -> startTxId: 1 endTxId: 5 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:41,046 [IPC Server handler 3 on 45921] INFO  server.Journal (Journal.java:acceptRecovery(872)) - Skipping download of log startTxId: 1 endTxId: 5 isInProgress: false: already have up-to-date logs ; journal id: myjournal
2020-04-02 05:05:41,055 [IPC Server handler 0 on 37640] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(346)) - Updating lastPromisedEpoch from 1 to 2 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:41,056 [IPC Server handler 0 on 37640] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(205)) - Scanning storage FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal)
2020-04-02 05:05:41,057 [IPC Server handler 0 on 37640] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(211)) - Latest log is EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_0000000000000000001-0000000000000000005,first=0000000000000000001,last=0000000000000000005,inProgress=false,hasCorruptHeader=false) ; journal id: myjournal
2020-04-02 05:05:41,058 [IPC Server handler 3 on 45921] INFO  server.Journal (Journal.java:acceptRecovery(905)) - Accepted recovery for segment 1: segmentState { startTxId: 1 endTxId: 5 isInProgress: false } acceptedInEpoch: 2 ; journal id: myjournal
2020-04-02 05:05:41,066 [IPC Server handler 2 on 37640] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_0000000000000000001-0000000000000000005,first=0000000000000000001,last=0000000000000000005,inProgress=false,hasCorruptHeader=false) -> startTxId: 1 endTxId: 5 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:41,066 [IPC Server handler 2 on 37640] INFO  server.Journal (Journal.java:prepareRecovery(784)) - Prepared recovery for segment 1: segmentState { startTxId: 1 endTxId: 5 isInProgress: false } lastWriterEpoch: 1 lastCommittedTxId: 5 ; journal id: myjournal
2020-04-02 05:05:41,069 [IPC Server handler 4 on 37640] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_0000000000000000001-0000000000000000005,first=0000000000000000001,last=0000000000000000005,inProgress=false,hasCorruptHeader=false) -> startTxId: 1 endTxId: 5 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:41,069 [IPC Server handler 4 on 37640] INFO  server.Journal (Journal.java:acceptRecovery(872)) - Skipping download of log startTxId: 1 endTxId: 5 isInProgress: false: already have up-to-date logs ; journal id: myjournal
2020-04-02 05:05:41,070 [Thread-259] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:41,072 [Thread-259] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:41,073 [IPC Server handler 4 on 37640] INFO  server.Journal (Journal.java:acceptRecovery(905)) - Accepted recovery for segment 1: segmentState { startTxId: 1 endTxId: 5 isInProgress: false } acceptedInEpoch: 2 ; journal id: myjournal
2020-04-02 05:05:41,073 [Thread-259] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:41,073 [Thread-259] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:41,074 [Thread-259] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@660686c7 expecting start txid #1
2020-04-02 05:05:41,074 [Thread-259] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file https://localhost:39988/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1090066364%3A1585803939097%3AtestClusterID&inProgressOk=true, https://localhost:44718/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1090066364%3A1585803939097%3AtestClusterID&inProgressOk=true maxTxnsToRead = 9223372036854775807
2020-04-02 05:05:41,074 [Thread-259] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream 'https://localhost:39988/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1090066364%3A1585803939097%3AtestClusterID&inProgressOk=true, https://localhost:44718/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1090066364%3A1585803939097%3AtestClusterID&inProgressOk=true' to transaction ID 1
2020-04-02 05:05:41,074 [Thread-259] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream 'https://localhost:39988/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1090066364%3A1585803939097%3AtestClusterID&inProgressOk=true' to transaction ID 1
2020-04-02 05:05:41,187 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803941187,root/localhost for HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:41,264 [qtp79238716-978] WARN  server.GetJournalEditServlet (GetJournalEditServlet.java:isValidRequestor(110)) - SecondaryNameNode principal not considered, dfs.secondary.namenode.kerberos.principal = null, dfs.namenode.secondary.http-address = null
2020-04-02 05:05:41,265 [qtp79238716-978] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(396)) - Sending fileName: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_0000000000000000001-0000000000000000005, fileSize: 185. Sent total: 185 bytes. Size of last segment intended to send: -1 bytes.
2020-04-02 05:05:41,268 [Thread-259] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file https://localhost:39988/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1090066364%3A1585803939097%3AtestClusterID&inProgressOk=true, https://localhost:44718/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1090066364%3A1585803939097%3AtestClusterID&inProgressOk=true of size 185 edits # 5 loaded in 0 seconds
2020-04-02 05:05:41,268 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:41,277 [Thread-259] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 6
2020-04-02 05:05:41,278 [IPC Server handler 0 on 45921] INFO  server.Journal (Journal.java:startLogSegment(582)) - Updating lastWriterEpoch from 1 to 2 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:41,282 [IPC Server handler 2 on 42462] INFO  server.Journal (Journal.java:startLogSegment(582)) - Updating lastWriterEpoch from 1 to 2 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:41,282 [IPC Server handler 2 on 37640] INFO  server.Journal (Journal.java:startLogSegment(582)) - Updating lastWriterEpoch from 1 to 2 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:41,299 [Thread-259] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:41,300 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 442 msecs
2020-04-02 05:05:41,300 [Thread-259] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:46553
2020-04-02 05:05:41,301 [Thread-259] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:41,303 [Socket Reader #1 for port 46553] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46553
2020-04-02 05:05:41,308 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:41,309 [Thread-259] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:41,333 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:41,337 [Thread-259] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:05:41,338 [Thread-259] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:05:41,338 [Thread-259] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:41,347 [Thread-259] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:41,385 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:41,385 [IPC Server listener on 46553] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46553: starting
2020-04-02 05:05:41,389 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:41,390 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:41,390 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:41,390 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:41,390 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:41,390 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 37 msec
2020-04-02 05:05:41,405 [Thread-259] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:46553
2020-04-02 05:05:41,410 [Thread[Thread-429,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:05:41,412 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:41,413 [Thread-259] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:41,415 [Thread-259] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 2 milliseconds
name space=2
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:41,416 [Thread-259] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 46553 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:41,440 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@5cfdc36c] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:05:41,453 [Thread[Thread-429,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:41,454 [Thread-259] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1409)) - Waiting for the Mini HDFS Cluster to start...
2020-04-02 05:05:41,454 [CacheReplicationMonitor(1742880326)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:42,454 [Thread-259] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1409)) - Waiting for the Mini HDFS Cluster to start...
2020-04-02 05:05:43,444 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] WARN  datanode.DataNode (BPServiceActor.java:offerService(728)) - IOException in offerService
java.io.EOFException: End of File Exception between local host is: "f8287aaf0779/172.17.0.11"; destination host is: "localhost":46553; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:789)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy27.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:514)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:645)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:842)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2020-04-02 05:05:43,455 [Thread-259] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1409)) - Waiting for the Mini HDFS Cluster to start...
2020-04-02 05:05:44,455 [Thread-259] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1409)) - Waiting for the Mini HDFS Cluster to start...
2020-04-02 05:05:45,455 [Thread-259] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1409)) - Waiting for the Mini HDFS Cluster to start...
2020-04-02 05:05:46,451 [Socket Reader #1 for port 46553] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:46,456 [Thread-259] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1409)) - Waiting for the Mini HDFS Cluster to start...
2020-04-02 05:05:46,462 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:46553 with active state
2020-04-02 05:05:46,468 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-51517513-172.17.0.11-1585803939097 (Datanode Uuid 72900ae7-24a8-4a6d-bc4a-69046a9f3d2f) service to localhost/127.0.0.1:46553 beginning handshake with NN
2020-04-02 05:05:46,470 [IPC Server handler 5 on 46553] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42965, datanodeUuid=72900ae7-24a8-4a6d-bc4a-69046a9f3d2f, infoPort=0, infoSecurePort=43625, ipcPort=35916, storageInfo=lv=-57;cid=testClusterID;nsid=1090066364;c=1585803939097) storage 72900ae7-24a8-4a6d-bc4a-69046a9f3d2f
2020-04-02 05:05:46,470 [IPC Server handler 5 on 46553] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42965
2020-04-02 05:05:46,471 [IPC Server handler 5 on 46553] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 72900ae7-24a8-4a6d-bc4a-69046a9f3d2f (127.0.0.1:42965).
2020-04-02 05:05:46,478 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-51517513-172.17.0.11-1585803939097 (Datanode Uuid 72900ae7-24a8-4a6d-bc4a-69046a9f3d2f) service to localhost/127.0.0.1:46553 successfully registered with NN
2020-04-02 05:05:46,478 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:46,483 [IPC Server handler 7 on 46553] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-36fd048c-d797-46f6-86f0-c7d903c90294 for DN 127.0.0.1:42965
2020-04-02 05:05:46,483 [IPC Server handler 7 on 46553] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-95951cee-9278-441c-8509-16ddf718694c for DN 127.0.0.1:42965
2020-04-02 05:05:46,488 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x61d9a531e9e5d440: Processing first storage report for DS-95951cee-9278-441c-8509-16ddf718694c from datanode 72900ae7-24a8-4a6d-bc4a-69046a9f3d2f
2020-04-02 05:05:46,489 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x61d9a531e9e5d440: from storage DS-95951cee-9278-441c-8509-16ddf718694c node DatanodeRegistration(127.0.0.1:42965, datanodeUuid=72900ae7-24a8-4a6d-bc4a-69046a9f3d2f, infoPort=0, infoSecurePort=43625, ipcPort=35916, storageInfo=lv=-57;cid=testClusterID;nsid=1090066364;c=1585803939097), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:46,489 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x61d9a531e9e5d440: Processing first storage report for DS-36fd048c-d797-46f6-86f0-c7d903c90294 from datanode 72900ae7-24a8-4a6d-bc4a-69046a9f3d2f
2020-04-02 05:05:46,489 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x61d9a531e9e5d440: from storage DS-36fd048c-d797-46f6-86f0-c7d903c90294 node DatanodeRegistration(127.0.0.1:42965, datanodeUuid=72900ae7-24a8-4a6d-bc4a-69046a9f3d2f, infoPort=0, infoSecurePort=43625, ipcPort=35916, storageInfo=lv=-57;cid=testClusterID;nsid=1090066364;c=1585803939097), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:46,494 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x61d9a531e9e5d440,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 8 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:46,494 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-51517513-172.17.0.11-1585803939097
2020-04-02 05:05:47,456 [Thread-259] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartNameNode(2140)) - Restarted the namenode
2020-04-02 05:05:47,465 [Socket Reader #1 for port 46553] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:47,481 [IPC Server handler 7 on 46553] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:47,486 [Thread-259] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:47,489 [IPC Server handler 6 on 46553] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/test-dir	dst=null	perm=null	proto=rpc
2020-04-02 05:05:47,491 [IPC Server handler 0 on 46553] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=mkdirs	src=/test-dir-2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:05:47,501 [Thread-259] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:05:47,501 [Thread-259] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 46553 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:47,501 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:47,501 [Thread[Thread-429,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:05:47,502 [Thread-259] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 6, 9
2020-04-02 05:05:47,502 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5153422c] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:05:47,505 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@6a984b98] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:05:47,509 [Thread-259] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 5 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 5 Number of syncs: 5 SyncTimes(ms): 53 
2020-04-02 05:05:47,513 [IPC Server handler 3 on 37640] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_inprogress_0000000000000000006 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_0000000000000000006-0000000000000000010
2020-04-02 05:05:47,513 [IPC Server handler 3 on 45921] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_inprogress_0000000000000000006 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_0000000000000000006-0000000000000000010
2020-04-02 05:05:47,517 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:05:47,517 [CacheReplicationMonitor(1742880326)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:05:47,520 [Thread-259] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46553
2020-04-02 05:05:47,527 [IPC Server handler 3 on 42462] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_inprogress_0000000000000000006 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_0000000000000000006-0000000000000000010
2020-04-02 05:05:47,531 [IPC Server listener on 46553] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46553
2020-04-02 05:05:47,535 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:47,535 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:05:47,540 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:05:47,552 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:47,553 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:05:47,554 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@9afe0d9{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:05:47,581 [Thread-259] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@76f3eb68{SSL,[ssl, http/1.1]}{localhost:40876}
2020-04-02 05:05:47,581 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3b5f4ef2{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:47,582 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5fb9b18a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:47,593 [Thread-259] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:47,594 [Thread-259] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:05:47,594 [Thread-259] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:47,594 [Thread-259] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://localhost:46553
2020-04-02 05:05:47,595 [Thread-259] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use localhost:46553 to access this namenode/service.
2020-04-02 05:05:47,602 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803947601,root/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:47,604 [Thread-259] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user root/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab
2020-04-02 05:05:47,610 [Thread-259] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:47,611 [Thread-259] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:40876
2020-04-02 05:05:47,611 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:47,612 [Thread-259] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:47,613 [Thread-259] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:47,613 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:47,614 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@759295d3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:47,615 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:47,615 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:47,615 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:47,616 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:47,618 [Thread-259] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:47,618 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:47,619 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:05:47,619 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:05:47,619 [Thread-259] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40876
2020-04-02 05:05:47,619 [Thread-259] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:47,830 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3e38f2bb{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:47,831 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@63c701bf{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:47,837 [Thread-259] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:47,838 [Thread-259] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/root.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:47,839 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3b345e77{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:47,840 [Thread-259] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@76098b29(server,h=[],w=[]) for SslContextFactory@40466dd6(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/TestSecureNNWithQJM/trustKS.jks)
2020-04-02 05:05:47,843 [Thread-259] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@610ca2ac{SSL,[ssl, http/1.1]}{localhost:40876}
2020-04-02 05:05:47,843 [Thread-259] INFO  server.Server (Server.java:doStart(419)) - Started @29006ms
2020-04-02 05:05:47,844 [Thread-259] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(685)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-04-02 05:05:47,845 [Thread-259] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:47,851 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:47,851 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:47,851 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:47,851 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:47,852 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:47,852 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:47,852 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:47,856 [Thread-259] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:47,856 [Thread-259] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:47,856 [Thread-259] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:47,857 [Thread-259] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:47,857 [Thread-259] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:47
2020-04-02 05:05:47,857 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:47,857 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:47,857 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:05:47,857 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:47,886 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:47,889 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:47,897 [Thread-259] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:47,897 [Thread-259] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:47,897 [Thread-259] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:47,897 [Thread-259] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:47,897 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:05:47,897 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:47,897 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:47,898 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:47,898 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:47,898 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:47,898 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:47,898 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:47,898 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:47,899 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:05:47,899 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:47,905 [Thread-259] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:47,905 [Thread-259] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:47,905 [Thread-259] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:47,905 [Thread-259] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:47,917 [Thread-259] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:47,918 [Thread-259] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:47,918 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:47,918 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:47,918 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:05:47,919 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:47,920 [Thread-259] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:47,922 [Thread-259] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:47,922 [Thread-259] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:47,923 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:47,923 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:47,923 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:47,923 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:47,934 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:05:47,934 [Thread-259] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:47,938 [Thread-259] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:47,943 [Thread-259] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 6464@f8287aaf0779
2020-04-02 05:05:47,947 [Thread-259] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(442)) - Starting recovery process for unclosed journal segments...
2020-04-02 05:05:48,008 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803948008,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:48,014 [pool-1-thread-3] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803948014,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:48,016 [Socket Reader #1 for port 37640] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:48,026 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803948025,root/localhost for root/localhost@EXAMPLE.COM
2020-04-02 05:05:48,034 [Socket Reader #1 for port 45921] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:48,055 [IPC Server handler 1 on 37640] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(346)) - Updating lastPromisedEpoch from 2 to 3 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:48,056 [IPC Server handler 1 on 45921] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(346)) - Updating lastPromisedEpoch from 2 to 3 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:48,057 [IPC Server handler 1 on 37640] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(205)) - Scanning storage FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal)
2020-04-02 05:05:48,057 [IPC Server handler 1 on 37640] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(211)) - Latest log is EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_0000000000000000006-0000000000000000010,first=0000000000000000006,last=0000000000000000010,inProgress=false,hasCorruptHeader=false) ; journal id: myjournal
2020-04-02 05:05:48,058 [Socket Reader #1 for port 42462] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:48,058 [IPC Server handler 1 on 45921] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(205)) - Scanning storage FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal)
2020-04-02 05:05:48,058 [IPC Server handler 1 on 45921] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(211)) - Latest log is EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_0000000000000000006-0000000000000000010,first=0000000000000000006,last=0000000000000000010,inProgress=false,hasCorruptHeader=false) ; journal id: myjournal
2020-04-02 05:05:48,059 [Thread-259] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(444)) - Successfully started new epoch 3
2020-04-02 05:05:48,060 [Thread-259] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(284)) - Beginning recovery of unclosed segment starting at txid 6
2020-04-02 05:05:48,061 [IPC Server handler 0 on 37640] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(6): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_0000000000000000006-0000000000000000010,first=0000000000000000006,last=0000000000000000010,inProgress=false,hasCorruptHeader=false) -> startTxId: 6 endTxId: 10 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:48,061 [IPC Server handler 0 on 37640] INFO  server.Journal (Journal.java:prepareRecovery(784)) - Prepared recovery for segment 6: segmentState { startTxId: 6 endTxId: 10 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 10 ; journal id: myjournal
2020-04-02 05:05:48,077 [IPC Server handler 2 on 45921] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(6): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_0000000000000000006-0000000000000000010,first=0000000000000000006,last=0000000000000000010,inProgress=false,hasCorruptHeader=false) -> startTxId: 6 endTxId: 10 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:48,078 [IPC Server handler 0 on 42462] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(346)) - Updating lastPromisedEpoch from 2 to 3 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:48,082 [IPC Server handler 0 on 42462] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(205)) - Scanning storage FileJournalManager(root=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal)
2020-04-02 05:05:48,083 [IPC Server handler 0 on 42462] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(211)) - Latest log is EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_0000000000000000006-0000000000000000010,first=0000000000000000006,last=0000000000000000010,inProgress=false,hasCorruptHeader=false) ; journal id: myjournal
2020-04-02 05:05:48,086 [IPC Server handler 2 on 45921] INFO  server.Journal (Journal.java:prepareRecovery(784)) - Prepared recovery for segment 6: segmentState { startTxId: 6 endTxId: 10 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 10 ; journal id: myjournal
2020-04-02 05:05:48,086 [IPC Server handler 1 on 42462] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(6): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_0000000000000000006-0000000000000000010,first=0000000000000000006,last=0000000000000000010,inProgress=false,hasCorruptHeader=false) -> startTxId: 6 endTxId: 10 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:48,086 [IPC Server handler 1 on 42462] INFO  server.Journal (Journal.java:prepareRecovery(784)) - Prepared recovery for segment 6: segmentState { startTxId: 6 endTxId: 10 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 10 ; journal id: myjournal
2020-04-02 05:05:48,090 [Thread-259] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(293)) - Recovery prepare phase complete. Responses:
127.0.0.1:42462: segmentState { startTxId: 6 endTxId: 10 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 10
127.0.0.1:37640: segmentState { startTxId: 6 endTxId: 10 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 10
2020-04-02 05:05:48,090 [Thread-259] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(317)) - Using longest log: 127.0.0.1:42462=segmentState {
  startTxId: 6
  endTxId: 10
  isInProgress: false
}
lastWriterEpoch: 2
lastCommittedTxId: 10

2020-04-02 05:05:48,092 [IPC Server handler 0 on 45921] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(6): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_0000000000000000006-0000000000000000010,first=0000000000000000006,last=0000000000000000010,inProgress=false,hasCorruptHeader=false) -> startTxId: 6 endTxId: 10 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:48,092 [IPC Server handler 0 on 45921] INFO  server.Journal (Journal.java:acceptRecovery(872)) - Skipping download of log startTxId: 6 endTxId: 10 isInProgress: false: already have up-to-date logs ; journal id: myjournal
2020-04-02 05:05:48,092 [IPC Server handler 2 on 42462] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(6): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_0000000000000000006-0000000000000000010,first=0000000000000000006,last=0000000000000000010,inProgress=false,hasCorruptHeader=false) -> startTxId: 6 endTxId: 10 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:48,093 [IPC Server handler 2 on 42462] INFO  server.Journal (Journal.java:acceptRecovery(872)) - Skipping download of log startTxId: 6 endTxId: 10 isInProgress: false: already have up-to-date logs ; journal id: myjournal
2020-04-02 05:05:48,102 [IPC Server handler 2 on 42462] INFO  server.Journal (Journal.java:acceptRecovery(905)) - Accepted recovery for segment 6: segmentState { startTxId: 6 endTxId: 10 isInProgress: false } acceptedInEpoch: 3 ; journal id: myjournal
2020-04-02 05:05:48,102 [IPC Server handler 2 on 37640] INFO  server.Journal (Journal.java:getSegmentInfo(740)) - getSegmentInfo(6): EditLogFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_0000000000000000006-0000000000000000010,first=0000000000000000006,last=0000000000000000010,inProgress=false,hasCorruptHeader=false) -> startTxId: 6 endTxId: 10 isInProgress: false ; journal id: myjournal
2020-04-02 05:05:48,103 [IPC Server handler 2 on 37640] INFO  server.Journal (Journal.java:acceptRecovery(872)) - Skipping download of log startTxId: 6 endTxId: 10 isInProgress: false: already have up-to-date logs ; journal id: myjournal
2020-04-02 05:05:48,102 [IPC Server handler 0 on 45921] INFO  server.Journal (Journal.java:acceptRecovery(905)) - Accepted recovery for segment 6: segmentState { startTxId: 6 endTxId: 10 isInProgress: false } acceptedInEpoch: 3 ; journal id: myjournal
2020-04-02 05:05:48,104 [IPC Server handler 2 on 37640] INFO  server.Journal (Journal.java:acceptRecovery(905)) - Accepted recovery for segment 6: segmentState { startTxId: 6 endTxId: 10 isInProgress: false } acceptedInEpoch: 3 ; journal id: myjournal
2020-04-02 05:05:48,143 [Thread-259] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:48,145 [Thread-259] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:48,145 [Thread-259] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:48,146 [Thread-259] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:48,146 [Thread-259] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@9d32f34 expecting start txid #1
2020-04-02 05:05:48,146 [Thread-259] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file https://localhost:44718/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1090066364%3A1585803939097%3AtestClusterID&inProgressOk=true, https://localhost:39988/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1090066364%3A1585803939097%3AtestClusterID&inProgressOk=true maxTxnsToRead = 9223372036854775807
2020-04-02 05:05:48,146 [Thread-259] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream 'https://localhost:44718/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1090066364%3A1585803939097%3AtestClusterID&inProgressOk=true, https://localhost:39988/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1090066364%3A1585803939097%3AtestClusterID&inProgressOk=true' to transaction ID 1
2020-04-02 05:05:48,146 [Thread-259] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream 'https://localhost:44718/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1090066364%3A1585803939097%3AtestClusterID&inProgressOk=true' to transaction ID 1
2020-04-02 05:05:48,246 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803948245,root/localhost for HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:48,366 [qtp1441588710-587] WARN  server.GetJournalEditServlet (GetJournalEditServlet.java:isValidRequestor(110)) - SecondaryNameNode principal not considered, dfs.secondary.namenode.kerberos.principal = null, dfs.namenode.secondary.http-address = null
2020-04-02 05:05:48,369 [qtp1441588710-587] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(396)) - Sending fileName: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_0000000000000000001-0000000000000000005, fileSize: 185. Sent total: 185 bytes. Size of last segment intended to send: -1 bytes.
2020-04-02 05:05:48,372 [Thread-259] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file https://localhost:44718/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1090066364%3A1585803939097%3AtestClusterID&inProgressOk=true, https://localhost:39988/getJournal?jid=myjournal&segmentTxId=1&storageInfo=-64%3A1090066364%3A1585803939097%3AtestClusterID&inProgressOk=true of size 185 edits # 5 loaded in 0 seconds
2020-04-02 05:05:48,373 [Thread-259] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@189cd452 expecting start txid #6
2020-04-02 05:05:48,373 [Thread-259] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file https://localhost:39988/getJournal?jid=myjournal&segmentTxId=6&storageInfo=-64%3A1090066364%3A1585803939097%3AtestClusterID&inProgressOk=true, https://localhost:44718/getJournal?jid=myjournal&segmentTxId=6&storageInfo=-64%3A1090066364%3A1585803939097%3AtestClusterID&inProgressOk=true maxTxnsToRead = 9223372036854775807
2020-04-02 05:05:48,373 [Thread-259] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream 'https://localhost:39988/getJournal?jid=myjournal&segmentTxId=6&storageInfo=-64%3A1090066364%3A1585803939097%3AtestClusterID&inProgressOk=true, https://localhost:44718/getJournal?jid=myjournal&segmentTxId=6&storageInfo=-64%3A1090066364%3A1585803939097%3AtestClusterID&inProgressOk=true' to transaction ID 1
2020-04-02 05:05:48,373 [Thread-259] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream 'https://localhost:39988/getJournal?jid=myjournal&segmentTxId=6&storageInfo=-64%3A1090066364%3A1585803939097%3AtestClusterID&inProgressOk=true' to transaction ID 1
2020-04-02 05:05:48,475 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803948474,root/localhost for HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:48,530 [qtp79238716-602] WARN  server.GetJournalEditServlet (GetJournalEditServlet.java:isValidRequestor(110)) - SecondaryNameNode principal not considered, dfs.secondary.namenode.kerberos.principal = null, dfs.namenode.secondary.http-address = null
2020-04-02 05:05:48,531 [qtp79238716-602] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(396)) - Sending fileName: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_0000000000000000006-0000000000000000010, fileSize: 187. Sent total: 187 bytes. Size of last segment intended to send: -1 bytes.
2020-04-02 05:05:48,532 [Thread-259] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file https://localhost:39988/getJournal?jid=myjournal&segmentTxId=6&storageInfo=-64%3A1090066364%3A1585803939097%3AtestClusterID&inProgressOk=true, https://localhost:44718/getJournal?jid=myjournal&segmentTxId=6&storageInfo=-64%3A1090066364%3A1585803939097%3AtestClusterID&inProgressOk=true of size 187 edits # 5 loaded in 0 seconds
2020-04-02 05:05:48,533 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:48,550 [Thread-259] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 11
2020-04-02 05:05:48,552 [IPC Server handler 1 on 42462] INFO  server.Journal (Journal.java:startLogSegment(582)) - Updating lastWriterEpoch from 2 to 3 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:48,558 [IPC Server handler 0 on 37640] INFO  server.Journal (Journal.java:startLogSegment(582)) - Updating lastWriterEpoch from 2 to 3 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:48,559 [IPC Server handler 2 on 45921] INFO  server.Journal (Journal.java:startLogSegment(582)) - Updating lastWriterEpoch from 2 to 3 for client /127.0.0.1 ; journal id: myjournal
2020-04-02 05:05:48,601 [Thread-259] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:48,601 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 667 msecs
2020-04-02 05:05:48,602 [Thread-259] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:46553
2020-04-02 05:05:48,603 [Thread-259] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:48,604 [Socket Reader #1 for port 46553] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46553
2020-04-02 05:05:48,614 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:48,614 [Thread-259] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:48,623 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@3163fea0] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:05:48,639 [Thread-259] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:48,641 [Thread-259] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:05:48,642 [Thread-259] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:05:48,642 [Thread-259] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:48,666 [Thread-259] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:48,691 [Thread[Thread-475,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:05:48,695 [Thread[Thread-475,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:48,693 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:48,698 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:48,698 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:48,698 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:48,698 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:48,698 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 56 msec
2020-04-02 05:05:48,754 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:48,756 [IPC Server listener on 46553] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46553: starting
2020-04-02 05:05:48,810 [Thread-259] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:46553
2020-04-02 05:05:48,811 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:48,811 [Thread-259] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:48,812 [Thread-259] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=3
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:48,820 [Thread-259] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 46553 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:48,850 [Thread-259] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1409)) - Waiting for the Mini HDFS Cluster to start...
2020-04-02 05:05:48,853 [CacheReplicationMonitor(741955777)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:49,481 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] WARN  datanode.DataNode (BPServiceActor.java:offerService(728)) - IOException in offerService
java.io.EOFException: End of File Exception between local host is: "f8287aaf0779/172.17.0.11"; destination host is: "localhost":46553; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:789)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy27.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:514)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:645)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:842)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2020-04-02 05:05:49,851 [Thread-259] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1409)) - Waiting for the Mini HDFS Cluster to start...
2020-04-02 05:05:50,851 [Thread-259] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1409)) - Waiting for the Mini HDFS Cluster to start...
2020-04-02 05:05:51,852 [Thread-259] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1409)) - Waiting for the Mini HDFS Cluster to start...
2020-04-02 05:05:52,508 [Socket Reader #1 for port 46553] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:52,522 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:46553 with active state
2020-04-02 05:05:52,526 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-51517513-172.17.0.11-1585803939097 (Datanode Uuid 72900ae7-24a8-4a6d-bc4a-69046a9f3d2f) service to localhost/127.0.0.1:46553 beginning handshake with NN
2020-04-02 05:05:52,527 [IPC Server handler 2 on 46553] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42965, datanodeUuid=72900ae7-24a8-4a6d-bc4a-69046a9f3d2f, infoPort=0, infoSecurePort=43625, ipcPort=35916, storageInfo=lv=-57;cid=testClusterID;nsid=1090066364;c=1585803939097) storage 72900ae7-24a8-4a6d-bc4a-69046a9f3d2f
2020-04-02 05:05:52,527 [IPC Server handler 2 on 46553] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42965
2020-04-02 05:05:52,528 [IPC Server handler 2 on 46553] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 72900ae7-24a8-4a6d-bc4a-69046a9f3d2f (127.0.0.1:42965).
2020-04-02 05:05:52,534 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-51517513-172.17.0.11-1585803939097 (Datanode Uuid 72900ae7-24a8-4a6d-bc4a-69046a9f3d2f) service to localhost/127.0.0.1:46553 successfully registered with NN
2020-04-02 05:05:52,534 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:52,542 [IPC Server handler 3 on 46553] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-36fd048c-d797-46f6-86f0-c7d903c90294 for DN 127.0.0.1:42965
2020-04-02 05:05:52,543 [IPC Server handler 3 on 46553] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-95951cee-9278-441c-8509-16ddf718694c for DN 127.0.0.1:42965
2020-04-02 05:05:52,550 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x61d9a531e9e5d441: Processing first storage report for DS-95951cee-9278-441c-8509-16ddf718694c from datanode 72900ae7-24a8-4a6d-bc4a-69046a9f3d2f
2020-04-02 05:05:52,550 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x61d9a531e9e5d441: from storage DS-95951cee-9278-441c-8509-16ddf718694c node DatanodeRegistration(127.0.0.1:42965, datanodeUuid=72900ae7-24a8-4a6d-bc4a-69046a9f3d2f, infoPort=0, infoSecurePort=43625, ipcPort=35916, storageInfo=lv=-57;cid=testClusterID;nsid=1090066364;c=1585803939097), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:52,550 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x61d9a531e9e5d441: Processing first storage report for DS-36fd048c-d797-46f6-86f0-c7d903c90294 from datanode 72900ae7-24a8-4a6d-bc4a-69046a9f3d2f
2020-04-02 05:05:52,550 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x61d9a531e9e5d441: from storage DS-36fd048c-d797-46f6-86f0-c7d903c90294 node DatanodeRegistration(127.0.0.1:42965, datanodeUuid=72900ae7-24a8-4a6d-bc4a-69046a9f3d2f, infoPort=0, infoSecurePort=43625, ipcPort=35916, storageInfo=lv=-57;cid=testClusterID;nsid=1090066364;c=1585803939097), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:52,553 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x61d9a531e9e5d441,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:52,553 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-51517513-172.17.0.11-1585803939097
2020-04-02 05:05:52,852 [Thread-259] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartNameNode(2140)) - Restarted the namenode
2020-04-02 05:05:52,861 [Socket Reader #1 for port 46553] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for root/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:52,884 [IPC Server handler 1 on 46553] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:52,886 [Thread-259] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:52,899 [IPC Server handler 0 on 46553] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/test-dir	dst=null	perm=null	proto=rpc
2020-04-02 05:05:52,909 [IPC Server handler 2 on 46553] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/test-dir-2	dst=null	perm=null	proto=rpc
2020-04-02 05:05:52,910 [Thread-259] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:05:52,910 [Thread-259] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:05:52,910 [Thread-259] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 35916 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:52,911 [Thread-259] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:52,911 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4160a5e6] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:52,913 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-95951cee-9278-441c-8509-16ddf718694c) exiting.
2020-04-02 05:05:52,914 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-36fd048c-d797-46f6-86f0-c7d903c90294) exiting.
2020-04-02 05:05:53,040 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@42329a28{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:53,041 [Thread-259] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7b0f339b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:53,041 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@35f4d709{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:53,041 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@45ed7005{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:53,049 [Thread-259] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35916
2020-04-02 05:05:53,052 [IPC Server listener on 35916] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35916
2020-04-02 05:05:53,054 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:53,054 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:53,055 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-51517513-172.17.0.11-1585803939097 (Datanode Uuid 72900ae7-24a8-4a6d-bc4a-69046a9f3d2f) service to localhost/127.0.0.1:46553
2020-04-02 05:05:53,055 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-51517513-172.17.0.11-1585803939097 (Datanode Uuid 72900ae7-24a8-4a6d-bc4a-69046a9f3d2f)
2020-04-02 05:05:53,055 [BP-51517513-172.17.0.11-1585803939097 heartbeating to localhost/127.0.0.1:46553] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-51517513-172.17.0.11-1585803939097
2020-04-02 05:05:53,084 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-51517513-172.17.0.11-1585803939097] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:53,151 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-51517513-172.17.0.11-1585803939097] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:53,157 [Thread-259] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:53,157 [Thread-259] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:53,158 [Thread-259] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:53,158 [Thread-259] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:53,164 [Thread-259] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:53,165 [Thread-259] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:05:53,165 [Thread-259] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 46553 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:53,165 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:53,165 [Thread[Thread-475,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:05:53,166 [Thread-259] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 11, 13
2020-04-02 05:05:53,166 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@3c6996af] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:05:53,166 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@1ca89b58] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:05:53,189 [Thread-259] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 4 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 10 Number of syncs: 4 SyncTimes(ms): 67 
2020-04-02 05:05:53,192 [IPC Server handler 2 on 45921] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_inprogress_0000000000000000011 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal/current/edits_0000000000000000011-0000000000000000014
2020-04-02 05:05:53,195 [IPC Server handler 1 on 42462] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_inprogress_0000000000000000011 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal/current/edits_0000000000000000011-0000000000000000014
2020-04-02 05:05:53,196 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:05:53,198 [CacheReplicationMonitor(741955777)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:05:53,206 [Thread-259] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46553
2020-04-02 05:05:53,208 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:53,208 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:05:53,208 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:05:53,209 [IPC Server listener on 46553] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46553
2020-04-02 05:05:53,216 [IPC Server handler 0 on 37640] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_inprogress_0000000000000000011 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal/current/edits_0000000000000000011-0000000000000000014
2020-04-02 05:05:53,235 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:53,236 [Thread-259] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:05:53,237 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3b345e77{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:05:53,276 [Thread-259] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@610ca2ac{SSL,[ssl, http/1.1]}{localhost:40876}
2020-04-02 05:05:53,276 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@63c701bf{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:53,276 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3e38f2bb{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:53,315 [Thread-259] INFO  server.JournalNode (JournalNode.java:stop(286)) - [msx-restart] JournalNode 45921 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:53,315 [Thread-259] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45921
2020-04-02 05:05:53,316 [IPC Server listener on 45921] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45921
2020-04-02 05:05:53,323 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:53,330 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@26c596d{/,null,UNAVAILABLE}{/journal}
2020-04-02 05:05:53,350 [Thread-259] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@51eedb35{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:05:53,351 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d08717b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:53,351 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@171d3a9d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:53,352 [Thread-259] INFO  common.Storage (JNStorage.java:close(280)) - Closing journal storage for Storage Directory root= /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/waitactive; location= null
2020-04-02 05:05:53,352 [Thread-259] INFO  common.Storage (JNStorage.java:close(280)) - Closing journal storage for Storage Directory root= /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/myjournal; location= null
2020-04-02 05:05:53,353 [Thread-259] INFO  server.JournalNode (JournalNode.java:stop(286)) - [msx-restart] JournalNode 37640 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:53,354 [Thread-259] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37640
2020-04-02 05:05:53,356 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@208016b0{/,null,UNAVAILABLE}{/journal}
2020-04-02 05:05:53,356 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:53,386 [IPC Server listener on 37640] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37640
2020-04-02 05:05:53,414 [Thread-259] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6b40a74d{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:05:53,415 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@27ea2a2e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:53,415 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6ed6b7e3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:53,425 [Thread-259] INFO  common.Storage (JNStorage.java:close(280)) - Closing journal storage for Storage Directory root= /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/waitactive; location= null
2020-04-02 05:05:53,426 [Thread-259] INFO  common.Storage (JNStorage.java:close(280)) - Closing journal storage for Storage Directory root= /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/myjournal; location= null
2020-04-02 05:05:53,427 [Thread-259] INFO  server.JournalNode (JournalNode.java:stop(286)) - [msx-restart] JournalNode 42462 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:53,427 [Thread-259] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42462
2020-04-02 05:05:53,435 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6edab47c{/,null,UNAVAILABLE}{/journal}
2020-04-02 05:05:53,436 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:53,438 [IPC Server listener on 42462] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42462
2020-04-02 05:05:53,451 [Thread-259] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@65fd2c24{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:05:53,452 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@628d11cb{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:53,452 [Thread-259] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2bf75669{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:53,473 [Thread-259] INFO  common.Storage (JNStorage.java:close(280)) - Closing journal storage for Storage Directory root= /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/waitactive; location= null
2020-04-02 05:05:53,474 [Thread-259] INFO  common.Storage (JNStorage.java:close(280)) - Closing journal storage for Storage Directory root= /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/myjournal; location= null
2020-04-02 05:05:53,483 [Thread-259] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping NameNode metrics system...
2020-04-02 05:05:53,503 [Thread-259] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - NameNode metrics system stopped.
2020-04-02 05:05:53,504 [Thread-259] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - NameNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.qjournal.TestSecureNNWithQJM#testSecondaryNameNodeHttpAddressNotNeeded
[msx] writeFile testName = org.apache.hadoop.hdfs.qjournal.TestSecureNNWithQJM#testSecondaryNameNodeHttpAddressNotNeeded
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:05:53,515 [main] INFO  impl.DefaultInternalKdcServerImpl (DefaultInternalKdcServerImpl.java:doStop(102)) - Default Internal kdc server stopped.
2020-04-02 05:05:54,515 [main] INFO  minikdc.MiniKdc (MiniKdc.java:stop(359)) - MiniKdc stopped.
[msx] all testRunFinished

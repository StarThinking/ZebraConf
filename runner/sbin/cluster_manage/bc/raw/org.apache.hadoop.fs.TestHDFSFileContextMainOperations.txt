[msx] before_class
2020-04-02 05:04:04,009 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=2
Formatting using clusterid: testClusterID
2020-04-02 05:04:04,755 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:04:04,771 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:04:04,773 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:04:04,777 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:04:04,785 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:04:04,785 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:04:04,786 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:04:04,790 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:04:04,853 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:04,859 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:04:04,860 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:04:04,860 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:04:04,866 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:04:04,867 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:04:04
2020-04-02 05:04:04,870 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:04:04,871 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:04,873 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:04:04,873 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:04:04,894 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:04:04,902 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:04:04,903 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:04:04,903 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:04:04,904 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:04:04,904 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 2
2020-04-02 05:04:04,904 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:04:04,904 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:04:04,905 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:04:04,905 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:04:04,905 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:04:04,906 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:04:04,938 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:04:04,957 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:04:04,957 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:04,958 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:04:04,958 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:04:04,965 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:04:04,965 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:04:04,965 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:04:04,966 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:04:04,972 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:04:04,974 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:04:04,980 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:04:04,981 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:04,981 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:04:04,981 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:04:04,991 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:04:04,992 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:04:04,992 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:04:04,997 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:04:04,997 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:04:05,001 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:04:05,001 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:05,002 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:04:05,002 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:04:05,047 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:05,067 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:04:05,072 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:04:05,098 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:04:05,098 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:04:05,232 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:04:05,232 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:04:05,260 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:04:05,264 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:04:05,427 [main] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:04:05,507 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:04:06,107 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:04:06,107 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:04:06,114 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:04:06,146 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:04:06,200 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@506ae4d4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:04:06,217 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:04:06,222 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:06,238 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3748ms
2020-04-02 05:04:06,372 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:04:06,378 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:04:06,379 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:06,388 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:04:06,390 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:04:06,391 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:04:06,391 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:04:06,421 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:04:06,421 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:04:06,431 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46568
2020-04-02 05:04:06,434 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:04:06,490 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d5620ce{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:04:06,491 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@642a7222{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:04:06,538 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@544d57e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:04:06,549 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@27e47833{HTTP/1.1,[http/1.1]}{localhost:46568}
2020-04-02 05:04:06,550 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4059ms
2020-04-02 05:04:06,563 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:04:06,564 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:04:06,564 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:04:06,565 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:04:06,565 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:04:06,565 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:04:06,565 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:04:06,566 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:04:06,567 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:06,568 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:04:06,568 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:04:06,569 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:04:06,569 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:04:06
2020-04-02 05:04:06,570 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:04:06,570 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:06,570 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:04:06,570 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:04:06,593 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:04:06,594 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:04:06,595 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:04:06,595 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:04:06,595 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:04:06,595 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 2
2020-04-02 05:04:06,596 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:04:06,596 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:04:06,596 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:04:06,597 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:04:06,597 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:04:06,597 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:04:06,598 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:04:06,598 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:06,599 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:04:06,599 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:04:06,606 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:04:06,607 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:04:06,607 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:04:06,607 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:04:06,607 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:04:06,608 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:04:06,608 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:04:06,608 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:06,609 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:04:06,609 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:04:06,610 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:04:06,610 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:04:06,610 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:04:06,610 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:04:06,611 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:04:06,611 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:04:06,611 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:06,611 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:04:06,611 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:04:06,623 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 5253@59c1167abdeb
2020-04-02 05:04:06,632 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 5253@59c1167abdeb
2020-04-02 05:04:06,636 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:04:06,637 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:04:06,637 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:04:06,638 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:04:06,669 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:04:06,677 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:04:06,677 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:04:06,683 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:04:06,684 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:04:06,745 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:04:06,746 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 127 msecs
2020-04-02 05:04:06,939 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:04:06,951 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:04:06,963 [Socket Reader #1 for port 38542] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38542
2020-04-02 05:04:07,322 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:38542 to access this namenode/service.
2020-04-02 05:04:07,327 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:04:07,364 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:04:07,392 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:04:07,393 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:04:07,393 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:04:07,393 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:04:07,396 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:04:07,397 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:04:07,397 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:04:07,397 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:04:07,397 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:04:07,397 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 4 msec
2020-04-02 05:04:07,447 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:38542
2020-04-02 05:04:07,444 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:04:07,444 [IPC Server listener on 38542] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38542: starting
2020-04-02 05:04:07,451 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:04:07,451 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:04:07,456 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 4 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:04:07,463 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 38542 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:07,464 [CacheReplicationMonitor(1443785558)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:04:07,471 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:04:07,592 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:04:07,623 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:04:07,633 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:04:07,633 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:04:07,639 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:07,644 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:04:07,647 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:04:07,649 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:07,658 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:04:07,668 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40672
2020-04-02 05:04:07,670 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:04:07,670 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:04:07,717 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:07,719 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:04:07,720 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:04:07,722 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:07,723 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:04:07,725 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:04:07,725 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:04:07,725 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:04:07,729 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35408
2020-04-02 05:04:07,729 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:04:07,731 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@320de594{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:04:07,732 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@abf688e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:04:07,738 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@fb9c7aa{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:04:07,739 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4c398c80{HTTP/1.1,[http/1.1]}{localhost:35408}
2020-04-02 05:04:07,744 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5254ms
2020-04-02 05:04:08,179 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39408
2020-04-02 05:04:08,180 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3d08f3f5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:04:08,182 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:04:08,183 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:04:08,204 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:04:08,205 [Socket Reader #1 for port 41557] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41557
2020-04-02 05:04:08,222 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:41557
2020-04-02 05:04:08,243 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:04:08,247 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:04:08,771 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38542 starting to offer service
2020-04-02 05:04:08,816 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:04:08,818 [IPC Server listener on 41557] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41557: starting
2020-04-02 05:04:08,826 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 41557 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:08,829 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:04:08,842 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:04:08,842 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:04:08,848 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:04:08,849 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:04:08,849 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:08,849 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:04:08,866 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:04:08,866 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:08,867 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:04:08,868 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:39449
2020-04-02 05:04:08,868 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:04:08,868 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:04:08,870 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:08,881 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:04:08,903 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:04:08,903 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:08,912 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:04:08,922 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:04:08,922 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:04:08,922 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:04:08,928 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37910
2020-04-02 05:04:08,929 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:04:08,943 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@fd46303{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:04:08,944 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4204541c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:04:08,958 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@33352f32{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:04:08,962 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5f3b9c57{HTTP/1.1,[http/1.1]}{localhost:37910}
2020-04-02 05:04:08,963 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6473ms
2020-04-02 05:04:09,126 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37934
2020-04-02 05:04:09,127 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2cf23c81] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:04:09,128 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:04:09,128 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:04:09,129 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:04:09,131 [Socket Reader #1 for port 40773] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40773
2020-04-02 05:04:09,148 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40773
2020-04-02 05:04:09,185 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:04:09,186 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:04:09,189 [Thread-84] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38542 starting to offer service
2020-04-02 05:04:09,203 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:04:09,206 [IPC Server listener on 40773] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40773: starting
2020-04-02 05:04:09,212 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40773 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:09,461 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38542
2020-04-02 05:04:09,461 [Thread-84] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38542
2020-04-02 05:04:09,467 [Thread-84] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:04:09,469 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:04:09,471 [Thread-84] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 5253@59c1167abdeb
2020-04-02 05:04:09,472 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 5253@59c1167abdeb
2020-04-02 05:04:09,472 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 471869960. Formatting...
2020-04-02 05:04:09,473 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 471869960. Formatting...
2020-04-02 05:04:09,473 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f437bce0-4caf-48d2-b20f-d0ce4fd0dd03 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:04:09,474 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-54746245-acee-4605-b3a2-76160e1ebb72 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:04:09,477 [Thread-84] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 5253@59c1167abdeb
2020-04-02 05:04:09,478 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 471869960. Formatting...
2020-04-02 05:04:09,483 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 5253@59c1167abdeb
2020-04-02 05:04:09,483 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 471869960. Formatting...
2020-04-02 05:04:09,483 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-40b68935-c633-4c1c-86d0-4f23e2beb39e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:04:09,484 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-eec506ae-cf75-4c6b-9ece-cd33e8e8b2ee for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:04:09,533 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:09,548 [Thread-84] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:09,548 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:09,549 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:09,550 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1054551904-172.17.0.20-1585803845034 is not formatted. Formatting ...
2020-04-02 05:04:09,551 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1054551904-172.17.0.20-1585803845034 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1054551904-172.17.0.20-1585803845034/current
2020-04-02 05:04:09,550 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1054551904-172.17.0.20-1585803845034 is not formatted. Formatting ...
2020-04-02 05:04:09,551 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1054551904-172.17.0.20-1585803845034 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current
2020-04-02 05:04:09,567 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:09,568 [Thread-84] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:09,568 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1054551904-172.17.0.20-1585803845034 is not formatted. Formatting ...
2020-04-02 05:04:09,568 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1054551904-172.17.0.20-1585803845034 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1054551904-172.17.0.20-1585803845034/current
2020-04-02 05:04:09,570 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:09,572 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:09,572 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1054551904-172.17.0.20-1585803845034 is not formatted. Formatting ...
2020-04-02 05:04:09,572 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1054551904-172.17.0.20-1585803845034 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current
2020-04-02 05:04:09,577 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=471869960;bpid=BP-1054551904-172.17.0.20-1585803845034;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=471869960;c=1585803845034;bpid=BP-1054551904-172.17.0.20-1585803845034;dnuuid=null
2020-04-02 05:04:09,582 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91
2020-04-02 05:04:09,596 [Thread-84] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=471869960;bpid=BP-1054551904-172.17.0.20-1585803845034;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=471869960;c=1585803845034;bpid=BP-1054551904-172.17.0.20-1585803845034;dnuuid=null
2020-04-02 05:04:09,600 [Thread-84] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 5422153c-cb39-477f-b99e-b1245041abaa
2020-04-02 05:04:09,739 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-f437bce0-4caf-48d2-b20f-d0ce4fd0dd03
2020-04-02 05:04:09,742 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:04:09,754 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-40b68935-c633-4c1c-86d0-4f23e2beb39e
2020-04-02 05:04:09,754 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:04:09,750 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-54746245-acee-4605-b3a2-76160e1ebb72
2020-04-02 05:04:09,755 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:04:09,759 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-eec506ae-cf75-4c6b-9ece-cd33e8e8b2ee
2020-04-02 05:04:09,759 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:04:09,775 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:04:09,775 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:04:09,787 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:04:09,787 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:04:09,800 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:04:09,802 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:04:09,810 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:04:09,810 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:04:09,810 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:04:09,810 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:04:09,821 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:09,821 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:09,822 [Thread-100] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:04:09,830 [Thread-101] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:04:09,831 [Thread-104] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:04:09,833 [Thread-102] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:04:09,896 [Thread-101] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1054551904-172.17.0.20-1585803845034 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 66ms
2020-04-02 05:04:09,897 [Thread-102] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1054551904-172.17.0.20-1585803845034 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 63ms
2020-04-02 05:04:09,899 [Thread-100] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1054551904-172.17.0.20-1585803845034 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 76ms
2020-04-02 05:04:09,922 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1054551904-172.17.0.20-1585803845034: 101ms
2020-04-02 05:04:09,927 [Thread-110] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:04:09,927 [Thread-104] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1054551904-172.17.0.20-1585803845034 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 96ms
2020-04-02 05:04:09,927 [Thread-110] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/replicas doesn't exist 
2020-04-02 05:04:09,930 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1054551904-172.17.0.20-1585803845034: 108ms
2020-04-02 05:04:09,930 [Thread-111] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:04:09,931 [Thread-110] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 4ms
2020-04-02 05:04:09,937 [Thread-112] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:04:09,947 [Thread-113] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:04:09,930 [Thread-111] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/replicas doesn't exist 
2020-04-02 05:04:09,948 [Thread-113] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1054551904-172.17.0.20-1585803845034/current/replicas doesn't exist 
2020-04-02 05:04:09,948 [Thread-112] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1054551904-172.17.0.20-1585803845034/current/replicas doesn't exist 
2020-04-02 05:04:09,949 [Thread-111] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 19ms
2020-04-02 05:04:09,949 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1054551904-172.17.0.20-1585803845034: 24ms
2020-04-02 05:04:09,949 [Thread-112] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-04-02 05:04:09,950 [Thread-113] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 2ms
2020-04-02 05:04:09,950 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1054551904-172.17.0.20-1585803845034: 20ms
2020-04-02 05:04:09,956 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:04:09,958 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:04:09,956 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:04:09,960 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-eec506ae-cf75-4c6b-9ece-cd33e8e8b2ee): finished scanning block pool BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:09,960 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-f437bce0-4caf-48d2-b20f-d0ce4fd0dd03): finished scanning block pool BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:09,966 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:04:09,966 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-54746245-acee-4605-b3a2-76160e1ebb72): finished scanning block pool BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:09,966 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-40b68935-c633-4c1c-86d0-4f23e2beb39e): finished scanning block pool BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:09,972 [Thread-84] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:16 AM with interval of 21600000ms
2020-04-02 05:04:09,972 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:51 AM with interval of 21600000ms
2020-04-02 05:04:09,974 [IPC Server handler 9 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:09,989 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:38542] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1054551904-172.17.0.20-1585803845034 (Datanode Uuid 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91) service to localhost/127.0.0.1:38542 beginning handshake with NN
2020-04-02 05:04:09,989 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:38542] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1054551904-172.17.0.20-1585803845034 (Datanode Uuid 5422153c-cb39-477f-b99e-b1245041abaa) service to localhost/127.0.0.1:38542 beginning handshake with NN
2020-04-02 05:04:09,992 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:04:09,992 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:04:10,001 [IPC Server handler 7 on 38542] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40672, datanodeUuid=5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, infoPort=39408, infoSecurePort=0, ipcPort=41557, storageInfo=lv=-57;cid=testClusterID;nsid=471869960;c=1585803845034) storage 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91
2020-04-02 05:04:10,005 [IPC Server handler 7 on 38542] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40672
2020-04-02 05:04:10,006 [IPC Server handler 7 on 38542] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91 (127.0.0.1:40672).
2020-04-02 05:04:10,009 [IPC Server handler 4 on 38542] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39449, datanodeUuid=5422153c-cb39-477f-b99e-b1245041abaa, infoPort=37934, infoSecurePort=0, ipcPort=40773, storageInfo=lv=-57;cid=testClusterID;nsid=471869960;c=1585803845034) storage 5422153c-cb39-477f-b99e-b1245041abaa
2020-04-02 05:04:10,010 [IPC Server handler 4 on 38542] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39449
2020-04-02 05:04:10,010 [IPC Server handler 4 on 38542] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5422153c-cb39-477f-b99e-b1245041abaa (127.0.0.1:39449).
2020-04-02 05:04:10,014 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:38542] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1054551904-172.17.0.20-1585803845034 (Datanode Uuid 5422153c-cb39-477f-b99e-b1245041abaa) service to localhost/127.0.0.1:38542 successfully registered with NN
2020-04-02 05:04:10,014 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:38542] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38542 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:04:10,015 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:38542] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1054551904-172.17.0.20-1585803845034 (Datanode Uuid 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91) service to localhost/127.0.0.1:38542 successfully registered with NN
2020-04-02 05:04:10,015 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:38542] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38542 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:04:10,018 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-f437bce0-4caf-48d2-b20f-d0ce4fd0dd03): no suitable block pools found to scan.  Waiting 1814399938 ms.
2020-04-02 05:04:10,018 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-54746245-acee-4605-b3a2-76160e1ebb72): no suitable block pools found to scan.  Waiting 1814399937 ms.
2020-04-02 05:04:10,022 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-eec506ae-cf75-4c6b-9ece-cd33e8e8b2ee): no suitable block pools found to scan.  Waiting 1814399934 ms.
2020-04-02 05:04:10,022 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-40b68935-c633-4c1c-86d0-4f23e2beb39e): no suitable block pools found to scan.  Waiting 1814399933 ms.
2020-04-02 05:04:10,033 [IPC Server handler 6 on 38542] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-54746245-acee-4605-b3a2-76160e1ebb72 for DN 127.0.0.1:40672
2020-04-02 05:04:10,034 [IPC Server handler 6 on 38542] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-eec506ae-cf75-4c6b-9ece-cd33e8e8b2ee for DN 127.0.0.1:40672
2020-04-02 05:04:10,036 [IPC Server handler 8 on 38542] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f437bce0-4caf-48d2-b20f-d0ce4fd0dd03 for DN 127.0.0.1:39449
2020-04-02 05:04:10,038 [IPC Server handler 8 on 38542] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-40b68935-c633-4c1c-86d0-4f23e2beb39e for DN 127.0.0.1:39449
2020-04-02 05:04:10,066 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe9958644f94be3a1: Processing first storage report for DS-40b68935-c633-4c1c-86d0-4f23e2beb39e from datanode 5422153c-cb39-477f-b99e-b1245041abaa
2020-04-02 05:04:10,067 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe9958644f94be3a1: from storage DS-40b68935-c633-4c1c-86d0-4f23e2beb39e node DatanodeRegistration(127.0.0.1:39449, datanodeUuid=5422153c-cb39-477f-b99e-b1245041abaa, infoPort=37934, infoSecurePort=0, ipcPort=40773, storageInfo=lv=-57;cid=testClusterID;nsid=471869960;c=1585803845034), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:04:10,068 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x3700f4b0a00e4cfd: Processing first storage report for DS-54746245-acee-4605-b3a2-76160e1ebb72 from datanode 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91
2020-04-02 05:04:10,068 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x3700f4b0a00e4cfd: from storage DS-54746245-acee-4605-b3a2-76160e1ebb72 node DatanodeRegistration(127.0.0.1:40672, datanodeUuid=5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, infoPort=39408, infoSecurePort=0, ipcPort=41557, storageInfo=lv=-57;cid=testClusterID;nsid=471869960;c=1585803845034), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:10,068 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe9958644f94be3a1: Processing first storage report for DS-f437bce0-4caf-48d2-b20f-d0ce4fd0dd03 from datanode 5422153c-cb39-477f-b99e-b1245041abaa
2020-04-02 05:04:10,068 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe9958644f94be3a1: from storage DS-f437bce0-4caf-48d2-b20f-d0ce4fd0dd03 node DatanodeRegistration(127.0.0.1:39449, datanodeUuid=5422153c-cb39-477f-b99e-b1245041abaa, infoPort=37934, infoSecurePort=0, ipcPort=40773, storageInfo=lv=-57;cid=testClusterID;nsid=471869960;c=1585803845034), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:10,068 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x3700f4b0a00e4cfd: Processing first storage report for DS-eec506ae-cf75-4c6b-9ece-cd33e8e8b2ee from datanode 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91
2020-04-02 05:04:10,068 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x3700f4b0a00e4cfd: from storage DS-eec506ae-cf75-4c6b-9ece-cd33e8e8b2ee node DatanodeRegistration(127.0.0.1:40672, datanodeUuid=5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, infoPort=39408, infoSecurePort=0, ipcPort=41557, storageInfo=lv=-57;cid=testClusterID;nsid=471869960;c=1585803845034), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:04:10,087 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:38542] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xe9958644f94be3a1,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 32 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:04:10,087 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:38542] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x3700f4b0a00e4cfd,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 34 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:04:10,087 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:38542] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:10,087 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:38542] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:10,100 [IPC Server handler 0 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,113 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:04:10,155 [IPC Server handler 1 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameRoot
[msx] unitTestCounterInClass = 0
2020-04-02 05:04:10,174 [IPC Server handler 5 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:10,230 [IPC Server handler 4 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameRoot/srcdir/src1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:10,269 [IPC Server handler 7 on 38542] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:39449, 127.0.0.1:40672 for /tmp/TestHDFSFileContextMainOperations/test/testRenameRoot/srcdir/src1
2020-04-02 05:04:10,342 [DataXceiver for client DFSClient_NONMAPREDUCE_-766698216_1 at /127.0.0.1:38558 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741825_1001 src: /127.0.0.1:38558 dest: /127.0.0.1:39449
2020-04-02 05:04:10,366 [DataXceiver for client DFSClient_NONMAPREDUCE_-766698216_1 at /127.0.0.1:53818 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741825_1001 src: /127.0.0.1:53818 dest: /127.0.0.1:40672
2020-04-02 05:04:10,400 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53818, dest: /127.0.0.1:40672, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-766698216_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741825_1001, duration(ns): 15616002
2020-04-02 05:04:10,401 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:10,411 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40672]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38558, dest: /127.0.0.1:39449, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-766698216_1, offset: 0, srvID: 5422153c-cb39-477f-b99e-b1245041abaa, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741825_1001, duration(ns): 27025791
2020-04-02 05:04:10,412 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40672]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40672] terminating
2020-04-02 05:04:10,423 [IPC Server handler 6 on 38542] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/testRenameRoot/srcdir/src1
2020-04-02 05:04:10,830 [IPC Server handler 3 on 38542] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/testRenameRoot/srcdir/src1 is closed by DFSClient_NONMAPREDUCE_-766698216_1
2020-04-02 05:04:10,839 [IPC Server handler 0 on 38542] WARN  hdfs.StateChange (FSDirRenameOp.java:validateRenameSource(566)) - DIR* FSDirectory.unprotectedRenameTo: rename source cannot be the root
2020-04-02 05:04:10,841 [IPC Server handler 0 on 38542] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 0 on 38542, call Call#19 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:48526
java.io.IOException: rename source cannot be the root
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.validateRenameSource(FSDirRenameOp.java:568)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:359)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.rename2(ClientNamenodeProtocolServerSideTranslatorPB.java:668)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:04:10,852 [IPC Server handler 1 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,856 [IPC Server handler 5 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameRoot/srcdir/src1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:10,857 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:38542/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:10,867 [IPC Server handler 9 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameRoot
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameRoot
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCrossFileSystemRename
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:10,887 [IPC Server handler 4 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:10,889 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:38542/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:10,892 [IPC Server handler 7 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCrossFileSystemRename
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCrossFileSystemRename
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testTruncate
[msx] perform reset as unitTestCounterInClass 2 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:10,896 [IPC Server handler 8 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:10,906 [IPC Server handler 2 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:10,916 [IPC Server handler 6 on 38542] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:40672, 127.0.0.1:39449 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:10,922 [DataXceiver for client DFSClient_NONMAPREDUCE_491542954_1 at /127.0.0.1:53880 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741826_1002 src: /127.0.0.1:53880 dest: /127.0.0.1:40672
2020-04-02 05:04:10,924 [DataXceiver for client DFSClient_NONMAPREDUCE_491542954_1 at /127.0.0.1:38630 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741826_1002 src: /127.0.0.1:38630 dest: /127.0.0.1:39449
2020-04-02 05:04:10,932 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38630, dest: /127.0.0.1:39449, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_491542954_1, offset: 0, srvID: 5422153c-cb39-477f-b99e-b1245041abaa, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741826_1002, duration(ns): 6419556
2020-04-02 05:04:10,933 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:10,938 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39449]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53880, dest: /127.0.0.1:40672, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_491542954_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741826_1002, duration(ns): 11137582
2020-04-02 05:04:10,939 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39449]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39449] terminating
2020-04-02 05:04:10,948 [IPC Server handler 5 on 38542] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:39449, 127.0.0.1:40672 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:10,957 [DataXceiver for client DFSClient_NONMAPREDUCE_491542954_1 at /127.0.0.1:38636 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741827_1003 src: /127.0.0.1:38636 dest: /127.0.0.1:39449
2020-04-02 05:04:10,959 [DataXceiver for client DFSClient_NONMAPREDUCE_491542954_1 at /127.0.0.1:53892 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741827_1003 src: /127.0.0.1:53892 dest: /127.0.0.1:40672
2020-04-02 05:04:10,984 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53892, dest: /127.0.0.1:40672, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_491542954_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741827_1003, duration(ns): 22943577
2020-04-02 05:04:10,984 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:10,986 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40672]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38636, dest: /127.0.0.1:39449, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_491542954_1, offset: 0, srvID: 5422153c-cb39-477f-b99e-b1245041abaa, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741827_1003, duration(ns): 25080057
2020-04-02 05:04:10,988 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40672]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40672] terminating
2020-04-02 05:04:10,990 [IPC Server handler 7 on 38542] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_491542954_1
2020-04-02 05:04:10,998 [IPC Server handler 8 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=truncate	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:11,002 [IPC Server handler 2 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:11,005 [main] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:<clinit>(53)) - seed=-1547324985522541270
2020-04-02 05:04:11,008 [IPC Server handler 6 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:11,017 [IPC Server handler 3 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:11,087 [IPC Server handler 0 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:11,098 [IPC Server handler 1 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:11,099 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:38542/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:11,101 [IPC Server handler 5 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testTruncate
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testTruncate
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testEditsLogOldRename
[msx] perform reset as unitTestCounterInClass 3 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:11,106 [IPC Server handler 9 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:11,113 [IPC Server handler 4 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/testEditsLogOldRename/srcdir/src1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:11,121 [IPC Server handler 7 on 38542] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:40672, 127.0.0.1:39449 for /tmp/TestHDFSFileContextMainOperations/testEditsLogOldRename/srcdir/src1
2020-04-02 05:04:11,130 [DataXceiver for client DFSClient_NONMAPREDUCE_-766698216_1 at /127.0.0.1:53910 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741828_1004 src: /127.0.0.1:53910 dest: /127.0.0.1:40672
2020-04-02 05:04:11,140 [DataXceiver for client DFSClient_NONMAPREDUCE_-766698216_1 at /127.0.0.1:38658 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741828_1004 src: /127.0.0.1:38658 dest: /127.0.0.1:39449
2020-04-02 05:04:11,193 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38658, dest: /127.0.0.1:39449, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-766698216_1, offset: 0, srvID: 5422153c-cb39-477f-b99e-b1245041abaa, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741828_1004, duration(ns): 35842668
2020-04-02 05:04:11,194 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:11,218 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39449]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53910, dest: /127.0.0.1:40672, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-766698216_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741828_1004, duration(ns): 32868192
2020-04-02 05:04:11,218 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39449]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39449] terminating
2020-04-02 05:04:11,225 [IPC Server handler 2 on 38542] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/testEditsLogOldRename/srcdir/src1 is closed by DFSClient_NONMAPREDUCE_-766698216_1
2020-04-02 05:04:11,228 [IPC Server handler 3 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/testEditsLogOldRename/dstdir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:11,231 [IPC Server handler 0 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/testEditsLogOldRename/dstdir/dst1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:11,234 [IPC Server handler 1 on 38542] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:39449, 127.0.0.1:40672 for /tmp/TestHDFSFileContextMainOperations/testEditsLogOldRename/dstdir/dst1
2020-04-02 05:04:11,237 [DataXceiver for client DFSClient_NONMAPREDUCE_-766698216_1 at /127.0.0.1:38670 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741829_1005 src: /127.0.0.1:38670 dest: /127.0.0.1:39449
2020-04-02 05:04:11,239 [DataXceiver for client DFSClient_NONMAPREDUCE_-766698216_1 at /127.0.0.1:53928 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741829_1005 src: /127.0.0.1:53928 dest: /127.0.0.1:40672
2020-04-02 05:04:11,260 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53928, dest: /127.0.0.1:40672, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-766698216_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741829_1005, duration(ns): 18830087
2020-04-02 05:04:11,260 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:11,264 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40672]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38670, dest: /127.0.0.1:39449, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-766698216_1, offset: 0, srvID: 5422153c-cb39-477f-b99e-b1245041abaa, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741829_1005, duration(ns): 22532955
2020-04-02 05:04:11,264 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40672]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40672] terminating
2020-04-02 05:04:11,269 [IPC Server handler 4 on 38542] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/testEditsLogOldRename/dstdir/dst1 is closed by DFSClient_NONMAPREDUCE_-766698216_1
2020-04-02 05:04:11,276 [IPC Server handler 7 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/tmp/TestHDFSFileContextMainOperations/testEditsLogOldRename/dstdir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:11,278 [IPC Server handler 8 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations/testEditsLogOldRename/dstdir/dst1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:11,286 [IPC Server handler 6 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/tmp/TestHDFSFileContextMainOperations/testEditsLogOldRename/srcdir/src1	dst=/tmp/TestHDFSFileContextMainOperations/testEditsLogOldRename/dstdir/dst1	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:11,295 [IPC Server handler 2 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/testEditsLogOldRename/srcdir/src1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:11,297 [IPC Server handler 3 on 38542] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/testEditsLogOldRename/dstdir/dst1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:11,298 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:04:11,298 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:04:11,299 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40773 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:11,299 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:11,300 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1c98290c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:11,303 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-40b68935-c633-4c1c-86d0-4f23e2beb39e) exiting.
2020-04-02 05:04:11,305 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-f437bce0-4caf-48d2-b20f-d0ce4fd0dd03) exiting.
2020-04-02 05:04:11,369 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@33352f32{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:11,375 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5f3b9c57{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:11,375 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4204541c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:11,376 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@fd46303{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:04:11,380 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40773
2020-04-02 05:04:11,388 [IPC Server listener on 40773] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40773
2020-04-02 05:04:11,388 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:11,388 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:38542] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:11,389 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:38542] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1054551904-172.17.0.20-1585803845034 (Datanode Uuid 5422153c-cb39-477f-b99e-b1245041abaa) service to localhost/127.0.0.1:38542
2020-04-02 05:04:11,389 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:38542] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1054551904-172.17.0.20-1585803845034 (Datanode Uuid 5422153c-cb39-477f-b99e-b1245041abaa)
2020-04-02 05:04:11,390 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:38542] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:11,401 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1054551904-172.17.0.20-1585803845034] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:11,413 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1054551904-172.17.0.20-1585803845034] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:11,420 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:11,420 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:11,421 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:11,421 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:11,431 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:11,431 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:04:11,431 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 41557 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:11,432 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:11,433 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4212a0c8] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:11,433 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-54746245-acee-4605-b3a2-76160e1ebb72) exiting.
2020-04-02 05:04:11,434 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-eec506ae-cf75-4c6b-9ece-cd33e8e8b2ee) exiting.
2020-04-02 05:04:11,466 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@fb9c7aa{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:11,467 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4c398c80{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:11,468 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@abf688e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:11,468 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@320de594{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:04:11,470 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41557
2020-04-02 05:04:11,484 [IPC Server listener on 41557] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41557
2020-04-02 05:04:11,486 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:11,486 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:38542] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:11,489 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:38542] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1054551904-172.17.0.20-1585803845034 (Datanode Uuid 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91) service to localhost/127.0.0.1:38542
2020-04-02 05:04:11,489 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:38542] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1054551904-172.17.0.20-1585803845034 (Datanode Uuid 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91)
2020-04-02 05:04:11,489 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:38542] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:11,500 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:11,507 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:11,513 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:11,513 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:11,514 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:11,515 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:11,517 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:11,517 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:04:11,517 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 38542 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:11,518 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:11,518 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 49
2020-04-02 05:04:11,518 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@5066d65f] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:04:11,519 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@3401a114] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:04:11,519 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 50 Total time for transactions(ms): 42 Number of transactions batched in Syncs: 16 Number of syncs: 35 SyncTimes(ms): 9 17 
2020-04-02 05:04:11,521 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000050
2020-04-02 05:04:11,521 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000050
2020-04-02 05:04:11,522 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:04:11,523 [CacheReplicationMonitor(1443785558)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:04:11,530 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38542
2020-04-02 05:04:11,531 [IPC Server listener on 38542] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38542
2020-04-02 05:04:11,534 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:11,535 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:04:11,535 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:04:11,569 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:11,569 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:04:11,570 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@544d57e{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:04:11,581 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@27e47833{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:11,584 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@642a7222{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:11,585 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6d5620ce{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:04:11,588 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:04:11,593 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:04:11,594 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:04:11,603 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:04:11,605 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:04:11,611 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:04:11,613 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:04:11,614 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:04:11,615 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:04:11,615 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:04:11,623 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3f093abe] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:04:11,623 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:04:11,624 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:11,626 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:04:11,627 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:04:11,627 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:11,629 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:04:11,630 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:04:11,630 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:04:11,630 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:04:11,632 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:04:11,633 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:04:11,633 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 32974
2020-04-02 05:04:11,634 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:04:11,636 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5aabbb29{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:04:11,637 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1ac85b0c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:04:11,644 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@617fe9e1{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:04:11,645 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6970140a{HTTP/1.1,[http/1.1]}{localhost:32974}
2020-04-02 05:04:11,648 [main] INFO  server.Server (Server.java:doStart(419)) - Started @9158ms
2020-04-02 05:04:11,652 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:04:11,653 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:04:11,653 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:04:11,653 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:04:11,653 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:04:11,654 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:04:11,654 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:04:11,654 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:04:11,655 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:11,655 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:04:11,655 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:04:11,656 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:04:11,656 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:04:11
2020-04-02 05:04:11,656 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:04:11,656 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:11,657 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:04:11,657 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:04:11,670 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:04:11,671 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:04:11,671 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:04:11,671 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:04:11,671 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:04:11,671 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:04:11,672 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:04:11,672 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:04:11,672 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:04:11,672 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:04:11,672 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:04:11,672 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:04:11,673 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:04:11,673 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:11,673 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:04:11,673 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:04:11,680 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:04:11,680 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:04:11,681 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:04:11,681 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:04:11,681 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:04:11,681 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:04:11,682 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:04:11,682 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:11,682 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:04:11,683 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:04:11,685 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:04:11,685 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:04:11,685 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:04:11,686 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:04:11,687 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:04:11,687 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:04:11,687 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:11,687 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:04:11,688 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:04:11,691 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 5253@59c1167abdeb
2020-04-02 05:04:11,692 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 5253@59c1167abdeb
2020-04-02 05:04:11,694 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:04:11,696 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:04:11,703 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:04:11,704 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:04:11,706 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:04:11,706 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:04:11,706 [main] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6815c5f2 expecting start txid #1
2020-04-02 05:04:11,706 [main] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000050, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000050 maxTxnsToRead = 9223372036854775807
2020-04-02 05:04:11,707 [main] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000050' to transaction ID 1
2020-04-02 05:04:11,729 [main] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000050, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000050 of size 5138 edits # 50 loaded in 0 seconds
2020-04-02 05:04:11,729 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:04:11,730 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 51
2020-04-02 05:04:11,745 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:04:11,746 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 57 msecs
2020-04-02 05:04:11,746 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:04:11,746 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:04:11,747 [Socket Reader #1 for port 34890] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34890
2020-04-02 05:04:11,752 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:34890 to access this namenode/service.
2020-04-02 05:04:11,753 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:04:11,791 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:04:11,795 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:04:11,796 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:04:11,796 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:04:11,797 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:04:11,945 [IPC Server listener on 34890] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34890: starting
2020-04-02 05:04:11,945 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:04:11,952 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:04:11,952 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:04:11,952 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:04:11,952 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:04:11,953 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:04:11,953 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 147 msec
2020-04-02 05:04:11,959 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:34890
2020-04-02 05:04:11,959 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:04:11,959 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:04:11,969 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 9 milliseconds
name space=10
storage space=4096
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:04:11,977 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 34890 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:11,981 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:04:11,982 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:04:11,983 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:04:11,994 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:04:11,994 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:04:11,995 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:11,995 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:04:11,995 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:04:11,995 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:11,996 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:04:11,997 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:45100
2020-04-02 05:04:11,997 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:04:11,997 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:04:11,998 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:12,000 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:04:12,001 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:04:12,001 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:12,002 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:04:12,003 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:04:12,003 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:04:12,003 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:04:12,004 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43844
2020-04-02 05:04:12,005 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:04:11,995 [CacheReplicationMonitor(1206601926)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:04:12,022 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@127e70c5{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:04:12,030 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4108fa66{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:04:12,055 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5ebd56e9{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:04:12,058 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@63f34b70{HTTP/1.1,[http/1.1]}{localhost:43844}
2020-04-02 05:04:12,058 [main] INFO  server.Server (Server.java:doStart(419)) - Started @9568ms
2020-04-02 05:04:12,082 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37003
2020-04-02 05:04:12,083 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:04:12,083 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1b58ff9e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:04:12,083 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:04:12,084 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:04:12,084 [Socket Reader #1 for port 33958] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33958
2020-04-02 05:04:12,093 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:33958
2020-04-02 05:04:12,101 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:04:12,102 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:04:12,102 [Thread-205] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34890 starting to offer service
2020-04-02 05:04:12,106 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:04:12,107 [IPC Server listener on 33958] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33958: starting
2020-04-02 05:04:12,115 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 33958 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:12,117 [Thread-205] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34890
2020-04-02 05:04:12,119 [Thread-205] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:04:12,122 [Thread-205] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 5253@59c1167abdeb
2020-04-02 05:04:12,128 [IPC Server handler 1 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:12,129 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:04:12,129 [Thread-205] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 5253@59c1167abdeb
2020-04-02 05:04:12,129 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:04:12,138 [Thread-205] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:12,138 [Thread-205] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:12,147 [Thread-205] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:12,148 [Thread-205] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:12,149 [Thread-205] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=471869960;bpid=BP-1054551904-172.17.0.20-1585803845034;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=471869960;c=1585803845034;bpid=BP-1054551904-172.17.0.20-1585803845034;dnuuid=5175af85-f0ed-4fdf-bbb6-c6b1d202ce91
2020-04-02 05:04:12,152 [Thread-205] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-54746245-acee-4605-b3a2-76160e1ebb72
2020-04-02 05:04:12,152 [Thread-205] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:04:12,156 [Thread-205] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-eec506ae-cf75-4c6b-9ece-cd33e8e8b2ee
2020-04-02 05:04:12,158 [Thread-205] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:04:12,159 [Thread-205] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:04:12,160 [Thread-205] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:04:12,163 [Thread-205] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:04:12,164 [Thread-205] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:04:12,166 [Thread-205] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:04:12,166 [Thread-205] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:12,167 [Thread-220] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:04:12,168 [Thread-221] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:04:12,170 [Thread-220] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current: 29757
2020-04-02 05:04:12,170 [Thread-221] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current: 27686
2020-04-02 05:04:12,178 [Thread-221] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1054551904-172.17.0.20-1585803845034 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 10ms
2020-04-02 05:04:12,187 [Thread-220] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1054551904-172.17.0.20-1585803845034 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 20ms
2020-04-02 05:04:12,187 [Thread-205] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1054551904-172.17.0.20-1585803845034: 22ms
2020-04-02 05:04:12,188 [Thread-222] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:04:12,188 [Thread-223] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:04:12,191 [Thread-223] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/replicas
2020-04-02 05:04:12,191 [Thread-223] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 3ms
2020-04-02 05:04:12,194 [Thread-222] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/replicas
2020-04-02 05:04:12,194 [Thread-222] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 6ms
2020-04-02 05:04:12,196 [Thread-205] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1054551904-172.17.0.20-1585803845034: 8ms
2020-04-02 05:04:12,209 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-54746245-acee-4605-b3a2-76160e1ebb72): no suitable block pools found to scan.  Waiting 1814397746 ms.
2020-04-02 05:04:12,209 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-eec506ae-cf75-4c6b-9ece-cd33e8e8b2ee): no suitable block pools found to scan.  Waiting 1814397747 ms.
2020-04-02 05:04:12,213 [Thread-205] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:50 AM with interval of 21600000ms
2020-04-02 05:04:12,220 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:34890] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1054551904-172.17.0.20-1585803845034 (Datanode Uuid 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91) service to localhost/127.0.0.1:34890 beginning handshake with NN
2020-04-02 05:04:12,222 [IPC Server handler 2 on 34890] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45100, datanodeUuid=5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, infoPort=37003, infoSecurePort=0, ipcPort=33958, storageInfo=lv=-57;cid=testClusterID;nsid=471869960;c=1585803845034) storage 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91
2020-04-02 05:04:12,222 [IPC Server handler 2 on 34890] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45100
2020-04-02 05:04:12,222 [IPC Server handler 2 on 34890] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91 (127.0.0.1:45100).
2020-04-02 05:04:12,227 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:34890] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1054551904-172.17.0.20-1585803845034 (Datanode Uuid 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91) service to localhost/127.0.0.1:34890 successfully registered with NN
2020-04-02 05:04:12,227 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:34890] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:34890 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:04:12,233 [IPC Server handler 4 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:12,233 [IPC Server handler 3 on 34890] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-54746245-acee-4605-b3a2-76160e1ebb72 for DN 127.0.0.1:45100
2020-04-02 05:04:12,235 [IPC Server handler 3 on 34890] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-eec506ae-cf75-4c6b-9ece-cd33e8e8b2ee for DN 127.0.0.1:45100
2020-04-02 05:04:12,235 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2718)) - No heartbeat from DataNode: 127.0.0.1:45100
2020-04-02 05:04:12,237 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:04:12,241 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa3fc4124eb02faa7: Processing first storage report for DS-54746245-acee-4605-b3a2-76160e1ebb72 from datanode 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91
2020-04-02 05:04:12,242 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa3fc4124eb02faa7: from storage DS-54746245-acee-4605-b3a2-76160e1ebb72 node DatanodeRegistration(127.0.0.1:45100, datanodeUuid=5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, infoPort=37003, infoSecurePort=0, ipcPort=33958, storageInfo=lv=-57;cid=testClusterID;nsid=471869960;c=1585803845034), blocks: 3, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:04:12,243 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa3fc4124eb02faa7: Processing first storage report for DS-eec506ae-cf75-4c6b-9ece-cd33e8e8b2ee from datanode 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91
2020-04-02 05:04:12,244 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa3fc4124eb02faa7: from storage DS-eec506ae-cf75-4c6b-9ece-cd33e8e8b2ee node DatanodeRegistration(127.0.0.1:45100, datanodeUuid=5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, infoPort=37003, infoSecurePort=0, ipcPort=33958, storageInfo=lv=-57;cid=testClusterID;nsid=471869960;c=1585803845034), blocks: 2, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:04:12,246 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:34890] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xa3fc4124eb02faa7,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 0 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:04:12,247 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:34890] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:12,338 [IPC Server handler 6 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:12,339 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:04:12,347 [IPC Server handler 7 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:12,350 [IPC Server handler 8 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/testEditsLogOldRename/srcdir/src1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:12,351 [IPC Server handler 9 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/testEditsLogOldRename/dstdir/dst1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:12,352 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:34890/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:12,358 [IPC Server handler 0 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testEditsLogOldRename
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testEditsLogOldRename
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testOldRenameWithQuota
[msx] perform reset as unitTestCounterInClass 4 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:12,364 [IPC Server handler 1 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:12,369 [IPC Server handler 4 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/testOldRenameWithQuota/srcdir/src1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:12,377 [IPC Server handler 3 on 34890] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:45100 for /tmp/TestHDFSFileContextMainOperations/test/testOldRenameWithQuota/srcdir/src1
2020-04-02 05:04:12,395 [DataXceiver for client DFSClient_NONMAPREDUCE_279830253_1 at /127.0.0.1:42058 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741830_1006 src: /127.0.0.1:42058 dest: /127.0.0.1:45100
2020-04-02 05:04:12,421 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42058, dest: /127.0.0.1:45100, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_279830253_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741830_1006, duration(ns): 16225879
2020-04-02 05:04:12,423 [IPC Server handler 5 on 34890] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741830_1006 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/testOldRenameWithQuota/srcdir/src1
2020-04-02 05:04:12,426 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:12,827 [IPC Server handler 7 on 34890] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/testOldRenameWithQuota/srcdir/src1 is closed by DFSClient_NONMAPREDUCE_279830253_1
2020-04-02 05:04:12,830 [IPC Server handler 8 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/testOldRenameWithQuota/srcdir/src2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:12,836 [IPC Server handler 9 on 34890] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:45100 for /tmp/TestHDFSFileContextMainOperations/test/testOldRenameWithQuota/srcdir/src2
2020-04-02 05:04:12,839 [DataXceiver for client DFSClient_NONMAPREDUCE_279830253_1 at /127.0.0.1:42148 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741831_1007 src: /127.0.0.1:42148 dest: /127.0.0.1:45100
2020-04-02 05:04:12,875 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42148, dest: /127.0.0.1:45100, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_279830253_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741831_1007, duration(ns): 32245800
2020-04-02 05:04:12,875 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:12,877 [IPC Server handler 1 on 34890] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/testOldRenameWithQuota/srcdir/src2 is closed by DFSClient_NONMAPREDUCE_279830253_1
2020-04-02 05:04:12,878 [IPC Server handler 2 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/tmp/TestHDFSFileContextMainOperations/test/testOldRenameWithQuota/srcdir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:12,880 [IPC Server handler 4 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/testOldRenameWithQuota/dstdir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:12,881 [IPC Server handler 3 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/tmp/TestHDFSFileContextMainOperations/test/testOldRenameWithQuota/dstdir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:12,883 [IPC Server handler 5 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/tmp/TestHDFSFileContextMainOperations/test/testOldRenameWithQuota/srcdir/src1	dst=/tmp/TestHDFSFileContextMainOperations/test/testOldRenameWithQuota/dstdir/dst1	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:12,884 [IPC Server handler 6 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testOldRenameWithQuota/srcdir/src1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:12,885 [IPC Server handler 7 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testOldRenameWithQuota/dstdir/dst1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:12,888 [IPC Server handler 8 on 34890] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 8 on 34890, call Call#87 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename from 127.0.0.1:47654: org.apache.hadoop.hdfs.protocol.NSQuotaExceededException: The NameSpace quota (directories and files) of directory /tmp/TestHDFSFileContextMainOperations/test/testOldRenameWithQuota/dstdir is exceeded: quota=2 file count=3
2020-04-02 05:04:12,892 [IPC Server handler 9 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testOldRenameWithQuota/srcdir/src2	dst=null	perm=null	proto=rpc
2020-04-02 05:04:12,893 [IPC Server handler 0 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testOldRenameWithQuota/dstdir/dst2	dst=null	perm=null	proto=rpc
2020-04-02 05:04:12,895 [IPC Server handler 1 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/tmp/TestHDFSFileContextMainOperations/test/testOldRenameWithQuota/srcdir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:12,896 [IPC Server handler 2 on 34890] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 2 on 34890, call Call#91 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename from 127.0.0.1:47654: org.apache.hadoop.hdfs.protocol.NSQuotaExceededException: The NameSpace quota (directories and files) of directory /tmp/TestHDFSFileContextMainOperations/test/testOldRenameWithQuota/srcdir is exceeded: quota=1 file count=3
2020-04-02 05:04:12,900 [IPC Server handler 4 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testOldRenameWithQuota/dstdir/dst1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:12,902 [IPC Server handler 3 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testOldRenameWithQuota/srcdir/src1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:12,907 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:34890/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:12,910 [IPC Server handler 5 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testOldRenameWithQuota
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testOldRenameWithQuota
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameWithQuota
[msx] perform reset as unitTestCounterInClass 5 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:12,914 [IPC Server handler 6 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:12,920 [IPC Server handler 7 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir/src1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:12,930 [IPC Server handler 8 on 34890] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741832_1008, replicas=127.0.0.1:45100 for /tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir/src1
2020-04-02 05:04:12,942 [DataXceiver for client DFSClient_NONMAPREDUCE_279830253_1 at /127.0.0.1:42166 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741832_1008 src: /127.0.0.1:42166 dest: /127.0.0.1:45100
2020-04-02 05:04:12,978 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42166, dest: /127.0.0.1:45100, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_279830253_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741832_1008, duration(ns): 16216894
2020-04-02 05:04:12,978 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:12,981 [IPC Server handler 9 on 34890] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir/src1 is closed by DFSClient_NONMAPREDUCE_279830253_1
2020-04-02 05:04:12,984 [IPC Server handler 1 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir/src2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:12,993 [IPC Server handler 2 on 34890] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741833_1009, replicas=127.0.0.1:45100 for /tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir/src2
2020-04-02 05:04:12,997 [DataXceiver for client DFSClient_NONMAPREDUCE_279830253_1 at /127.0.0.1:42172 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741833_1009 src: /127.0.0.1:42172 dest: /127.0.0.1:45100
2020-04-02 05:04:13,012 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42172, dest: /127.0.0.1:45100, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_279830253_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741833_1009, duration(ns): 9470425
2020-04-02 05:04:13,012 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:13,014 [IPC Server handler 3 on 34890] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir/src2 is closed by DFSClient_NONMAPREDUCE_279830253_1
2020-04-02 05:04:13,015 [IPC Server handler 5 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:13,017 [IPC Server handler 6 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/dstdir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:13,019 [IPC Server handler 7 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/dstdir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:13,020 [IPC Server handler 8 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename (options=[TO_TRASH])	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir/src1	dst=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/dstdir/dst1	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:13,024 [IPC Server handler 0 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir/src1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:13,029 [IPC Server handler 9 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/dstdir/dst1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:13,032 [IPC Server handler 1 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename (options=[OVERWRITE])	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir/src2	dst=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/dstdir/dst1	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:13,033 [IPC Server handler 2 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir/src2	dst=null	perm=null	proto=rpc
2020-04-02 05:04:13,034 [IPC Server handler 4 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/dstdir/dst1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:13,037 [IPC Server handler 3 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir/src2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:13,041 [IPC Server handler 5 on 34890] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741834_1010, replicas=127.0.0.1:45100 for /tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir/src2
2020-04-02 05:04:13,045 [DataXceiver for client DFSClient_NONMAPREDUCE_279830253_1 at /127.0.0.1:42176 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741834_1010 src: /127.0.0.1:42176 dest: /127.0.0.1:45100
2020-04-02 05:04:13,070 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42176, dest: /127.0.0.1:45100, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_279830253_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741834_1010, duration(ns): 20727872
2020-04-02 05:04:13,071 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:13,079 [IPC Server handler 7 on 34890] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741834_1010 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir/src2
2020-04-02 05:04:13,483 [IPC Server handler 8 on 34890] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir/src2 is closed by DFSClient_NONMAPREDUCE_279830253_1
2020-04-02 05:04:13,485 [IPC Server handler 0 on 34890] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 0 on 34890, call Call#118 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:47654: org.apache.hadoop.hdfs.protocol.NSQuotaExceededException: The NameSpace quota (directories and files) of directory /tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/dstdir is exceeded: quota=2 file count=3
2020-04-02 05:04:13,489 [IPC Server handler 9 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir/src2	dst=null	perm=null	proto=rpc
2020-04-02 05:04:13,491 [IPC Server handler 1 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/dstdir/dst2	dst=null	perm=null	proto=rpc
2020-04-02 05:04:13,492 [IPC Server handler 2 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:13,494 [IPC Server handler 4 on 34890] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 4 on 34890, call Call#122 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:47654: org.apache.hadoop.hdfs.protocol.NSQuotaExceededException: The NameSpace quota (directories and files) of directory /tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir is exceeded: quota=1 file count=3
2020-04-02 05:04:13,498 [IPC Server handler 3 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/dstdir/dst1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:13,499 [IPC Server handler 5 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir/src1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:13,501 [IPC Server handler 6 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:13,503 [IPC Server handler 7 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir/src1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:13,508 [IPC Server handler 8 on 34890] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741835_1011, replicas=127.0.0.1:45100 for /tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir/src1
2020-04-02 05:04:13,512 [DataXceiver for client DFSClient_NONMAPREDUCE_279830253_1 at /127.0.0.1:42196 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741835_1011 src: /127.0.0.1:42196 dest: /127.0.0.1:45100
2020-04-02 05:04:13,588 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42196, dest: /127.0.0.1:45100, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_279830253_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741835_1011, duration(ns): 51313182
2020-04-02 05:04:13,591 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:13,594 [IPC Server handler 9 on 34890] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir/src1 is closed by DFSClient_NONMAPREDUCE_279830253_1
2020-04-02 05:04:13,596 [IPC Server handler 1 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:13,598 [IPC Server handler 2 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename (options=[OVERWRITE])	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/dstdir/dst1	dst=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir/src1	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:13,600 [IPC Server handler 4 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/dstdir/dst1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:13,601 [IPC Server handler 3 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameWithQuota/srcdir/src1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:13,601 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:34890/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:13,603 [IPC Server handler 5 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameWithQuota
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameWithQuota
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testIsValidNameInvalidNames
[msx] perform reset as unitTestCounterInClass 6 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:13,609 [IPC Server handler 6 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:13,610 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:34890/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:13,611 [IPC Server handler 7 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testIsValidNameInvalidNames
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testIsValidNameInvalidNames
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameToRoot
[msx] perform reset as unitTestCounterInClass 7 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:13,627 [IPC Server handler 8 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:13,630 [IPC Server handler 0 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameRoot/srcdir/src1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:13,644 [IPC Server handler 9 on 34890] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741836_1012, replicas=127.0.0.1:45100 for /tmp/TestHDFSFileContextMainOperations/test/testRenameRoot/srcdir/src1
2020-04-02 05:04:13,654 [DataXceiver for client DFSClient_NONMAPREDUCE_279830253_1 at /127.0.0.1:42208 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741836_1012 src: /127.0.0.1:42208 dest: /127.0.0.1:45100
2020-04-02 05:04:13,718 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42208, dest: /127.0.0.1:45100, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_279830253_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741836_1012, duration(ns): 41316208
2020-04-02 05:04:13,718 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:13,722 [IPC Server handler 2 on 34890] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741836_1012 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/testRenameRoot/srcdir/src1
2020-04-02 05:04:14,124 [IPC Server handler 4 on 34890] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/testRenameRoot/srcdir/src1 is closed by DFSClient_NONMAPREDUCE_279830253_1
2020-04-02 05:04:14,128 [IPC Server handler 3 on 34890] WARN  hdfs.StateChange (FSDirRenameOp.java:unprotectedRenameTo(370)) - DIR* FSDirectory.unprotectedRenameTo: rename destination cannot be the root
2020-04-02 05:04:14,129 [IPC Server handler 3 on 34890] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 3 on 34890, call Call#143 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:47654
java.io.IOException: rename destination cannot be the root
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:372)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.rename2(ClientNamenodeProtocolServerSideTranslatorPB.java:668)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:04:14,132 [IPC Server handler 5 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testRenameRoot/srcdir/src1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:14,135 [IPC Server handler 6 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:04:14,136 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:34890/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:14,138 [IPC Server handler 7 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameToRoot
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameToRoot
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testEditsLogRename
[msx] perform reset as unitTestCounterInClass 8 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:14,142 [IPC Server handler 8 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:14,145 [IPC Server handler 0 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/testEditsLogRename/srcdir/src1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:14,162 [IPC Server handler 9 on 34890] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741837_1013, replicas=127.0.0.1:45100 for /tmp/TestHDFSFileContextMainOperations/testEditsLogRename/srcdir/src1
2020-04-02 05:04:14,165 [DataXceiver for client DFSClient_NONMAPREDUCE_279830253_1 at /127.0.0.1:42252 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741837_1013 src: /127.0.0.1:42252 dest: /127.0.0.1:45100
2020-04-02 05:04:14,169 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42252, dest: /127.0.0.1:45100, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_279830253_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741837_1013, duration(ns): 2514838
2020-04-02 05:04:14,170 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:14,171 [IPC Server handler 2 on 34890] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/testEditsLogRename/srcdir/src1 is closed by DFSClient_NONMAPREDUCE_279830253_1
2020-04-02 05:04:14,172 [IPC Server handler 4 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/testEditsLogRename/dstdir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:14,174 [IPC Server handler 3 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/testEditsLogRename/dstdir/dst1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:14,177 [IPC Server handler 5 on 34890] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741838_1014, replicas=127.0.0.1:45100 for /tmp/TestHDFSFileContextMainOperations/testEditsLogRename/dstdir/dst1
2020-04-02 05:04:14,179 [DataXceiver for client DFSClient_NONMAPREDUCE_279830253_1 at /127.0.0.1:42258 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741838_1014 src: /127.0.0.1:42258 dest: /127.0.0.1:45100
2020-04-02 05:04:14,191 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42258, dest: /127.0.0.1:45100, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_279830253_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741838_1014, duration(ns): 9608580
2020-04-02 05:04:14,191 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:14,192 [IPC Server handler 7 on 34890] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741838_1014 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/testEditsLogRename/dstdir/dst1
2020-04-02 05:04:14,594 [IPC Server handler 8 on 34890] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/testEditsLogRename/dstdir/dst1 is closed by DFSClient_NONMAPREDUCE_279830253_1
2020-04-02 05:04:14,596 [IPC Server handler 0 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/tmp/TestHDFSFileContextMainOperations/testEditsLogRename/dstdir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:14,597 [IPC Server handler 9 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations/testEditsLogRename/dstdir/dst1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:14,599 [IPC Server handler 1 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename (options=[OVERWRITE])	src=/tmp/TestHDFSFileContextMainOperations/testEditsLogRename/srcdir/src1	dst=/tmp/TestHDFSFileContextMainOperations/testEditsLogRename/dstdir/dst1	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:14,600 [IPC Server handler 2 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/testEditsLogRename/srcdir/src1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:14,601 [IPC Server handler 4 on 34890] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/testEditsLogRename/dstdir/dst1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:14,601 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:04:14,602 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:04:14,602 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33958 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:14,602 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:14,602 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@71f67a79] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:14,603 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-54746245-acee-4605-b3a2-76160e1ebb72) exiting.
2020-04-02 05:04:14,603 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-eec506ae-cf75-4c6b-9ece-cd33e8e8b2ee) exiting.
2020-04-02 05:04:14,623 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5ebd56e9{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:14,624 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@63f34b70{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:14,624 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4108fa66{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:14,625 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@127e70c5{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:04:14,626 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33958
2020-04-02 05:04:14,628 [IPC Server listener on 33958] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33958
2020-04-02 05:04:14,630 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:14,630 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:34890] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:14,631 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:34890] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1054551904-172.17.0.20-1585803845034 (Datanode Uuid 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91) service to localhost/127.0.0.1:34890
2020-04-02 05:04:14,634 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:34890] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1054551904-172.17.0.20-1585803845034 (Datanode Uuid 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91)
2020-04-02 05:04:14,634 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:34890] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:14,648 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:14,657 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:14,659 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:14,660 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:14,660 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:14,660 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:14,661 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:14,662 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:04:14,662 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 34890 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:14,662 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:14,662 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 51, 135
2020-04-02 05:04:14,662 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@70925b45] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:04:14,662 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@4b629f13] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:04:14,663 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 86 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 74 Number of syncs: 63 SyncTimes(ms): 5 5 
2020-04-02 05:04:14,663 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000051 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000051-0000000000000000136
2020-04-02 05:04:14,664 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000051 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000051-0000000000000000136
2020-04-02 05:04:14,664 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:04:14,665 [CacheReplicationMonitor(1206601926)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:04:14,667 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34890
2020-04-02 05:04:14,671 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:14,671 [IPC Server listener on 34890] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34890
2020-04-02 05:04:14,671 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:04:14,671 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:04:14,680 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:14,680 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:04:14,681 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@617fe9e1{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:04:14,683 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6970140a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:14,683 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1ac85b0c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:14,683 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5aabbb29{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:04:14,684 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:04:14,686 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:04:14,686 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:04:14,692 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:04:14,693 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:04:14,697 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:04:14,699 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:04:14,699 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:04:14,699 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:04:14,700 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:04:14,704 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@10027fc9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:04:14,704 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:04:14,705 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:14,706 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:04:14,706 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:04:14,706 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:14,707 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:04:14,708 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:04:14,708 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:04:14,708 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:04:14,709 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:04:14,709 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:04:14,710 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44499
2020-04-02 05:04:14,710 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:04:14,711 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2ca47471{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:04:14,712 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@51768776{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:04:14,718 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2970a5bc{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:04:14,720 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@50305a{HTTP/1.1,[http/1.1]}{localhost:44499}
2020-04-02 05:04:14,720 [main] INFO  server.Server (Server.java:doStart(419)) - Started @12230ms
2020-04-02 05:04:14,723 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:04:14,723 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:04:14,723 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:04:14,723 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:04:14,724 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:04:14,724 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:04:14,724 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:04:14,724 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:04:14,725 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:14,725 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:04:14,725 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:04:14,725 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:04:14,726 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:04:14
2020-04-02 05:04:14,726 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:04:14,726 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:14,726 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:04:14,727 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:04:14,730 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:04:14,730 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:04:14,730 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:04:14,730 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:04:14,730 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:04:14,731 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:04:14,731 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:04:14,731 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:04:14,731 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:04:14,731 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:04:14,731 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:04:14,731 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:04:14,732 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:04:14,732 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:14,732 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:04:14,732 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:04:14,735 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:04:14,735 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:04:14,735 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:04:14,735 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:04:14,735 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:04:14,735 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:04:14,735 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:04:14,735 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:14,736 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:04:14,736 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:04:14,736 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:04:14,736 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:04:14,736 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:04:14,737 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:04:14,737 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:04:14,737 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:04:14,738 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:04:14,738 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:04:14,738 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:04:14,741 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 5253@59c1167abdeb
2020-04-02 05:04:14,741 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 5253@59c1167abdeb
2020-04-02 05:04:14,743 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:04:14,743 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:04:14,743 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:04:14,744 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:04:14,745 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:04:14,745 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:04:14,745 [main] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6bc28a83 expecting start txid #1
2020-04-02 05:04:14,746 [main] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000050, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000050 maxTxnsToRead = 9223372036854775807
2020-04-02 05:04:14,746 [main] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000050' to transaction ID 1
2020-04-02 05:04:14,751 [main] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000050, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000050 of size 5138 edits # 50 loaded in 0 seconds
2020-04-02 05:04:14,751 [main] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@324c64cd expecting start txid #51
2020-04-02 05:04:14,751 [main] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000051-0000000000000000136, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000051-0000000000000000136 maxTxnsToRead = 9223372036854775807
2020-04-02 05:04:14,752 [main] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000051-0000000000000000136' to transaction ID 1
2020-04-02 05:04:14,765 [main] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000051-0000000000000000136, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000051-0000000000000000136 of size 9906 edits # 86 loaded in 0 seconds
2020-04-02 05:04:14,766 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:04:14,766 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 137
2020-04-02 05:04:14,776 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:04:14,776 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 37 msecs
2020-04-02 05:04:14,777 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:04:14,777 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:04:14,778 [Socket Reader #1 for port 43909] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43909
2020-04-02 05:04:14,783 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:43909 to access this namenode/service.
2020-04-02 05:04:14,783 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:04:14,805 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:04:14,807 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:04:14,808 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:04:14,808 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:04:14,808 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:04:14,815 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:04:14,815 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:04:14,815 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:04:14,815 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:04:14,815 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:04:14,815 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 7 msec
2020-04-02 05:04:14,819 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:04:14,819 [IPC Server listener on 43909] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43909: starting
2020-04-02 05:04:14,822 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:43909
2020-04-02 05:04:14,823 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:04:14,823 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:04:14,826 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 3 milliseconds
name space=10
storage space=2048
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:04:14,828 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 43909 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:14,830 [CacheReplicationMonitor(837841609)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:04:14,832 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:04:14,833 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:04:14,834 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:04:14,835 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:04:14,836 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:04:14,836 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:14,836 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:04:14,837 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:04:14,837 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:04:14,837 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:04:14,838 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:36017
2020-04-02 05:04:14,838 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:04:14,839 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:04:14,840 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:14,842 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:04:14,843 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:04:14,843 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:04:14,844 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:04:14,845 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:04:14,845 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:04:14,845 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:04:14,846 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33976
2020-04-02 05:04:14,846 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:04:14,847 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@14bb2297{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:04:14,848 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@797501a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:04:14,854 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1c25b8a7{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:04:14,856 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@200606de{HTTP/1.1,[http/1.1]}{localhost:33976}
2020-04-02 05:04:14,856 [main] INFO  server.Server (Server.java:doStart(419)) - Started @12366ms
2020-04-02 05:04:14,876 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40229
2020-04-02 05:04:14,876 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:04:14,876 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@f8908f6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:04:14,876 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:04:14,877 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:04:14,877 [Socket Reader #1 for port 39974] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39974
2020-04-02 05:04:14,880 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:39974
2020-04-02 05:04:14,883 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:04:14,883 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:04:14,884 [Thread-314] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43909 starting to offer service
2020-04-02 05:04:14,887 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:04:14,887 [IPC Server listener on 39974] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39974: starting
2020-04-02 05:04:14,892 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 39974 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:14,895 [Thread-314] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43909
2020-04-02 05:04:14,896 [Thread-314] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:04:14,899 [Thread-314] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 5253@59c1167abdeb
2020-04-02 05:04:14,900 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:14,900 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:04:14,901 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:04:14,902 [Thread-314] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 5253@59c1167abdeb
2020-04-02 05:04:14,915 [Thread-314] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:14,915 [Thread-314] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:14,926 [Thread-314] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:14,927 [Thread-314] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:14,928 [Thread-314] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=471869960;bpid=BP-1054551904-172.17.0.20-1585803845034;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=471869960;c=1585803845034;bpid=BP-1054551904-172.17.0.20-1585803845034;dnuuid=5175af85-f0ed-4fdf-bbb6-c6b1d202ce91
2020-04-02 05:04:14,930 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-54746245-acee-4605-b3a2-76160e1ebb72
2020-04-02 05:04:14,931 [Thread-314] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:04:14,934 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-eec506ae-cf75-4c6b-9ece-cd33e8e8b2ee
2020-04-02 05:04:14,935 [Thread-314] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:04:14,936 [Thread-314] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:04:14,937 [Thread-314] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:04:14,938 [Thread-314] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:04:14,938 [Thread-314] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:04:14,938 [Thread-314] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:04:14,938 [Thread-314] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:14,939 [Thread-329] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:04:14,939 [Thread-330] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:04:14,940 [Thread-330] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current: 35970
2020-04-02 05:04:14,941 [Thread-329] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current: 40112
2020-04-02 05:04:14,947 [Thread-330] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1054551904-172.17.0.20-1585803845034 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 8ms
2020-04-02 05:04:14,955 [Thread-329] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1054551904-172.17.0.20-1585803845034 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 16ms
2020-04-02 05:04:14,955 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1054551904-172.17.0.20-1585803845034: 16ms
2020-04-02 05:04:14,955 [Thread-331] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:04:14,956 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:04:14,957 [Thread-331] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/replicas
2020-04-02 05:04:14,958 [Thread-332] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/replicas
2020-04-02 05:04:14,958 [Thread-331] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 2ms
2020-04-02 05:04:14,958 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1054551904-172.17.0.20-1585803845034 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 2ms
2020-04-02 05:04:14,958 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1054551904-172.17.0.20-1585803845034: 3ms
2020-04-02 05:04:14,959 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-54746245-acee-4605-b3a2-76160e1ebb72): no suitable block pools found to scan.  Waiting 1814394997 ms.
2020-04-02 05:04:14,959 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-eec506ae-cf75-4c6b-9ece-cd33e8e8b2ee): no suitable block pools found to scan.  Waiting 1814394997 ms.
2020-04-02 05:04:14,959 [Thread-314] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:27 AM with interval of 21600000ms
2020-04-02 05:04:14,961 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1054551904-172.17.0.20-1585803845034 (Datanode Uuid 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91) service to localhost/127.0.0.1:43909 beginning handshake with NN
2020-04-02 05:04:14,962 [IPC Server handler 2 on 43909] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36017, datanodeUuid=5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, infoPort=40229, infoSecurePort=0, ipcPort=39974, storageInfo=lv=-57;cid=testClusterID;nsid=471869960;c=1585803845034) storage 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91
2020-04-02 05:04:14,962 [IPC Server handler 2 on 43909] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36017
2020-04-02 05:04:14,962 [IPC Server handler 2 on 43909] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91 (127.0.0.1:36017).
2020-04-02 05:04:14,964 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1054551904-172.17.0.20-1585803845034 (Datanode Uuid 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91) service to localhost/127.0.0.1:43909 successfully registered with NN
2020-04-02 05:04:14,964 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:43909 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:04:14,967 [IPC Server handler 3 on 43909] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-54746245-acee-4605-b3a2-76160e1ebb72 for DN 127.0.0.1:36017
2020-04-02 05:04:14,967 [IPC Server handler 3 on 43909] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-eec506ae-cf75-4c6b-9ece-cd33e8e8b2ee for DN 127.0.0.1:36017
2020-04-02 05:04:14,970 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x90276b188386d948: Processing first storage report for DS-54746245-acee-4605-b3a2-76160e1ebb72 from datanode 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91
2020-04-02 05:04:14,971 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x90276b188386d948: from storage DS-54746245-acee-4605-b3a2-76160e1ebb72 node DatanodeRegistration(127.0.0.1:36017, datanodeUuid=5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, infoPort=40229, infoSecurePort=0, ipcPort=39974, storageInfo=lv=-57;cid=testClusterID;nsid=471869960;c=1585803845034), blocks: 8, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:04:14,971 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x90276b188386d948: Processing first storage report for DS-eec506ae-cf75-4c6b-9ece-cd33e8e8b2ee from datanode 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91
2020-04-02 05:04:14,972 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x90276b188386d948: from storage DS-eec506ae-cf75-4c6b-9ece-cd33e8e8b2ee node DatanodeRegistration(127.0.0.1:36017, datanodeUuid=5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, infoPort=40229, infoSecurePort=0, ipcPort=39974, storageInfo=lv=-57;cid=testClusterID;nsid=471869960;c=1585803845034), blocks: 6, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:04:14,976 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x90276b188386d948,  containing 2 storage report(s), of which we sent 2. The reports had 14 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:04:14,976 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:15,004 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,005 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:04:15,011 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:15,013 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/testEditsLogRename/srcdir/src1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,015 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/testEditsLogRename/dstdir/dst1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,016 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:15,021 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testEditsLogRename
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testEditsLogRename
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendNonExistingFile
[msx] perform reset as unitTestCounterInClass 9 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:15,025 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:15,027 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testCreateFlagAppendNonExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,028 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:15,029 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendNonExistingFile
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendNonExistingFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testWorkingDirectory
[msx] perform reset as unitTestCounterInClass 10 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:15,032 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:15,034 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,035 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,036 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,037 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,039 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/existingDir1	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:15,040 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/existingDir1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,042 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/existingDir2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:15,043 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/existingDir2	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,045 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/existingDir2/foo	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:15,048 [IPC Server handler 4 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/existingDir2/foo is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:15,050 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestHDFSFileContextMainOperations/test/existingDir2/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,052 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/existingDir2/newDir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:15,053 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/existingDir2/newDir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,054 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/nonexistingPath	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,058 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:15,059 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testWorkingDirectory
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testWorkingDirectory
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testEmptyCreateFlag
[msx] perform reset as unitTestCounterInClass 11 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:15,063 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:15,064 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:15,066 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testEmptyCreateFlag
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testEmptyCreateFlag
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagCreateAppendExistingFile
[msx] perform reset as unitTestCounterInClass 12 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:15,069 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:15,072 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/testCreateFlagCreateAppendExistingFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:15,079 [IPC Server handler 4 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741839_1015, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/testCreateFlagCreateAppendExistingFile
2020-04-02 05:04:15,082 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:54688 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741839_1015 src: /127.0.0.1:54688 dest: /127.0.0.1:36017
2020-04-02 05:04:15,097 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54688, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741839_1015, duration(ns): 7396835
2020-04-02 05:04:15,097 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:15,101 [IPC Server handler 7 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/testCreateFlagCreateAppendExistingFile is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:15,103 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testCreateFlagCreateAppendExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,109 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=append	src=/tmp/TestHDFSFileContextMainOperations/test/testCreateFlagCreateAppendExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,125 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:54698 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741839_1015 src: /127.0.0.1:54698 dest: /127.0.0.1:36017
2020-04-02 05:04:15,126 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:54698 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741839_1015]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:append(1187)) - Appending to FinalizedReplica, blk_1073741839_1015, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741839
2020-04-02 05:04:15,175 [IPC Server handler 0 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5340)) - updatePipeline(blk_1073741839_1015, newGS=1016, newLength=2048, newNodes=[127.0.0.1:36017], client=DFSClient_NONMAPREDUCE_1392736373_1)
2020-04-02 05:04:15,178 [IPC Server handler 0 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5358)) - updatePipeline(blk_1073741839_1015 => blk_1073741839_1016) success
2020-04-02 05:04:15,189 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741839_1016, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54698, dest: /127.0.0.1:36017, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741839_1016, duration(ns): 16632094
2020-04-02 05:04:15,190 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741839_1016, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741839_1016, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:15,192 [IPC Server handler 2 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/testCreateFlagCreateAppendExistingFile is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:15,193 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testCreateFlagCreateAppendExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,199 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testCreateFlagCreateAppendExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,200 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:15,203 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagCreateAppendExistingFile
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagCreateAppendExistingFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusFilterWithNoMatchingPathsAndNonTrivialFilter
[msx] perform reset as unitTestCounterInClass 13 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:15,206 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:15,208 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,209 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:15,211 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:15,212 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axx	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:15,213 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axx	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:15,261 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,270 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:15,271 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusFilterWithNoMatchingPathsAndNonTrivialFilter
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusFilterWithNoMatchingPathsAndNonTrivialFilter
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testNullCreateFlag
[msx] perform reset as unitTestCounterInClass 14 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:15,274 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:15,275 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:15,276 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testNullCreateFlag
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testNullCreateFlag
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameFileToNonExistentDirectory
[msx] perform reset as unitTestCounterInClass 15 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:15,279 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:15,282 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:15,294 [IPC Server handler 8 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741840_1017, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:15,297 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:54726 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741840_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741840_1017 src: /127.0.0.1:54726 dest: /127.0.0.1:36017
2020-04-02 05:04:15,313 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741840_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54726, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741840_1017, duration(ns): 11672143
2020-04-02 05:04:15,317 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741840_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741840_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:15,324 [IPC Server handler 0 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:15,325 [IPC Server handler 1 on 43909] WARN  hdfs.StateChange (FSDirRenameOp.java:unprotectedRenameTo(387)) - DIR* FSDirectory.unprotectedRenameTo: rename destination parent /tmp/TestHDFSFileContextMainOperations/test/nonExistent/newfile not found.
2020-04-02 05:04:15,325 [IPC Server handler 1 on 43909] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 1 on 43909, call Call#224 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:51146: java.io.FileNotFoundException: rename destination parent /tmp/TestHDFSFileContextMainOperations/test/nonExistent/newfile not found.
2020-04-02 05:04:15,327 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,328 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/nonExistent/newfile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,329 [IPC Server handler 4 on 43909] WARN  hdfs.StateChange (FSDirRenameOp.java:unprotectedRenameTo(387)) - DIR* FSDirectory.unprotectedRenameTo: rename destination parent /tmp/TestHDFSFileContextMainOperations/test/nonExistent/newfile not found.
2020-04-02 05:04:15,329 [IPC Server handler 4 on 43909] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 4 on 43909, call Call#227 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:51146: java.io.FileNotFoundException: rename destination parent /tmp/TestHDFSFileContextMainOperations/test/nonExistent/newfile not found.
2020-04-02 05:04:15,331 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,332 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/nonExistent/newfile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,333 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:15,334 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameFileToNonExistentDirectory
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameFileToNonExistentDirectory
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testDeleteEmptyDirectory
[msx] perform reset as unitTestCounterInClass 16 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:15,336 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:15,337 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:15,338 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,339 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,340 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,340 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:15,341 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testDeleteEmptyDirectory
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testDeleteEmptyDirectory
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameDirectoryToNonExistentParent
[msx] perform reset as unitTestCounterInClass 17 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:15,343 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:15,345 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:15,346 [IPC Server handler 7 on 43909] WARN  hdfs.StateChange (FSDirRenameOp.java:unprotectedRenameTo(387)) - DIR* FSDirectory.unprotectedRenameTo: rename destination parent /tmp/TestHDFSFileContextMainOperations/test/nonExistent/newdir not found.
2020-04-02 05:04:15,346 [IPC Server handler 7 on 43909] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 7 on 43909, call Call#239 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:51146: java.io.FileNotFoundException: rename destination parent /tmp/TestHDFSFileContextMainOperations/test/nonExistent/newdir not found.
2020-04-02 05:04:15,348 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,349 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/nonExistent/newdir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,350 [IPC Server handler 9 on 43909] WARN  hdfs.StateChange (FSDirRenameOp.java:unprotectedRenameTo(387)) - DIR* FSDirectory.unprotectedRenameTo: rename destination parent /tmp/TestHDFSFileContextMainOperations/test/nonExistent/newdir not found.
2020-04-02 05:04:15,350 [IPC Server handler 9 on 43909] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 9 on 43909, call Call#242 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:51146: java.io.FileNotFoundException: rename destination parent /tmp/TestHDFSFileContextMainOperations/test/nonExistent/newdir not found.
2020-04-02 05:04:15,352 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,354 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/nonExistent/newdir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,354 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:15,356 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameDirectoryToNonExistentParent
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameDirectoryToNonExistentParent
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendOverwrite
[msx] perform reset as unitTestCounterInClass 18 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:15,359 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:15,360 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:15,360 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendOverwrite
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendOverwrite
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testInputStreamClosedTwice
[msx] perform reset as unitTestCounterInClass 19 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:15,365 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:15,367 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:15,370 [IPC Server handler 6 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741841_1018, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:15,372 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:54732 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741841_1018]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741841_1018 src: /127.0.0.1:54732 dest: /127.0.0.1:36017
2020-04-02 05:04:15,378 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741841_1018, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54732, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741841_1018, duration(ns): 3008642
2020-04-02 05:04:15,378 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741841_1018, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741841_1018, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:15,379 [IPC Server handler 9 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741841_1018 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:15,781 [IPC Server handler 0 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:15,783 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,784 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:15,786 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testInputStreamClosedTwice
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testInputStreamClosedTwice
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testSetVerifyChecksum
[msx] perform reset as unitTestCounterInClass 20 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:15,789 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:15,791 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/zoo	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:15,794 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/zoo	dst=null	perm=null	proto=rpc
2020-04-02 05:04:15,797 [IPC Server handler 7 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741842_1019, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/zoo
2020-04-02 05:04:15,800 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:54808 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741842_1019]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741842_1019 src: /127.0.0.1:54808 dest: /127.0.0.1:36017
2020-04-02 05:04:15,807 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741842_1019, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54808, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741842_1019, duration(ns): 4678843
2020-04-02 05:04:15,807 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741842_1019, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741842_1019, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:15,809 [IPC Server handler 8 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741842_1019 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/zoo
2020-04-02 05:04:16,211 [IPC Server handler 9 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/zoo is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:16,213 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/zoo	dst=null	perm=null	proto=rpc
2020-04-02 05:04:16,214 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestHDFSFileContextMainOperations/test/zoo	dst=null	perm=null	proto=rpc
2020-04-02 05:04:16,225 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:16,226 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testSetVerifyChecksum
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testSetVerifyChecksum
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testWriteReadAndDeleteOneBlock
[msx] perform reset as unitTestCounterInClass 21 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:16,229 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:16,231 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:16,233 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:16,241 [IPC Server handler 7 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741843_1020, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:16,243 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:54870 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741843_1020]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741843_1020 src: /127.0.0.1:54870 dest: /127.0.0.1:36017
2020-04-02 05:04:16,255 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741843_1020, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54870, dest: /127.0.0.1:36017, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741843_1020, duration(ns): 5593495
2020-04-02 05:04:16,256 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741843_1020, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741843_1020, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:16,257 [IPC Server handler 8 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:16,260 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:16,262 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:16,263 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:16,270 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:16,271 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:16,271 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:16,273 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testWriteReadAndDeleteOneBlock
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testWriteReadAndDeleteOneBlock
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testOpen2
[msx] perform reset as unitTestCounterInClass 22 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:16,275 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:16,277 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/zoo	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:16,283 [IPC Server handler 6 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741844_1021, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/zoo
2020-04-02 05:04:16,286 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:54872 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741844_1021]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741844_1021 src: /127.0.0.1:54872 dest: /127.0.0.1:36017
2020-04-02 05:04:16,294 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741844_1021, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54872, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741844_1021, duration(ns): 4321056
2020-04-02 05:04:16,294 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741844_1021, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741844_1021, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:16,295 [IPC Server handler 9 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/zoo is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:16,297 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/zoo	dst=null	perm=null	proto=rpc
2020-04-02 05:04:16,299 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestHDFSFileContextMainOperations/test/zoo	dst=null	perm=null	proto=rpc
2020-04-02 05:04:16,304 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:16,305 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testOpen2
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testOpen2
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGetFileStatusThrowsExceptionForNonExistentFile
[msx] perform reset as unitTestCounterInClass 23 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:16,308 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:16,310 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:16,310 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:16,311 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGetFileStatusThrowsExceptionForNonExistentFile
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGetFileStatusThrowsExceptionForNonExistentFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testMkdirsFailsForSubdirectoryOfExistingFile
[msx] perform reset as unitTestCounterInClass 24 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:16,314 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:16,315 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:16,316 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:16,317 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:16,319 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:16,323 [IPC Server handler 1 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741845_1022, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:16,325 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:54882 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741845_1022]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741845_1022 src: /127.0.0.1:54882 dest: /127.0.0.1:36017
2020-04-02 05:04:16,331 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741845_1022, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54882, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741845_1022, duration(ns): 3027839
2020-04-02 05:04:16,331 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741845_1022, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741845_1022, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:16,333 [IPC Server handler 3 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:16,335 [IPC Server handler 4 on 43909] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 4 on 43909, call Call#297 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 127.0.0.1:51146: org.apache.hadoop.fs.ParentNotDirectoryException: /tmp/TestHDFSFileContextMainOperations/test/hadoop/file (is not a directory)
2020-04-02 05:04:16,340 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file/subdir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:16,341 [IPC Server handler 7 on 43909] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 7 on 43909, call Call#299 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 127.0.0.1:51146: org.apache.hadoop.fs.ParentNotDirectoryException: /tmp/TestHDFSFileContextMainOperations/test/hadoop/file (is not a directory)
2020-04-02 05:04:16,343 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file/deep/sub/dir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:16,344 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:16,345 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testMkdirsFailsForSubdirectoryOfExistingFile
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testMkdirsFailsForSubdirectoryOfExistingFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendCreateOverwrite
[msx] perform reset as unitTestCounterInClass 25 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:16,348 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:16,349 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:16,350 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendCreateOverwrite
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendCreateOverwrite
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testListStatusFilterWithNoMatches
[msx] perform reset as unitTestCounterInClass 26 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:16,353 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:16,354 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop2/aaa	dst=null	perm=null	proto=rpc
2020-04-02 05:04:16,356 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop2/aaa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:16,358 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:16,359 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:16,360 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axx	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:16,361 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:16,362 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:16,363 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testListStatusFilterWithNoMatches
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testListStatusFilterWithNoMatches
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testFileContextStatistics
[msx] perform reset as unitTestCounterInClass 27 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:16,366 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:16,370 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/zoo	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:16,373 [IPC Server handler 1 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741846_1023, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/zoo
2020-04-02 05:04:16,376 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:54892 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741846_1023]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741846_1023 src: /127.0.0.1:54892 dest: /127.0.0.1:36017
2020-04-02 05:04:16,383 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741846_1023, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54892, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741846_1023, duration(ns): 3398972
2020-04-02 05:04:16,383 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741846_1023, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741846_1023, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:16,385 [IPC Server handler 2 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741846_1023 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/zoo
2020-04-02 05:04:16,787 [IPC Server handler 4 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/zoo is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:16,789 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestHDFSFileContextMainOperations/test/zoo	dst=null	perm=null	proto=rpc
  FileSystem hdfs://127.0.0.1: 0 bytes read, 0 bytes written, 0 read ops, 0 large read ops, 0 write ops
  FileSystem hdfs://localhost:38542: 0 bytes read, 0 bytes written, 0 read ops, 0 large read ops, 0 write ops
  FileSystem hdfs://localhost:34890: 0 bytes read, 0 bytes written, 0 read ops, 0 large read ops, 0 write ops
  FileSystem file://null: 0 bytes read, 0 bytes written, 0 read ops, 0 large read ops, 0 write ops
  FileSystem hdfs://localhost:43909: 2048 bytes read, 2048 bytes written, 0 read ops, 0 large read ops, 0 write ops
2020-04-02 05:04:16,796 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:16,798 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testFileContextStatistics
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testFileContextStatistics
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testListFiles
[msx] perform reset as unitTestCounterInClass 28 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:16,801 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:16,803 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/dir1	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:16,804 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/dir1/dir1	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:16,806 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/dir2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:16,808 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/dir1/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:16,812 [IPC Server handler 2 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741847_1024, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/dir1/file1
2020-04-02 05:04:16,815 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:54988 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741847_1024]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741847_1024 src: /127.0.0.1:54988 dest: /127.0.0.1:36017
2020-04-02 05:04:16,820 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741847_1024, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54988, dest: /127.0.0.1:36017, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741847_1024, duration(ns): 2041201
2020-04-02 05:04:16,821 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741847_1024, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741847_1024, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:16,822 [IPC Server handler 4 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741847_1024 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/dir1/file1
2020-04-02 05:04:17,223 [IPC Server handler 5 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/dir1/file1 is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:17,225 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/dir1/file2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:17,228 [IPC Server handler 6 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741848_1025, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/dir1/file2
2020-04-02 05:04:17,230 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55072 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741848_1025]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741848_1025 src: /127.0.0.1:55072 dest: /127.0.0.1:36017
2020-04-02 05:04:17,234 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741848_1025, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55072, dest: /127.0.0.1:36017, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741848_1025, duration(ns): 1797309
2020-04-02 05:04:17,234 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741848_1025, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741848_1025, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:17,235 [IPC Server handler 9 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/dir1/file2 is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:17,237 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/dir1/dir1/file2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:17,240 [IPC Server handler 1 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741849_1026, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/dir1/dir1/file2
2020-04-02 05:04:17,242 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55074 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741849_1026]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741849_1026 src: /127.0.0.1:55074 dest: /127.0.0.1:36017
2020-04-02 05:04:17,246 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741849_1026, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55074, dest: /127.0.0.1:36017, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741849_1026, duration(ns): 1536021
2020-04-02 05:04:17,246 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741849_1026, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741849_1026, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:17,247 [IPC Server handler 2 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/dir1/dir1/file2 is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:17,249 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/dir2/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:17,251 [IPC Server handler 5 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741850_1027, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/dir2/file1
2020-04-02 05:04:17,254 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55080 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741850_1027]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741850_1027 src: /127.0.0.1:55080 dest: /127.0.0.1:36017
2020-04-02 05:04:17,258 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741850_1027, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55080, dest: /127.0.0.1:36017, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741850_1027, duration(ns): 2143775
2020-04-02 05:04:17,259 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741850_1027, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741850_1027, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:17,259 [IPC Server handler 6 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741850_1027 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/dir2/file1
2020-04-02 05:04:17,661 [IPC Server handler 8 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/dir2/file1 is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:17,665 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,667 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test/dir1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,671 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test/dir1/dir1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,674 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test/dir2	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,675 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:17,677 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testListFiles
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testListFiles
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testWriteReadAndDeleteEmptyFile
[msx] perform reset as unitTestCounterInClass 29 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:17,680 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:17,682 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:17,684 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:17,686 [IPC Server handler 6 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:17,687 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,689 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,690 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,691 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,693 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,694 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:17,695 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testWriteReadAndDeleteEmptyFile
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testWriteReadAndDeleteEmptyFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusFilterWithSomePathMatchesAndTrivialFilter
[msx] perform reset as unitTestCounterInClass 30 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:17,698 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:17,699 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,701 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:17,702 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:17,705 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axx	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:17,706 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axx	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:17,709 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,710 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:17,712 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusFilterWithSomePathMatchesAndTrivialFilter
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusFilterWithSomePathMatchesAndTrivialFilter
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testFsStatus
[msx] perform reset as unitTestCounterInClass 31 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:17,714 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:17,722 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:17,723 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testFsStatus
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testFsStatus
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGetFileContext1
[msx] perform reset as unitTestCounterInClass 32 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:17,726 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:17,737 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/zoo	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:17,739 [IPC Server handler 9 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/zoo is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:17,741 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/zoo	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,741 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:17,745 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGetFileContext1
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGetFileContext1
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testListStatus
[msx] perform reset as unitTestCounterInClass 33 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:17,748 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:17,749 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/a	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,750 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/a	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:17,752 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/b	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:17,754 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/c/1	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:17,756 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,758 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,761 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/a	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,765 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,767 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,769 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/a	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,769 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:17,770 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testListStatus
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testListStatus
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameDirectoryAsEmptyDirectory
[msx] perform reset as unitTestCounterInClass 34 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:17,773 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:17,774 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:17,775 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:17,777 [IPC Server handler 6 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741851_1028, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/file1
2020-04-02 05:04:17,781 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55114 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741851_1028]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741851_1028 src: /127.0.0.1:55114 dest: /127.0.0.1:36017
2020-04-02 05:04:17,787 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741851_1028, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55114, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741851_1028, duration(ns): 1898645
2020-04-02 05:04:17,787 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741851_1028, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741851_1028, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:17,789 [IPC Server handler 9 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/file1 is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:17,795 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/subdir/file2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:17,798 [IPC Server handler 1 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741852_1029, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/subdir/file2
2020-04-02 05:04:17,799 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55120 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741852_1029]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741852_1029 src: /127.0.0.1:55120 dest: /127.0.0.1:36017
2020-04-02 05:04:17,805 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741852_1029, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55120, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741852_1029, duration(ns): 2732527
2020-04-02 05:04:17,805 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741852_1029, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741852_1029, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:17,806 [IPC Server handler 3 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/subdir/file2 is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:17,809 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/new/newdir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:17,810 [IPC Server handler 5 on 43909] WARN  hdfs.StateChange (FSDirRenameOp.java:validateOverwrite(537)) - DIR* FSDirectory.unprotectedRenameTo: rename destination /tmp/TestHDFSFileContextMainOperations/test/new/newdir already exists
2020-04-02 05:04:17,811 [IPC Server handler 5 on 43909] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 5 on 43909, call Call#398 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:51146: org.apache.hadoop.fs.FileAlreadyExistsException: rename destination /tmp/TestHDFSFileContextMainOperations/test/new/newdir already exists
2020-04-02 05:04:17,813 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,814 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/new/newdir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,816 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename (options=[OVERWRITE])	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=/tmp/TestHDFSFileContextMainOperations/test/new/newdir	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:17,816 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,817 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/new/newdir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:17,817 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:17,819 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameDirectoryAsEmptyDirectory
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameDirectoryAsEmptyDirectory
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameFileAsExistingFile
[msx] perform reset as unitTestCounterInClass 35 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:17,822 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:17,824 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:17,826 [IPC Server handler 4 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741853_1030, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:17,829 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55132 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741853_1030]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741853_1030 src: /127.0.0.1:55132 dest: /127.0.0.1:36017
2020-04-02 05:04:17,835 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741853_1030, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55132, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741853_1030, duration(ns): 3986375
2020-04-02 05:04:17,835 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741853_1030, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741853_1030, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:17,836 [IPC Server handler 7 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:17,838 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/new/existingFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:17,840 [IPC Server handler 8 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741854_1031, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/new/existingFile
2020-04-02 05:04:17,842 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55136 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741854_1031]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741854_1031 src: /127.0.0.1:55136 dest: /127.0.0.1:36017
2020-04-02 05:04:17,846 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741854_1031, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55136, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741854_1031, duration(ns): 1603453
2020-04-02 05:04:17,846 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741854_1031, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741854_1031, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:17,847 [IPC Server handler 0 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741854_1031 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/new/existingFile
2020-04-02 05:04:17,977 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741837_1013 replica FinalizedReplica, blk_1073741837_1013, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741837 for deletion
2020-04-02 05:04:17,979 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741839_1016 replica FinalizedReplica, blk_1073741839_1016, FINALIZED
  getNumBytes()     = 4096
  getBytesOnDisk()  = 4096
  getVisibleLength()= 4096
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741839 for deletion
2020-04-02 05:04:17,979 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741837_1013 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741837
2020-04-02 05:04:17,980 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741840_1017 replica FinalizedReplica, blk_1073741840_1017, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741840 for deletion
2020-04-02 05:04:17,981 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741839_1016 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741839
2020-04-02 05:04:17,981 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741841_1018 replica FinalizedReplica, blk_1073741841_1018, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741841 for deletion
2020-04-02 05:04:17,981 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741840_1017 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741840
2020-04-02 05:04:17,981 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741842_1019 replica FinalizedReplica, blk_1073741842_1019, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741842 for deletion
2020-04-02 05:04:17,982 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741843_1020 replica FinalizedReplica, blk_1073741843_1020, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741843 for deletion
2020-04-02 05:04:17,982 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741841_1018 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741841
2020-04-02 05:04:17,983 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741844_1021 replica FinalizedReplica, blk_1073741844_1021, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741844 for deletion
2020-04-02 05:04:17,983 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741842_1019 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741842
2020-04-02 05:04:17,983 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741843_1020 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741843
2020-04-02 05:04:17,984 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741844_1021 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741844
2020-04-02 05:04:17,985 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741845_1022 replica FinalizedReplica, blk_1073741845_1022, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741845 for deletion
2020-04-02 05:04:17,985 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741846_1023 replica FinalizedReplica, blk_1073741846_1023, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741846 for deletion
2020-04-02 05:04:17,986 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741845_1022 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741845
2020-04-02 05:04:17,986 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741846_1023 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741846
2020-04-02 05:04:17,987 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741847_1024 replica FinalizedReplica, blk_1073741847_1024, FINALIZED
  getNumBytes()     = 1
  getBytesOnDisk()  = 1
  getVisibleLength()= 1
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741847 for deletion
2020-04-02 05:04:17,988 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741848_1025 replica FinalizedReplica, blk_1073741848_1025, FINALIZED
  getNumBytes()     = 1
  getBytesOnDisk()  = 1
  getVisibleLength()= 1
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741848 for deletion
2020-04-02 05:04:17,988 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741847_1024 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741847
2020-04-02 05:04:17,989 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741848_1025 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741848
2020-04-02 05:04:17,989 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741849_1026 replica FinalizedReplica, blk_1073741849_1026, FINALIZED
  getNumBytes()     = 1
  getBytesOnDisk()  = 1
  getVisibleLength()= 1
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741849 for deletion
2020-04-02 05:04:17,990 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741850_1027 replica FinalizedReplica, blk_1073741850_1027, FINALIZED
  getNumBytes()     = 1
  getBytesOnDisk()  = 1
  getVisibleLength()= 1
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741850 for deletion
2020-04-02 05:04:17,990 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741849_1026 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741849
2020-04-02 05:04:17,990 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741850_1027 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741850
2020-04-02 05:04:18,248 [IPC Server handler 2 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/new/existingFile is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:18,250 [IPC Server handler 3 on 43909] WARN  hdfs.StateChange (FSDirRenameOp.java:validateOverwrite(537)) - DIR* FSDirectory.unprotectedRenameTo: rename destination /tmp/TestHDFSFileContextMainOperations/test/new/existingFile already exists
2020-04-02 05:04:18,250 [IPC Server handler 3 on 43909] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 3 on 43909, call Call#416 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:51146: org.apache.hadoop.fs.FileAlreadyExistsException: rename destination /tmp/TestHDFSFileContextMainOperations/test/new/existingFile already exists
2020-04-02 05:04:18,253 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:18,255 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/new/existingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:18,257 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename (options=[OVERWRITE])	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=/tmp/TestHDFSFileContextMainOperations/test/new/existingFile	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:18,257 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:18,258 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/new/existingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:18,259 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:18,260 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameFileAsExistingFile
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameFileAsExistingFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testWriteReadAndDeleteHalfABlock
[msx] perform reset as unitTestCounterInClass 36 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:18,261 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:18,264 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:18,266 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:18,268 [IPC Server handler 3 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741855_1032, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:18,271 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55232 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741855_1032]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741855_1032 src: /127.0.0.1:55232 dest: /127.0.0.1:36017
2020-04-02 05:04:18,277 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741855_1032, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55232, dest: /127.0.0.1:36017, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741855_1032, duration(ns): 2384924
2020-04-02 05:04:18,278 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741855_1032, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741855_1032, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:18,278 [IPC Server handler 5 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741855_1032 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:18,680 [IPC Server handler 7 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:18,681 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:18,683 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:18,684 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:18,688 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:18,689 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:18,689 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:18,690 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testWriteReadAndDeleteHalfABlock
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testWriteReadAndDeleteHalfABlock
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testListCorruptFileBlocks
[msx] perform reset as unitTestCounterInClass 37 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:18,692 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:18,694 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/zoo	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:18,697 [IPC Server handler 5 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741856_1033, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/zoo
2020-04-02 05:04:18,699 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55252 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741856_1033]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741856_1033 src: /127.0.0.1:55252 dest: /127.0.0.1:36017
2020-04-02 05:04:18,705 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741856_1033, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55252, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741856_1033, duration(ns): 3195751
2020-04-02 05:04:18,705 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741856_1033, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741856_1033, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:18,707 [IPC Server handler 6 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/zoo is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:18,716 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:18,717 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testListCorruptFileBlocks
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testListCorruptFileBlocks
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameFileAsExistingDirectory
[msx] perform reset as unitTestCounterInClass 38 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:18,719 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:18,721 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:18,723 [IPC Server handler 2 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741857_1034, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:18,725 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55260 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741857_1034]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741857_1034 src: /127.0.0.1:55260 dest: /127.0.0.1:36017
2020-04-02 05:04:18,729 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741857_1034, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55260, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741857_1034, duration(ns): 1314067
2020-04-02 05:04:18,729 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741857_1034, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741857_1034, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:18,730 [IPC Server handler 4 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741857_1034 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:19,131 [IPC Server handler 5 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:19,133 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/new/existingDir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:19,134 [IPC Server handler 6 on 43909] WARN  hdfs.StateChange (FSDirRenameOp.java:validateOverwrite(531)) - DIR* FSDirectory.unprotectedRenameTo: Source /tmp/TestHDFSFileContextMainOperations/test/hadoop/file and destination /tmp/TestHDFSFileContextMainOperations/test/new/existingDir must both be directories
2020-04-02 05:04:19,135 [IPC Server handler 6 on 43909] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 6 on 43909, call Call#450 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:51146
java.io.IOException: Source /tmp/TestHDFSFileContextMainOperations/test/hadoop/file and destination /tmp/TestHDFSFileContextMainOperations/test/new/existingDir must both be directories
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.validateOverwrite(FSDirRenameOp.java:533)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:380)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.rename2(ClientNamenodeProtocolServerSideTranslatorPB.java:668)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:04:19,137 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:19,138 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/new/existingDir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:19,139 [IPC Server handler 0 on 43909] WARN  hdfs.StateChange (FSDirRenameOp.java:validateOverwrite(531)) - DIR* FSDirectory.unprotectedRenameTo: Source /tmp/TestHDFSFileContextMainOperations/test/hadoop/file and destination /tmp/TestHDFSFileContextMainOperations/test/new/existingDir must both be directories
2020-04-02 05:04:19,139 [IPC Server handler 0 on 43909] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 0 on 43909, call Call#453 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:51146
java.io.IOException: Source /tmp/TestHDFSFileContextMainOperations/test/hadoop/file and destination /tmp/TestHDFSFileContextMainOperations/test/new/existingDir must both be directories
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.validateOverwrite(FSDirRenameOp.java:533)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:380)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.rename2(ClientNamenodeProtocolServerSideTranslatorPB.java:668)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:04:19,141 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:19,142 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/new/existingDir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:19,143 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:19,144 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameFileAsExistingDirectory
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameFileAsExistingDirectory
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagOverwriteNonExistingFile
[msx] perform reset as unitTestCounterInClass 39 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:19,149 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:19,150 [IPC Server handler 5 on 43909] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 5 on 43909, call Call#458 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 127.0.0.1:51146: java.io.FileNotFoundException: Can't overwrite non-existent /tmp/TestHDFSFileContextMainOperations/test/testCreateFlagOverwriteNonExistingFile
2020-04-02 05:04:19,152 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:19,153 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagOverwriteNonExistingFile
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagOverwriteNonExistingFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testListStatusThrowsExceptionForNonExistentFile
[msx] perform reset as unitTestCounterInClass 40 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:19,156 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:19,157 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:19,157 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:19,158 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testListStatusThrowsExceptionForNonExistentFile
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testListStatusThrowsExceptionForNonExistentFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testWriteReadAndDeleteOneAndAHalfBlocks
[msx] perform reset as unitTestCounterInClass 41 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:19,160 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:19,161 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:19,163 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:19,165 [IPC Server handler 3 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741858_1035, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:19,168 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55358 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741858_1035]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741858_1035 src: /127.0.0.1:55358 dest: /127.0.0.1:36017
2020-04-02 05:04:19,175 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741858_1035, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55358, dest: /127.0.0.1:36017, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741858_1035, duration(ns): 3503214
2020-04-02 05:04:19,175 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741858_1035, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741858_1035, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:19,177 [IPC Server handler 5 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741859_1036, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:19,179 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55364 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741859_1036]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741859_1036 src: /127.0.0.1:55364 dest: /127.0.0.1:36017
2020-04-02 05:04:19,182 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741859_1036, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55364, dest: /127.0.0.1:36017, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741859_1036, duration(ns): 1375842
2020-04-02 05:04:19,182 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741859_1036, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741859_1036, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:19,184 [IPC Server handler 6 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:19,185 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:19,186 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:19,187 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:19,194 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:19,195 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:19,196 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:19,197 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testWriteReadAndDeleteOneAndAHalfBlocks
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testWriteReadAndDeleteOneAndAHalfBlocks
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testListStatusFilterWithSomeMatches
[msx] perform reset as unitTestCounterInClass 42 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:19,200 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:19,202 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=null	proto=rpc
2020-04-02 05:04:19,203 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:19,205 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:19,206 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axx	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:19,207 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop2/aaa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:19,208 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:19,209 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:19,210 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testListStatusFilterWithSomeMatches
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testListStatusFilterWithSomeMatches
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameDirectoryAsNonExistentDirectory
[msx] perform reset as unitTestCounterInClass 43 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:19,213 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:19,215 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:19,217 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:19,219 [IPC Server handler 5 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741860_1037, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/file1
2020-04-02 05:04:19,222 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55374 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741860_1037]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741860_1037 src: /127.0.0.1:55374 dest: /127.0.0.1:36017
2020-04-02 05:04:19,225 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741860_1037, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55374, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741860_1037, duration(ns): 1312580
2020-04-02 05:04:19,225 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741860_1037, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741860_1037, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:19,226 [IPC Server handler 6 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741860_1037 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/file1
2020-04-02 05:04:19,627 [IPC Server handler 8 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/file1 is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:19,630 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/subdir/file2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:19,634 [IPC Server handler 0 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741861_1038, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/subdir/file2
2020-04-02 05:04:19,636 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55482 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741861_1038]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741861_1038 src: /127.0.0.1:55482 dest: /127.0.0.1:36017
2020-04-02 05:04:19,639 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741861_1038, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55482, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741861_1038, duration(ns): 1227890
2020-04-02 05:04:19,639 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741861_1038, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741861_1038, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:19,640 [IPC Server handler 2 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741861_1038 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/subdir/file2
2020-04-02 05:04:20,042 [IPC Server handler 3 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/subdir/file2 is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:20,043 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/new	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,045 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename (options=[TO_TRASH])	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=/tmp/TestHDFSFileContextMainOperations/test/new/newdir	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,046 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,047 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/new/newdir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,049 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/file1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,049 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/subdir/file2	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,050 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/new/newdir/file1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,051 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/new/newdir/subdir/file2	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,052 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:20,053 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,054 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,056 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:20,059 [IPC Server handler 5 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741862_1039, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/file1
2020-04-02 05:04:20,060 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55568 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741862_1039]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741862_1039 src: /127.0.0.1:55568 dest: /127.0.0.1:36017
2020-04-02 05:04:20,064 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741862_1039, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55568, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741862_1039, duration(ns): 2189212
2020-04-02 05:04:20,064 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741862_1039, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741862_1039, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:20,065 [IPC Server handler 6 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741862_1039 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/file1
2020-04-02 05:04:20,466 [IPC Server handler 8 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/file1 is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:20,468 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/subdir/file2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:20,473 [IPC Server handler 0 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741863_1040, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/subdir/file2
2020-04-02 05:04:20,475 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55678 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741863_1040]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741863_1040 src: /127.0.0.1:55678 dest: /127.0.0.1:36017
2020-04-02 05:04:20,479 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741863_1040, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55678, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741863_1040, duration(ns): 1203597
2020-04-02 05:04:20,479 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741863_1040, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741863_1040, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:20,481 [IPC Server handler 2 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/subdir/file2 is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:20,482 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/new	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,484 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename (options=[OVERWRITE])	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=/tmp/TestHDFSFileContextMainOperations/test/new/newdir	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,485 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,486 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/new/newdir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,487 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/file1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,487 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/subdir/file2	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,488 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/new/newdir/file1	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,489 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/new/newdir/subdir/file2	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,489 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:20,490 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameDirectoryAsNonExistentDirectory
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameDirectoryAsNonExistentDirectory
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusSomeMatchesInDirectories
[msx] perform reset as unitTestCounterInClass 44 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:20,498 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,506 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,509 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,510 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,511 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axx	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,512 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop2/aaa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,515 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,518 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:20,519 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusSomeMatchesInDirectories
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusSomeMatchesInDirectories
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testUnsupportedSymlink
[msx] perform reset as unitTestCounterInClass 45 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:20,522 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,523 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:20,524 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testUnsupportedSymlink
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testUnsupportedSymlink
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusFilterWithMultiplePathMatchesAndNonTrivialFilter
[msx] perform reset as unitTestCounterInClass 46 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:20,525 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,526 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,527 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,528 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,529 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axx	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,531 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axx	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,533 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,535 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:20,536 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusFilterWithMultiplePathMatchesAndNonTrivialFilter
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusFilterWithMultiplePathMatchesAndNonTrivialFilter
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusFilterWithMultipleWildCardMatchesAndTrivialFilter
[msx] perform reset as unitTestCounterInClass 47 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:20,538 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,539 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,541 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,541 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,543 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axx	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,544 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axx	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,547 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,550 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:20,552 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusFilterWithMultipleWildCardMatchesAndTrivialFilter
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusFilterWithMultipleWildCardMatchesAndTrivialFilter
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testWriteReadAndDeleteTwoBlocks
[msx] perform reset as unitTestCounterInClass 48 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:20,555 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,557 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,559 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:20,566 [IPC Server handler 1 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741864_1041, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:20,568 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55694 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741864_1041]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741864_1041 src: /127.0.0.1:55694 dest: /127.0.0.1:36017
2020-04-02 05:04:20,571 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741864_1041, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55694, dest: /127.0.0.1:36017, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741864_1041, duration(ns): 1780259
2020-04-02 05:04:20,572 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741864_1041, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741864_1041, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:20,574 [IPC Server handler 3 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741865_1042, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:20,576 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55698 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741865_1042]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741865_1042 src: /127.0.0.1:55698 dest: /127.0.0.1:36017
2020-04-02 05:04:20,578 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741865_1042, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55698, dest: /127.0.0.1:36017, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741865_1042, duration(ns): 861713
2020-04-02 05:04:20,579 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741865_1042, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741865_1042, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:20,580 [IPC Server handler 5 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:20,583 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,585 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,586 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,594 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,598 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,601 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:20,605 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testWriteReadAndDeleteTwoBlocks
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testWriteReadAndDeleteTwoBlocks
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusFilterWithEmptyPathResults
[msx] perform reset as unitTestCounterInClass 49 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:20,608 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,610 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,612 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,617 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,622 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axx	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,623 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axx	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,625 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,626 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:20,627 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusFilterWithEmptyPathResults
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusFilterWithEmptyPathResults
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusWithNoMatchesInPath
[msx] perform reset as unitTestCounterInClass 50 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:20,630 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,631 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,633 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,636 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,638 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axx	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,639 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop2/aaa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,643 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,645 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:20,646 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusWithNoMatchesInPath
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusWithNoMatchesInPath
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusWithMultipleMatchesOfSingleChar
[msx] perform reset as unitTestCounterInClass 51 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:20,657 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,661 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,667 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,668 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,669 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axx	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,670 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop2/aaa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,672 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,673 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:20,674 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusWithMultipleMatchesOfSingleChar
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusWithMultipleMatchesOfSingleChar
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testDeleteOnExitUnexisting
[msx] perform reset as unitTestCounterInClass 52 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:20,677 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,678 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/zoo	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,678 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:20,679 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testDeleteOnExitUnexisting
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testDeleteOnExitUnexisting
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameDirectoryToItself
[msx] perform reset as unitTestCounterInClass 53 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:20,681 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,683 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,691 [IPC Server handler 1 on 43909] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 1 on 43909, call Call#594 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:51146: org.apache.hadoop.fs.FileAlreadyExistsException: The source /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir and destination /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir are the same
2020-04-02 05:04:20,703 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,706 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,708 [IPC Server handler 4 on 43909] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 4 on 43909, call Call#597 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:51146: org.apache.hadoop.fs.FileAlreadyExistsException: The source /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir and destination /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir are the same
2020-04-02 05:04:20,710 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,712 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:20,714 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:20,715 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameDirectoryToItself
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameDirectoryToItself
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
[msx] perform reset as unitTestCounterInClass 54 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:20,720 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:20,728 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/testCreateFlagAppendExistingFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:20,732 [IPC Server handler 0 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741866_1043, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/testCreateFlagAppendExistingFile
2020-04-02 05:04:20,735 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55746 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741866_1043]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741866_1043 src: /127.0.0.1:55746 dest: /127.0.0.1:36017
2020-04-02 05:04:20,743 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741866_1043, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55746, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741866_1043, duration(ns): 5761527
2020-04-02 05:04:20,743 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741866_1043, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741866_1043, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:20,746 [IPC Server handler 2 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741866_1043 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/testCreateFlagAppendExistingFile
2020-04-02 05:04:20,968 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741856_1033 replica FinalizedReplica, blk_1073741856_1033, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741856 for deletion
2020-04-02 05:04:20,968 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741857_1034 replica FinalizedReplica, blk_1073741857_1034, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741857 for deletion
2020-04-02 05:04:20,969 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741856_1033 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741856
2020-04-02 05:04:20,969 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741858_1035 replica FinalizedReplica, blk_1073741858_1035, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741858 for deletion
2020-04-02 05:04:20,970 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741857_1034 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741857
2020-04-02 05:04:20,970 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741858_1035 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741858
2020-04-02 05:04:20,970 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741859_1036 replica FinalizedReplica, blk_1073741859_1036, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741859 for deletion
2020-04-02 05:04:20,971 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741860_1037 replica FinalizedReplica, blk_1073741860_1037, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741860 for deletion
2020-04-02 05:04:20,971 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741859_1036 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741859
2020-04-02 05:04:20,971 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741861_1038 replica FinalizedReplica, blk_1073741861_1038, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741861 for deletion
2020-04-02 05:04:20,971 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741860_1037 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741860
2020-04-02 05:04:20,972 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741862_1039 replica FinalizedReplica, blk_1073741862_1039, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741862 for deletion
2020-04-02 05:04:20,973 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741861_1038 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741861
2020-04-02 05:04:20,973 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741863_1040 replica FinalizedReplica, blk_1073741863_1040, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741863 for deletion
2020-04-02 05:04:20,974 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741862_1039 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741862
2020-04-02 05:04:20,974 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741864_1041 replica FinalizedReplica, blk_1073741864_1041, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741864 for deletion
2020-04-02 05:04:20,974 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741863_1040 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741863
2020-04-02 05:04:20,974 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741865_1042 replica FinalizedReplica, blk_1073741865_1042, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741865 for deletion
2020-04-02 05:04:20,975 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741864_1041 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741864
2020-04-02 05:04:20,976 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741851_1028 replica FinalizedReplica, blk_1073741851_1028, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741851 for deletion
2020-04-02 05:04:20,976 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741865_1042 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741865
2020-04-02 05:04:20,977 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741852_1029 replica FinalizedReplica, blk_1073741852_1029, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741852 for deletion
2020-04-02 05:04:20,977 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741851_1028 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741851
2020-04-02 05:04:20,977 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741853_1030 replica FinalizedReplica, blk_1073741853_1030, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741853 for deletion
2020-04-02 05:04:20,978 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741852_1029 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741852
2020-04-02 05:04:20,978 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741854_1031 replica FinalizedReplica, blk_1073741854_1031, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741854 for deletion
2020-04-02 05:04:20,979 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741855_1032 replica FinalizedReplica, blk_1073741855_1032, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741855 for deletion
2020-04-02 05:04:20,979 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741854_1031 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741854
2020-04-02 05:04:20,982 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741853_1030 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741853
2020-04-02 05:04:20,983 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741855_1032 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741855
2020-04-02 05:04:21,147 [IPC Server handler 4 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/testCreateFlagAppendExistingFile is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:21,149 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testCreateFlagAppendExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:21,151 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=append	src=/tmp/TestHDFSFileContextMainOperations/test/testCreateFlagAppendExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:21,155 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55810 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741866_1043]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741866_1043 src: /127.0.0.1:55810 dest: /127.0.0.1:36017
2020-04-02 05:04:21,155 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55810 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741866_1043]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:append(1187)) - Appending to FinalizedReplica, blk_1073741866_1043, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741866
2020-04-02 05:04:21,171 [IPC Server handler 8 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5340)) - updatePipeline(blk_1073741866_1043, newGS=1044, newLength=2048, newNodes=[127.0.0.1:36017], client=DFSClient_NONMAPREDUCE_1392736373_1)
2020-04-02 05:04:21,172 [IPC Server handler 8 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5358)) - updatePipeline(blk_1073741866_1043 => blk_1073741866_1044) success
2020-04-02 05:04:21,178 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741866_1044, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55810, dest: /127.0.0.1:36017, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741866_1044, duration(ns): 6185867
2020-04-02 05:04:21,178 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741866_1044, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741866_1044, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:21,179 [IPC Server handler 9 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741866_1044 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/testCreateFlagAppendExistingFile
2020-04-02 05:04:21,580 [IPC Server handler 1 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/testCreateFlagAppendExistingFile is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:21,582 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testCreateFlagAppendExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:21,583 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testCreateFlagAppendExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:21,583 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:21,584 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testWriteInNonExistentDirectory
[msx] perform reset as unitTestCounterInClass 55 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:21,587 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:21,588 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:21,589 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:21,591 [IPC Server handler 8 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741867_1045, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:21,593 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55836 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741867_1045]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741867_1045 src: /127.0.0.1:55836 dest: /127.0.0.1:36017
2020-04-02 05:04:21,595 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741867_1045, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55836, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741867_1045, duration(ns): 659911
2020-04-02 05:04:21,595 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741867_1045, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741867_1045, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:21,596 [IPC Server handler 0 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741867_1045 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:21,998 [IPC Server handler 1 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:21,999 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:22,001 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:22,002 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:22,003 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:22,003 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testWriteInNonExistentDirectory
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testWriteInNonExistentDirectory
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusWithMultipleWildCardMatches
[msx] perform reset as unitTestCounterInClass 56 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:22,006 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:22,007 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=null	proto=rpc
2020-04-02 05:04:22,008 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:22,009 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:22,012 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axx	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:22,013 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop2/aaa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:22,015 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:22,019 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:22,021 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop2	dst=null	perm=null	proto=rpc
2020-04-02 05:04:22,022 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop2	dst=null	perm=null	proto=rpc
2020-04-02 05:04:22,024 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:22,026 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusWithMultipleWildCardMatches
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusWithMultipleWildCardMatches
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameDirectoryAsFile
[msx] perform reset as unitTestCounterInClass 57 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:22,028 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:22,030 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:22,031 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/new/newfile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:22,035 [IPC Server handler 9 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741868_1046, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/new/newfile
2020-04-02 05:04:22,039 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:55928 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741868_1046]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741868_1046 src: /127.0.0.1:55928 dest: /127.0.0.1:36017
2020-04-02 05:04:22,042 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741868_1046, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55928, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741868_1046, duration(ns): 1430031
2020-04-02 05:04:22,042 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741868_1046, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741868_1046, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:22,043 [IPC Server handler 2 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741868_1046 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/new/newfile
2020-04-02 05:04:22,444 [IPC Server handler 3 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/new/newfile is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:22,446 [IPC Server handler 4 on 43909] WARN  hdfs.StateChange (FSDirRenameOp.java:validateOverwrite(531)) - DIR* FSDirectory.unprotectedRenameTo: Source /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir and destination /tmp/TestHDFSFileContextMainOperations/test/new/newfile must both be directories
2020-04-02 05:04:22,446 [IPC Server handler 4 on 43909] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 4 on 43909, call Call#647 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:51146
java.io.IOException: Source /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir and destination /tmp/TestHDFSFileContextMainOperations/test/new/newfile must both be directories
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.validateOverwrite(FSDirRenameOp.java:533)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:380)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.rename2(ClientNamenodeProtocolServerSideTranslatorPB.java:668)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:04:22,449 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:22,449 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/new/newfile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:22,450 [IPC Server handler 6 on 43909] WARN  hdfs.StateChange (FSDirRenameOp.java:validateOverwrite(531)) - DIR* FSDirectory.unprotectedRenameTo: Source /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir and destination /tmp/TestHDFSFileContextMainOperations/test/new/newfile must both be directories
2020-04-02 05:04:22,450 [IPC Server handler 6 on 43909] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 6 on 43909, call Call#650 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:51146
java.io.IOException: Source /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir and destination /tmp/TestHDFSFileContextMainOperations/test/new/newfile must both be directories
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.validateOverwrite(FSDirRenameOp.java:533)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:380)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.rename2(ClientNamenodeProtocolServerSideTranslatorPB.java:668)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:04:22,456 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:22,457 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/new/newfile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:22,458 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:22,459 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameDirectoryAsFile
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameDirectoryAsFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameFileToExistingParent
[msx] perform reset as unitTestCounterInClass 58 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:22,462 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:22,465 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:22,476 [IPC Server handler 3 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741869_1047, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:22,481 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:56054 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741869_1047]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741869_1047 src: /127.0.0.1:56054 dest: /127.0.0.1:36017
2020-04-02 05:04:22,484 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741869_1047, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56054, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741869_1047, duration(ns): 670268
2020-04-02 05:04:22,484 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741869_1047, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741869_1047, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:22,485 [IPC Server handler 4 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741869_1047 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:22,887 [IPC Server handler 7 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:22,889 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/new	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:22,890 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename (options=[OVERWRITE])	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=/tmp/TestHDFSFileContextMainOperations/test/new/newfile	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:22,894 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:22,895 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/new/newfile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:22,896 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:22,897 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameFileToExistingParent
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameFileToExistingParent
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameFileToDestinationWithParentFile
[msx] perform reset as unitTestCounterInClass 59 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:22,899 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:22,900 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:22,904 [IPC Server handler 5 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741870_1048, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:22,909 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:56162 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741870_1048]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741870_1048 src: /127.0.0.1:56162 dest: /127.0.0.1:36017
2020-04-02 05:04:22,913 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741870_1048, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56162, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741870_1048, duration(ns): 2929261
2020-04-02 05:04:22,913 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741870_1048, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741870_1048, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:22,915 [IPC Server handler 7 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741870_1048 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:23,316 [IPC Server handler 6 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:23,318 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/parentFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:23,321 [IPC Server handler 0 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741871_1049, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/parentFile
2020-04-02 05:04:23,324 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:56210 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741871_1049]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741871_1049 src: /127.0.0.1:56210 dest: /127.0.0.1:36017
2020-04-02 05:04:23,329 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741871_1049, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56210, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741871_1049, duration(ns): 3075254
2020-04-02 05:04:23,329 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741871_1049, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741871_1049, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:23,331 [IPC Server handler 1 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/parentFile is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:23,335 [IPC Server handler 2 on 43909] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 2 on 43909, call Call#675 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:51146: org.apache.hadoop.fs.ParentNotDirectoryException: /tmp/TestHDFSFileContextMainOperations/test/parentFile (is not a directory)
2020-04-02 05:04:23,337 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,338 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/parentFile/newfile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,342 [IPC Server handler 4 on 43909] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 4 on 43909, call Call#678 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:51146: org.apache.hadoop.fs.ParentNotDirectoryException: /tmp/TestHDFSFileContextMainOperations/test/parentFile (is not a directory)
2020-04-02 05:04:23,344 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,345 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/parentFile/newfile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,345 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:23,346 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameFileToDestinationWithParentFile
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameFileToDestinationWithParentFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testDeleteRecursively
[msx] perform reset as unitTestCounterInClass 60 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:23,349 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:23,350 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:23,353 [IPC Server handler 1 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741872_1050, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:23,357 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:56212 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741872_1050]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741872_1050 src: /127.0.0.1:56212 dest: /127.0.0.1:36017
2020-04-02 05:04:23,369 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741872_1050, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56212, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741872_1050, duration(ns): 1994334
2020-04-02 05:04:23,369 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741872_1050, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741872_1050, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:23,370 [IPC Server handler 3 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741872_1050 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:23,773 [IPC Server handler 5 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:23,774 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/subdir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:23,775 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,776 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,777 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/subdir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,778 [IPC Server handler 0 on 43909] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 0 on 43909, call Call#692 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 127.0.0.1:51146
org.apache.hadoop.fs.PathIsNotEmptyDirectoryException: `/tmp/TestHDFSFileContextMainOperations/test/hadoop is non empty': Directory is not empty
	at org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2998)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:04:23,780 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,781 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,782 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/subdir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,783 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,783 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,784 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,784 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/subdir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,785 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:23,785 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testDeleteRecursively
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testDeleteRecursively
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testMkdirs
[msx] perform reset as unitTestCounterInClass 61 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:23,787 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:23,788 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,789 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,790 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:23,791 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,791 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,792 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:23,794 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,794 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,795 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,796 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,798 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,799 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,799 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:23,800 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testMkdirs
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testMkdirs
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusNonExistentFile
[msx] perform reset as unitTestCounterInClass 62 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:23,804 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:23,805 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoopfsdf	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,807 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test/hadoopfsdf	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,808 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test/hadoopfsdf	dst=null	perm=null	proto=rpc
2020-04-02 05:04:23,809 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:23,809 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusNonExistentFile
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusNonExistentFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameDirectoryAsNonEmptyDirectory
[msx] perform reset as unitTestCounterInClass 63 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:23,812 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:23,813 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:23,815 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:23,818 [IPC Server handler 9 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741873_1051, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/file1
2020-04-02 05:04:23,820 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:56336 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741873_1051]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741873_1051 src: /127.0.0.1:56336 dest: /127.0.0.1:36017
2020-04-02 05:04:23,822 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741873_1051, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56336, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741873_1051, duration(ns): 487902
2020-04-02 05:04:23,822 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741873_1051, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741873_1051, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:23,823 [IPC Server handler 1 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741873_1051 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/file1
2020-04-02 05:04:23,968 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741872_1050 replica FinalizedReplica, blk_1073741872_1050, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741872 for deletion
2020-04-02 05:04:23,968 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741866_1044 replica FinalizedReplica, blk_1073741866_1044, FINALIZED
  getNumBytes()     = 4096
  getBytesOnDisk()  = 4096
  getVisibleLength()= 4096
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741866 for deletion
2020-04-02 05:04:23,968 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741872_1050 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741872
2020-04-02 05:04:23,969 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741867_1045 replica FinalizedReplica, blk_1073741867_1045, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741867 for deletion
2020-04-02 05:04:23,970 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741868_1046 replica FinalizedReplica, blk_1073741868_1046, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741868 for deletion
2020-04-02 05:04:23,970 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741867_1045 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741867
2020-04-02 05:04:23,970 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741869_1047 replica FinalizedReplica, blk_1073741869_1047, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741869 for deletion
2020-04-02 05:04:23,971 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741870_1048 replica FinalizedReplica, blk_1073741870_1048, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741870 for deletion
2020-04-02 05:04:23,970 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741866_1044 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741866
2020-04-02 05:04:23,972 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741871_1049 replica FinalizedReplica, blk_1073741871_1049, FINALIZED
  getNumBytes()     = 2048
  getBytesOnDisk()  = 2048
  getVisibleLength()= 2048
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741871 for deletion
2020-04-02 05:04:23,971 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741869_1047 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741869
2020-04-02 05:04:23,972 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741868_1046 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741868
2020-04-02 05:04:23,973 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741871_1049 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741871
2020-04-02 05:04:23,973 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1054551904-172.17.0.20-1585803845034 blk_1073741870_1048 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034/current/finalized/subdir0/subdir0/blk_1073741870
2020-04-02 05:04:24,225 [IPC Server handler 5 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/file1 is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:24,227 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/subdir/file2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:24,228 [IPC Server handler 7 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741874_1052, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/subdir/file2
2020-04-02 05:04:24,235 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:56430 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741874_1052]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741874_1052 src: /127.0.0.1:56430 dest: /127.0.0.1:36017
2020-04-02 05:04:24,240 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741874_1052, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56430, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741874_1052, duration(ns): 3193042
2020-04-02 05:04:24,240 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741874_1052, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741874_1052, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:24,241 [IPC Server handler 6 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741874_1052 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/subdir/file2
2020-04-02 05:04:24,643 [IPC Server handler 0 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/dir/subdir/file2 is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:24,644 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/new/newdir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:24,646 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/new/newdir/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:24,652 [IPC Server handler 2 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741875_1053, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/new/newdir/file1
2020-04-02 05:04:24,662 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:56516 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741875_1053]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741875_1053 src: /127.0.0.1:56516 dest: /127.0.0.1:36017
2020-04-02 05:04:24,665 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741875_1053, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56516, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741875_1053, duration(ns): 941829
2020-04-02 05:04:24,665 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741875_1053, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741875_1053, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:24,666 [IPC Server handler 5 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741875_1053 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/new/newdir/file1
2020-04-02 05:04:25,067 [IPC Server handler 4 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/new/newdir/file1 is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:25,068 [IPC Server handler 7 on 43909] WARN  hdfs.StateChange (FSDirRenameOp.java:validateOverwrite(537)) - DIR* FSDirectory.unprotectedRenameTo: rename destination /tmp/TestHDFSFileContextMainOperations/test/new/newdir already exists
2020-04-02 05:04:25,069 [IPC Server handler 7 on 43909] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 7 on 43909, call Call#739 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:51146: org.apache.hadoop.fs.FileAlreadyExistsException: rename destination /tmp/TestHDFSFileContextMainOperations/test/new/newdir already exists
2020-04-02 05:04:25,070 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:25,071 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/new/newdir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:25,071 [IPC Server handler 9 on 43909] WARN  hdfs.StateChange (FSDirRenameOp.java:validateOverwrite(546)) - DIR* FSDirectory.unprotectedRenameTo: rename destination directory is not empty: /tmp/TestHDFSFileContextMainOperations/test/new/newdir
2020-04-02 05:04:25,072 [IPC Server handler 9 on 43909] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 9 on 43909, call Call#742 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:51146
java.io.IOException: rename destination directory is not empty: /tmp/TestHDFSFileContextMainOperations/test/new/newdir
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.validateOverwrite(FSDirRenameOp.java:548)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:380)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.rename2(ClientNamenodeProtocolServerSideTranslatorPB.java:668)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:04:25,073 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/dir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:25,074 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/new/newdir	dst=null	perm=null	proto=rpc
2020-04-02 05:04:25,075 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:25,076 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameDirectoryAsNonEmptyDirectory
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameDirectoryAsNonEmptyDirectory
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testDeleteNonExistentFile
[msx] perform reset as unitTestCounterInClass 64 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:25,078 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:25,079 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:25,080 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:25,080 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:25,081 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testDeleteNonExistentFile
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testDeleteNonExistentFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameNonExistentPath
[msx] perform reset as unitTestCounterInClass 65 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:25,083 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:25,086 [IPC Server handler 0 on 43909] WARN  hdfs.StateChange (FSDirRenameOp.java:validateRenameSource(560)) - DIR* FSDirectory.unprotectedRenameTo: rename source /tmp/TestHDFSFileContextMainOperations/test/hadoop/nonExistent is not found.
2020-04-02 05:04:25,086 [IPC Server handler 0 on 43909] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 0 on 43909, call Call#751 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:51146: java.io.FileNotFoundException: rename source /tmp/TestHDFSFileContextMainOperations/test/hadoop/nonExistent is not found.
2020-04-02 05:04:25,089 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/nonExistent	dst=null	perm=null	proto=rpc
2020-04-02 05:04:25,090 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/new/newpath	dst=null	perm=null	proto=rpc
2020-04-02 05:04:25,091 [IPC Server handler 2 on 43909] WARN  hdfs.StateChange (FSDirRenameOp.java:validateRenameSource(560)) - DIR* FSDirectory.unprotectedRenameTo: rename source /tmp/TestHDFSFileContextMainOperations/test/hadoop/nonExistent is not found.
2020-04-02 05:04:25,091 [IPC Server handler 2 on 43909] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 2 on 43909, call Call#754 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:51146: java.io.FileNotFoundException: rename source /tmp/TestHDFSFileContextMainOperations/test/hadoop/nonExistent is not found.
2020-04-02 05:04:25,098 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/nonExistent	dst=null	perm=null	proto=rpc
2020-04-02 05:04:25,100 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/new/newpath	dst=null	perm=null	proto=rpc
2020-04-02 05:04:25,100 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:25,101 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameNonExistentPath
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameNonExistentPath
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagCreateAppendNonExistingFile
[msx] perform reset as unitTestCounterInClass 66 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:25,108 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:25,111 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testCreateFlagCreateAppendNonExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:25,113 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/testCreateFlagCreateAppendNonExistingFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:25,114 [IPC Server handler 0 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741876_1054, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/testCreateFlagCreateAppendNonExistingFile
2020-04-02 05:04:25,116 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:56608 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741876_1054]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741876_1054 src: /127.0.0.1:56608 dest: /127.0.0.1:36017
2020-04-02 05:04:25,118 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741876_1054, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56608, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741876_1054, duration(ns): 631564
2020-04-02 05:04:25,118 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741876_1054, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741876_1054, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:25,126 [IPC Server handler 1 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/testCreateFlagCreateAppendNonExistingFile is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:25,127 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testCreateFlagCreateAppendNonExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:25,128 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testCreateFlagCreateAppendNonExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:25,129 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:25,130 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagCreateAppendNonExistingFile
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagCreateAppendNonExistingFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusFilterWithMultiplePathWildcardsAndNonTrivialFilter
[msx] perform reset as unitTestCounterInClass 67 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:25,134 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:25,135 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=null	proto=rpc
2020-04-02 05:04:25,136 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/aaa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:25,142 [IPC Server handler 6 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axa	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:25,146 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axx	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:25,147 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/axx	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:25,149 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop	dst=null	perm=null	proto=rpc
2020-04-02 05:04:25,151 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:25,154 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusFilterWithMultiplePathWildcardsAndNonTrivialFilter
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testGlobStatusFilterWithMultiplePathWildcardsAndNonTrivialFilter
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testOutputStreamClosedTwice
[msx] perform reset as unitTestCounterInClass 68 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:25,162 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:25,164 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:25,166 [IPC Server handler 8 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741877_1055, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:25,167 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:56610 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741877_1055]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741877_1055 src: /127.0.0.1:56610 dest: /127.0.0.1:36017
2020-04-02 05:04:25,169 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741877_1055, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56610, dest: /127.0.0.1:36017, bytes: 2, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741877_1055, duration(ns): 540107
2020-04-02 05:04:25,169 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741877_1055, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741877_1055, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:25,171 [IPC Server handler 4 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:25,172 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:25,173 [IPC Server handler 7 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testOutputStreamClosedTwice
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testOutputStreamClosedTwice
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagOverwriteExistingFile
[msx] perform reset as unitTestCounterInClass 69 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:25,176 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:25,178 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/testCreateFlagOverwriteExistingFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:25,180 [IPC Server handler 1 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741878_1056, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/testCreateFlagOverwriteExistingFile
2020-04-02 05:04:25,186 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:56612 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741878_1056]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741878_1056 src: /127.0.0.1:56612 dest: /127.0.0.1:36017
2020-04-02 05:04:25,197 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741878_1056, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56612, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741878_1056, duration(ns): 9764168
2020-04-02 05:04:25,197 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741878_1056, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741878_1056, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:25,199 [IPC Server handler 3 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/testCreateFlagOverwriteExistingFile is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:25,201 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/testCreateFlagOverwriteExistingFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:25,203 [IPC Server handler 8 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741879_1057, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/testCreateFlagOverwriteExistingFile
2020-04-02 05:04:25,207 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:56614 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741879_1057]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741879_1057 src: /127.0.0.1:56614 dest: /127.0.0.1:36017
2020-04-02 05:04:25,209 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741879_1057, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56614, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741879_1057, duration(ns): 629472
2020-04-02 05:04:25,209 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741879_1057, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741879_1057, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:25,210 [IPC Server handler 6 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741879_1057 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/testCreateFlagOverwriteExistingFile
2020-04-02 05:04:25,613 [IPC Server handler 7 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/testCreateFlagOverwriteExistingFile is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:25,614 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testCreateFlagOverwriteExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:25,615 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/testCreateFlagOverwriteExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:04:25,616 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:25,617 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagOverwriteExistingFile
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagOverwriteExistingFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameFileToItself
[msx] perform reset as unitTestCounterInClass 70 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:25,619 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:25,620 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:25,627 [IPC Server handler 5 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741880_1058, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:25,642 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:56620 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741880_1058]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741880_1058 src: /127.0.0.1:56620 dest: /127.0.0.1:36017
2020-04-02 05:04:25,664 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741880_1058, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56620, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741880_1058, duration(ns): 14041679
2020-04-02 05:04:25,665 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741880_1058, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741880_1058, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:25,670 [IPC Server handler 8 on 43909] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741880_1058 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestHDFSFileContextMainOperations/test/hadoop/file
2020-04-02 05:04:26,072 [IPC Server handler 6 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:26,073 [IPC Server handler 7 on 43909] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 7 on 43909, call Call#800 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:51146: org.apache.hadoop.fs.FileAlreadyExistsException: The source /tmp/TestHDFSFileContextMainOperations/test/hadoop/file and destination /tmp/TestHDFSFileContextMainOperations/test/hadoop/file are the same
2020-04-02 05:04:26,075 [IPC Server handler 0 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:26,076 [IPC Server handler 9 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:26,077 [IPC Server handler 1 on 43909] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 1 on 43909, call Call#803 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename2 from 127.0.0.1:51146: org.apache.hadoop.fs.FileAlreadyExistsException: The source /tmp/TestHDFSFileContextMainOperations/test/hadoop/file and destination /tmp/TestHDFSFileContextMainOperations/test/hadoop/file are the same
2020-04-02 05:04:26,079 [IPC Server handler 2 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:26,080 [IPC Server handler 3 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestHDFSFileContextMainOperations/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:04:26,080 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:26,082 [IPC Server handler 5 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameFileToItself
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testRenameFileToItself
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagCreateExistingFile
[msx] perform reset as unitTestCounterInClass 71 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:26,084 [IPC Server handler 8 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestHDFSFileContextMainOperations/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:04:26,087 [IPC Server handler 4 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestHDFSFileContextMainOperations/test/testCreateFlagCreateExistingFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:04:26,089 [IPC Server handler 6 on 43909] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741881_1059, replicas=127.0.0.1:36017 for /tmp/TestHDFSFileContextMainOperations/test/testCreateFlagCreateExistingFile
2020-04-02 05:04:26,110 [DataXceiver for client DFSClient_NONMAPREDUCE_1392736373_1 at /127.0.0.1:56626 [Receiving block BP-1054551904-172.17.0.20-1585803845034:blk_1073741881_1059]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1054551904-172.17.0.20-1585803845034:blk_1073741881_1059 src: /127.0.0.1:56626 dest: /127.0.0.1:36017
2020-04-02 05:04:26,130 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741881_1059, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56626, dest: /127.0.0.1:36017, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1392736373_1, offset: 0, srvID: 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91, blockid: BP-1054551904-172.17.0.20-1585803845034:blk_1073741881_1059, duration(ns): 13639241
2020-04-02 05:04:26,130 [PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741881_1059, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1054551904-172.17.0.20-1585803845034:blk_1073741881_1059, type=LAST_IN_PIPELINE terminating
2020-04-02 05:04:26,134 [IPC Server handler 0 on 43909] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestHDFSFileContextMainOperations/test/testCreateFlagCreateExistingFile is closed by DFSClient_NONMAPREDUCE_1392736373_1
2020-04-02 05:04:26,145 [IPC Server handler 9 on 43909] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 9 on 43909, call Call#812 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 127.0.0.1:51146: org.apache.hadoop.fs.FileAlreadyExistsException: /tmp/TestHDFSFileContextMainOperations/test/testCreateFlagCreateExistingFile for client 127.0.0.1 already exists
2020-04-02 05:04:26,148 [main] INFO  fs.FileContextMainOperationsBaseTest (FileContextMainOperationsBaseTest.java:tearDown(119)) - Deleting test root path hdfs://localhost:43909/tmp/TestHDFSFileContextMainOperations
2020-04-02 05:04:26,154 [IPC Server handler 1 on 43909] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestHDFSFileContextMainOperations	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagCreateExistingFile
[msx] writeFile testName = org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagCreateExistingFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:26,156 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:04:26,156 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:04:26,156 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 39974 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:26,156 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:26,156 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@29ad44e3] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:26,157 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-54746245-acee-4605-b3a2-76160e1ebb72) exiting.
2020-04-02 05:04:26,157 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-eec506ae-cf75-4c6b-9ece-cd33e8e8b2ee) exiting.
2020-04-02 05:04:26,210 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1c25b8a7{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:26,212 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@200606de{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:26,213 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@797501a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:26,213 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@14bb2297{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:04:26,227 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39974
2020-04-02 05:04:26,229 [IPC Server listener on 39974] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39974
2020-04-02 05:04:26,229 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:26,231 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1054551904-172.17.0.20-1585803845034 (Datanode Uuid 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91) service to localhost/127.0.0.1:43909
2020-04-02 05:04:26,231 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1054551904-172.17.0.20-1585803845034 (Datanode Uuid 5175af85-f0ed-4fdf-bbb6-c6b1d202ce91)
2020-04-02 05:04:26,232 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:26,232 [BP-1054551904-172.17.0.20-1585803845034 heartbeating to localhost/127.0.0.1:43909] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1054551904-172.17.0.20-1585803845034
2020-04-02 05:04:26,249 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1054551904-172.17.0.20-1585803845034] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:26,252 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1054551904-172.17.0.20-1585803845034] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:26,256 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:26,257 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:26,258 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:26,258 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:26,260 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:26,261 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:04:26,261 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 43909 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:26,261 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:26,262 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@42a9a63e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:04:26,262 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 137, 686
2020-04-02 05:04:26,262 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@62da83ed] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:04:26,263 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 551 Total time for transactions(ms): 44 Number of transactions batched in Syncs: 278 Number of syncs: 410 SyncTimes(ms): 22 8 
2020-04-02 05:04:26,264 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000137 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000137-0000000000000000687
2020-04-02 05:04:26,267 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000137 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000137-0000000000000000687
2020-04-02 05:04:26,268 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:04:26,268 [CacheReplicationMonitor(837841609)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:04:26,269 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43909
2020-04-02 05:04:26,270 [IPC Server listener on 43909] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43909
2020-04-02 05:04:26,285 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:04:26,285 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:04:26,285 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:26,311 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:26,311 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:04:26,313 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2970a5bc{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:04:26,334 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@50305a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:26,335 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@51768776{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:26,335 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2ca47471{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:04:26,337 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:04:26,342 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:04:26,343 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] all testRunFinished

[msx] before_class
2020-04-02 05:03:00,913 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=4, numDataNodes=4
2020-04-02 05:03:00,930 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(874)) - MiniDFSCluster disabling checkpointing in the Standby node since no HTTP ports have been specified.
2020-04-02 05:03:00,931 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(880)) - MiniDFSCluster disabling log-roll triggering in the Standby node since no IPC ports have been specified.
Formatting using clusterid: testClusterID
2020-04-02 05:03:01,719 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:01,743 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:01,745 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:01,747 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:01,757 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:01,757 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:01,758 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:01,764 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns0
2020-04-02 05:03:01,765 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:01,820 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:01,825 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:03:01,826 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:01,827 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:01,834 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:01,835 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:01
2020-04-02 05:03:01,837 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:01,838 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,840 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:03:01,841 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:01,865 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:01,876 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:01,877 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:01,877 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:01,878 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:01,878 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:01,879 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:01,879 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:01,879 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:01,880 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:01,880 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:01,880 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:01,912 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:03:01,935 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:01,936 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,937 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:03:01,937 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:01,945 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:01,945 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:01,946 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:01,947 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:01,954 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:01,967 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:01,973 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:01,974 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,975 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:03:01,975 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:01,987 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:01,988 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:01,988 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:01,995 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:01,996 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:01,999 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:01,999 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:02,000 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:03:02,000 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:02,053 [JUnit] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:02,073 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:03:02,076 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:03:02,079 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1 has been successfully formatted.
2020-04-02 05:03:02,092 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:03:02,092 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:03:02,237 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:03:02,237 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:03:02,250 [JUnit] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:03:02,324 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1263)) - Copying namedir from primary node dir file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3
2020-04-02 05:03:02,343 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1263)) - Copying namedir from primary node dir file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-4
2020-04-02 05:03:02,349 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:03:02,918 [JUnit] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:03:02,971 [JUnit] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:03:03,051 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:03:03,052 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:03:03,058 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:03:03,060 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-04-02 05:03:03,061 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use ns0 to access this namenode/service.
2020-04-02 05:03:03,106 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@70cf32e3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:03,125 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:03:03,164 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3573ms
2020-04-02 05:03:03,348 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:03,356 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:03:03,365 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:03,368 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:03:03,368 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:03,369 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:03,420 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:03,421 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:03,440 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41822
2020-04-02 05:03:03,442 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:03,498 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@a82c5f1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:03,508 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@51c693d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:03,697 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@71e9ebae{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:03:03,705 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5ef5c734{HTTP/1.1,[http/1.1]}{localhost:41822}
2020-04-02 05:03:03,717 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @4114ms
2020-04-02 05:03:03,729 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:03,730 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:03,732 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:03,733 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:03,733 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:03,734 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:03,734 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:03,735 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns0
2020-04-02 05:03:03,735 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:03,736 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:03,738 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:03,738 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:03,739 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:03,739 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:03
2020-04-02 05:03:03,740 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:03,740 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:03,741 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:03,747 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:03,755 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:03,756 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:03,756 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:03,758 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:03,759 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:03,760 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:03,760 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:03,761 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:03,768 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:03,769 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:03,770 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:03,771 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:03,771 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:03,772 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:03,772 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:03,778 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:03,781 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:03,782 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:03,782 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:03,783 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:03,787 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:03,787 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:03,787 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:03,788 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:03,790 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:03,790 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:03,791 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:03,791 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:03,791 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:03,792 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:03,792 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:03,792 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:03,792 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:03,793 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:03,793 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:03,804 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 3682@dfeaa374b3e2
2020-04-02 05:03:03,807 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 3682@dfeaa374b3e2
2020-04-02 05:03:03,808 [JUnit] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1
2020-04-02 05:03:03,812 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:03:03,812 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:03:03,852 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:03:03,861 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:03:03,862 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:03:03,868 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-04-02 05:03:03,869 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:03:03,869 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 68 msecs
2020-04-02 05:03:04,103 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to 0.0.0.0:0
2020-04-02 05:03:04,123 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:04,142 [Socket Reader #1 for port 33679] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33679
2020-04-02 05:03:04,465 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:03:04,535 [JUnit] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:03:04,553 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:03:04,553 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:03:04,554 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:03:04,602 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:04,602 [IPC Server listener on 33679] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33679: starting
2020-04-02 05:03:04,630 [JUnit] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:33679
2020-04-02 05:03:04,634 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1376)) - Starting services required for standby state
2020-04-02 05:03:04,637 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-04-02 05:03:04,637 [JUnit] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(189)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-04-02 05:03:04,640 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 33679 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:04,646 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:03:04,647 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:03:04,647 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:03:04,648 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-04-02 05:03:04,648 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use ns0 to access this namenode/service.
2020-04-02 05:03:04,657 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1698fc68] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:04,657 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:03:04,659 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:04,660 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:03:04,663 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:04,664 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:03:04,665 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:04,665 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:04,667 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:04,667 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:04,668 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39586
2020-04-02 05:03:04,668 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:04,672 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2b5825fa{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:04,673 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2cae1042{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:04,684 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1f2f9244{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:03:04,686 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4c4d27c8{HTTP/1.1,[http/1.1]}{localhost:39586}
2020-04-02 05:03:04,687 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5096ms
2020-04-02 05:03:04,708 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:04,709 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:04,709 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:04,709 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:04,712 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:04,712 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:04,712 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:04,713 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns0
2020-04-02 05:03:04,713 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:04,714 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:04,714 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:04,714 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:04,715 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:04,715 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:04
2020-04-02 05:03:04,715 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:04,716 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:04,716 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:04,716 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:04,728 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:04,729 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:04,729 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:04,729 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:04,730 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:04,730 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:04,730 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:04,730 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:04,730 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:04,731 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:04,731 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:04,731 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:04,732 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:04,732 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:04,732 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:04,732 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:04,739 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:04,740 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:04,740 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:04,740 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:04,741 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:04,741 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:04,741 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:04,741 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:04,741 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:04,742 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:04,744 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:04,744 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:04,744 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:04,745 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:04,745 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:04,745 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:04,745 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:04,746 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:04,746 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:04,749 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/in_use.lock acquired by nodename 3682@dfeaa374b3e2
2020-04-02 05:03:04,751 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-4/in_use.lock acquired by nodename 3682@dfeaa374b3e2
2020-04-02 05:03:04,753 [JUnit] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1
2020-04-02 05:03:04,757 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:03:04,757 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:03:04,767 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:03:04,769 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:03:04,773 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000
2020-04-02 05:03:04,774 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-04-02 05:03:04,774 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:03:04,775 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 27 msecs
2020-04-02 05:03:04,775 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to 0.0.0.0:0
2020-04-02 05:03:04,776 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:04,776 [Socket Reader #1 for port 44155] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44155
2020-04-02 05:03:04,786 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:03:04,807 [JUnit] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:03:04,809 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:03:04,809 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:03:04,809 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:03:04,820 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:04,822 [IPC Server listener on 44155] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44155: starting
2020-04-02 05:03:04,822 [JUnit] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:44155
2020-04-02 05:03:04,823 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1376)) - Starting services required for standby state
2020-04-02 05:03:04,823 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-04-02 05:03:04,823 [JUnit] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(189)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-04-02 05:03:04,824 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 44155 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
Formatting using clusterid: testClusterID
2020-04-02 05:03:04,841 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:04,842 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:04,842 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:04,842 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:04,842 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:04,842 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:04,842 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:04,843 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns1
2020-04-02 05:03:04,843 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:04,844 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:04,844 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:04,844 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:04,845 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:04,845 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:04
2020-04-02 05:03:04,845 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:04,845 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:04,846 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:04,847 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:04,866 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:04,867 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:04,867 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:04,867 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:04,868 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:04,868 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:04,868 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:04,868 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:04,868 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:04,868 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:04,868 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:04,869 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:04,869 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:04,869 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:04,870 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:04,870 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:04,881 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:04,883 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:04,883 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:04,883 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:04,894 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:04,894 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:04,894 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:04,894 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:04,895 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:04,895 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:04,902 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:04,902 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:04,902 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:04,902 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:04,903 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:04,903 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:04,903 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:04,903 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:04,903 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:04,911 [JUnit] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:04,915 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 has been successfully formatted.
2020-04-02 05:03:04,919 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 has been successfully formatted.
2020-04-02 05:03:04,923 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3 has been successfully formatted.
2020-04-02 05:03:04,929 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:03:04,929 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:03:04,936 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:03:04,944 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:03:04,947 [JUnit] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:03:04,949 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1263)) - Copying namedir from primary node dir file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 to file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7
2020-04-02 05:03:04,954 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1263)) - Copying namedir from primary node dir file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 to file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-8
2020-04-02 05:03:04,959 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:03:04,960 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:03:04,960 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:03:04,961 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-04-02 05:03:04,961 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use ns1 to access this namenode/service.
2020-04-02 05:03:04,974 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@662f5666] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:04,974 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:03:04,978 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:04,980 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:03:04,983 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:04,984 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:03:04,985 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:04,985 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:04,987 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:04,987 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:04,988 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45666
2020-04-02 05:03:04,988 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:04,996 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f8f9349{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:04,997 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7446d8d5{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:05,011 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@590c73d3{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:03:05,012 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6b9ce1bf{HTTP/1.1,[http/1.1]}{localhost:45666}
2020-04-02 05:03:05,013 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5422ms
2020-04-02 05:03:05,015 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:05,015 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:05,015 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:05,016 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:05,016 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:05,016 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:05,016 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:05,017 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns1
2020-04-02 05:03:05,017 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:05,017 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:05,018 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:05,018 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:05,021 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:05,021 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:05
2020-04-02 05:03:05,022 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:05,022 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:05,023 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:05,023 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:05,038 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:05,039 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:05,039 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:05,039 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:05,039 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:05,040 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:05,040 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:05,040 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:05,040 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:05,040 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:05,040 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:05,041 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:05,041 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:05,041 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:05,044 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:05,044 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:05,051 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:05,051 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:05,051 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:05,051 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:05,051 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:05,052 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:05,052 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:05,052 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:05,052 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:05,053 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:05,055 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:05,055 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:05,055 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:05,055 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:05,055 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:05,056 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:05,056 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:05,056 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:05,056 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:05,059 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/in_use.lock acquired by nodename 3682@dfeaa374b3e2
2020-04-02 05:03:05,061 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/in_use.lock acquired by nodename 3682@dfeaa374b3e2
2020-04-02 05:03:05,061 [JUnit] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3
2020-04-02 05:03:05,064 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:03:05,064 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:03:05,066 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:03:05,067 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:03:05,067 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage_0000000000000000000
2020-04-02 05:03:05,067 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-04-02 05:03:05,067 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:03:05,068 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 10 msecs
2020-04-02 05:03:05,068 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to 0.0.0.0:0
2020-04-02 05:03:05,068 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:05,069 [Socket Reader #1 for port 43585] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43585
2020-04-02 05:03:05,075 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:03:05,109 [JUnit] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:03:05,111 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:03:05,111 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:03:05,111 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:03:05,117 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:05,117 [IPC Server listener on 43585] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43585: starting
2020-04-02 05:03:05,120 [JUnit] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:43585
2020-04-02 05:03:05,120 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1376)) - Starting services required for standby state
2020-04-02 05:03:05,121 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-04-02 05:03:05,121 [JUnit] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(189)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-04-02 05:03:05,121 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 43585 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:05,135 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:03:05,136 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:03:05,136 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:03:05,136 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-04-02 05:03:05,137 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use ns1 to access this namenode/service.
2020-04-02 05:03:05,144 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@36546a22] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:05,144 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:03:05,146 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:05,148 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:03:05,151 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:05,154 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:03:05,154 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:05,154 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:05,156 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:05,157 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:05,157 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38724
2020-04-02 05:03:05,158 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:05,160 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@47605f2f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:05,161 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1dd0e7c4{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:05,170 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@650eab8{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:03:05,171 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@30f5a68a{HTTP/1.1,[http/1.1]}{localhost:38724}
2020-04-02 05:03:05,171 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5580ms
2020-04-02 05:03:05,173 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:05,173 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:05,179 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:05,180 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:05,180 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:05,180 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:05,180 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:05,181 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns1
2020-04-02 05:03:05,181 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:05,181 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:05,191 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:05,192 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:05,192 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:05,192 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:05
2020-04-02 05:03:05,193 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:05,193 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:05,193 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:05,193 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:05,205 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:05,206 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:05,206 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:05,206 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:05,207 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:05,207 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:05,207 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:05,207 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:05,207 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:05,207 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:05,207 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:05,208 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:05,208 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:05,208 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:05,208 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:05,209 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:05,214 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:05,215 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:05,215 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:05,215 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:05,215 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:05,215 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:05,216 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:05,216 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:05,216 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:05,216 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:05,218 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:05,218 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:05,218 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:05,219 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:05,219 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:05,219 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:05,219 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:05,219 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:05,220 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:05,223 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/in_use.lock acquired by nodename 3682@dfeaa374b3e2
2020-04-02 05:03:05,224 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-8/in_use.lock acquired by nodename 3682@dfeaa374b3e2
2020-04-02 05:03:05,225 [JUnit] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3
2020-04-02 05:03:05,227 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:03:05,227 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:03:05,229 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:03:05,230 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:03:05,230 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/current/fsimage_0000000000000000000
2020-04-02 05:03:05,230 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-04-02 05:03:05,230 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:03:05,230 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 9 msecs
2020-04-02 05:03:05,231 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to 0.0.0.0:0
2020-04-02 05:03:05,231 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:05,241 [Socket Reader #1 for port 41130] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41130
2020-04-02 05:03:05,241 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:03:05,373 [JUnit] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:03:05,375 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:03:05,375 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:03:05,376 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:03:05,384 [IPC Server listener on 41130] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41130: starting
2020-04-02 05:03:05,385 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:05,401 [JUnit] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:41130
2020-04-02 05:03:05,402 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1376)) - Starting services required for standby state
2020-04-02 05:03:05,402 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-04-02 05:03:05,402 [JUnit] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(189)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-04-02 05:03:05,402 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 41130 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:05,412 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:05,428 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:05,442 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:05,444 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:05,445 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:05,451 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:05,454 [JUnit] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:05,457 [JUnit] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:05,458 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:05,463 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:05,470 [JUnit] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:46742
2020-04-02 05:03:05,472 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:05,472 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:05,492 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:05,493 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:05,496 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:05,497 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:05,497 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:05,497 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:05,501 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43387
2020-04-02 05:03:05,501 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:05,503 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5ef0d29e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:05,504 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@51850751{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:05,514 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5860f3d7{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:05,516 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1d7f7be7{HTTP/1.1,[http/1.1]}{localhost:43387}
2020-04-02 05:03:05,517 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5925ms
2020-04-02 05:03:06,263 [JUnit] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33193
2020-04-02 05:03:06,264 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@182f1e9a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:06,265 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:06,266 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:06,284 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:06,285 [Socket Reader #1 for port 45097] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45097
2020-04-02 05:03:06,295 [JUnit] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:45097
2020-04-02 05:03:06,317 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-04-02 05:03:06,320 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-04-02 05:03:06,333 [Thread-153] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33679 starting to offer service
2020-04-02 05:03:06,334 [Thread-154] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44155 starting to offer service
2020-04-02 05:03:06,335 [Thread-156] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41130 starting to offer service
2020-04-02 05:03:06,335 [Thread-155] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43585 starting to offer service
2020-04-02 05:03:06,345 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:06,346 [IPC Server listener on 45097] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45097: starting
2020-04-02 05:03:06,357 [JUnit] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 45097 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:06,359 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:06,367 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:06,368 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:06,372 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:06,372 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:06,372 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:06,372 [JUnit] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:06,373 [JUnit] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:06,373 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:06,373 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:06,375 [JUnit] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:39470
2020-04-02 05:03:06,376 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:06,376 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:06,414 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:06,418 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:06,419 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:06,420 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:06,420 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:06,421 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:06,424 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44670
2020-04-02 05:03:06,424 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:06,444 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4d63b624{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:06,461 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5b800468{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:06,476 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@733c423e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:06,477 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4b629f13{HTTP/1.1,[http/1.1]}{localhost:44670}
2020-04-02 05:03:06,477 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @6886ms
2020-04-02 05:03:06,567 [JUnit] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42457
2020-04-02 05:03:06,568 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:06,568 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1b9ea3e3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:06,568 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:06,569 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:06,570 [Socket Reader #1 for port 38813] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38813
2020-04-02 05:03:06,577 [JUnit] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:38813
2020-04-02 05:03:06,581 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-04-02 05:03:06,582 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-04-02 05:03:06,583 [Thread-183] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33679 starting to offer service
2020-04-02 05:03:06,583 [Thread-184] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44155 starting to offer service
2020-04-02 05:03:06,583 [Thread-185] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43585 starting to offer service
2020-04-02 05:03:06,586 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:06,588 [JUnit] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 38813 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:06,587 [IPC Server listener on 38813] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38813: starting
2020-04-02 05:03:06,593 [Thread-186] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41130 starting to offer service
2020-04-02 05:03:06,593 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:06,596 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:06,597 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:06,599 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:06,599 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:06,600 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:06,600 [JUnit] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:06,600 [JUnit] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:06,600 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:06,601 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:06,602 [JUnit] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34004
2020-04-02 05:03:06,602 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:06,602 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:06,605 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:06,606 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:06,608 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:06,609 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:06,609 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:06,609 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:06,610 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39374
2020-04-02 05:03:06,610 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:06,617 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@52350abb{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:06,618 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1a6f2363{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:06,626 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@23c388c2{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:06,627 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@486be205{HTTP/1.1,[http/1.1]}{localhost:39374}
2020-04-02 05:03:06,628 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @7037ms
2020-04-02 05:03:06,664 [JUnit] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41368
2020-04-02 05:03:06,664 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:06,665 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:06,664 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@74f7d1d2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:06,665 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:06,666 [Socket Reader #1 for port 36104] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36104
2020-04-02 05:03:06,674 [JUnit] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:36104
2020-04-02 05:03:06,679 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-04-02 05:03:06,680 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-04-02 05:03:06,681 [Thread-209] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33679 starting to offer service
2020-04-02 05:03:06,681 [Thread-210] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44155 starting to offer service
2020-04-02 05:03:06,686 [Thread-211] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43585 starting to offer service
2020-04-02 05:03:06,684 [JUnit] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 36104 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:06,684 [IPC Server listener on 36104] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36104: starting
2020-04-02 05:03:06,684 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:06,683 [Thread-212] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41130 starting to offer service
2020-04-02 05:03:06,694 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:06,695 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:06,703 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:06,706 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:06,707 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:06,707 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:06,707 [JUnit] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:06,708 [JUnit] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:06,709 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:06,709 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:06,710 [JUnit] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:45716
2020-04-02 05:03:06,710 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:06,710 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:06,718 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:06,719 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:06,720 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:06,720 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:06,720 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:06,720 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:06,721 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35107
2020-04-02 05:03:06,721 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:06,726 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3a0807b7{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:06,726 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5769e7ae{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:06,735 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@41200e0c{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:06,739 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@40f33492{HTTP/1.1,[http/1.1]}{localhost:35107}
2020-04-02 05:03:06,740 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @7149ms
2020-04-02 05:03:06,811 [Thread-153] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:06,812 [Thread-209] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:06,813 [Thread-184] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:06,815 [Thread-209] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 3682@dfeaa374b3e2
2020-04-02 05:03:06,816 [Thread-184] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 3682@dfeaa374b3e2
2020-04-02 05:03:06,816 [Thread-153] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 3682@dfeaa374b3e2
2020-04-02 05:03:06,818 [Thread-209] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 is not formatted for namespace 1354143010. Formatting...
2020-04-02 05:03:06,819 [JUnit] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34272
2020-04-02 05:03:06,819 [Thread-184] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 is not formatted for namespace 1354143010. Formatting...
2020-04-02 05:03:06,819 [Thread-153] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 is not formatted for namespace 1354143010. Formatting...
2020-04-02 05:03:06,819 [Thread-184] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-96f1659a-c211-4ad3-84e0-da83c3540e46 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 
2020-04-02 05:03:06,819 [Thread-209] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bf5b0949-559d-40b7-b6dd-3d05fe8d872e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 
2020-04-02 05:03:06,819 [Thread-153] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0c6ae5eb-828f-492f-b11b-76ebfd537f74 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 
2020-04-02 05:03:06,819 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:06,820 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:06,821 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:06,819 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2ad3a1bb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:06,823 [Socket Reader #1 for port 34411] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34411
2020-04-02 05:03:06,825 [Thread-153] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 3682@dfeaa374b3e2
2020-04-02 05:03:06,825 [Thread-153] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 is not formatted for namespace 1354143010. Formatting...
2020-04-02 05:03:06,825 [Thread-209] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 3682@dfeaa374b3e2
2020-04-02 05:03:06,826 [Thread-153] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-648aac64-888b-4fed-a7be-2bcf276a79ed for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 
2020-04-02 05:03:06,826 [Thread-209] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 is not formatted for namespace 1354143010. Formatting...
2020-04-02 05:03:06,826 [Thread-209] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8401c763-4155-4d3e-be82-e7fc93cc3150 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 
2020-04-02 05:03:06,830 [JUnit] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:34411
2020-04-02 05:03:06,835 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-04-02 05:03:06,835 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-04-02 05:03:06,837 [Thread-184] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 3682@dfeaa374b3e2
2020-04-02 05:03:06,838 [Thread-184] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 is not formatted for namespace 1354143010. Formatting...
2020-04-02 05:03:06,838 [Thread-184] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b2b74576-90c6-41f8-afc7-9899cdd61f3b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 
2020-04-02 05:03:06,846 [Thread-235] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33679 starting to offer service
2020-04-02 05:03:06,848 [Thread-236] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44155 starting to offer service
2020-04-02 05:03:06,858 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:06,859 [Thread-209] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:06,860 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-419159729-172.17.0.16-1585803782037 is not formatted. Formatting ...
2020-04-02 05:03:06,860 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-419159729-172.17.0.16-1585803782037 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-419159729-172.17.0.16-1585803782037/current
2020-04-02 05:03:06,867 [Thread-238] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41130 starting to offer service
2020-04-02 05:03:06,870 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:06,867 [Thread-237] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43585 starting to offer service
2020-04-02 05:03:06,870 [Thread-184] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:06,870 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:06,871 [Thread-184] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:06,871 [Thread-153] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:06,871 [Thread-184] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-419159729-172.17.0.16-1585803782037 is not formatted. Formatting ...
2020-04-02 05:03:06,871 [Thread-184] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-419159729-172.17.0.16-1585803782037 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-419159729-172.17.0.16-1585803782037/current
2020-04-02 05:03:06,871 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-419159729-172.17.0.16-1585803782037 is not formatted. Formatting ...
2020-04-02 05:03:06,872 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-419159729-172.17.0.16-1585803782037 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-419159729-172.17.0.16-1585803782037/current
2020-04-02 05:03:06,875 [IPC Server listener on 34411] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34411: starting
2020-04-02 05:03:06,883 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:06,884 [Thread-153] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:06,884 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-419159729-172.17.0.16-1585803782037 is not formatted. Formatting ...
2020-04-02 05:03:06,884 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-419159729-172.17.0.16-1585803782037 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-419159729-172.17.0.16-1585803782037/current
2020-04-02 05:03:06,887 [JUnit] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 34411 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:06,924 [Thread-184] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:06,924 [Thread-184] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:06,924 [Thread-184] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-419159729-172.17.0.16-1585803782037 is not formatted. Formatting ...
2020-04-02 05:03:06,924 [Thread-184] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-419159729-172.17.0.16-1585803782037 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-419159729-172.17.0.16-1585803782037/current
2020-04-02 05:03:06,938 [Thread-153] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1354143010;bpid=BP-419159729-172.17.0.16-1585803782037;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1354143010;c=1585803782037;bpid=BP-419159729-172.17.0.16-1585803782037;dnuuid=null
2020-04-02 05:03:06,939 [Thread-184] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1354143010;bpid=BP-419159729-172.17.0.16-1585803782037;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1354143010;c=1585803782037;bpid=BP-419159729-172.17.0.16-1585803782037;dnuuid=null
2020-04-02 05:03:06,938 [Thread-156] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:06,939 [Thread-156] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 has already been used.
2020-04-02 05:03:06,941 [Thread-237] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:06,942 [Thread-156] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 has already been used.
2020-04-02 05:03:06,942 [Thread-237] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 3682@dfeaa374b3e2
2020-04-02 05:03:06,943 [Thread-237] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 is not formatted for namespace 1861411397. Formatting...
2020-04-02 05:03:06,943 [Thread-237] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d797cfd7-71fd-4fec-97e7-55ba58c03ae0 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 
2020-04-02 05:03:06,946 [Thread-186] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:06,946 [Thread-186] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 has already been used.
2020-04-02 05:03:06,946 [Thread-186] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 has already been used.
2020-04-02 05:03:06,957 [Thread-237] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 3682@dfeaa374b3e2
2020-04-02 05:03:06,957 [Thread-237] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 is not formatted for namespace 1861411397. Formatting...
2020-04-02 05:03:06,957 [Thread-237] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2fad084c-0130-4112-82b3-6df89b724633 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 
2020-04-02 05:03:06,959 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:06,959 [Thread-156] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:06,959 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-648652610-172.17.0.16-1585803784911 is not formatted. Formatting ...
2020-04-02 05:03:06,959 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-648652610-172.17.0.16-1585803784911 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-648652610-172.17.0.16-1585803784911/current
2020-04-02 05:03:06,959 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:06,982 [Thread-186] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:06,982 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-648652610-172.17.0.16-1585803784911 is not formatted. Formatting ...
2020-04-02 05:03:06,983 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-648652610-172.17.0.16-1585803784911 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-648652610-172.17.0.16-1585803784911/current
2020-04-02 05:03:06,984 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:06,985 [Thread-209] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:06,985 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-419159729-172.17.0.16-1585803782037 is not formatted. Formatting ...
2020-04-02 05:03:06,985 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-419159729-172.17.0.16-1585803782037 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-419159729-172.17.0.16-1585803782037/current
2020-04-02 05:03:06,988 [Thread-209] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1354143010;bpid=BP-419159729-172.17.0.16-1585803782037;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1354143010;c=1585803782037;bpid=BP-419159729-172.17.0.16-1585803782037;dnuuid=null
2020-04-02 05:03:06,998 [Thread-211] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:06,999 [Thread-211] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 has already been used.
2020-04-02 05:03:06,999 [Thread-211] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 has already been used.
2020-04-02 05:03:07,008 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,008 [Thread-211] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,008 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-648652610-172.17.0.16-1585803784911 is not formatted. Formatting ...
2020-04-02 05:03:07,008 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-648652610-172.17.0.16-1585803784911 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-648652610-172.17.0.16-1585803784911/current
2020-04-02 05:03:07,011 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,012 [Thread-186] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,012 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-648652610-172.17.0.16-1585803784911 is not formatted. Formatting ...
2020-04-02 05:03:07,012 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-648652610-172.17.0.16-1585803784911 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-648652610-172.17.0.16-1585803784911/current
2020-04-02 05:03:07,015 [Thread-186] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1861411397;bpid=BP-648652610-172.17.0.16-1585803784911;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1861411397;c=1585803784911;bpid=BP-648652610-172.17.0.16-1585803784911;dnuuid=null
2020-04-02 05:03:07,017 [Thread-184] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 3beef44b-eecd-4dc3-8459-79d3cbba1f10
2020-04-02 05:03:07,018 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,018 [Thread-156] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,019 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-648652610-172.17.0.16-1585803784911 is not formatted. Formatting ...
2020-04-02 05:03:07,019 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-648652610-172.17.0.16-1585803784911 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-648652610-172.17.0.16-1585803784911/current
2020-04-02 05:03:07,021 [Thread-156] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1861411397;bpid=BP-648652610-172.17.0.16-1585803784911;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1861411397;c=1585803784911;bpid=BP-648652610-172.17.0.16-1585803784911;dnuuid=null
2020-04-02 05:03:07,022 [Thread-153] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 58ed72fe-15e4-4236-9714-451bf909cdd5
2020-04-02 05:03:07,022 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,023 [Thread-237] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,023 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-648652610-172.17.0.16-1585803784911 is not formatted. Formatting ...
2020-04-02 05:03:07,023 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-648652610-172.17.0.16-1585803784911 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-648652610-172.17.0.16-1585803784911/current
2020-04-02 05:03:07,023 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,024 [Thread-211] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,024 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-648652610-172.17.0.16-1585803784911 is not formatted. Formatting ...
2020-04-02 05:03:07,024 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-648652610-172.17.0.16-1585803784911 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-648652610-172.17.0.16-1585803784911/current
2020-04-02 05:03:07,027 [Thread-211] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1861411397;bpid=BP-648652610-172.17.0.16-1585803784911;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1861411397;c=1585803784911;bpid=BP-648652610-172.17.0.16-1585803784911;dnuuid=56a98bd3-705c-4f7e-9076-e336ffe51701
2020-04-02 05:03:07,028 [Thread-209] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 56a98bd3-705c-4f7e-9076-e336ffe51701
2020-04-02 05:03:07,038 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,038 [Thread-237] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,038 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-648652610-172.17.0.16-1585803784911 is not formatted. Formatting ...
2020-04-02 05:03:07,039 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-648652610-172.17.0.16-1585803784911 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-648652610-172.17.0.16-1585803784911/current
2020-04-02 05:03:07,040 [Thread-237] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1861411397;bpid=BP-648652610-172.17.0.16-1585803784911;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1861411397;c=1585803784911;bpid=BP-648652610-172.17.0.16-1585803784911;dnuuid=null
2020-04-02 05:03:07,041 [Thread-236] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:07,041 [Thread-236] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 has already been used.
2020-04-02 05:03:07,041 [Thread-236] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 has already been used.
2020-04-02 05:03:07,051 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:07,052 [Thread-236] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:07,052 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-419159729-172.17.0.16-1585803782037 is not formatted. Formatting ...
2020-04-02 05:03:07,052 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-419159729-172.17.0.16-1585803782037 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-419159729-172.17.0.16-1585803782037/current
2020-04-02 05:03:07,074 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:07,074 [Thread-236] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:07,074 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-419159729-172.17.0.16-1585803782037 is not formatted. Formatting ...
2020-04-02 05:03:07,074 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-419159729-172.17.0.16-1585803782037 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-419159729-172.17.0.16-1585803782037/current
2020-04-02 05:03:07,076 [Thread-236] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1354143010;bpid=BP-419159729-172.17.0.16-1585803782037;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1354143010;c=1585803782037;bpid=BP-419159729-172.17.0.16-1585803782037;dnuuid=null
2020-04-02 05:03:07,078 [Thread-237] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 5e08f506-e09b-4387-9057-09dd238f2db3
2020-04-02 05:03:07,185 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-0c6ae5eb-828f-492f-b11b-76ebfd537f74
2020-04-02 05:03:07,186 [Thread-153] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:03:07,186 [Thread-184] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-96f1659a-c211-4ad3-84e0-da83c3540e46
2020-04-02 05:03:07,186 [Thread-184] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:03:07,185 [Thread-209] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-bf5b0949-559d-40b7-b6dd-3d05fe8d872e
2020-04-02 05:03:07,189 [Thread-209] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:03:07,189 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-648aac64-888b-4fed-a7be-2bcf276a79ed
2020-04-02 05:03:07,189 [Thread-153] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:03:07,189 [Thread-184] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-b2b74576-90c6-41f8-afc7-9899cdd61f3b
2020-04-02 05:03:07,191 [Thread-184] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:03:07,193 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-d797cfd7-71fd-4fec-97e7-55ba58c03ae0
2020-04-02 05:03:07,193 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:03:07,195 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-2fad084c-0130-4112-82b3-6df89b724633
2020-04-02 05:03:07,195 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:03:07,200 [Thread-209] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8401c763-4155-4d3e-be82-e7fc93cc3150
2020-04-02 05:03:07,201 [Thread-209] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:03:07,203 [Thread-184] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:07,203 [Thread-209] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:07,204 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:07,204 [Thread-153] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:07,209 [Thread-184] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:07,222 [Thread-186] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,223 [Thread-257] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-04-02 05:03:07,223 [Thread-258] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-04-02 05:03:07,225 [Thread-156] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:07,226 [Thread-153] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:07,228 [Thread-211] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:07,228 [Thread-209] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:07,228 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:07,229 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-04-02 05:03:07,228 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-04-02 05:03:07,228 [Thread-236] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:07,232 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-04-02 05:03:07,229 [Thread-261] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-04-02 05:03:07,240 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-04-02 05:03:07,246 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-04-02 05:03:07,254 [Thread-156] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:07,255 [Thread-184] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:07,254 [Thread-211] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:07,254 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:07,257 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:07,257 [Thread-184] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:07,257 [Thread-156] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:07,262 [Thread-156] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:07,257 [Thread-211] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:07,258 [Thread-184] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:07,258 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:07,264 [Thread-184] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:07,265 [Thread-211] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:07,264 [Thread-156] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,266 [Thread-211] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,266 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,318 [Thread-258] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-648652610-172.17.0.16-1585803784911 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 95ms
2020-04-02 05:03:07,319 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-419159729-172.17.0.16-1585803782037 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 79ms
2020-04-02 05:03:07,320 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-419159729-172.17.0.16-1585803782037 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 88ms
2020-04-02 05:03:07,321 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-419159729-172.17.0.16-1585803782037 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 85ms
2020-04-02 05:03:07,322 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-419159729-172.17.0.16-1585803782037 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 75ms
2020-04-02 05:03:07,322 [Thread-209] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-419159729-172.17.0.16-1585803782037: 94ms
2020-04-02 05:03:07,322 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-419159729-172.17.0.16-1585803782037 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 92ms
2020-04-02 05:03:07,323 [Thread-261] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-419159729-172.17.0.16-1585803782037 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 83ms
2020-04-02 05:03:07,322 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-419159729-172.17.0.16-1585803782037: 87ms
2020-04-02 05:03:07,323 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-419159729-172.17.0.16-1585803782037: 97ms
2020-04-02 05:03:07,323 [Thread-257] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-648652610-172.17.0.16-1585803784911 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 100ms
2020-04-02 05:03:07,324 [Thread-186] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-648652610-172.17.0.16-1585803784911: 102ms
2020-04-02 05:03:07,325 [Thread-273] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-04-02 05:03:07,325 [Thread-274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-04-02 05:03:07,325 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-04-02 05:03:07,325 [Thread-279] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-04-02 05:03:07,326 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-04-02 05:03:07,325 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-04-02 05:03:07,325 [Thread-284] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-04-02 05:03:07,326 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-04-02 05:03:07,326 [Thread-281] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-419159729-172.17.0.16-1585803782037/current/replicas doesn't exist 
2020-04-02 05:03:07,326 [Thread-278] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-04-02 05:03:07,326 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-04-02 05:03:07,327 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-04-02 05:03:07,327 [Thread-277] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-04-02 05:03:07,331 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 5ms
2020-04-02 05:03:07,330 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-04-02 05:03:07,326 [Thread-285] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-419159729-172.17.0.16-1585803782037/current/replicas doesn't exist 
2020-04-02 05:03:07,334 [Thread-276] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-04-02 05:03:07,326 [Thread-278] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-419159729-172.17.0.16-1585803782037/current/replicas doesn't exist 
2020-04-02 05:03:07,326 [Thread-280] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-419159729-172.17.0.16-1585803782037/current/replicas doesn't exist 
2020-04-02 05:03:07,326 [Thread-284] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-648652610-172.17.0.16-1585803784911/current/replicas doesn't exist 
2020-04-02 05:03:07,326 [Thread-286] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-419159729-172.17.0.16-1585803782037/current/replicas doesn't exist 
2020-04-02 05:03:07,326 [Thread-279] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-648652610-172.17.0.16-1585803784911/current/replicas doesn't exist 
2020-04-02 05:03:07,334 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 8ms
2020-04-02 05:03:07,334 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-04-02 05:03:07,334 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-04-02 05:03:07,335 [Thread-283] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-419159729-172.17.0.16-1585803782037/current/replicas doesn't exist 
2020-04-02 05:03:07,347 [Thread-278] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 22ms
2020-04-02 05:03:07,348 [Thread-279] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 22ms
2020-04-02 05:03:07,348 [Thread-284] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 22ms
2020-04-02 05:03:07,348 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 22ms
2020-04-02 05:03:07,348 [Thread-186] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-648652610-172.17.0.16-1585803784911: 23ms
2020-04-02 05:03:07,354 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 28ms
2020-04-02 05:03:07,354 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-419159729-172.17.0.16-1585803782037: 29ms
2020-04-02 05:03:07,355 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 20ms
2020-04-02 05:03:07,356 [Thread-209] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-419159729-172.17.0.16-1585803782037: 31ms
2020-04-02 05:03:07,355 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-419159729-172.17.0.16-1585803782037: 31ms
2020-04-02 05:03:07,363 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:07,365 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-96f1659a-c211-4ad3-84e0-da83c3540e46): finished scanning block pool BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,371 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-419159729-172.17.0.16-1585803782037 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 44ms
2020-04-02 05:03:07,375 [Thread-186] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:47 AM with interval of 21600000ms
2020-04-02 05:03:07,377 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:07,377 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-2fad084c-0130-4112-82b3-6df89b724633): finished scanning block pool BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:07,377 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:07,363 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:07,363 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:07,363 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:07,395 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-b2b74576-90c6-41f8-afc7-9899cdd61f3b): finished scanning block pool BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,363 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:07,363 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:07,395 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-8401c763-4155-4d3e-be82-e7fc93cc3150): finished scanning block pool BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:07,396 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-0c6ae5eb-828f-492f-b11b-76ebfd537f74): finished scanning block pool BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:07,395 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-648aac64-888b-4fed-a7be-2bcf276a79ed): finished scanning block pool BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:07,395 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-bf5b0949-559d-40b7-b6dd-3d05fe8d872e): finished scanning block pool BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:07,394 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-d797cfd7-71fd-4fec-97e7-55ba58c03ae0): finished scanning block pool BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:07,399 [Thread-153] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:43 AM with interval of 21600000ms
2020-04-02 05:03:07,401 [Thread-236] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:55 AM with interval of 21600000ms
2020-04-02 05:03:07,401 [Thread-209] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:54 AM with interval of 21600000ms
2020-04-02 05:03:07,407 [Thread-274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-648652610-172.17.0.16-1585803784911 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 82ms
2020-04-02 05:03:07,408 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 3beef44b-eecd-4dc3-8459-79d3cbba1f10) service to localhost/127.0.0.1:43585 beginning handshake with NN
2020-04-02 05:03:07,408 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 58ed72fe-15e4-4236-9714-451bf909cdd5) service to localhost/127.0.0.1:33679 beginning handshake with NN
2020-04-02 05:03:07,408 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 58ed72fe-15e4-4236-9714-451bf909cdd5) service to localhost/127.0.0.1:44155 beginning handshake with NN
2020-04-02 05:03:07,410 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 3beef44b-eecd-4dc3-8459-79d3cbba1f10) service to localhost/127.0.0.1:41130 beginning handshake with NN
2020-04-02 05:03:07,415 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-bf5b0949-559d-40b7-b6dd-3d05fe8d872e): no suitable block pools found to scan.  Waiting 1814399948 ms.
2020-04-02 05:03:07,415 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-8401c763-4155-4d3e-be82-e7fc93cc3150): no suitable block pools found to scan.  Waiting 1814399948 ms.
2020-04-02 05:03:07,416 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-648aac64-888b-4fed-a7be-2bcf276a79ed): no suitable block pools found to scan.  Waiting 1814399947 ms.
2020-04-02 05:03:07,415 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-b2b74576-90c6-41f8-afc7-9899cdd61f3b): no suitable block pools found to scan.  Waiting 1814399948 ms.
2020-04-02 05:03:07,415 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-96f1659a-c211-4ad3-84e0-da83c3540e46): no suitable block pools found to scan.  Waiting 1814399948 ms.
2020-04-02 05:03:07,416 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-d797cfd7-71fd-4fec-97e7-55ba58c03ae0): no suitable block pools found to scan.  Waiting 1814399961 ms.
2020-04-02 05:03:07,416 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-0c6ae5eb-828f-492f-b11b-76ebfd537f74): no suitable block pools found to scan.  Waiting 1814399947 ms.
2020-04-02 05:03:07,415 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-2fad084c-0130-4112-82b3-6df89b724633): no suitable block pools found to scan.  Waiting 1814399961 ms.
2020-04-02 05:03:07,417 [Thread-273] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-648652610-172.17.0.16-1585803784911 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 92ms
2020-04-02 05:03:07,418 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-648652610-172.17.0.16-1585803784911 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 91ms
2020-04-02 05:03:07,419 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-648652610-172.17.0.16-1585803784911: 94ms
2020-04-02 05:03:07,419 [Thread-276] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-648652610-172.17.0.16-1585803784911 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 84ms
2020-04-02 05:03:07,419 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 56a98bd3-705c-4f7e-9076-e336ffe51701) service to localhost/127.0.0.1:44155 beginning handshake with NN
2020-04-02 05:03:07,419 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 5e08f506-e09b-4387-9057-09dd238f2db3) service to localhost/127.0.0.1:33679 beginning handshake with NN
2020-04-02 05:03:07,419 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 56a98bd3-705c-4f7e-9076-e336ffe51701) service to localhost/127.0.0.1:33679 beginning handshake with NN
2020-04-02 05:03:07,424 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-04-02 05:03:07,429 [Thread-310] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-648652610-172.17.0.16-1585803784911/current/replicas doesn't exist 
2020-04-02 05:03:07,425 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-04-02 05:03:07,425 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 5e08f506-e09b-4387-9057-09dd238f2db3) service to localhost/127.0.0.1:44155 beginning handshake with NN
2020-04-02 05:03:07,430 [Thread-309] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-648652610-172.17.0.16-1585803784911/current/replicas doesn't exist 
2020-04-02 05:03:07,430 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 1ms
2020-04-02 05:03:07,430 [IPC Server handler 9 on 43585] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39470, datanodeUuid=3beef44b-eecd-4dc3-8459-79d3cbba1f10, infoPort=42457, infoSecurePort=0, ipcPort=38813, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911) storage 3beef44b-eecd-4dc3-8459-79d3cbba1f10
2020-04-02 05:03:07,430 [IPC Server handler 2 on 44155] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46742, datanodeUuid=58ed72fe-15e4-4236-9714-451bf909cdd5, infoPort=33193, infoSecurePort=0, ipcPort=45097, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037) storage 58ed72fe-15e4-4236-9714-451bf909cdd5
2020-04-02 05:03:07,428 [IPC Server handler 4 on 33679] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46742, datanodeUuid=58ed72fe-15e4-4236-9714-451bf909cdd5, infoPort=33193, infoSecurePort=0, ipcPort=45097, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037) storage 58ed72fe-15e4-4236-9714-451bf909cdd5
2020-04-02 05:03:07,428 [IPC Server handler 0 on 41130] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39470, datanodeUuid=3beef44b-eecd-4dc3-8459-79d3cbba1f10, infoPort=42457, infoSecurePort=0, ipcPort=38813, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911) storage 3beef44b-eecd-4dc3-8459-79d3cbba1f10
2020-04-02 05:03:07,432 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-419159729-172.17.0.16-1585803782037 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 98ms
2020-04-02 05:03:07,431 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 1ms
2020-04-02 05:03:07,437 [Thread-184] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-419159729-172.17.0.16-1585803782037: 112ms
2020-04-02 05:03:07,437 [IPC Server handler 9 on 43585] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39470
2020-04-02 05:03:07,437 [IPC Server handler 4 on 33679] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46742
2020-04-02 05:03:07,438 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-04-02 05:03:07,438 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-04-02 05:03:07,438 [Thread-312] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-419159729-172.17.0.16-1585803782037/current/replicas doesn't exist 
2020-04-02 05:03:07,438 [IPC Server handler 4 on 33679] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 58ed72fe-15e4-4236-9714-451bf909cdd5 (127.0.0.1:46742).
2020-04-02 05:03:07,439 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 1ms
2020-04-02 05:03:07,437 [IPC Server handler 0 on 41130] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39470
2020-04-02 05:03:07,437 [IPC Server handler 2 on 44155] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46742
2020-04-02 05:03:07,440 [Thread-277] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-648652610-172.17.0.16-1585803784911 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 106ms
2020-04-02 05:03:07,440 [IPC Server handler 0 on 41130] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3beef44b-eecd-4dc3-8459-79d3cbba1f10 (127.0.0.1:39470).
2020-04-02 05:03:07,440 [IPC Server handler 9 on 43585] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3beef44b-eecd-4dc3-8459-79d3cbba1f10 (127.0.0.1:39470).
2020-04-02 05:03:07,438 [Thread-311] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-419159729-172.17.0.16-1585803782037/current/replicas doesn't exist 
2020-04-02 05:03:07,437 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-648652610-172.17.0.16-1585803784911: 18ms
2020-04-02 05:03:07,440 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-648652610-172.17.0.16-1585803784911: 116ms
2020-04-02 05:03:07,440 [IPC Server handler 2 on 44155] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 58ed72fe-15e4-4236-9714-451bf909cdd5 (127.0.0.1:46742).
2020-04-02 05:03:07,444 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 6ms
2020-04-02 05:03:07,450 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 3beef44b-eecd-4dc3-8459-79d3cbba1f10) service to localhost/127.0.0.1:41130 successfully registered with NN
2020-04-02 05:03:07,450 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 3beef44b-eecd-4dc3-8459-79d3cbba1f10) service to localhost/127.0.0.1:43585 successfully registered with NN
2020-04-02 05:03:07,455 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:43585 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:07,446 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:07,450 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 58ed72fe-15e4-4236-9714-451bf909cdd5) service to localhost/127.0.0.1:33679 successfully registered with NN
2020-04-02 05:03:07,449 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 58ed72fe-15e4-4236-9714-451bf909cdd5) service to localhost/127.0.0.1:44155 successfully registered with NN
2020-04-02 05:03:07,446 [IPC Server handler 5 on 33679] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45716, datanodeUuid=5e08f506-e09b-4387-9057-09dd238f2db3, infoPort=34272, infoSecurePort=0, ipcPort=34411, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037) storage 5e08f506-e09b-4387-9057-09dd238f2db3
2020-04-02 05:03:07,458 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-648652610-172.17.0.16-1585803784911 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 123ms
2020-04-02 05:03:07,446 [IPC Server handler 0 on 44155] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34004, datanodeUuid=56a98bd3-705c-4f7e-9076-e336ffe51701, infoPort=41368, infoSecurePort=0, ipcPort=36104, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037) storage 56a98bd3-705c-4f7e-9076-e336ffe51701
2020-04-02 05:03:07,460 [IPC Server handler 5 on 33679] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45716
2020-04-02 05:03:07,446 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-04-02 05:03:07,446 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-04-02 05:03:07,462 [Thread-314] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-648652610-172.17.0.16-1585803784911/current/replicas doesn't exist 
2020-04-02 05:03:07,463 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 1ms
2020-04-02 05:03:07,446 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 56a98bd3-705c-4f7e-9076-e336ffe51701) service to localhost/127.0.0.1:43585 beginning handshake with NN
2020-04-02 05:03:07,446 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 56a98bd3-705c-4f7e-9076-e336ffe51701) service to localhost/127.0.0.1:41130 beginning handshake with NN
2020-04-02 05:03:07,446 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:07,462 [Thread-313] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-648652610-172.17.0.16-1585803784911/current/replicas doesn't exist 
2020-04-02 05:03:07,474 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 12ms
2020-04-02 05:03:07,474 [IPC Server handler 2 on 41130] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34004, datanodeUuid=56a98bd3-705c-4f7e-9076-e336ffe51701, infoPort=41368, infoSecurePort=0, ipcPort=36104, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911) storage 56a98bd3-705c-4f7e-9076-e336ffe51701
2020-04-02 05:03:07,474 [IPC Server handler 2 on 41130] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34004
2020-04-02 05:03:07,461 [IPC Server handler 5 on 33679] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5e08f506-e09b-4387-9057-09dd238f2db3 (127.0.0.1:45716).
2020-04-02 05:03:07,476 [IPC Server handler 7 on 33679] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34004, datanodeUuid=56a98bd3-705c-4f7e-9076-e336ffe51701, infoPort=41368, infoSecurePort=0, ipcPort=36104, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037) storage 56a98bd3-705c-4f7e-9076-e336ffe51701
2020-04-02 05:03:07,477 [IPC Server handler 7 on 33679] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34004
2020-04-02 05:03:07,477 [IPC Server handler 7 on 33679] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 56a98bd3-705c-4f7e-9076-e336ffe51701 (127.0.0.1:34004).
2020-04-02 05:03:07,460 [IPC Server handler 0 on 44155] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34004
2020-04-02 05:03:07,477 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 5e08f506-e09b-4387-9057-09dd238f2db3) service to localhost/127.0.0.1:33679 successfully registered with NN
2020-04-02 05:03:07,459 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-648652610-172.17.0.16-1585803784911: 134ms
2020-04-02 05:03:07,457 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-8401c763-4155-4d3e-be82-e7fc93cc3150): finished scanning block pool BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,457 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:44155 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:07,457 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33679 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:07,455 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41130 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:07,454 [Thread-184] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-419159729-172.17.0.16-1585803782037: 17ms
2020-04-02 05:03:07,479 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33679 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:07,481 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-04-02 05:03:07,481 [Thread-315] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-648652610-172.17.0.16-1585803784911/current/replicas doesn't exist 
2020-04-02 05:03:07,482 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 3beef44b-eecd-4dc3-8459-79d3cbba1f10) service to localhost/127.0.0.1:44155 beginning handshake with NN
2020-04-02 05:03:07,482 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:07,482 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 0ms
2020-04-02 05:03:07,482 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-b2b74576-90c6-41f8-afc7-9899cdd61f3b): finished scanning block pool BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:07,479 [IPC Server handler 0 on 44155] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 56a98bd3-705c-4f7e-9076-e336ffe51701 (127.0.0.1:34004).
2020-04-02 05:03:07,489 [IPC Server handler 7 on 44155] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45716, datanodeUuid=5e08f506-e09b-4387-9057-09dd238f2db3, infoPort=34272, infoSecurePort=0, ipcPort=34411, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037) storage 5e08f506-e09b-4387-9057-09dd238f2db3
2020-04-02 05:03:07,476 [IPC Server handler 2 on 41130] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 56a98bd3-705c-4f7e-9076-e336ffe51701 (127.0.0.1:34004).
2020-04-02 05:03:07,489 [IPC Server handler 7 on 44155] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45716
2020-04-02 05:03:07,490 [IPC Server handler 7 on 44155] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5e08f506-e09b-4387-9057-09dd238f2db3 (127.0.0.1:45716).
2020-04-02 05:03:07,490 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 56a98bd3-705c-4f7e-9076-e336ffe51701) service to localhost/127.0.0.1:44155 successfully registered with NN
2020-04-02 05:03:07,490 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:44155 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:07,490 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-b2b74576-90c6-41f8-afc7-9899cdd61f3b): no suitable block pools found to scan.  Waiting 1814399873 ms.
2020-04-02 05:03:07,490 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 56a98bd3-705c-4f7e-9076-e336ffe51701) service to localhost/127.0.0.1:41130 successfully registered with NN
2020-04-02 05:03:07,490 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41130 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:07,491 [IPC Server handler 8 on 44155] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39470, datanodeUuid=3beef44b-eecd-4dc3-8459-79d3cbba1f10, infoPort=42457, infoSecurePort=0, ipcPort=38813, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037) storage 3beef44b-eecd-4dc3-8459-79d3cbba1f10
2020-04-02 05:03:07,491 [IPC Server handler 8 on 44155] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39470
2020-04-02 05:03:07,492 [IPC Server handler 8 on 44155] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3beef44b-eecd-4dc3-8459-79d3cbba1f10 (127.0.0.1:39470).
2020-04-02 05:03:07,492 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 3beef44b-eecd-4dc3-8459-79d3cbba1f10) service to localhost/127.0.0.1:44155 successfully registered with NN
2020-04-02 05:03:07,493 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:44155 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:07,474 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-648652610-172.17.0.16-1585803784911: 30ms
2020-04-02 05:03:07,474 [IPC Server handler 4 on 43585] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34004, datanodeUuid=56a98bd3-705c-4f7e-9076-e336ffe51701, infoPort=41368, infoSecurePort=0, ipcPort=36104, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911) storage 56a98bd3-705c-4f7e-9076-e336ffe51701
2020-04-02 05:03:07,472 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-bf5b0949-559d-40b7-b6dd-3d05fe8d872e): finished scanning block pool BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,497 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:07,490 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 5e08f506-e09b-4387-9057-09dd238f2db3) service to localhost/127.0.0.1:44155 successfully registered with NN
2020-04-02 05:03:07,497 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:44155 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:07,482 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-8401c763-4155-4d3e-be82-e7fc93cc3150): no suitable block pools found to scan.  Waiting 1814399881 ms.
2020-04-02 05:03:07,497 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-bf5b0949-559d-40b7-b6dd-3d05fe8d872e): no suitable block pools found to scan.  Waiting 1814399866 ms.
2020-04-02 05:03:07,482 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 3beef44b-eecd-4dc3-8459-79d3cbba1f10) service to localhost/127.0.0.1:33679 beginning handshake with NN
2020-04-02 05:03:07,481 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-419159729-172.17.0.16-1585803782037 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:07,481 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-04-02 05:03:07,481 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 56a98bd3-705c-4f7e-9076-e336ffe51701) service to localhost/127.0.0.1:33679 successfully registered with NN
2020-04-02 05:03:07,499 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-96f1659a-c211-4ad3-84e0-da83c3540e46): finished scanning block pool BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:07,497 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 5e08f506-e09b-4387-9057-09dd238f2db3) service to localhost/127.0.0.1:41130 beginning handshake with NN
2020-04-02 05:03:07,497 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-2fad084c-0130-4112-82b3-6df89b724633): finished scanning block pool BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,497 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 5e08f506-e09b-4387-9057-09dd238f2db3) service to localhost/127.0.0.1:43585 beginning handshake with NN
2020-04-02 05:03:07,497 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:07,497 [IPC Server handler 4 on 43585] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34004
2020-04-02 05:03:07,501 [IPC Server handler 1 on 41130] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45716, datanodeUuid=5e08f506-e09b-4387-9057-09dd238f2db3, infoPort=34272, infoSecurePort=0, ipcPort=34411, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911) storage 5e08f506-e09b-4387-9057-09dd238f2db3
2020-04-02 05:03:07,499 [IPC Server handler 8 on 33679] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39470, datanodeUuid=3beef44b-eecd-4dc3-8459-79d3cbba1f10, infoPort=42457, infoSecurePort=0, ipcPort=38813, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037) storage 3beef44b-eecd-4dc3-8459-79d3cbba1f10
2020-04-02 05:03:07,502 [IPC Server handler 8 on 33679] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39470
2020-04-02 05:03:07,500 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-96f1659a-c211-4ad3-84e0-da83c3540e46): no suitable block pools found to scan.  Waiting 1814399863 ms.
2020-04-02 05:03:07,499 [Thread-316] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-648652610-172.17.0.16-1585803784911/current/replicas doesn't exist 
2020-04-02 05:03:07,499 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33679 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:07,502 [IPC Server handler 1 on 41130] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45716
2020-04-02 05:03:07,504 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 5ms
2020-04-02 05:03:07,504 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-648652610-172.17.0.16-1585803784911: 25ms
2020-04-02 05:03:07,505 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-d797cfd7-71fd-4fec-97e7-55ba58c03ae0): finished scanning block pool BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,505 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:07,506 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-0c6ae5eb-828f-492f-b11b-76ebfd537f74): finished scanning block pool BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,506 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-0c6ae5eb-828f-492f-b11b-76ebfd537f74): no suitable block pools found to scan.  Waiting 1814399857 ms.
2020-04-02 05:03:07,506 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-648652610-172.17.0.16-1585803784911 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:07,507 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-648aac64-888b-4fed-a7be-2bcf276a79ed): finished scanning block pool BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:07,507 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-d797cfd7-71fd-4fec-97e7-55ba58c03ae0): no suitable block pools found to scan.  Waiting 1814399870 ms.
2020-04-02 05:03:07,507 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-648aac64-888b-4fed-a7be-2bcf276a79ed): no suitable block pools found to scan.  Waiting 1814399856 ms.
2020-04-02 05:03:07,507 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 58ed72fe-15e4-4236-9714-451bf909cdd5) service to localhost/127.0.0.1:43585 beginning handshake with NN
2020-04-02 05:03:07,508 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 58ed72fe-15e4-4236-9714-451bf909cdd5) service to localhost/127.0.0.1:41130 beginning handshake with NN
2020-04-02 05:03:07,511 [IPC Server handler 1 on 41130] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5e08f506-e09b-4387-9057-09dd238f2db3 (127.0.0.1:45716).
2020-04-02 05:03:07,512 [IPC Server handler 4 on 41130] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46742, datanodeUuid=58ed72fe-15e4-4236-9714-451bf909cdd5, infoPort=33193, infoSecurePort=0, ipcPort=45097, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911) storage 58ed72fe-15e4-4236-9714-451bf909cdd5
2020-04-02 05:03:07,512 [IPC Server handler 4 on 41130] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46742
2020-04-02 05:03:07,512 [IPC Server handler 4 on 41130] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 58ed72fe-15e4-4236-9714-451bf909cdd5 (127.0.0.1:46742).
2020-04-02 05:03:07,512 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 5e08f506-e09b-4387-9057-09dd238f2db3) service to localhost/127.0.0.1:41130 successfully registered with NN
2020-04-02 05:03:07,512 [IPC Server handler 8 on 33679] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3beef44b-eecd-4dc3-8459-79d3cbba1f10 (127.0.0.1:39470).
2020-04-02 05:03:07,513 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 58ed72fe-15e4-4236-9714-451bf909cdd5) service to localhost/127.0.0.1:41130 successfully registered with NN
2020-04-02 05:03:07,512 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41130 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:07,513 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41130 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:07,513 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-2fad084c-0130-4112-82b3-6df89b724633): no suitable block pools found to scan.  Waiting 1814399863 ms.
2020-04-02 05:03:07,513 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 3beef44b-eecd-4dc3-8459-79d3cbba1f10) service to localhost/127.0.0.1:33679 successfully registered with NN
2020-04-02 05:03:07,513 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33679 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:07,527 [IPC Server handler 4 on 43585] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 56a98bd3-705c-4f7e-9076-e336ffe51701 (127.0.0.1:34004).
2020-04-02 05:03:07,527 [IPC Server handler 8 on 43585] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46742, datanodeUuid=58ed72fe-15e4-4236-9714-451bf909cdd5, infoPort=33193, infoSecurePort=0, ipcPort=45097, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911) storage 58ed72fe-15e4-4236-9714-451bf909cdd5
2020-04-02 05:03:07,528 [IPC Server handler 8 on 43585] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46742
2020-04-02 05:03:07,528 [IPC Server handler 8 on 43585] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 58ed72fe-15e4-4236-9714-451bf909cdd5 (127.0.0.1:46742).
2020-04-02 05:03:07,533 [IPC Server handler 7 on 43585] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45716, datanodeUuid=5e08f506-e09b-4387-9057-09dd238f2db3, infoPort=34272, infoSecurePort=0, ipcPort=34411, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911) storage 5e08f506-e09b-4387-9057-09dd238f2db3
2020-04-02 05:03:07,546 [IPC Server handler 7 on 43585] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45716
2020-04-02 05:03:07,546 [IPC Server handler 7 on 43585] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5e08f506-e09b-4387-9057-09dd238f2db3 (127.0.0.1:45716).
2020-04-02 05:03:07,546 [IPC Server handler 9 on 44155] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bf5b0949-559d-40b7-b6dd-3d05fe8d872e for DN 127.0.0.1:34004
2020-04-02 05:03:07,547 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 56a98bd3-705c-4f7e-9076-e336ffe51701) service to localhost/127.0.0.1:43585 successfully registered with NN
2020-04-02 05:03:07,548 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:43585 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:07,548 [IPC Server handler 7 on 41130] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d797cfd7-71fd-4fec-97e7-55ba58c03ae0 for DN 127.0.0.1:45716
2020-04-02 05:03:07,548 [IPC Server handler 6 on 43585] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-96f1659a-c211-4ad3-84e0-da83c3540e46 for DN 127.0.0.1:39470
2020-04-02 05:03:07,548 [IPC Server handler 9 on 44155] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8401c763-4155-4d3e-be82-e7fc93cc3150 for DN 127.0.0.1:34004
2020-04-02 05:03:07,549 [IPC Server handler 6 on 43585] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b2b74576-90c6-41f8-afc7-9899cdd61f3b for DN 127.0.0.1:39470
2020-04-02 05:03:07,549 [IPC Server handler 7 on 41130] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2fad084c-0130-4112-82b3-6df89b724633 for DN 127.0.0.1:45716
2020-04-02 05:03:07,549 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 5e08f506-e09b-4387-9057-09dd238f2db3) service to localhost/127.0.0.1:43585 successfully registered with NN
2020-04-02 05:03:07,551 [IPC Server handler 6 on 44155] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d797cfd7-71fd-4fec-97e7-55ba58c03ae0 for DN 127.0.0.1:45716
2020-04-02 05:03:07,552 [IPC Server handler 5 on 41130] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-96f1659a-c211-4ad3-84e0-da83c3540e46 for DN 127.0.0.1:39470
2020-04-02 05:03:07,551 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:43585 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:07,557 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 58ed72fe-15e4-4236-9714-451bf909cdd5) service to localhost/127.0.0.1:43585 successfully registered with NN
2020-04-02 05:03:07,560 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:43585 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:07,556 [IPC Server handler 6 on 33679] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d797cfd7-71fd-4fec-97e7-55ba58c03ae0 for DN 127.0.0.1:45716
2020-04-02 05:03:07,555 [IPC Server handler 5 on 41130] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b2b74576-90c6-41f8-afc7-9899cdd61f3b for DN 127.0.0.1:39470
2020-04-02 05:03:07,554 [IPC Server handler 5 on 43585] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bf5b0949-559d-40b7-b6dd-3d05fe8d872e for DN 127.0.0.1:34004
2020-04-02 05:03:07,553 [IPC Server handler 6 on 44155] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2fad084c-0130-4112-82b3-6df89b724633 for DN 127.0.0.1:45716
2020-04-02 05:03:07,564 [IPC Server handler 5 on 43585] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8401c763-4155-4d3e-be82-e7fc93cc3150 for DN 127.0.0.1:34004
2020-04-02 05:03:07,564 [IPC Server handler 3 on 41130] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0c6ae5eb-828f-492f-b11b-76ebfd537f74 for DN 127.0.0.1:46742
2020-04-02 05:03:07,562 [IPC Server handler 6 on 33679] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2fad084c-0130-4112-82b3-6df89b724633 for DN 127.0.0.1:45716
2020-04-02 05:03:07,565 [IPC Server handler 3 on 41130] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-648aac64-888b-4fed-a7be-2bcf276a79ed for DN 127.0.0.1:46742
2020-04-02 05:03:07,565 [IPC Server handler 1 on 43585] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0c6ae5eb-828f-492f-b11b-76ebfd537f74 for DN 127.0.0.1:46742
2020-04-02 05:03:07,565 [IPC Server handler 3 on 44155] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0c6ae5eb-828f-492f-b11b-76ebfd537f74 for DN 127.0.0.1:46742
2020-04-02 05:03:07,568 [IPC Server handler 1 on 43585] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-648aac64-888b-4fed-a7be-2bcf276a79ed for DN 127.0.0.1:46742
2020-04-02 05:03:07,567 [IPC Server handler 8 on 41130] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bf5b0949-559d-40b7-b6dd-3d05fe8d872e for DN 127.0.0.1:34004
2020-04-02 05:03:07,569 [IPC Server handler 8 on 41130] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8401c763-4155-4d3e-be82-e7fc93cc3150 for DN 127.0.0.1:34004
2020-04-02 05:03:07,567 [IPC Server handler 9 on 33679] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-96f1659a-c211-4ad3-84e0-da83c3540e46 for DN 127.0.0.1:39470
2020-04-02 05:03:07,569 [IPC Server handler 2 on 43585] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d797cfd7-71fd-4fec-97e7-55ba58c03ae0 for DN 127.0.0.1:45716
2020-04-02 05:03:07,572 [IPC Server handler 2 on 43585] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2fad084c-0130-4112-82b3-6df89b724633 for DN 127.0.0.1:45716
2020-04-02 05:03:07,568 [IPC Server handler 3 on 44155] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-648aac64-888b-4fed-a7be-2bcf276a79ed for DN 127.0.0.1:46742
2020-04-02 05:03:07,571 [IPC Server handler 9 on 33679] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b2b74576-90c6-41f8-afc7-9899cdd61f3b for DN 127.0.0.1:39470
2020-04-02 05:03:07,574 [IPC Server handler 4 on 44155] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-96f1659a-c211-4ad3-84e0-da83c3540e46 for DN 127.0.0.1:39470
2020-04-02 05:03:07,575 [IPC Server handler 4 on 44155] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b2b74576-90c6-41f8-afc7-9899cdd61f3b for DN 127.0.0.1:39470
2020-04-02 05:03:07,575 [IPC Server handler 2 on 33679] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0c6ae5eb-828f-492f-b11b-76ebfd537f74 for DN 127.0.0.1:46742
2020-04-02 05:03:07,576 [IPC Server handler 2 on 33679] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-648aac64-888b-4fed-a7be-2bcf276a79ed for DN 127.0.0.1:46742
2020-04-02 05:03:07,580 [IPC Server handler 1 on 33679] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bf5b0949-559d-40b7-b6dd-3d05fe8d872e for DN 127.0.0.1:34004
2020-04-02 05:03:07,580 [IPC Server handler 1 on 33679] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8401c763-4155-4d3e-be82-e7fc93cc3150 for DN 127.0.0.1:34004
2020-04-02 05:03:07,607 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x47d7515acdd6b5a2: Processing first storage report for DS-8401c763-4155-4d3e-be82-e7fc93cc3150 from datanode 56a98bd3-705c-4f7e-9076-e336ffe51701
2020-04-02 05:03:07,607 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x98fb8388bc4b5cf0: Processing first storage report for DS-648aac64-888b-4fed-a7be-2bcf276a79ed from datanode 58ed72fe-15e4-4236-9714-451bf909cdd5
2020-04-02 05:03:07,607 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5b0fbe01df61bf29: Processing first storage report for DS-96f1659a-c211-4ad3-84e0-da83c3540e46 from datanode 3beef44b-eecd-4dc3-8459-79d3cbba1f10
2020-04-02 05:03:07,607 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x1a6144b6c216cc20: Processing first storage report for DS-96f1659a-c211-4ad3-84e0-da83c3540e46 from datanode 3beef44b-eecd-4dc3-8459-79d3cbba1f10
2020-04-02 05:03:07,609 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x1a6144b6c216cc20: from storage DS-96f1659a-c211-4ad3-84e0-da83c3540e46 node DatanodeRegistration(127.0.0.1:39470, datanodeUuid=3beef44b-eecd-4dc3-8459-79d3cbba1f10, infoPort=42457, infoSecurePort=0, ipcPort=38813, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,609 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5b0fbe01df61bf29: from storage DS-96f1659a-c211-4ad3-84e0-da83c3540e46 node DatanodeRegistration(127.0.0.1:39470, datanodeUuid=3beef44b-eecd-4dc3-8459-79d3cbba1f10, infoPort=42457, infoSecurePort=0, ipcPort=38813, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,610 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x98fb8388bc4b5cf0: from storage DS-648aac64-888b-4fed-a7be-2bcf276a79ed node DatanodeRegistration(127.0.0.1:46742, datanodeUuid=58ed72fe-15e4-4236-9714-451bf909cdd5, infoPort=33193, infoSecurePort=0, ipcPort=45097, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037), blocks: 0, hasStaleStorage: true, processing time: 4 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,610 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x47d7515acdd6b5a2: from storage DS-8401c763-4155-4d3e-be82-e7fc93cc3150 node DatanodeRegistration(127.0.0.1:34004, datanodeUuid=56a98bd3-705c-4f7e-9076-e336ffe51701, infoPort=41368, infoSecurePort=0, ipcPort=36104, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911), blocks: 0, hasStaleStorage: true, processing time: 4 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,613 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xfc07c18a22b28a88: Processing first storage report for DS-96f1659a-c211-4ad3-84e0-da83c3540e46 from datanode 3beef44b-eecd-4dc3-8459-79d3cbba1f10
2020-04-02 05:03:07,614 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xfc07c18a22b28a88: from storage DS-96f1659a-c211-4ad3-84e0-da83c3540e46 node DatanodeRegistration(127.0.0.1:39470, datanodeUuid=3beef44b-eecd-4dc3-8459-79d3cbba1f10, infoPort=42457, infoSecurePort=0, ipcPort=38813, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,614 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa82c19c6c9914892: Processing first storage report for DS-648aac64-888b-4fed-a7be-2bcf276a79ed from datanode 58ed72fe-15e4-4236-9714-451bf909cdd5
2020-04-02 05:03:07,614 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa82c19c6c9914892: from storage DS-648aac64-888b-4fed-a7be-2bcf276a79ed node DatanodeRegistration(127.0.0.1:46742, datanodeUuid=58ed72fe-15e4-4236-9714-451bf909cdd5, infoPort=33193, infoSecurePort=0, ipcPort=45097, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,614 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x47d7515acdd6b5a2: Processing first storage report for DS-bf5b0949-559d-40b7-b6dd-3d05fe8d872e from datanode 56a98bd3-705c-4f7e-9076-e336ffe51701
2020-04-02 05:03:07,614 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x47d7515acdd6b5a2: from storage DS-bf5b0949-559d-40b7-b6dd-3d05fe8d872e node DatanodeRegistration(127.0.0.1:34004, datanodeUuid=56a98bd3-705c-4f7e-9076-e336ffe51701, infoPort=41368, infoSecurePort=0, ipcPort=36104, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,610 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x9086b2238458fcf3: Processing first storage report for DS-2fad084c-0130-4112-82b3-6df89b724633 from datanode 5e08f506-e09b-4387-9057-09dd238f2db3
2020-04-02 05:03:07,613 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x3e4761b19a4fa862: Processing first storage report for DS-2fad084c-0130-4112-82b3-6df89b724633 from datanode 5e08f506-e09b-4387-9057-09dd238f2db3
2020-04-02 05:03:07,613 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x44f2d290d827291b: Processing first storage report for DS-2fad084c-0130-4112-82b3-6df89b724633 from datanode 5e08f506-e09b-4387-9057-09dd238f2db3
2020-04-02 05:03:07,614 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x3e4761b19a4fa862: from storage DS-2fad084c-0130-4112-82b3-6df89b724633 node DatanodeRegistration(127.0.0.1:45716, datanodeUuid=5e08f506-e09b-4387-9057-09dd238f2db3, infoPort=34272, infoSecurePort=0, ipcPort=34411, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,614 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x9086b2238458fcf3: from storage DS-2fad084c-0130-4112-82b3-6df89b724633 node DatanodeRegistration(127.0.0.1:45716, datanodeUuid=5e08f506-e09b-4387-9057-09dd238f2db3, infoPort=34272, infoSecurePort=0, ipcPort=34411, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037), blocks: 0, hasStaleStorage: true, processing time: 4 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,615 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x484f7485c3072b6c: Processing first storage report for DS-8401c763-4155-4d3e-be82-e7fc93cc3150 from datanode 56a98bd3-705c-4f7e-9076-e336ffe51701
2020-04-02 05:03:07,615 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x44f2d290d827291b: from storage DS-2fad084c-0130-4112-82b3-6df89b724633 node DatanodeRegistration(127.0.0.1:45716, datanodeUuid=5e08f506-e09b-4387-9057-09dd238f2db3, infoPort=34272, infoSecurePort=0, ipcPort=34411, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,615 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x484f7485c3072b6c: from storage DS-8401c763-4155-4d3e-be82-e7fc93cc3150 node DatanodeRegistration(127.0.0.1:34004, datanodeUuid=56a98bd3-705c-4f7e-9076-e336ffe51701, infoPort=41368, infoSecurePort=0, ipcPort=36104, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,615 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x1a6144b6c216cc20: Processing first storage report for DS-b2b74576-90c6-41f8-afc7-9899cdd61f3b from datanode 3beef44b-eecd-4dc3-8459-79d3cbba1f10
2020-04-02 05:03:07,615 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x98fb8388bc4b5cf0: Processing first storage report for DS-0c6ae5eb-828f-492f-b11b-76ebfd537f74 from datanode 58ed72fe-15e4-4236-9714-451bf909cdd5
2020-04-02 05:03:07,615 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5b0fbe01df61bf29: Processing first storage report for DS-b2b74576-90c6-41f8-afc7-9899cdd61f3b from datanode 3beef44b-eecd-4dc3-8459-79d3cbba1f10
2020-04-02 05:03:07,615 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x98fb8388bc4b5cf0: from storage DS-0c6ae5eb-828f-492f-b11b-76ebfd537f74 node DatanodeRegistration(127.0.0.1:46742, datanodeUuid=58ed72fe-15e4-4236-9714-451bf909cdd5, infoPort=33193, infoSecurePort=0, ipcPort=45097, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,615 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x1a6144b6c216cc20: from storage DS-b2b74576-90c6-41f8-afc7-9899cdd61f3b node DatanodeRegistration(127.0.0.1:39470, datanodeUuid=3beef44b-eecd-4dc3-8459-79d3cbba1f10, infoPort=42457, infoSecurePort=0, ipcPort=38813, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,615 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x3e4761b19a4fa862: Processing first storage report for DS-d797cfd7-71fd-4fec-97e7-55ba58c03ae0 from datanode 5e08f506-e09b-4387-9057-09dd238f2db3
2020-04-02 05:03:07,616 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xfc07c18a22b28a88: Processing first storage report for DS-b2b74576-90c6-41f8-afc7-9899cdd61f3b from datanode 3beef44b-eecd-4dc3-8459-79d3cbba1f10
2020-04-02 05:03:07,616 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xfc07c18a22b28a88: from storage DS-b2b74576-90c6-41f8-afc7-9899cdd61f3b node DatanodeRegistration(127.0.0.1:39470, datanodeUuid=3beef44b-eecd-4dc3-8459-79d3cbba1f10, infoPort=42457, infoSecurePort=0, ipcPort=38813, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,616 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xfbcff6b8b5b7ae32: Processing first storage report for DS-2fad084c-0130-4112-82b3-6df89b724633 from datanode 5e08f506-e09b-4387-9057-09dd238f2db3
2020-04-02 05:03:07,616 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xfbcff6b8b5b7ae32: from storage DS-2fad084c-0130-4112-82b3-6df89b724633 node DatanodeRegistration(127.0.0.1:45716, datanodeUuid=5e08f506-e09b-4387-9057-09dd238f2db3, infoPort=34272, infoSecurePort=0, ipcPort=34411, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,615 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5b0fbe01df61bf29: from storage DS-b2b74576-90c6-41f8-afc7-9899cdd61f3b node DatanodeRegistration(127.0.0.1:39470, datanodeUuid=3beef44b-eecd-4dc3-8459-79d3cbba1f10, infoPort=42457, infoSecurePort=0, ipcPort=38813, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,616 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xfbcff6b8b5b7ae32: Processing first storage report for DS-d797cfd7-71fd-4fec-97e7-55ba58c03ae0 from datanode 5e08f506-e09b-4387-9057-09dd238f2db3
2020-04-02 05:03:07,616 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x3e4761b19a4fa862: from storage DS-d797cfd7-71fd-4fec-97e7-55ba58c03ae0 node DatanodeRegistration(127.0.0.1:45716, datanodeUuid=5e08f506-e09b-4387-9057-09dd238f2db3, infoPort=34272, infoSecurePort=0, ipcPort=34411, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,616 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb5b756e729b9e2fd: Processing first storage report for DS-8401c763-4155-4d3e-be82-e7fc93cc3150 from datanode 56a98bd3-705c-4f7e-9076-e336ffe51701
2020-04-02 05:03:07,617 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x484f7485c3072b6c: Processing first storage report for DS-bf5b0949-559d-40b7-b6dd-3d05fe8d872e from datanode 56a98bd3-705c-4f7e-9076-e336ffe51701
2020-04-02 05:03:07,616 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xfbcff6b8b5b7ae32: from storage DS-d797cfd7-71fd-4fec-97e7-55ba58c03ae0 node DatanodeRegistration(127.0.0.1:45716, datanodeUuid=5e08f506-e09b-4387-9057-09dd238f2db3, infoPort=34272, infoSecurePort=0, ipcPort=34411, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,617 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa82c19c6c9914892: Processing first storage report for DS-0c6ae5eb-828f-492f-b11b-76ebfd537f74 from datanode 58ed72fe-15e4-4236-9714-451bf909cdd5
2020-04-02 05:03:07,617 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa82c19c6c9914892: from storage DS-0c6ae5eb-828f-492f-b11b-76ebfd537f74 node DatanodeRegistration(127.0.0.1:46742, datanodeUuid=58ed72fe-15e4-4236-9714-451bf909cdd5, infoPort=33193, infoSecurePort=0, ipcPort=45097, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,616 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x6ac1da1b20450a48: Processing first storage report for DS-648aac64-888b-4fed-a7be-2bcf276a79ed from datanode 58ed72fe-15e4-4236-9714-451bf909cdd5
2020-04-02 05:03:07,617 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x6ac1da1b20450a48: from storage DS-648aac64-888b-4fed-a7be-2bcf276a79ed node DatanodeRegistration(127.0.0.1:46742, datanodeUuid=58ed72fe-15e4-4236-9714-451bf909cdd5, infoPort=33193, infoSecurePort=0, ipcPort=45097, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,617 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x40c43fa97db67f70: Processing first storage report for DS-8401c763-4155-4d3e-be82-e7fc93cc3150 from datanode 56a98bd3-705c-4f7e-9076-e336ffe51701
2020-04-02 05:03:07,617 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x40c43fa97db67f70: from storage DS-8401c763-4155-4d3e-be82-e7fc93cc3150 node DatanodeRegistration(127.0.0.1:34004, datanodeUuid=56a98bd3-705c-4f7e-9076-e336ffe51701, infoPort=41368, infoSecurePort=0, ipcPort=36104, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,618 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x44f2d290d827291b: Processing first storage report for DS-d797cfd7-71fd-4fec-97e7-55ba58c03ae0 from datanode 5e08f506-e09b-4387-9057-09dd238f2db3
2020-04-02 05:03:07,618 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x44f2d290d827291b: from storage DS-d797cfd7-71fd-4fec-97e7-55ba58c03ae0 node DatanodeRegistration(127.0.0.1:45716, datanodeUuid=5e08f506-e09b-4387-9057-09dd238f2db3, infoPort=34272, infoSecurePort=0, ipcPort=34411, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,618 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x40c43fa97db67f70: Processing first storage report for DS-bf5b0949-559d-40b7-b6dd-3d05fe8d872e from datanode 56a98bd3-705c-4f7e-9076-e336ffe51701
2020-04-02 05:03:07,618 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x40c43fa97db67f70: from storage DS-bf5b0949-559d-40b7-b6dd-3d05fe8d872e node DatanodeRegistration(127.0.0.1:34004, datanodeUuid=56a98bd3-705c-4f7e-9076-e336ffe51701, infoPort=41368, infoSecurePort=0, ipcPort=36104, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,618 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x6ac1da1b20450a48: Processing first storage report for DS-0c6ae5eb-828f-492f-b11b-76ebfd537f74 from datanode 58ed72fe-15e4-4236-9714-451bf909cdd5
2020-04-02 05:03:07,618 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x6ac1da1b20450a48: from storage DS-0c6ae5eb-828f-492f-b11b-76ebfd537f74 node DatanodeRegistration(127.0.0.1:46742, datanodeUuid=58ed72fe-15e4-4236-9714-451bf909cdd5, infoPort=33193, infoSecurePort=0, ipcPort=45097, storageInfo=lv=-57;cid=testClusterID;nsid=1861411397;c=1585803784911), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,617 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x484f7485c3072b6c: from storage DS-bf5b0949-559d-40b7-b6dd-3d05fe8d872e node DatanodeRegistration(127.0.0.1:34004, datanodeUuid=56a98bd3-705c-4f7e-9076-e336ffe51701, infoPort=41368, infoSecurePort=0, ipcPort=36104, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,619 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x4250ebfe91fe0b3c: Processing first storage report for DS-96f1659a-c211-4ad3-84e0-da83c3540e46 from datanode 3beef44b-eecd-4dc3-8459-79d3cbba1f10
2020-04-02 05:03:07,619 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x4250ebfe91fe0b3c: from storage DS-96f1659a-c211-4ad3-84e0-da83c3540e46 node DatanodeRegistration(127.0.0.1:39470, datanodeUuid=3beef44b-eecd-4dc3-8459-79d3cbba1f10, infoPort=42457, infoSecurePort=0, ipcPort=38813, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,619 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x4250ebfe91fe0b3c: Processing first storage report for DS-b2b74576-90c6-41f8-afc7-9899cdd61f3b from datanode 3beef44b-eecd-4dc3-8459-79d3cbba1f10
2020-04-02 05:03:07,619 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x4250ebfe91fe0b3c: from storage DS-b2b74576-90c6-41f8-afc7-9899cdd61f3b node DatanodeRegistration(127.0.0.1:39470, datanodeUuid=3beef44b-eecd-4dc3-8459-79d3cbba1f10, infoPort=42457, infoSecurePort=0, ipcPort=38813, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,617 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb5b756e729b9e2fd: from storage DS-8401c763-4155-4d3e-be82-e7fc93cc3150 node DatanodeRegistration(127.0.0.1:34004, datanodeUuid=56a98bd3-705c-4f7e-9076-e336ffe51701, infoPort=41368, infoSecurePort=0, ipcPort=36104, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,626 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x9086b2238458fcf3: Processing first storage report for DS-d797cfd7-71fd-4fec-97e7-55ba58c03ae0 from datanode 5e08f506-e09b-4387-9057-09dd238f2db3
2020-04-02 05:03:07,626 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x9086b2238458fcf3: from storage DS-d797cfd7-71fd-4fec-97e7-55ba58c03ae0 node DatanodeRegistration(127.0.0.1:45716, datanodeUuid=5e08f506-e09b-4387-9057-09dd238f2db3, infoPort=34272, infoSecurePort=0, ipcPort=34411, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,626 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5d137530d70cb346: Processing first storage report for DS-648aac64-888b-4fed-a7be-2bcf276a79ed from datanode 58ed72fe-15e4-4236-9714-451bf909cdd5
2020-04-02 05:03:07,626 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5d137530d70cb346: from storage DS-648aac64-888b-4fed-a7be-2bcf276a79ed node DatanodeRegistration(127.0.0.1:46742, datanodeUuid=58ed72fe-15e4-4236-9714-451bf909cdd5, infoPort=33193, infoSecurePort=0, ipcPort=45097, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,627 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb5b756e729b9e2fd: Processing first storage report for DS-bf5b0949-559d-40b7-b6dd-3d05fe8d872e from datanode 56a98bd3-705c-4f7e-9076-e336ffe51701
2020-04-02 05:03:07,627 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb5b756e729b9e2fd: from storage DS-bf5b0949-559d-40b7-b6dd-3d05fe8d872e node DatanodeRegistration(127.0.0.1:34004, datanodeUuid=56a98bd3-705c-4f7e-9076-e336ffe51701, infoPort=41368, infoSecurePort=0, ipcPort=36104, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,627 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5d137530d70cb346: Processing first storage report for DS-0c6ae5eb-828f-492f-b11b-76ebfd537f74 from datanode 58ed72fe-15e4-4236-9714-451bf909cdd5
2020-04-02 05:03:07,627 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5d137530d70cb346: from storage DS-0c6ae5eb-828f-492f-b11b-76ebfd537f74 node DatanodeRegistration(127.0.0.1:46742, datanodeUuid=58ed72fe-15e4-4236-9714-451bf909cdd5, infoPort=33193, infoSecurePort=0, ipcPort=45097, storageInfo=lv=-57;cid=testClusterID;nsid=1354143010;c=1585803782037), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,666 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xb5b756e729b9e2fd,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 66 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,666 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x5d137530d70cb346,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 11 msec to generate and 70 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,666 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x9086b2238458fcf3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 12 msec to generate and 70 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,666 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x47d7515acdd6b5a2,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 65 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,668 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x4250ebfe91fe0b3c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 11 msec to generate and 72 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,669 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xa82c19c6c9914892,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 14 msec to generate and 72 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,669 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x484f7485c3072b6c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 73 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,679 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x3e4761b19a4fa862,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 11 msec to generate and 81 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,682 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x98fb8388bc4b5cf0,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 14 msec to generate and 73 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,682 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x6ac1da1b20450a48,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 15 msec to generate and 82 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,683 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xfbcff6b8b5b7ae32,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 87 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,698 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x1a6144b6c216cc20,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 15 msec to generate and 75 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,698 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x44f2d290d827291b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 8 msec to generate and 101 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,698 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xfc07c18a22b28a88,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 88 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,707 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x5b0fbe01df61bf29,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 111 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,710 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x40c43fa97db67f70,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 12 msec to generate and 114 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,791 [IPC Server handler 7 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,813 [IPC Server handler 7 on 44155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,830 [IPC Server handler 8 on 43585] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,847 [IPC Server handler 1 on 41130] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,849 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:03:07,859 [IPC Server handler 8 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,866 [IPC Server handler 8 on 44155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,875 [IPC Server handler 7 on 43585] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,879 [IPC Server handler 4 on 41130] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,882 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:03:07,925 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(250)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-04-02 05:03:07,927 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:07,928 [Socket Reader #1 for port 38617] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38617
2020-04-02 05:03:07,936 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-04-02 05:03:07,936 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-04-02 05:03:07,937 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-04-02 05:03:07,955 [JUnit] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-04-02 05:03:07,956 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:07,957 [Socket Reader #1 for port 41365] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41365
2020-04-02 05:03:07,966 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:07,968 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:07,969 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:07,969 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:07,969 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:07,970 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-04-02 05:03:07,984 [JUnit] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore
2020-04-02 05:03:07,985 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-04-02 05:03:07,989 [JUnit] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC
2020-04-02 05:03:07,995 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:43585
2020-04-02 05:03:07,995 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:43585
2020-04-02 05:03:07,996 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:43585
2020-04-02 05:03:07,996 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:45666
2020-04-02 05:03:07,997 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:33679
2020-04-02 05:03:07,997 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:33679
2020-04-02 05:03:07,997 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:33679
2020-04-02 05:03:07,997 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:41822
2020-04-02 05:03:07,998 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:41130
2020-04-02 05:03:07,998 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:41130
2020-04-02 05:03:07,998 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:41130
2020-04-02 05:03:07,998 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:38724
2020-04-02 05:03:07,999 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:44155
2020-04-02 05:03:07,999 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:44155
2020-04-02 05:03:07,999 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:44155
2020-04-02 05:03:07,999 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:39586
2020-04-02 05:03:08,013 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(250)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-04-02 05:03:08,014 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:08,015 [Socket Reader #1 for port 44980] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44980
2020-04-02 05:03:08,018 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-04-02 05:03:08,019 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-04-02 05:03:08,019 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-04-02 05:03:08,021 [JUnit] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-04-02 05:03:08,021 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:08,022 [Socket Reader #1 for port 41006] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41006
2020-04-02 05:03:08,025 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:08,026 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:08,026 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:08,026 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:08,026 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:08,026 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-04-02 05:03:08,028 [JUnit] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-1
2020-04-02 05:03:08,028 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-04-02 05:03:08,029 [JUnit] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-1
2020-04-02 05:03:08,030 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:43585
2020-04-02 05:03:08,030 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:43585
2020-04-02 05:03:08,030 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:43585
2020-04-02 05:03:08,030 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:45666
2020-04-02 05:03:08,031 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:33679
2020-04-02 05:03:08,031 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:33679
2020-04-02 05:03:08,031 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:33679
2020-04-02 05:03:08,031 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:41822
2020-04-02 05:03:08,031 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:41130
2020-04-02 05:03:08,031 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:41130
2020-04-02 05:03:08,032 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:41130
2020-04-02 05:03:08,032 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:38724
2020-04-02 05:03:08,032 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:44155
2020-04-02 05:03:08,032 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:44155
2020-04-02 05:03:08,032 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:44155
2020-04-02 05:03:08,032 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:39586
2020-04-02 05:03:08,047 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(250)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-04-02 05:03:08,049 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:08,050 [Socket Reader #1 for port 46702] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46702
2020-04-02 05:03:08,054 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-04-02 05:03:08,054 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-04-02 05:03:08,054 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-04-02 05:03:08,056 [JUnit] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-04-02 05:03:08,056 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:08,057 [Socket Reader #1 for port 38443] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38443
2020-04-02 05:03:08,062 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:08,062 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:08,062 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:08,063 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:08,063 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:08,063 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-04-02 05:03:08,075 [JUnit] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-2
2020-04-02 05:03:08,076 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-04-02 05:03:08,078 [JUnit] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-2
2020-04-02 05:03:08,079 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:43585
2020-04-02 05:03:08,079 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:43585
2020-04-02 05:03:08,079 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:43585
2020-04-02 05:03:08,079 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:45666
2020-04-02 05:03:08,081 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:33679
2020-04-02 05:03:08,081 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:33679
2020-04-02 05:03:08,081 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:33679
2020-04-02 05:03:08,082 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:41822
2020-04-02 05:03:08,082 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:41130
2020-04-02 05:03:08,082 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:41130
2020-04-02 05:03:08,082 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:41130
2020-04-02 05:03:08,082 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:38724
2020-04-02 05:03:08,083 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:44155
2020-04-02 05:03:08,083 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:44155
2020-04-02 05:03:08,083 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:44155
2020-04-02 05:03:08,083 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:39586
2020-04-02 05:03:08,097 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(250)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-04-02 05:03:08,099 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:08,099 [Socket Reader #1 for port 39465] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39465
2020-04-02 05:03:08,103 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-04-02 05:03:08,103 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-04-02 05:03:08,103 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-04-02 05:03:08,105 [JUnit] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-04-02 05:03:08,106 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:08,107 [Socket Reader #1 for port 34736] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34736
2020-04-02 05:03:08,112 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:08,112 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:08,113 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:08,113 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:08,113 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:08,113 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-04-02 05:03:08,114 [JUnit] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-3
2020-04-02 05:03:08,115 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-04-02 05:03:08,116 [JUnit] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-3
2020-04-02 05:03:08,116 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:43585
2020-04-02 05:03:08,117 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:43585
2020-04-02 05:03:08,117 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:43585
2020-04-02 05:03:08,117 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:45666
2020-04-02 05:03:08,117 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:41130
2020-04-02 05:03:08,117 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:41130
2020-04-02 05:03:08,118 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:41130
2020-04-02 05:03:08,118 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:38724
2020-04-02 05:03:08,118 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:33679
2020-04-02 05:03:08,118 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:33679
2020-04-02 05:03:08,118 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:33679
2020-04-02 05:03:08,118 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:41822
2020-04-02 05:03:08,119 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:44155
2020-04-02 05:03:08,119 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:44155
2020-04-02 05:03:08,119 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:44155
2020-04-02 05:03:08,119 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:39586
2020-04-02 05:03:08,124 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router dfeaa374b3e2:38617: State Store unavailable
2020-04-02 05:03:08,125 [JUnit] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:08,125 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6a175569] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:08,128 [JUnit] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.RouterHDFSContract.createCluster(RouterHDFSContract.java:53)
	at org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate.createCluster(TestRouterHDFSContractCreate.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2020-04-02 05:03:08,131 [JUnit] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:08,131 [JUnit] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:08,132 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:08,132 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-04-02 05:03:08,133 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-04-02 05:03:08,134 [IPC Server listener on 38617] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38617: starting
2020-04-02 05:03:08,134 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:08,134 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:08,134 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:08,138 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(321)) - Router RPC up at: /0.0.0.0:38617
2020-04-02 05:03:08,140 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:08,140 [IPC Server listener on 41365] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41365: starting
2020-04-02 05:03:08,147 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:03:08,148 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:08,149 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:08,150 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for router at: http://0.0.0.0:0
2020-04-02 05:03:08,150 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:08,154 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:08,155 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-04-02 05:03:08,155 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:08,157 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:08,158 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-04-02 05:03:08,158 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:08,158 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:08,161 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:08,162 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:08,162 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 36995
2020-04-02 05:03:08,162 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:08,165 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2e6ee0bc{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:08,167 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@467f77a5{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:08,172 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@62577d6{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-04-02 05:03:08,174 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@49bd54f7{HTTP/1.1,[http/1.1]}{0.0.0.0:36995}
2020-04-02 05:03:08,174 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @8583ms
2020-04-02 05:03:08,174 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:08,174 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:08,176 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:08,177 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:08,177 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-04-02 05:03:08,180 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router dfeaa374b3e2:38617: State Store unavailable
2020-04-02 05:03:08,185 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-4
2020-04-02 05:03:08,185 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-4
2020-04-02 05:03:08,188 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-4
2020-04-02 05:03:08,189 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-4
2020-04-02 05:03:08,194 [JUnit] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState
2020-04-02 05:03:08,194 [JUnit] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:08,195 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@60b85ba1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:08,195 [JUnit] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.RouterHDFSContract.createCluster(RouterHDFSContract.java:53)
	at org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate.createCluster(TestRouterHDFSContractCreate.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2020-04-02 05:03:08,194 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router dfeaa374b3e2:44980: State Store unavailable
2020-04-02 05:03:08,196 [JUnit] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:08,196 [JUnit] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:08,196 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:08,197 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-04-02 05:03:08,197 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-04-02 05:03:08,199 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:08,200 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:08,199 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:08,201 [IPC Server listener on 44980] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44980: starting
2020-04-02 05:03:08,206 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:03:08,209 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:08,209 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:08,218 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(321)) - Router RPC up at: /0.0.0.0:44980
2020-04-02 05:03:08,218 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:08,218 [IPC Server listener on 41006] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41006: starting
2020-04-02 05:03:08,222 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for router at: http://0.0.0.0:0
2020-04-02 05:03:08,222 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:08,224 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:08,225 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-04-02 05:03:08,225 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:08,227 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:08,227 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-04-02 05:03:08,227 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:08,228 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:08,231 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:08,231 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:08,231 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34734
2020-04-02 05:03:08,231 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:08,233 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@24528a25{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:08,234 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@59221b97{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:08,240 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@9257031{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-04-02 05:03:08,242 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@75201592{HTTP/1.1,[http/1.1]}{0.0.0.0:34734}
2020-04-02 05:03:08,243 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @8651ms
2020-04-02 05:03:08,244 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:08,244 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:08,244 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:08,245 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:08,245 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-04-02 05:03:08,286 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-5
2020-04-02 05:03:08,286 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router dfeaa374b3e2:44980: State Store unavailable
2020-04-02 05:03:08,300 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-5
2020-04-02 05:03:08,301 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-5
2020-04-02 05:03:08,301 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-5
2020-04-02 05:03:08,301 [JUnit] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-1
2020-04-02 05:03:08,305 [JUnit] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:08,306 [JUnit] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.RouterHDFSContract.createCluster(RouterHDFSContract.java:53)
	at org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate.createCluster(TestRouterHDFSContractCreate.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2020-04-02 05:03:08,306 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router dfeaa374b3e2:46702: State Store unavailable
2020-04-02 05:03:08,307 [JUnit] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:08,308 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3d9fc57a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:08,309 [JUnit] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:08,314 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:08,314 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-04-02 05:03:08,314 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-04-02 05:03:08,315 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:08,315 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:08,315 [IPC Server listener on 46702] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46702: starting
2020-04-02 05:03:08,317 [IPC Server handler 9 on 44155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,317 [IPC Server handler 6 on 44155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,317 [IPC Server handler 6 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,318 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(321)) - Router RPC up at: /0.0.0.0:46702
2020-04-02 05:03:08,319 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:08,319 [IPC Server listener on 38443] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38443: starting
2020-04-02 05:03:08,320 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for router at: http://0.0.0.0:0
2020-04-02 05:03:08,320 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:08,327 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:08,338 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:08,339 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-04-02 05:03:08,339 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:08,340 [IPC Server handler 1 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,340 [IPC Server handler 8 on 41130] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,341 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:08,341 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-04-02 05:03:08,341 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:08,344 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:08,344 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:03:08,344 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:08,345 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:08,354 [IPC Server handler 2 on 43585] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,360 [IPC Server handler 7 on 41130] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,360 [IPC Server handler 6 on 43585] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,360 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:08,360 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:08,361 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35208
2020-04-02 05:03:08,361 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:08,379 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4a8b5227{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:08,381 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6979efad{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:08,388 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5710768a{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-04-02 05:03:08,408 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@199e4c2b{HTTP/1.1,[http/1.1]}{0.0.0.0:35208}
2020-04-02 05:03:08,408 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @8817ms
2020-04-02 05:03:08,409 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:08,409 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:08,409 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:08,412 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:08,431 [IPC Server handler 0 on 41130] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,433 [IPC Server handler 3 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,439 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-04-02 05:03:08,440 [IPC Server handler 4 on 43585] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,447 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router dfeaa374b3e2:46702: State Store unavailable
2020-04-02 05:03:08,448 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-6
2020-04-02 05:03:08,448 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-6
2020-04-02 05:03:08,448 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-6
2020-04-02 05:03:08,448 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-6
2020-04-02 05:03:08,449 [JUnit] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-2
2020-04-02 05:03:08,450 [JUnit] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:08,450 [JUnit] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.RouterHDFSContract.createCluster(RouterHDFSContract.java:53)
	at org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate.createCluster(TestRouterHDFSContractCreate.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2020-04-02 05:03:08,458 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router dfeaa374b3e2:39465: State Store unavailable
2020-04-02 05:03:08,458 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2c1dc8e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:08,458 [JUnit] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:08,462 [JUnit] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:08,462 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:08,463 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-04-02 05:03:08,463 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-04-02 05:03:08,463 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:08,463 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:08,463 [IPC Server listener on 39465] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39465: starting
2020-04-02 05:03:08,472 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:08,475 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:03:08,475 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:08,476 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:08,478 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(321)) - Router RPC up at: /0.0.0.0:39465
2020-04-02 05:03:08,479 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:08,479 [IPC Server listener on 34736] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34736: starting
2020-04-02 05:03:08,482 [IPC Server handler 2 on 44155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,491 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for router at: http://0.0.0.0:0
2020-04-02 05:03:08,495 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:08,497 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:08,498 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-04-02 05:03:08,498 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:08,500 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:08,500 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-04-02 05:03:08,500 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:08,500 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:08,501 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:08,501 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:08,502 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41787
2020-04-02 05:03:08,502 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:08,506 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62df0ff3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:08,506 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62e8f862{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:08,520 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@71ea1fda{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-04-02 05:03:08,523 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@62b3df3a{HTTP/1.1,[http/1.1]}{0.0.0.0:41787}
2020-04-02 05:03:08,524 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @8933ms
2020-04-02 05:03:08,524 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:08,524 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:08,525 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:08,526 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:08,527 [IPC Server handler 3 on 43585] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,529 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-04-02 05:03:08,542 [IPC Server handler 6 on 41130] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,544 [IPC Server handler 0 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,544 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router dfeaa374b3e2:39465: State Store unavailable
2020-04-02 05:03:08,544 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-7
2020-04-02 05:03:08,544 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-7
2020-04-02 05:03:08,545 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-7
2020-04-02 05:03:08,545 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-7
2020-04-02 05:03:08,548 [JUnit] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-3
2020-04-02 05:03:08,558 [IPC Server handler 5 on 44155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,584 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:08,586 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(471)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2020-04-02 05:03:08,589 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:03:08,590 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current
2020-04-02 05:03:08,591 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current
2020-04-02 05:03:08,591 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current
2020-04-02 05:03:08,591 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1225)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-04-02 05:03:08,592 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-04-02 05:03:08,693 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1236)) - Reprocessing replication and invalidation queues
2020-04-02 05:03:08,693 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:03:08,693 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1247)) - Will take over writing edit logs at txnid 1
2020-04-02 05:03:08,710 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:03:08,746 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:03:08,756 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 8 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:03:08,915 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:08,915 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:03:08,916 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:03:08,916 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:03:08,916 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:03:08,923 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:03:08,923 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 230 msec
2020-04-02 05:03:08,916 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(471)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2020-04-02 05:03:08,924 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:03:08,926 [CacheReplicationMonitor(1613838476)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:03:08,927 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current
2020-04-02 05:03:08,927 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current
2020-04-02 05:03:08,928 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current
2020-04-02 05:03:08,928 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1225)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-04-02 05:03:08,930 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-04-02 05:03:08,972 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1236)) - Reprocessing replication and invalidation queues
2020-04-02 05:03:08,972 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:03:08,972 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1247)) - Will take over writing edit logs at txnid 1
2020-04-02 05:03:08,972 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:03:09,013 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:03:09,019 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 3 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:03:09,027 [CacheReplicationMonitor(1341498634)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:03:09,028 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:03:09,029 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:03:09,029 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:03:09,029 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:03:09,029 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:03:09,029 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 57 msec
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testOverwriteNonEmptyDirectory
[msx] unitTestCounterInClass = 0
2020-04-02 05:03:10,052 [Thread-476] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:39465 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_1621419190_1332, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:10,102 [IPC Server handler 9 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:10,151 [Thread-476] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - verify trying to create a file over a non-empty dir fails, use builder API=false
2020-04-02 05:03:10,160 [IPC Server handler 1 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testOverwriteNonEmptyDirectory	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:10,180 [IPC Server handler 6 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteNonEmptyDirectory	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,217 [IPC Server handler 2 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testOverwriteNonEmptyDirectory/child	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:10,260 [IPC Server handler 4 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:34004, 127.0.0.1:39470, 127.0.0.1:46742 for /test/testOverwriteNonEmptyDirectory/child
2020-04-02 05:03:10,336 [DataXceiver for client DFSClient_NONMAPREDUCE_1621419190_1332 at /127.0.0.1:57696 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741825_1001 src: /127.0.0.1:57696 dest: /127.0.0.1:34004
2020-04-02 05:03:10,361 [DataXceiver for client DFSClient_NONMAPREDUCE_1621419190_1332 at /127.0.0.1:39512 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741825_1001 src: /127.0.0.1:39512 dest: /127.0.0.1:39470
2020-04-02 05:03:10,367 [DataXceiver for client DFSClient_NONMAPREDUCE_1621419190_1332 at /127.0.0.1:39194 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741825_1001 src: /127.0.0.1:39194 dest: /127.0.0.1:46742
2020-04-02 05:03:10,450 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39194, dest: /127.0.0.1:46742, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1621419190_1332, offset: 0, srvID: 58ed72fe-15e4-4236-9714-451bf909cdd5, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741825_1001, duration(ns): 51504897
2020-04-02 05:03:10,451 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:10,457 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46742]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39512, dest: /127.0.0.1:39470, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1621419190_1332, offset: 0, srvID: 3beef44b-eecd-4dc3-8459-79d3cbba1f10, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741825_1001, duration(ns): 57401804
2020-04-02 05:03:10,468 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46742]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46742] terminating
2020-04-02 05:03:10,470 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 3beef44b-eecd-4dc3-8459-79d3cbba1f10) service to localhost/127.0.0.1:43585 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:10,470 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 3beef44b-eecd-4dc3-8459-79d3cbba1f10) service to localhost/127.0.0.1:43585
2020-04-02 05:03:10,472 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39470, 127.0.0.1:46742]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57696, dest: /127.0.0.1:34004, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1621419190_1332, offset: 0, srvID: 56a98bd3-705c-4f7e-9076-e336ffe51701, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741825_1001, duration(ns): 75510663
2020-04-02 05:03:10,474 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39470, 127.0.0.1:46742]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39470, 127.0.0.1:46742] terminating
2020-04-02 05:03:10,522 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 58ed72fe-15e4-4236-9714-451bf909cdd5) service to localhost/127.0.0.1:33679 trying to claim ACTIVE state with txid=7
2020-04-02 05:03:10,523 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 56a98bd3-705c-4f7e-9076-e336ffe51701) service to localhost/127.0.0.1:33679 trying to claim ACTIVE state with txid=7
2020-04-02 05:03:10,523 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 58ed72fe-15e4-4236-9714-451bf909cdd5) service to localhost/127.0.0.1:33679
2020-04-02 05:03:10,524 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 56a98bd3-705c-4f7e-9076-e336ffe51701) service to localhost/127.0.0.1:33679
2020-04-02 05:03:10,524 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 5e08f506-e09b-4387-9057-09dd238f2db3) service to localhost/127.0.0.1:33679 trying to claim ACTIVE state with txid=7
2020-04-02 05:03:10,524 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 5e08f506-e09b-4387-9057-09dd238f2db3) service to localhost/127.0.0.1:33679
2020-04-02 05:03:10,526 [IPC Server handler 6 on 33679] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/testOverwriteNonEmptyDirectory/child is closed by DFSClient_NONMAPREDUCE_1621419190_1332
2020-04-02 05:03:10,529 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 3beef44b-eecd-4dc3-8459-79d3cbba1f10) service to localhost/127.0.0.1:33679 trying to claim ACTIVE state with txid=8
2020-04-02 05:03:10,529 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 3beef44b-eecd-4dc3-8459-79d3cbba1f10) service to localhost/127.0.0.1:33679
2020-04-02 05:03:10,536 [IPC Server handler 4 on 33679] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 4 on 33679, call Call#154 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 127.0.0.1:54074: org.apache.hadoop.fs.FileAlreadyExistsException: /test/testOverwriteNonEmptyDirectory already exists as a directory
2020-04-02 05:03:10,541 [IPC Server handler 2 on 39465] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 2 on 39465, call Call#153 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 172.17.0.16:50078: org.apache.hadoop.fs.FileAlreadyExistsException: /test/testOverwriteNonEmptyDirectory already exists as a directory
2020-04-02 05:03:10,549 [IPC Server handler 3 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteNonEmptyDirectory	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,552 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 56a98bd3-705c-4f7e-9076-e336ffe51701) service to localhost/127.0.0.1:43585 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:10,553 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 56a98bd3-705c-4f7e-9076-e336ffe51701) service to localhost/127.0.0.1:43585
2020-04-02 05:03:10,555 [IPC Server handler 5 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteNonEmptyDirectory/child	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,558 [IPC Server handler 0 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteNonEmptyDirectory/child	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,559 [Thread-476] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - verify trying to create a file over a non-empty dir fails, use builder API=true
2020-04-02 05:03:10,561 [IPC Server handler 7 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testOverwriteNonEmptyDirectory	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:10,563 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 58ed72fe-15e4-4236-9714-451bf909cdd5) service to localhost/127.0.0.1:43585 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:10,563 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 58ed72fe-15e4-4236-9714-451bf909cdd5) service to localhost/127.0.0.1:43585
2020-04-02 05:03:10,567 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 5e08f506-e09b-4387-9057-09dd238f2db3) service to localhost/127.0.0.1:43585 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:10,567 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 5e08f506-e09b-4387-9057-09dd238f2db3) service to localhost/127.0.0.1:43585
2020-04-02 05:03:10,568 [IPC Server handler 8 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteNonEmptyDirectory	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,576 [IPC Server handler 1 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testOverwriteNonEmptyDirectory/child	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:10,583 [IPC Server handler 9 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:34004, 127.0.0.1:46742, 127.0.0.1:39470 for /test/testOverwriteNonEmptyDirectory/child
2020-04-02 05:03:10,588 [DataXceiver for client DFSClient_NONMAPREDUCE_1621419190_1332 at /127.0.0.1:57750 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741826_1002 src: /127.0.0.1:57750 dest: /127.0.0.1:34004
2020-04-02 05:03:10,592 [DataXceiver for client DFSClient_NONMAPREDUCE_1621419190_1332 at /127.0.0.1:39248 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741826_1002 src: /127.0.0.1:39248 dest: /127.0.0.1:46742
2020-04-02 05:03:10,596 [DataXceiver for client DFSClient_NONMAPREDUCE_1621419190_1332 at /127.0.0.1:39572 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741826_1002 src: /127.0.0.1:39572 dest: /127.0.0.1:39470
2020-04-02 05:03:10,619 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39572, dest: /127.0.0.1:39470, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1621419190_1332, offset: 0, srvID: 3beef44b-eecd-4dc3-8459-79d3cbba1f10, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741826_1002, duration(ns): 19972807
2020-04-02 05:03:10,619 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:10,624 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39470]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39248, dest: /127.0.0.1:46742, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1621419190_1332, offset: 0, srvID: 58ed72fe-15e4-4236-9714-451bf909cdd5, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741826_1002, duration(ns): 24064009
2020-04-02 05:03:10,624 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39470]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39470] terminating
2020-04-02 05:03:10,629 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46742, 127.0.0.1:39470]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57750, dest: /127.0.0.1:34004, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1621419190_1332, offset: 0, srvID: 56a98bd3-705c-4f7e-9076-e336ffe51701, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741826_1002, duration(ns): 28359126
2020-04-02 05:03:10,629 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46742, 127.0.0.1:39470]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46742, 127.0.0.1:39470] terminating
2020-04-02 05:03:10,631 [IPC Server handler 3 on 33679] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/testOverwriteNonEmptyDirectory/child is closed by DFSClient_NONMAPREDUCE_1621419190_1332
2020-04-02 05:03:10,643 [IPC Server handler 5 on 33679] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 5 on 33679, call Call#181 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 127.0.0.1:54074: org.apache.hadoop.fs.FileAlreadyExistsException: /test/testOverwriteNonEmptyDirectory already exists as a directory
2020-04-02 05:03:10,648 [IPC Server handler 0 on 39465] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 0 on 39465, call Call#180 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 172.17.0.16:50078: org.apache.hadoop.fs.FileAlreadyExistsException: /test/testOverwriteNonEmptyDirectory already exists as a directory
2020-04-02 05:03:10,652 [IPC Server handler 0 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteNonEmptyDirectory	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,656 [IPC Server handler 7 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteNonEmptyDirectory/child	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,658 [IPC Server handler 8 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteNonEmptyDirectory/child	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,662 [IPC Server handler 1 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,666 [IPC Server handler 9 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testOverwriteNonEmptyDirectory
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testOverwriteNonEmptyDirectory
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testCreateMakesParentDirs
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:10,682 [Thread-496] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:39465 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_1621419190_1332, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:10,687 [IPC Server handler 2 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:10,688 [Thread-496] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - check that after creating a file its parent directories exist
2020-04-02 05:03:10,691 [IPC Server handler 6 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testCreateCreatesAndPopulatesParents/parent/child	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:10,697 [IPC Server handler 4 on 33679] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/testCreateCreatesAndPopulatesParents/parent/child is closed by DFSClient_NONMAPREDUCE_1621419190_1332
2020-04-02 05:03:10,706 [IPC Server handler 3 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/test/testCreateCreatesAndPopulatesParents/parent	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,714 [IPC Server handler 5 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testCreateCreatesAndPopulatesParents/parent	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,719 [IPC Server handler 0 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/test/testCreateCreatesAndPopulatesParents	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,721 [IPC Server handler 7 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testCreateCreatesAndPopulatesParents	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,724 [IPC Server handler 8 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,726 [IPC Server handler 1 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testCreateMakesParentDirs
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testCreateMakesParentDirs
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testFileStatusBlocksizeEmptyFile
[msx] perform reset as unitTestCounterInClass 2 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:10,740 [Thread-498] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:46702 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_1419743730_1354, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:10,755 [IPC Server handler 9 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:10,756 [Thread-498] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - check that an empty file may return a 0-byte blocksize
2020-04-02 05:03:10,765 [IPC Server handler 2 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testFileStatusBlocksizeEmptyFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:10,770 [IPC Server handler 6 on 33679] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/testFileStatusBlocksizeEmptyFile is closed by DFSClient_NONMAPREDUCE_1419743730_1354
2020-04-02 05:03:10,774 [IPC Server handler 4 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testFileStatusBlocksizeEmptyFile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,777 [IPC Server handler 3 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,780 [IPC Server handler 5 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testFileStatusBlocksizeEmptyFile
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testFileStatusBlocksizeEmptyFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testCreatedFileIsImmediatelyVisible
[msx] perform reset as unitTestCounterInClass 3 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:10,791 [Thread-503] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:44980 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-1542337563_1359, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:10,807 [IPC Server handler 0 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:10,808 [Thread-503] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - verify that a newly created file exists as soon as open returns
2020-04-02 05:03:10,833 [IPC Server handler 7 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testCreatedFileIsImmediatelyVisible	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:10,847 [IPC Server handler 8 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testCreatedFileIsImmediatelyVisible	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,863 [IPC Server handler 1 on 33679] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/testCreatedFileIsImmediatelyVisible is closed by DFSClient_NONMAPREDUCE_-1542337563_1359
2020-04-02 05:03:10,868 [IPC Server handler 9 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,872 [IPC Server handler 2 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testCreatedFileIsImmediatelyVisible
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testCreatedFileIsImmediatelyVisible
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testCreatedFileIsVisibleOnFlush
[msx] perform reset as unitTestCounterInClass 4 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:10,882 [Thread-508] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:44980 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-1542337563_1359, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:10,884 [IPC Server handler 6 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:10,885 [Thread-508] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - verify that a newly created file exists once a flush has taken place
2020-04-02 05:03:10,890 [IPC Server handler 4 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testCreatedFileIsVisibleOnFlush	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:10,895 [IPC Server handler 3 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testCreatedFileIsVisibleOnFlush	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,900 [IPC Server handler 5 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:34004 for /test/testCreatedFileIsVisibleOnFlush
2020-04-02 05:03:10,907 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:57788 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741827_1003 src: /127.0.0.1:57788 dest: /127.0.0.1:34004
2020-04-02 05:03:10,919 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57788, dest: /127.0.0.1:34004, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 56a98bd3-705c-4f7e-9076-e336ffe51701, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741827_1003, duration(ns): 7476937
2020-04-02 05:03:10,919 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:10,921 [IPC Server handler 8 on 33679] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/testCreatedFileIsVisibleOnFlush is closed by DFSClient_NONMAPREDUCE_-1542337563_1359
2020-04-02 05:03:10,923 [IPC Server handler 1 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,926 [IPC Server handler 9 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testCreatedFileIsVisibleOnFlush
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testCreatedFileIsVisibleOnFlush
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testOverwriteEmptyDirectory
[msx] perform reset as unitTestCounterInClass 5 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:10,935 [Thread-513] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:39465 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_1621419190_1332, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:10,937 [IPC Server handler 2 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:10,942 [Thread-513] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - verify trying to create a file over an empty dir fails, use builder API=false
2020-04-02 05:03:10,948 [IPC Server handler 6 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testOverwriteEmptyDirectory	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:10,952 [IPC Server handler 4 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteEmptyDirectory	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,954 [IPC Server handler 3 on 33679] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 3 on 33679, call Call#259 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 127.0.0.1:54074: org.apache.hadoop.fs.FileAlreadyExistsException: /test/testOverwriteEmptyDirectory already exists as a directory
2020-04-02 05:03:10,961 [IPC Server handler 8 on 39465] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 8 on 39465, call Call#258 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 172.17.0.16:50078: org.apache.hadoop.fs.FileAlreadyExistsException: /test/testOverwriteEmptyDirectory already exists as a directory
2020-04-02 05:03:10,978 [IPC Server handler 5 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteEmptyDirectory	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,982 [Thread-513] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - verify trying to create a file over an empty dir fails, use builder API=true
2020-04-02 05:03:10,990 [IPC Server handler 0 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testOverwriteEmptyDirectory	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:10,994 [IPC Server handler 7 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteEmptyDirectory	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,997 [IPC Server handler 8 on 33679] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 8 on 33679, call Call#267 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 127.0.0.1:54074: org.apache.hadoop.fs.FileAlreadyExistsException: /test/testOverwriteEmptyDirectory already exists as a directory
2020-04-02 05:03:11,001 [IPC Server handler 1 on 39465] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 1 on 39465, call Call#266 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 172.17.0.16:50078: org.apache.hadoop.fs.FileAlreadyExistsException: /test/testOverwriteEmptyDirectory already exists as a directory
2020-04-02 05:03:11,005 [IPC Server handler 1 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteEmptyDirectory	dst=null	perm=null	proto=rpc
2020-04-02 05:03:11,007 [IPC Server handler 9 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:11,009 [IPC Server handler 2 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testOverwriteEmptyDirectory
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testOverwriteEmptyDirectory
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testCreateFileOverExistingFileNoOverwrite
[msx] perform reset as unitTestCounterInClass 6 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:11,018 [Thread-514] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:46702 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_1419743730_1354, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:11,021 [IPC Server handler 6 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:11,022 [Thread-514] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Verify overwriting an existing file fails, using builder API=false
2020-04-02 05:03:11,026 [IPC Server handler 4 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testCreateFileOverExistingFileNoOverwrite-builder	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:11,033 [IPC Server handler 3 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:46742 for /test/testCreateFileOverExistingFileNoOverwrite-builder
2020-04-02 05:03:11,039 [DataXceiver for client DFSClient_NONMAPREDUCE_1419743730_1354 at /127.0.0.1:39282 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741828_1004 src: /127.0.0.1:39282 dest: /127.0.0.1:46742
2020-04-02 05:03:11,057 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39282, dest: /127.0.0.1:46742, bytes: 256, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1419743730_1354, offset: 0, srvID: 58ed72fe-15e4-4236-9714-451bf909cdd5, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741828_1004, duration(ns): 10585399
2020-04-02 05:03:11,058 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:11,060 [IPC Server handler 7 on 33679] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/testCreateFileOverExistingFileNoOverwrite-builder is closed by DFSClient_NONMAPREDUCE_1419743730_1354
2020-04-02 05:03:11,062 [IPC Server handler 8 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testCreateFileOverExistingFileNoOverwrite-builder	dst=null	perm=null	proto=rpc
2020-04-02 05:03:11,066 [IPC Server handler 1 on 33679] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 1 on 33679, call Call#289 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 127.0.0.1:54172: org.apache.hadoop.fs.FileAlreadyExistsException: /test/testCreateFileOverExistingFileNoOverwrite-builder for client 127.0.0.1 already exists
2020-04-02 05:03:11,070 [IPC Server handler 5 on 46702] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 5 on 46702, call Call#288 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 172.17.0.16:54072: org.apache.hadoop.fs.FileAlreadyExistsException: /test/testCreateFileOverExistingFileNoOverwrite-builder for client 127.0.0.1 already exists
2020-04-02 05:03:11,072 [Thread-514] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Verify overwriting an existing file fails, using builder API=true
2020-04-02 05:03:11,076 [IPC Server handler 9 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testCreateFileOverExistingFileNoOverwrite	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:11,083 [IPC Server handler 2 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:34004 for /test/testCreateFileOverExistingFileNoOverwrite
2020-04-02 05:03:11,090 [DataXceiver for client DFSClient_NONMAPREDUCE_1419743730_1354 at /127.0.0.1:57792 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741829_1005 src: /127.0.0.1:57792 dest: /127.0.0.1:34004
2020-04-02 05:03:11,112 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57792, dest: /127.0.0.1:34004, bytes: 256, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1419743730_1354, offset: 0, srvID: 56a98bd3-705c-4f7e-9076-e336ffe51701, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741829_1005, duration(ns): 12422393
2020-04-02 05:03:11,112 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:11,133 [IPC Server handler 4 on 33679] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741829_1005 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /test/testCreateFileOverExistingFileNoOverwrite
2020-04-02 05:03:11,536 [IPC Server handler 3 on 33679] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/testCreateFileOverExistingFileNoOverwrite is closed by DFSClient_NONMAPREDUCE_1419743730_1354
2020-04-02 05:03:11,539 [IPC Server handler 5 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testCreateFileOverExistingFileNoOverwrite	dst=null	perm=null	proto=rpc
2020-04-02 05:03:11,543 [IPC Server handler 0 on 33679] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 0 on 33679, call Call#303 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 127.0.0.1:54172: org.apache.hadoop.fs.FileAlreadyExistsException: /test/testCreateFileOverExistingFileNoOverwrite for client 127.0.0.1 already exists
2020-04-02 05:03:11,546 [IPC Server handler 2 on 46702] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 2 on 46702, call Call#302 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 172.17.0.16:54072: org.apache.hadoop.fs.FileAlreadyExistsException: /test/testCreateFileOverExistingFileNoOverwrite for client 127.0.0.1 already exists
2020-04-02 05:03:11,550 [IPC Server handler 7 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:11,553 [IPC Server handler 8 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testCreateFileOverExistingFileNoOverwrite
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testCreateFileOverExistingFileNoOverwrite
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testFileStatusBlocksizeNonEmptyFile
[msx] perform reset as unitTestCounterInClass 7 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:11,567 [Thread-523] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:44980 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-1542337563_1359, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:11,569 [IPC Server handler 1 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:11,570 [Thread-523] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - validate the block size of a filesystem and files within it
2020-04-02 05:03:11,573 [IPC Server handler 9 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testFileStatusBlocksizeNonEmptyFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:11,577 [IPC Server handler 2 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:39470 for /test/testFileStatusBlocksizeNonEmptyFile
2020-04-02 05:03:11,583 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:39642 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741830_1006 src: /127.0.0.1:39642 dest: /127.0.0.1:39470
2020-04-02 05:03:11,597 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39642, dest: /127.0.0.1:39470, bytes: 256, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 3beef44b-eecd-4dc3-8459-79d3cbba1f10, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741830_1006, duration(ns): 9219585
2020-04-02 05:03:11,598 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:11,604 [IPC Server handler 6 on 33679] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/testFileStatusBlocksizeNonEmptyFile is closed by DFSClient_NONMAPREDUCE_-1542337563_1359
2020-04-02 05:03:11,606 [IPC Server handler 3 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testFileStatusBlocksizeNonEmptyFile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:11,608 [IPC Server handler 5 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testFileStatusBlocksizeNonEmptyFile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:11,610 [IPC Server handler 0 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:11,612 [IPC Server handler 7 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testFileStatusBlocksizeNonEmptyFile
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testFileStatusBlocksizeNonEmptyFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testCreatedFileIsEventuallyVisible
[msx] perform reset as unitTestCounterInClass 8 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:11,620 [Thread-528] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:39465 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_1621419190_1332, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:11,623 [IPC Server handler 8 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:11,624 [Thread-528] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - verify a written to file is visible after the stream is closed
2020-04-02 05:03:11,628 [IPC Server handler 1 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testCreatedFileIsEventuallyVisible	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:11,633 [IPC Server handler 9 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:46742 for /test/testCreatedFileIsEventuallyVisible
2020-04-02 05:03:11,637 [DataXceiver for client DFSClient_NONMAPREDUCE_1621419190_1332 at /127.0.0.1:39328 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741831_1007 src: /127.0.0.1:39328 dest: /127.0.0.1:46742
2020-04-02 05:03:11,649 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39328, dest: /127.0.0.1:46742, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1621419190_1332, offset: 0, srvID: 58ed72fe-15e4-4236-9714-451bf909cdd5, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741831_1007, duration(ns): 5808096
2020-04-02 05:03:11,649 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:11,651 [IPC Server handler 4 on 33679] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/testCreatedFileIsEventuallyVisible is closed by DFSClient_NONMAPREDUCE_1621419190_1332
2020-04-02 05:03:11,653 [IPC Server handler 6 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testCreatedFileIsEventuallyVisible	dst=null	perm=null	proto=rpc
2020-04-02 05:03:11,657 [IPC Server handler 3 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:11,661 [IPC Server handler 5 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testCreatedFileIsEventuallyVisible
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testCreatedFileIsEventuallyVisible
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testOverwriteExistingFile
[msx] perform reset as unitTestCounterInClass 9 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:11,670 [Thread-533] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:44980 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-1542337563_1359, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:11,672 [IPC Server handler 0 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:11,673 [Thread-533] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Overwrite an existing file and verify the new data is there, use builder API=false
2020-04-02 05:03:11,675 [IPC Server handler 7 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testOverwriteExistingFile-builder	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:11,679 [IPC Server handler 8 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741832_1008, replicas=127.0.0.1:34004 for /test/testOverwriteExistingFile-builder
2020-04-02 05:03:11,683 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:57840 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741832_1008 src: /127.0.0.1:57840 dest: /127.0.0.1:34004
2020-04-02 05:03:11,692 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57840, dest: /127.0.0.1:34004, bytes: 256, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 56a98bd3-705c-4f7e-9076-e336ffe51701, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741832_1008, duration(ns): 3882541
2020-04-02 05:03:11,692 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:11,694 [IPC Server handler 9 on 33679] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/testOverwriteExistingFile-builder is closed by DFSClient_NONMAPREDUCE_-1542337563_1359
2020-04-02 05:03:11,697 [IPC Server handler 2 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteExistingFile-builder	dst=null	perm=null	proto=rpc
2020-04-02 05:03:11,699 [IPC Server handler 4 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteExistingFile-builder	dst=null	perm=null	proto=rpc
2020-04-02 05:03:11,701 [IPC Server handler 6 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteExistingFile-builder	dst=null	perm=null	proto=rpc
2020-04-02 05:03:11,703 [IPC Server handler 3 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteExistingFile-builder	dst=null	perm=null	proto=rpc
2020-04-02 05:03:11,716 [IPC Server handler 5 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testOverwriteExistingFile-builder	dst=null	perm=null	proto=rpc
2020-04-02 05:03:11,775 [IPC Server handler 0 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testOverwriteExistingFile-builder	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:11,780 [IPC Server handler 7 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741833_1009, replicas=127.0.0.1:46742 for /test/testOverwriteExistingFile-builder
2020-04-02 05:03:11,784 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:39340 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741833_1009 src: /127.0.0.1:39340 dest: /127.0.0.1:46742
2020-04-02 05:03:11,803 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39340, dest: /127.0.0.1:46742, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 58ed72fe-15e4-4236-9714-451bf909cdd5, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741833_1009, duration(ns): 13752744
2020-04-02 05:03:11,803 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:11,807 [IPC Server handler 1 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741834_1010, replicas=127.0.0.1:34004 for /test/testOverwriteExistingFile-builder
2020-04-02 05:03:11,812 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:57850 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741834_1010 src: /127.0.0.1:57850 dest: /127.0.0.1:34004
2020-04-02 05:03:11,834 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57850, dest: /127.0.0.1:34004, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 56a98bd3-705c-4f7e-9076-e336ffe51701, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741834_1010, duration(ns): 18625630
2020-04-02 05:03:11,834 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:11,838 [IPC Server handler 2 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741835_1011, replicas=127.0.0.1:34004 for /test/testOverwriteExistingFile-builder
2020-04-02 05:03:11,843 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:57852 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741835_1011 src: /127.0.0.1:57852 dest: /127.0.0.1:34004
2020-04-02 05:03:11,852 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57852, dest: /127.0.0.1:34004, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 56a98bd3-705c-4f7e-9076-e336ffe51701, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741835_1011, duration(ns): 7030506
2020-04-02 05:03:11,853 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:11,862 [IPC Server handler 6 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741836_1012, replicas=127.0.0.1:34004 for /test/testOverwriteExistingFile-builder
2020-04-02 05:03:11,869 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:57854 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741836_1012 src: /127.0.0.1:57854 dest: /127.0.0.1:34004
2020-04-02 05:03:11,885 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57854, dest: /127.0.0.1:34004, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 56a98bd3-705c-4f7e-9076-e336ffe51701, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741836_1012, duration(ns): 12719398
2020-04-02 05:03:11,885 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:11,891 [IPC Server handler 5 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741837_1013, replicas=127.0.0.1:34004 for /test/testOverwriteExistingFile-builder
2020-04-02 05:03:11,895 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:57856 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741837_1013 src: /127.0.0.1:57856 dest: /127.0.0.1:34004
2020-04-02 05:03:11,904 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57856, dest: /127.0.0.1:34004, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 56a98bd3-705c-4f7e-9076-e336ffe51701, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741837_1013, duration(ns): 6377633
2020-04-02 05:03:11,905 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:11,909 [IPC Server handler 7 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741838_1014, replicas=127.0.0.1:45716 for /test/testOverwriteExistingFile-builder
2020-04-02 05:03:11,916 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:35888 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741838_1014 src: /127.0.0.1:35888 dest: /127.0.0.1:45716
2020-04-02 05:03:11,927 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35888, dest: /127.0.0.1:45716, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 5e08f506-e09b-4387-9057-09dd238f2db3, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741838_1014, duration(ns): 7252687
2020-04-02 05:03:11,928 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:11,937 [IPC Server handler 1 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741839_1015, replicas=127.0.0.1:45716 for /test/testOverwriteExistingFile-builder
2020-04-02 05:03:11,942 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:35894 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741839_1015 src: /127.0.0.1:35894 dest: /127.0.0.1:45716
2020-04-02 05:03:11,963 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35894, dest: /127.0.0.1:45716, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 5e08f506-e09b-4387-9057-09dd238f2db3, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741839_1015, duration(ns): 16482170
2020-04-02 05:03:11,964 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:11,982 [IPC Server handler 2 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741840_1016, replicas=127.0.0.1:34004 for /test/testOverwriteExistingFile-builder
2020-04-02 05:03:11,985 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:57874 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741840_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741840_1016 src: /127.0.0.1:57874 dest: /127.0.0.1:34004
2020-04-02 05:03:12,025 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741840_1016, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57874, dest: /127.0.0.1:34004, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 56a98bd3-705c-4f7e-9076-e336ffe51701, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741840_1016, duration(ns): 22977646
2020-04-02 05:03:12,025 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741840_1016, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:12,034 [IPC Server handler 6 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741841_1017, replicas=127.0.0.1:39470 for /test/testOverwriteExistingFile-builder
2020-04-02 05:03:12,037 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:39688 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741841_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741841_1017 src: /127.0.0.1:39688 dest: /127.0.0.1:39470
2020-04-02 05:03:12,043 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741841_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39688, dest: /127.0.0.1:39470, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 3beef44b-eecd-4dc3-8459-79d3cbba1f10, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741841_1017, duration(ns): 2496604
2020-04-02 05:03:12,043 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741841_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:12,045 [IPC Server handler 5 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741842_1018, replicas=127.0.0.1:45716 for /test/testOverwriteExistingFile-builder
2020-04-02 05:03:12,048 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:35908 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741842_1018]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741842_1018 src: /127.0.0.1:35908 dest: /127.0.0.1:45716
2020-04-02 05:03:12,055 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741842_1018, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35908, dest: /127.0.0.1:45716, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 5e08f506-e09b-4387-9057-09dd238f2db3, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741842_1018, duration(ns): 4250332
2020-04-02 05:03:12,056 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741842_1018, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:12,058 [IPC Server handler 7 on 33679] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/testOverwriteExistingFile-builder is closed by DFSClient_NONMAPREDUCE_-1542337563_1359
2020-04-02 05:03:12,060 [IPC Server handler 8 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteExistingFile-builder	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,062 [IPC Server handler 1 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteExistingFile-builder	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,064 [IPC Server handler 9 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteExistingFile-builder	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,066 [IPC Server handler 2 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteExistingFile-builder	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,070 [IPC Server handler 4 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testOverwriteExistingFile-builder	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,092 [Thread-533] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Overwrite an existing file and verify the new data is there, use builder API=true
2020-04-02 05:03:12,095 [IPC Server handler 6 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testOverwriteExistingFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:12,104 [IPC Server handler 3 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741843_1019, replicas=127.0.0.1:46742 for /test/testOverwriteExistingFile
2020-04-02 05:03:12,111 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:39404 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741843_1019]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741843_1019 src: /127.0.0.1:39404 dest: /127.0.0.1:46742
2020-04-02 05:03:12,123 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741843_1019, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39404, dest: /127.0.0.1:46742, bytes: 256, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 58ed72fe-15e4-4236-9714-451bf909cdd5, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741843_1019, duration(ns): 6810979
2020-04-02 05:03:12,123 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741843_1019, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:12,125 [IPC Server handler 0 on 33679] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/testOverwriteExistingFile is closed by DFSClient_NONMAPREDUCE_-1542337563_1359
2020-04-02 05:03:12,127 [IPC Server handler 7 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,132 [IPC Server handler 8 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,135 [IPC Server handler 1 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,136 [IPC Server handler 9 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,139 [IPC Server handler 2 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testOverwriteExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,145 [IPC Server handler 4 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testOverwriteExistingFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:12,153 [IPC Server handler 6 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741844_1020, replicas=127.0.0.1:45716 for /test/testOverwriteExistingFile
2020-04-02 05:03:12,156 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:35962 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741844_1020]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741844_1020 src: /127.0.0.1:35962 dest: /127.0.0.1:45716
2020-04-02 05:03:12,167 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741844_1020, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35962, dest: /127.0.0.1:45716, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 5e08f506-e09b-4387-9057-09dd238f2db3, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741844_1020, duration(ns): 6677713
2020-04-02 05:03:12,167 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741844_1020, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:12,177 [IPC Server handler 5 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741845_1021, replicas=127.0.0.1:46742 for /test/testOverwriteExistingFile
2020-04-02 05:03:12,181 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:39428 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741845_1021]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741845_1021 src: /127.0.0.1:39428 dest: /127.0.0.1:46742
2020-04-02 05:03:12,186 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741845_1021, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39428, dest: /127.0.0.1:46742, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 58ed72fe-15e4-4236-9714-451bf909cdd5, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741845_1021, duration(ns): 2424905
2020-04-02 05:03:12,187 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741845_1021, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741845_1021, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:12,189 [IPC Server handler 7 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741846_1022, replicas=127.0.0.1:34004 for /test/testOverwriteExistingFile
2020-04-02 05:03:12,191 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:57938 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741846_1022]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741846_1022 src: /127.0.0.1:57938 dest: /127.0.0.1:34004
2020-04-02 05:03:12,196 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741846_1022, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57938, dest: /127.0.0.1:34004, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 56a98bd3-705c-4f7e-9076-e336ffe51701, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741846_1022, duration(ns): 2151113
2020-04-02 05:03:12,196 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741846_1022, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:12,198 [IPC Server handler 1 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741847_1023, replicas=127.0.0.1:46742 for /test/testOverwriteExistingFile
2020-04-02 05:03:12,200 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:39432 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741847_1023]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741847_1023 src: /127.0.0.1:39432 dest: /127.0.0.1:46742
2020-04-02 05:03:12,206 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741847_1023, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39432, dest: /127.0.0.1:46742, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 58ed72fe-15e4-4236-9714-451bf909cdd5, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741847_1023, duration(ns): 2928514
2020-04-02 05:03:12,206 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741847_1023, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:12,208 [IPC Server handler 2 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741848_1024, replicas=127.0.0.1:39470 for /test/testOverwriteExistingFile
2020-04-02 05:03:12,212 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:39760 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741848_1024]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741848_1024 src: /127.0.0.1:39760 dest: /127.0.0.1:39470
2020-04-02 05:03:12,217 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741848_1024, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39760, dest: /127.0.0.1:39470, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 3beef44b-eecd-4dc3-8459-79d3cbba1f10, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741848_1024, duration(ns): 2761878
2020-04-02 05:03:12,218 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741848_1024, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:12,220 [IPC Server handler 6 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741849_1025, replicas=127.0.0.1:34004 for /test/testOverwriteExistingFile
2020-04-02 05:03:12,223 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:57952 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741849_1025]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741849_1025 src: /127.0.0.1:57952 dest: /127.0.0.1:34004
2020-04-02 05:03:12,229 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741849_1025, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57952, dest: /127.0.0.1:34004, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 56a98bd3-705c-4f7e-9076-e336ffe51701, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741849_1025, duration(ns): 2644793
2020-04-02 05:03:12,229 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741849_1025, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:12,231 [IPC Server handler 5 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741850_1026, replicas=127.0.0.1:39470 for /test/testOverwriteExistingFile
2020-04-02 05:03:12,234 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:39766 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741850_1026]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741850_1026 src: /127.0.0.1:39766 dest: /127.0.0.1:39470
2020-04-02 05:03:12,240 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741850_1026, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39766, dest: /127.0.0.1:39470, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 3beef44b-eecd-4dc3-8459-79d3cbba1f10, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741850_1026, duration(ns): 2514606
2020-04-02 05:03:12,240 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741850_1026, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:12,246 [IPC Server handler 7 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741851_1027, replicas=127.0.0.1:34004 for /test/testOverwriteExistingFile
2020-04-02 05:03:12,249 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:57956 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741851_1027]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741851_1027 src: /127.0.0.1:57956 dest: /127.0.0.1:34004
2020-04-02 05:03:12,256 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741851_1027, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57956, dest: /127.0.0.1:34004, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 56a98bd3-705c-4f7e-9076-e336ffe51701, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741851_1027, duration(ns): 2886102
2020-04-02 05:03:12,256 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741851_1027, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741851_1027, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:12,258 [IPC Server handler 1 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741852_1028, replicas=127.0.0.1:39470 for /test/testOverwriteExistingFile
2020-04-02 05:03:12,262 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:39770 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741852_1028]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741852_1028 src: /127.0.0.1:39770 dest: /127.0.0.1:39470
2020-04-02 05:03:12,269 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741852_1028, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39770, dest: /127.0.0.1:39470, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 3beef44b-eecd-4dc3-8459-79d3cbba1f10, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741852_1028, duration(ns): 3250848
2020-04-02 05:03:12,269 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741852_1028, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741852_1028, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:12,272 [IPC Server handler 2 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741853_1029, replicas=127.0.0.1:39470 for /test/testOverwriteExistingFile
2020-04-02 05:03:12,276 [DataXceiver for client DFSClient_NONMAPREDUCE_-1542337563_1359 at /127.0.0.1:39778 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741853_1029]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741853_1029 src: /127.0.0.1:39778 dest: /127.0.0.1:39470
2020-04-02 05:03:12,283 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741853_1029, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39778, dest: /127.0.0.1:39470, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1542337563_1359, offset: 0, srvID: 3beef44b-eecd-4dc3-8459-79d3cbba1f10, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741853_1029, duration(ns): 3318660
2020-04-02 05:03:12,283 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741853_1029, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741853_1029, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:12,285 [IPC Server handler 6 on 33679] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/testOverwriteExistingFile is closed by DFSClient_NONMAPREDUCE_-1542337563_1359
2020-04-02 05:03:12,288 [IPC Server handler 3 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,290 [IPC Server handler 5 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,293 [IPC Server handler 0 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,296 [IPC Server handler 7 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testOverwriteExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,298 [IPC Server handler 8 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testOverwriteExistingFile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,321 [IPC Server handler 1 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,324 [IPC Server handler 9 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testOverwriteExistingFile
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testOverwriteExistingFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testCreateNewFile
[msx] perform reset as unitTestCounterInClass 10 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:12,334 [Thread-609] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:39465 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_1621419190_1332, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:12,336 [IPC Server handler 2 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:12,337 [Thread-609] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Foundational 'create a file' test, using builder API=true
2020-04-02 05:03:12,338 [IPC Server handler 4 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testCreateNewFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:12,346 [IPC Server handler 6 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741854_1030, replicas=127.0.0.1:39470 for /test/testCreateNewFile
2020-04-02 05:03:12,349 [DataXceiver for client DFSClient_NONMAPREDUCE_1621419190_1332 at /127.0.0.1:39792 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741854_1030]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741854_1030 src: /127.0.0.1:39792 dest: /127.0.0.1:39470
2020-04-02 05:03:12,356 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741854_1030, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39792, dest: /127.0.0.1:39470, bytes: 256, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1621419190_1332, offset: 0, srvID: 3beef44b-eecd-4dc3-8459-79d3cbba1f10, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741854_1030, duration(ns): 3343947
2020-04-02 05:03:12,356 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741854_1030, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741854_1030, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:12,359 [IPC Server handler 5 on 33679] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/testCreateNewFile is closed by DFSClient_NONMAPREDUCE_1621419190_1332
2020-04-02 05:03:12,360 [IPC Server handler 0 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testCreateNewFile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,362 [IPC Server handler 7 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testCreateNewFile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,363 [IPC Server handler 8 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testCreateNewFile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,365 [IPC Server handler 1 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testCreateNewFile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,366 [IPC Server handler 9 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testCreateNewFile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,370 [Thread-609] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Foundational 'create a file' test, using builder API=false
2020-04-02 05:03:12,373 [IPC Server handler 2 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testCreateNewFile-builder	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:12,378 [IPC Server handler 4 on 33679] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741855_1031, replicas=127.0.0.1:45716 for /test/testCreateNewFile-builder
2020-04-02 05:03:12,381 [DataXceiver for client DFSClient_NONMAPREDUCE_1621419190_1332 at /127.0.0.1:36012 [Receiving block BP-419159729-172.17.0.16-1585803782037:blk_1073741855_1031]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-419159729-172.17.0.16-1585803782037:blk_1073741855_1031 src: /127.0.0.1:36012 dest: /127.0.0.1:45716
2020-04-02 05:03:12,389 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741855_1031, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36012, dest: /127.0.0.1:45716, bytes: 256, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1621419190_1332, offset: 0, srvID: 5e08f506-e09b-4387-9057-09dd238f2db3, blockid: BP-419159729-172.17.0.16-1585803782037:blk_1073741855_1031, duration(ns): 3987089
2020-04-02 05:03:12,390 [PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741855_1031, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-419159729-172.17.0.16-1585803782037:blk_1073741855_1031, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:12,391 [IPC Server handler 3 on 33679] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/testCreateNewFile-builder is closed by DFSClient_NONMAPREDUCE_1621419190_1332
2020-04-02 05:03:12,393 [IPC Server handler 5 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testCreateNewFile-builder	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,395 [IPC Server handler 0 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testCreateNewFile-builder	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,396 [IPC Server handler 7 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testCreateNewFile-builder	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,398 [IPC Server handler 8 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testCreateNewFile-builder	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,400 [IPC Server handler 1 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testCreateNewFile-builder	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,404 [IPC Server handler 9 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:12,406 [IPC Server handler 2 on 33679] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testCreateNewFile
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate#testCreateNewFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:12,407 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:03:12,407 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 3
2020-04-02 05:03:12,408 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 34411 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:12,408 [JUnit] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:03:12,408 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@b93aad] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:03:12,409 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-d797cfd7-71fd-4fec-97e7-55ba58c03ae0) exiting.
2020-04-02 05:03:12,409 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-2fad084c-0130-4112-82b3-6df89b724633) exiting.
2020-04-02 05:03:12,442 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@41200e0c{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:03:12,445 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@40f33492{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:12,446 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5769e7ae{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:12,446 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3a0807b7{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:12,449 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34411
2020-04-02 05:03:12,464 [IPC Server listener on 34411] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34411
2020-04-02 05:03:12,464 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:12,464 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:12,464 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:12,467 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 5e08f506-e09b-4387-9057-09dd238f2db3) service to localhost/127.0.0.1:44155
2020-04-02 05:03:12,466 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:12,468 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 5e08f506-e09b-4387-9057-09dd238f2db3) service to localhost/127.0.0.1:41130
2020-04-02 05:03:12,464 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:12,467 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 5e08f506-e09b-4387-9057-09dd238f2db3) service to localhost/127.0.0.1:33679
2020-04-02 05:03:12,470 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 5e08f506-e09b-4387-9057-09dd238f2db3) service to localhost/127.0.0.1:43585
2020-04-02 05:03:12,478 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 5e08f506-e09b-4387-9057-09dd238f2db3)
2020-04-02 05:03:12,478 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:12,485 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 5e08f506-e09b-4387-9057-09dd238f2db3)
2020-04-02 05:03:12,526 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-648652610-172.17.0.16-1585803784911] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:12,538 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-648652610-172.17.0.16-1585803784911] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:12,541 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:12,553 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-419159729-172.17.0.16-1585803782037] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:12,557 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-419159729-172.17.0.16-1585803782037] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:12,564 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:03:12,565 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:03:12,566 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:03:12,566 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:03:12,576 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:03:12,576 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:03:12,576 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 36104 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:12,577 [JUnit] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:03:12,577 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@77cf3f8b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:03:12,578 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-8401c763-4155-4d3e-be82-e7fc93cc3150) exiting.
2020-04-02 05:03:12,578 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-bf5b0949-559d-40b7-b6dd-3d05fe8d872e) exiting.
2020-04-02 05:03:12,628 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@23c388c2{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:03:12,628 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@486be205{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:12,629 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1a6f2363{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:12,629 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@52350abb{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:12,634 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36104
2020-04-02 05:03:12,665 [IPC Server listener on 36104] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36104
2020-04-02 05:03:12,689 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:12,689 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 56a98bd3-705c-4f7e-9076-e336ffe51701) service to localhost/127.0.0.1:41130
2020-04-02 05:03:12,689 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:12,689 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 56a98bd3-705c-4f7e-9076-e336ffe51701) service to localhost/127.0.0.1:43585
2020-04-02 05:03:12,689 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:12,690 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:12,690 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 56a98bd3-705c-4f7e-9076-e336ffe51701) service to localhost/127.0.0.1:44155
2020-04-02 05:03:12,690 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:12,690 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 56a98bd3-705c-4f7e-9076-e336ffe51701) service to localhost/127.0.0.1:33679
2020-04-02 05:03:12,689 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 56a98bd3-705c-4f7e-9076-e336ffe51701)
2020-04-02 05:03:12,690 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:12,703 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 56a98bd3-705c-4f7e-9076-e336ffe51701)
2020-04-02 05:03:12,709 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-648652610-172.17.0.16-1585803784911] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:12,715 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:12,715 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-648652610-172.17.0.16-1585803784911] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:12,727 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-419159729-172.17.0.16-1585803782037] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:12,737 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-419159729-172.17.0.16-1585803782037] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:12,759 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:03:12,759 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:03:12,762 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:03:12,762 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:03:12,767 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:03:12,767 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:03:12,768 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 38813 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:12,768 [JUnit] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:03:12,768 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@51f49060] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:03:12,768 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-96f1659a-c211-4ad3-84e0-da83c3540e46) exiting.
2020-04-02 05:03:12,769 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-b2b74576-90c6-41f8-afc7-9899cdd61f3b) exiting.
2020-04-02 05:03:12,801 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@733c423e{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:03:12,802 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4b629f13{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:12,802 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5b800468{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:12,803 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4d63b624{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:12,804 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38813
2020-04-02 05:03:12,816 [IPC Server listener on 38813] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38813
2020-04-02 05:03:12,816 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:12,816 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:12,816 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:12,817 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 3beef44b-eecd-4dc3-8459-79d3cbba1f10) service to localhost/127.0.0.1:44155
2020-04-02 05:03:12,817 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 3beef44b-eecd-4dc3-8459-79d3cbba1f10) service to localhost/127.0.0.1:33679
2020-04-02 05:03:12,817 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:12,817 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 3beef44b-eecd-4dc3-8459-79d3cbba1f10)
2020-04-02 05:03:12,817 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:12,817 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:12,820 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 3beef44b-eecd-4dc3-8459-79d3cbba1f10) service to localhost/127.0.0.1:41130
2020-04-02 05:03:12,817 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 3beef44b-eecd-4dc3-8459-79d3cbba1f10) service to localhost/127.0.0.1:43585
2020-04-02 05:03:12,821 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 3beef44b-eecd-4dc3-8459-79d3cbba1f10)
2020-04-02 05:03:12,828 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-419159729-172.17.0.16-1585803782037] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:12,835 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:12,835 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-419159729-172.17.0.16-1585803782037] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:12,843 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:03:12,843 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:03:12,845 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:03:12,846 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:03:12,851 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-648652610-172.17.0.16-1585803784911] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:12,859 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-648652610-172.17.0.16-1585803784911] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:12,871 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:03:12,871 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:03:12,871 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 45097 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:12,872 [JUnit] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:03:12,872 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@74cadd41] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:03:12,872 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-648aac64-888b-4fed-a7be-2bcf276a79ed) exiting.
2020-04-02 05:03:12,872 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-0c6ae5eb-828f-492f-b11b-76ebfd537f74) exiting.
2020-04-02 05:03:12,895 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5860f3d7{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:03:12,895 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1d7f7be7{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:12,896 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@51850751{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:12,896 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5ef0d29e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:12,898 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45097
2020-04-02 05:03:12,913 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:12,913 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:12,913 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:12,913 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:41130] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 58ed72fe-15e4-4236-9714-451bf909cdd5) service to localhost/127.0.0.1:41130
2020-04-02 05:03:12,913 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:12,913 [IPC Server listener on 45097] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45097
2020-04-02 05:03:12,913 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 58ed72fe-15e4-4236-9714-451bf909cdd5) service to localhost/127.0.0.1:43585
2020-04-02 05:03:12,913 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:33679] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 58ed72fe-15e4-4236-9714-451bf909cdd5) service to localhost/127.0.0.1:33679
2020-04-02 05:03:12,917 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:12,918 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 58ed72fe-15e4-4236-9714-451bf909cdd5) service to localhost/127.0.0.1:44155
2020-04-02 05:03:12,914 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-648652610-172.17.0.16-1585803784911 (Datanode Uuid 58ed72fe-15e4-4236-9714-451bf909cdd5)
2020-04-02 05:03:12,918 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-419159729-172.17.0.16-1585803782037 (Datanode Uuid 58ed72fe-15e4-4236-9714-451bf909cdd5)
2020-04-02 05:03:12,918 [BP-648652610-172.17.0.16-1585803784911 heartbeating to localhost/127.0.0.1:43585] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-648652610-172.17.0.16-1585803784911
2020-04-02 05:03:12,931 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-648652610-172.17.0.16-1585803784911] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:12,938 [BP-419159729-172.17.0.16-1585803782037 heartbeating to localhost/127.0.0.1:44155] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-419159729-172.17.0.16-1585803782037
2020-04-02 05:03:12,938 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-648652610-172.17.0.16-1585803784911] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:12,946 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-419159729-172.17.0.16-1585803782037] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:12,967 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-419159729-172.17.0.16-1585803782037] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:12,975 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:03:12,976 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:03:12,979 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:03:12,979 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:03:12,985 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:03:12,986 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:03:12,986 [JUnit] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 33679 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:12,986 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:03:12,986 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 152
2020-04-02 05:03:12,986 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4e406694] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:03:12,987 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@4c7a078] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:03:12,987 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 153 Total time for transactions(ms): 55 Number of transactions batched in Syncs: 33 Number of syncs: 121 SyncTimes(ms): 9 4 7 
2020-04-02 05:03:12,988 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current/edits_0000000000000000001-0000000000000000153
2020-04-02 05:03:12,989 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000153
2020-04-02 05:03:12,990 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000153
2020-04-02 05:03:12,990 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:03:12,990 [CacheReplicationMonitor(1613838476)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:03:12,990 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33679
2020-04-02 05:03:12,995 [IPC Server listener on 33679] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33679
2020-04-02 05:03:13,000 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:03:13,001 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:13,001 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:03:13,036 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:03:13,036 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:13,037 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@71e9ebae{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:03:13,041 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5ef5c734{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:13,042 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@51c693d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:13,042 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@a82c5f1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:13,055 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:03:13,055 [JUnit] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 44155 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:13,056 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:13,056 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(471)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2020-04-02 05:03:13,056 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44155
2020-04-02 05:03:13,061 [IPC Server listener on 44155] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44155
2020-04-02 05:03:13,061 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:03:13,079 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:13,079 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:03:13,095 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:03:13,145 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:13,145 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:13,149 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1f2f9244{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:03:13,151 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4c4d27c8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:13,152 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2cae1042{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:13,152 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2b5825fa{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:13,156 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:03:13,156 [JUnit] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 43585 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:13,157 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:03:13,157 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 1
2020-04-02 05:03:13,157 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@4f8caaf3] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:03:13,157 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@2b50150] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:03:13,166 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 21 7 3 
2020-04-02 05:03:13,167 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current/edits_0000000000000000001-0000000000000000002
2020-04-02 05:03:13,168 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/edits_0000000000000000001-0000000000000000002
2020-04-02 05:03:13,169 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/edits_0000000000000000001-0000000000000000002
2020-04-02 05:03:13,169 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:03:13,170 [CacheReplicationMonitor(1341498634)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:03:13,170 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43585
2020-04-02 05:03:13,175 [IPC Server listener on 43585] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43585
2020-04-02 05:03:13,175 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:13,175 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:03:13,175 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:03:13,181 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router dfeaa374b3e2:38617: State Store unavailable
2020-04-02 05:03:13,189 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:03:13,190 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:13,191 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@590c73d3{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:03:13,195 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6b9ce1bf{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:13,195 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7446d8d5{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:13,196 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f8f9349{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:13,200 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:13,207 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:03:13,208 [JUnit] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 41130 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:13,208 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:13,211 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(471)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2020-04-02 05:03:13,212 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41130
2020-04-02 05:03:13,218 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:03:13,224 [IPC Server listener on 41130] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41130
2020-04-02 05:03:13,224 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:03:13,225 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:13,247 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:03:13,279 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:13,284 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@650eab8{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:03:13,286 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@30f5a68a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:13,286 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1dd0e7c4{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:13,287 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@47605f2f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:13,287 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router dfeaa374b3e2:44980: State Store unavailable
2020-04-02 05:03:13,317 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:13,317 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router dfeaa374b3e2:38617: State Store unavailable
2020-04-02 05:03:13,329 [Thread-618] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-04-02 05:03:13,333 [Thread-618] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-04-02 05:03:13,342 [Thread-618] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-04-02 05:03:13,342 [Thread-618] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:13,350 [Thread-618] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-04-02 05:03:13,351 [Thread-618] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:13,364 [Thread-618] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-04-02 05:03:13,364 [Thread-618] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:13,372 [Thread-618] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-04-02 05:03:13,372 [Thread-618] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:13,386 [Thread-618] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@62577d6{/,null,UNAVAILABLE}{/router}
2020-04-02 05:03:13,389 [Thread-618] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@49bd54f7{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-02 05:03:13,392 [Thread-618] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@467f77a5{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:13,395 [Thread-618] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2e6ee0bc{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:13,406 [Thread-618] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41365
2020-04-02 05:03:13,408 [IPC Server listener on 41365] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41365
2020-04-02 05:03:13,413 [Thread-618] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38617
2020-04-02 05:03:13,408 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:13,415 [IPC Server listener on 38617] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38617
2020-04-02 05:03:13,415 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:13,422 [Thread-618] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-04-02 05:03:13,422 [Thread-618] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-04-02 05:03:13,426 [Thread-618] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-04-02 05:03:13,427 [Thread-618] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:13,448 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router dfeaa374b3e2:46702: State Store unavailable
2020-04-02 05:03:13,463 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:13,544 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router dfeaa374b3e2:39465: State Store unavailable
2020-04-02 05:03:14,268 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn1:127.0.0.1:41130: End of File Exception between local host is: "dfeaa374b3e2/172.17.0.16"; destination host is: "localhost":41130; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-04-02 05:03:14,271 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn1:127.0.0.1:41130
2020-04-02 05:03:14,281 [NamenodeHeartbeatService ns0 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns0-nn1:127.0.0.1:44155: End of File Exception between local host is: "dfeaa374b3e2/172.17.0.16"; destination host is: "localhost":44155; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-04-02 05:03:14,281 [NamenodeHeartbeatService ns0 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns0-nn1:127.0.0.1:44155
2020-04-02 05:03:14,281 [NamenodeHeartbeatService ns0 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns0-nn1:127.0.0.1:44155: End of File Exception between local host is: "dfeaa374b3e2/172.17.0.16"; destination host is: "localhost":44155; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-04-02 05:03:14,282 [NamenodeHeartbeatService ns0 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns0-nn1:127.0.0.1:44155
2020-04-02 05:03:14,282 [NamenodeHeartbeatService ns0 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns0-nn1:127.0.0.1:44155: End of File Exception between local host is: "dfeaa374b3e2/172.17.0.16"; destination host is: "localhost":44155; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-04-02 05:03:14,282 [NamenodeHeartbeatService ns0 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns0-nn1:127.0.0.1:44155
2020-04-02 05:03:14,287 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn0:127.0.0.1:43585: End of File Exception between local host is: "dfeaa374b3e2/172.17.0.16"; destination host is: "localhost":43585; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-04-02 05:03:14,287 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn0:127.0.0.1:43585
2020-04-02 05:03:14,301 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns0-nn0:127.0.0.1:33679: End of File Exception between local host is: "dfeaa374b3e2/172.17.0.16"; destination host is: "localhost":33679; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-04-02 05:03:14,301 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns0-nn0:127.0.0.1:33679: End of File Exception between local host is: "dfeaa374b3e2/172.17.0.16"; destination host is: "localhost":33679; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-04-02 05:03:14,301 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns0-nn0:127.0.0.1:33679
2020-04-02 05:03:14,301 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns0-nn0:127.0.0.1:33679
2020-04-02 05:03:14,301 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns0-nn0:127.0.0.1:33679: End of File Exception between local host is: "dfeaa374b3e2/172.17.0.16"; destination host is: "localhost":33679; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-04-02 05:03:14,302 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns0-nn0:127.0.0.1:33679
2020-04-02 05:03:14,307 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router dfeaa374b3e2:44980: State Store unavailable
2020-04-02 05:03:14,321 [Thread-621] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-04-02 05:03:14,321 [Thread-621] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-04-02 05:03:14,326 [Thread-621] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-04-02 05:03:14,326 [Thread-621] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:14,339 [Thread-621] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-04-02 05:03:14,339 [Thread-621] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:14,344 [Thread-621] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-04-02 05:03:14,345 [Thread-621] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:14,357 [Thread-621] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-04-02 05:03:14,357 [Thread-621] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:14,364 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn0:127.0.0.1:43585: DestHost:destPort localhost:43585 , LocalHost:localPort dfeaa374b3e2/172.17.0.16:0. Failed on local exception: java.io.InterruptedIOException: Interrupted: action=RetryAction(action=RETRY, delayMillis=1000, reason=retries get failed due to exceeded maximum allowed retries number: 10), retry policy=RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-02 05:03:14,368 [Thread-621] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@9257031{/,null,UNAVAILABLE}{/router}
2020-04-02 05:03:14,368 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn0:127.0.0.1:43585
2020-04-02 05:03:14,372 [Thread-621] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@75201592{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-02 05:03:14,376 [Thread-621] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@59221b97{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:14,380 [Thread-621] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@24528a25{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:14,384 [Thread-621] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41006
2020-04-02 05:03:14,391 [Thread-621] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44980
2020-04-02 05:03:14,391 [IPC Server listener on 41006] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41006
2020-04-02 05:03:14,397 [IPC Server listener on 44980] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44980
2020-04-02 05:03:14,391 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:14,401 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:14,402 [Thread-621] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping Router metrics system...
2020-04-02 05:03:14,414 [Thread-621] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - Router metrics system stopped.
2020-04-02 05:03:14,415 [Thread-621] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - Router metrics system shutdown complete.
2020-04-02 05:03:14,419 [Thread-621] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-04-02 05:03:14,419 [Thread-621] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-04-02 05:03:14,422 [Thread-621] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-04-02 05:03:14,423 [Thread-621] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:15,268 [NamenodeHeartbeatService ns1 nn1-0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:41130. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-02 05:03:15,304 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router dfeaa374b3e2:46702: State Store unavailable
2020-04-02 05:03:15,305 [Thread-623] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-04-02 05:03:15,305 [Thread-623] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-04-02 05:03:15,306 [Thread-623] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-04-02 05:03:15,306 [Thread-623] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:15,307 [Thread-623] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-04-02 05:03:15,307 [Thread-623] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:15,309 [Thread-623] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-04-02 05:03:15,309 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn1:127.0.0.1:41130: DestHost:destPort localhost:41130 , LocalHost:localPort dfeaa374b3e2/172.17.0.16:0. Failed on local exception: java.io.InterruptedIOException: Interrupted: action=RetryAction(action=RETRY, delayMillis=1000, reason=retries get failed due to exceeded maximum allowed retries number: 10), retry policy=RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-02 05:03:15,309 [Thread-623] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:15,309 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn1:127.0.0.1:41130
2020-04-02 05:03:15,309 [Thread-623] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-04-02 05:03:15,310 [Thread-623] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:15,312 [Thread-623] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5710768a{/,null,UNAVAILABLE}{/router}
2020-04-02 05:03:15,313 [Thread-623] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@199e4c2b{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-02 05:03:15,313 [Thread-623] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6979efad{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:15,314 [Thread-623] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4a8b5227{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:15,315 [Thread-623] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38443
2020-04-02 05:03:15,316 [IPC Server listener on 38443] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38443
2020-04-02 05:03:15,316 [Thread-623] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46702
2020-04-02 05:03:15,316 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:15,317 [IPC Server listener on 46702] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46702
2020-04-02 05:03:15,318 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:15,318 [Thread-623] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-04-02 05:03:15,319 [Thread-623] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-04-02 05:03:15,320 [Thread-623] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-04-02 05:03:15,320 [Thread-623] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:15,368 [NamenodeHeartbeatService ns1 nn0-0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:43585. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-02 05:03:16,305 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router dfeaa374b3e2:39465: State Store unavailable
2020-04-02 05:03:16,305 [Thread-625] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-04-02 05:03:16,305 [Thread-625] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-04-02 05:03:16,306 [Thread-625] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-04-02 05:03:16,306 [Thread-625] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:16,306 [Thread-625] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-04-02 05:03:16,307 [Thread-625] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:16,307 [Thread-625] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-04-02 05:03:16,307 [Thread-625] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:16,308 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn1:127.0.0.1:41130: DestHost:destPort localhost:41130 , LocalHost:localPort dfeaa374b3e2/172.17.0.16:0. Failed on local exception: java.io.InterruptedIOException: Interrupted: action=RetryAction(action=RETRY, delayMillis=1000, reason=retries get failed due to exceeded maximum allowed retries number: 10), retry policy=RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-02 05:03:16,308 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn1:127.0.0.1:41130
2020-04-02 05:03:16,308 [Thread-625] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-04-02 05:03:16,308 [Thread-625] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:16,310 [Thread-625] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@71ea1fda{/,null,UNAVAILABLE}{/router}
2020-04-02 05:03:16,310 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn0:127.0.0.1:43585: DestHost:destPort localhost:43585 , LocalHost:localPort dfeaa374b3e2/172.17.0.16:0. Failed on local exception: java.io.InterruptedIOException: Interrupted: action=RetryAction(action=RETRY, delayMillis=1000, reason=retries get failed due to exceeded maximum allowed retries number: 10), retry policy=RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-02 05:03:16,310 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn0:127.0.0.1:43585
2020-04-02 05:03:16,312 [Thread-625] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@62b3df3a{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-02 05:03:16,313 [Thread-625] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62e8f862{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:16,314 [Thread-625] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62df0ff3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:16,315 [Thread-625] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34736
2020-04-02 05:03:16,315 [IPC Server listener on 34736] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34736
2020-04-02 05:03:16,316 [Thread-625] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39465
2020-04-02 05:03:16,316 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:16,317 [IPC Server listener on 39465] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39465
2020-04-02 05:03:16,317 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:16,317 [Thread-625] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-04-02 05:03:16,317 [Thread-625] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-04-02 05:03:16,318 [Thread-625] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-04-02 05:03:16,318 [Thread-625] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
[msx] all testRunFinished
